{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T11:52:39.308483Z",
     "start_time": "2018-10-16T11:52:38.314311Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "__file__=''\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../LIB/'))\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../../../../automl/automl_libs/'))\n",
    "from env import FILE\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import chi2, SelectPercentile,SelectKBest\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T11:52:39.965482Z",
     "start_time": "2018-10-16T11:52:39.953154Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "def save_csr(matrix,file_prefix='csr'):\n",
    "    data_file = file_prefix + '_data.npy'\n",
    "    indices_file = file_prefix + '_indices.npy'\n",
    "    indptr_file = file_prefix + '_indptr.npy'\n",
    "    np.save(data_file,matrix.data)\n",
    "    print('data save')\n",
    "    np.save(indices_file,matrix.indices)\n",
    "    print('indices save')\n",
    "    np.save(indptr_file,matrix.indptr)\n",
    "    print('indptr save')\n",
    "    print('save done!')\n",
    "    \n",
    "def load_csr(file_prefix='csr'):\n",
    "    data_file = file_prefix + '_data.npy'\n",
    "    indices_file = file_prefix + '_indices.npy'\n",
    "    indptr_file = file_prefix + '_indptr.npy'\n",
    "    data = np.load(data_file)\n",
    "    print('data load')\n",
    "    indices = np.load(indices_file)\n",
    "    print('indices load')\n",
    "    indptr = np.load(indptr_file)\n",
    "    print('indptr load')\n",
    "    csr = csr_matrix((data, indices, indptr))\n",
    "    return csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = 2500,2400,2300,2700,3000,3500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T05:57:29.978096Z",
     "start_time": "2018-10-16T05:57:25.986604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "(2992639, 2257)\n"
     ]
    }
   ],
   "source": [
    "first = 2400\n",
    "train_csr = load_csr('../../data/features/xgb/train_csr_{}'.format(first))\n",
    "predict_csr = load_csr('../../data/features/xgb/predict_csr_{}'.format(first))\n",
    "train_y = np.load('../../data/features/xgb/train_y_f620_b70_col17k.npy')\n",
    "predicted_file = pd.read_csv('../../data/features/xgb/predict_f620_b70_col17k.csv')\n",
    "print(train_csr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slot_mean\n",
    "# fchannel\n",
    "# appid\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T11:54:01.660496Z",
     "start_time": "2018-10-16T11:53:10.785475Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "(2992639, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:06<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2992639, 2363)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m?\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m train_csr = sparse.hstack(\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_csr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_csr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     'float32')\n\u001b[1;32m     22\u001b[0m predict_csr = sparse.hstack(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow_offsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mcol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol_offsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_csr = load_csr('../../data/features/xgb/train_csr_2500')\n",
    "predict_csr = load_csr('../../data/features/xgb/predict_csr_2500')\n",
    "train_instance = pd.read_pickle('../../data/features/xgb/train_noclean_bytime.pkl')[['instance_id']].copy()\n",
    "train_y = np.load('../../data/features/xgb/train_y_f620_b70_col17k.npy')\n",
    "predicted_file = pd.read_csv('../../data/features/xgb/predict_f620_b70_col17k.csv')\n",
    "test_instance = predicted_file[['instance_id']].copy()\n",
    "all_instance = pd.concat([train_instance,test_instance],sort=False)\n",
    "\n",
    "X_u = pd.read_pickle('../../data/features/agg/svd_utag_slotId_appearance.pkl')\n",
    "\n",
    "X_u = all_instance.merge(X_u,on='instance_id',how='inner')\n",
    "X_u.drop('instance_id',inplace=True,axis=1)\n",
    "print(X_u.shape)\n",
    "\n",
    "cut_bin = 30\n",
    "# selected_col = [col for col in X_u.columns if 'utagsIndividual_svd' not in col]\n",
    "# X_u = X_u[selected_col]\n",
    "for col in tqdm(X_u.columns):\n",
    "        X_u[col] = pd.cut(X_u[col], bins=cut_bin, labels=False, retbins=True, right=False)[0]  \n",
    "        \n",
    "print(train_csr.shape)\n",
    "train_csr = sparse.hstack(\n",
    "    (sparse.csr_matrix(X_u.iloc[:train_csr.shape[0]]), train_csr), 'csr').astype(\n",
    "    'float32')\n",
    "predict_csr = sparse.hstack(\n",
    "    (sparse.csr_matrix(X_u.iloc[train_csr.shape[0]:]), predict_csr), 'csr').astype('float32')\n",
    "print(train_csr.shape)\n",
    "print(predict_csr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T11:55:36.156371Z",
     "start_time": "2018-10-16T11:55:36.145890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse.csr_matrix(X_u.iloc[train_csr.shape[0]:]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T09:49:35.580391Z",
     "start_time": "2018-10-16T09:49:35.498805Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=32, reg_alpha=0, reg_lambda=0.1,\n",
    "    max_depth=-1, n_estimators=5000, objective='binary',\n",
    "    subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "    learning_rate=0.05, random_state=1001, n_jobs=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-16T11:24:32.599Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415636\tvalid_1's binary_logloss: 0.416723\n",
      "[400]\tvalid_0's binary_logloss: 0.413396\tvalid_1's binary_logloss: 0.415585\n",
      "[600]\tvalid_0's binary_logloss: 0.411779\tvalid_1's binary_logloss: 0.41521\n",
      "[800]\tvalid_0's binary_logloss: 0.410322\tvalid_1's binary_logloss: 0.415023\n",
      "[1000]\tvalid_0's binary_logloss: 0.408952\tvalid_1's binary_logloss: 0.414914\n",
      "[1200]\tvalid_0's binary_logloss: 0.407632\tvalid_1's binary_logloss: 0.41485\n",
      "[1400]\tvalid_0's binary_logloss: 0.406369\tvalid_1's binary_logloss: 0.414807\n",
      "[1600]\tvalid_0's binary_logloss: 0.405143\tvalid_1's binary_logloss: 0.414753\n",
      "[1800]\tvalid_0's binary_logloss: 0.403957\tvalid_1's binary_logloss: 0.414714\n",
      "[2000]\tvalid_0's binary_logloss: 0.402794\tvalid_1's binary_logloss: 0.414682\n",
      "[2200]\tvalid_0's binary_logloss: 0.401645\tvalid_1's binary_logloss: 0.414674\n",
      "Early stopping, best iteration is:\n",
      "[2054]\tvalid_0's binary_logloss: 0.402478\tvalid_1's binary_logloss: 0.414666\n",
      "[0.41466637242207294]\n",
      "cv: 0.41466637242207294\n",
      "test mean: 0.46202520242605855\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415673\tvalid_1's binary_logloss: 0.416641\n",
      "[400]\tvalid_0's binary_logloss: 0.413452\tvalid_1's binary_logloss: 0.415512\n",
      "[600]\tvalid_0's binary_logloss: 0.411852\tvalid_1's binary_logloss: 0.415159\n",
      "[800]\tvalid_0's binary_logloss: 0.410421\tvalid_1's binary_logloss: 0.414967\n",
      "[1000]\tvalid_0's binary_logloss: 0.409061\tvalid_1's binary_logloss: 0.41483\n"
     ]
    }
   ],
   "source": [
    "predict_result = predicted_file[['instance_id']].copy()\n",
    "predict_result['predicted_score'] = 0\n",
    "\n",
    "n_fold = 5\n",
    "seed=np.random.randint(1000)\n",
    "gc.collect()\n",
    "skf = StratifiedKFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "best_score = []\n",
    "oof = np.zeros(len(train_y))\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_csr, train_y)):\n",
    "    lgb_model.fit(train_csr[train_index], train_y[train_index],\n",
    "                      eval_set=[(train_csr[train_index], train_y[train_index]),\n",
    "                                (train_csr[test_index], train_y[test_index])], early_stopping_rounds=200,verbose=200)\n",
    "    best_score.append(lgb_model.best_score_['valid_1']['binary_logloss'])\n",
    "    print(best_score)\n",
    "    print('cv:',np.mean(best_score))\n",
    "    test_pred = lgb_model.predict_proba(predict_csr, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    print('test mean:', test_pred.mean())\n",
    "    predict_result['predicted_score'] = predict_result['predicted_score'] + test_pred\n",
    "    oof[test_index] = lgb_model.predict_proba(train_csr[test_index], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    gc.collect()\n",
    "\n",
    "predict_result['predicted_score'] = predict_result['predicted_score']/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-16T11:24:33.817Z"
    }
   },
   "outputs": [],
   "source": [
    "colnum = train_csr.shape[1]\n",
    "cv_loss = np.mean(best_score)\n",
    "now = str(np.random.randint(1000000))\n",
    "predict_result[['instance_id', 'predicted_score']].to_csv( \"submission/%s_lgbUtagSlotApran_n%d_b%d_1h_col%d.csv\" % (now, n_fold, 70, colnum), index=False)\n",
    "np.save('submission/oof_%s_%.5f'%(now, cv_loss), oof) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
