{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T02:26:56.295794Z",
     "start_time": "2018-10-17T02:26:55.942112Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "__file__=''\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../LIB/'))\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../../../../automl/automl_libs/'))\n",
    "from env import FILE\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import chi2, SelectPercentile,SelectKBest\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T02:27:02.132335Z",
     "start_time": "2018-10-17T02:27:02.123570Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "def save_csr(matrix,file_prefix='csr'):\n",
    "    data_file = file_prefix + '_data.npy'\n",
    "    indices_file = file_prefix + '_indices.npy'\n",
    "    indptr_file = file_prefix + '_indptr.npy'\n",
    "    np.save(data_file,matrix.data)\n",
    "    print('data save')\n",
    "    np.save(indices_file,matrix.indices)\n",
    "    print('indices save')\n",
    "    np.save(indptr_file,matrix.indptr)\n",
    "    print('indptr save')\n",
    "    print('save done!')\n",
    "    \n",
    "def load_csr(file_prefix='csr'):\n",
    "    data_file = file_prefix + '_data.npy'\n",
    "    indices_file = file_prefix + '_indices.npy'\n",
    "    indptr_file = file_prefix + '_indptr.npy'\n",
    "    data = np.load(data_file)\n",
    "    print('data load')\n",
    "    indices = np.load(indices_file)\n",
    "    print('indices load')\n",
    "    indptr = np.load(indptr_file)\n",
    "    print('indptr load')\n",
    "    csr = csr_matrix((data, indices, indptr))\n",
    "    return csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = 2500,2400,2300,2700,3000,3500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T00:20:41.093004Z",
     "start_time": "2018-10-17T00:20:37.958311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "(2992639, 2363)\n"
     ]
    }
   ],
   "source": [
    "first = 2500\n",
    "train_csr = load_csr('../../data/features/xgb/train_csr_{}'.format(first))\n",
    "predict_csr = load_csr('../../data/features/xgb/predict_csr_{}'.format(first))\n",
    "train_y = np.load('../../data/features/xgb/train_y.npy')\n",
    "predicted_file = pd.read_pickle('../../data/features/xgb/predict_id.pkl')\n",
    "print(train_csr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slot_mean\n",
    "# fchannel\n",
    "# appid\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T01:55:51.236321Z",
     "start_time": "2018-10-17T01:53:48.409368Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "data load\n",
      "indices load\n",
      "indptr load\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072915, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:14<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2992639, 2363)\n",
      "(2992639, 2459)\n",
      "(80276, 2459)\n"
     ]
    }
   ],
   "source": [
    "train_csr = load_csr('../../data/features/xgb/train_csr_2500')\n",
    "predict_csr = load_csr('../../data/features/xgb/predict_csr_2500')\n",
    "train_instance = pd.read_pickle('../../data/features/xgb/train_id.pkl')[['instance_id']].copy()\n",
    "train_y = np.load('../../data/features/xgb/train_y.npy')\n",
    "predicted_file = pd.read_pickle('../../data/features/xgb/predict_id.pkl')\n",
    "test_instance = predicted_file[['instance_id']].copy()\n",
    "all_instance = pd.concat([train_instance,test_instance],sort=False)\n",
    "\n",
    "X_u = pd.read_pickle('../../data/features/agg/svd_utag_slot_mean.pkl')\n",
    "\n",
    "X_u = all_instance.merge(X_u,on='instance_id',how='inner')\n",
    "X_u.drop('instance_id',inplace=True,axis=1)\n",
    "print(X_u.shape)\n",
    "\n",
    "cut_bin = 30\n",
    "# selected_col = [col for col in X_u.columns if 'utagsIndividual_svd' not in col]\n",
    "# X_u = X_u[selected_col]\n",
    "for col in tqdm(X_u.columns):\n",
    "        X_u[col] = pd.cut(X_u[col], bins=cut_bin, labels=False, retbins=True, right=False)[0]  \n",
    "        \n",
    "print(train_csr.shape)\n",
    "train_csr = sparse.hstack(\n",
    "    (sparse.csr_matrix(X_u.iloc[:train_csr.shape[0]]), train_csr), 'csr').astype(\n",
    "    'float32')\n",
    "predict_csr = sparse.hstack(\n",
    "    (sparse.csr_matrix(X_u.iloc[train_csr.shape[0]:]), predict_csr), 'csr').astype('float32')\n",
    "print(train_csr.shape)\n",
    "print(predict_csr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T01:56:36.110914Z",
     "start_time": "2018-10-17T01:56:36.015021Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=32, reg_alpha=0, reg_lambda=0.1,\n",
    "    max_depth=-1, n_estimators=5000, objective='binary',\n",
    "    subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "    learning_rate=0.05, random_state=1001, n_jobs=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T02:14:16.897425Z",
     "start_time": "2018-10-17T01:56:40.750972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415432\tvalid_1's binary_logloss: 0.416117\n",
      "[400]\tvalid_0's binary_logloss: 0.413298\tvalid_1's binary_logloss: 0.415154\n",
      "[600]\tvalid_0's binary_logloss: 0.411676\tvalid_1's binary_logloss: 0.414842\n",
      "[800]\tvalid_0's binary_logloss: 0.410234\tvalid_1's binary_logloss: 0.414645\n",
      "[1000]\tvalid_0's binary_logloss: 0.408883\tvalid_1's binary_logloss: 0.414524\n",
      "[1200]\tvalid_0's binary_logloss: 0.40759\tvalid_1's binary_logloss: 0.414425\n",
      "[1400]\tvalid_0's binary_logloss: 0.406336\tvalid_1's binary_logloss: 0.414372\n",
      "[1600]\tvalid_0's binary_logloss: 0.405128\tvalid_1's binary_logloss: 0.414345\n",
      "[1800]\tvalid_0's binary_logloss: 0.40391\tvalid_1's binary_logloss: 0.414337\n",
      "[2000]\tvalid_0's binary_logloss: 0.402752\tvalid_1's binary_logloss: 0.414329\n",
      "Early stopping, best iteration is:\n",
      "[1833]\tvalid_0's binary_logloss: 0.403715\tvalid_1's binary_logloss: 0.414316\n",
      "[0.4143164791834925]\n",
      "cv: 0.4143164791834925\n",
      "test mean: 0.2153048236758741\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m?\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     lgb_model.fit(train_csr[train_index], train_y[train_index],\n\u001b[1;32m     13\u001b[0m                       eval_set=[(train_csr[train_index], train_y[train_index]),\n\u001b[0;32m---> 14\u001b[0;31m                                 (train_csr[test_index], train_y[test_index])], early_stopping_rounds=200,verbose=200)\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mbest_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'binary_logloss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    693\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m                                         callbacks=callbacks)\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    472\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predict_result = predicted_file[['instance_id']].copy()\n",
    "predict_result['predicted_score'] = 0\n",
    "\n",
    "n_fold = 5\n",
    "seed=np.random.randint(1000)\n",
    "seed=41\n",
    "gc.collect()\n",
    "skf = StratifiedKFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "best_score = []\n",
    "oof = np.zeros(len(train_y))\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_csr, train_y)):\n",
    "    lgb_model.fit(train_csr[train_index], train_y[train_index],\n",
    "                      eval_set=[(train_csr[train_index], train_y[train_index]),\n",
    "                                (train_csr[test_index], train_y[test_index])], early_stopping_rounds=200,verbose=200)\n",
    "    best_score.append(lgb_model.best_score_['valid_1']['binary_logloss'])\n",
    "    print(best_score)\n",
    "    print('cv:',np.mean(best_score))\n",
    "    test_pred = lgb_model.predict_proba(predict_csr, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    print('test mean:', test_pred.mean())\n",
    "    predict_result['predicted_score'] = predict_result['predicted_score'] + test_pred\n",
    "    oof[test_index] = lgb_model.predict_proba(train_csr[test_index], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    gc.collect()\n",
    "\n",
    "predict_result['predicted_score'] = predict_result['predicted_score']/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T01:50:39.352546Z",
     "start_time": "2018-10-17T00:26:03.770057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415537\tvalid_1's binary_logloss: 0.416211\n",
      "[400]\tvalid_0's binary_logloss: 0.413405\tvalid_1's binary_logloss: 0.41523\n",
      "[600]\tvalid_0's binary_logloss: 0.411809\tvalid_1's binary_logloss: 0.414866\n",
      "[800]\tvalid_0's binary_logloss: 0.410391\tvalid_1's binary_logloss: 0.414669\n",
      "[1000]\tvalid_0's binary_logloss: 0.409061\tvalid_1's binary_logloss: 0.414559\n",
      "[1200]\tvalid_0's binary_logloss: 0.407779\tvalid_1's binary_logloss: 0.414456\n",
      "[1400]\tvalid_0's binary_logloss: 0.406516\tvalid_1's binary_logloss: 0.414384\n",
      "[1600]\tvalid_0's binary_logloss: 0.405297\tvalid_1's binary_logloss: 0.414341\n",
      "[1800]\tvalid_0's binary_logloss: 0.404105\tvalid_1's binary_logloss: 0.414324\n",
      "[2000]\tvalid_0's binary_logloss: 0.402978\tvalid_1's binary_logloss: 0.414303\n",
      "[2200]\tvalid_0's binary_logloss: 0.401857\tvalid_1's binary_logloss: 0.414274\n",
      "Early stopping, best iteration is:\n",
      "[2196]\tvalid_0's binary_logloss: 0.401878\tvalid_1's binary_logloss: 0.41427\n",
      "[0.4142704934877704]\n",
      "cv: 0.4142704934877704\n",
      "test mean: 0.20635772994269608\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415531\tvalid_1's binary_logloss: 0.416164\n",
      "[400]\tvalid_0's binary_logloss: 0.41341\tvalid_1's binary_logloss: 0.415177\n",
      "[600]\tvalid_0's binary_logloss: 0.411833\tvalid_1's binary_logloss: 0.414828\n",
      "[800]\tvalid_0's binary_logloss: 0.410409\tvalid_1's binary_logloss: 0.414639\n",
      "[1000]\tvalid_0's binary_logloss: 0.40908\tvalid_1's binary_logloss: 0.414514\n",
      "[1200]\tvalid_0's binary_logloss: 0.407781\tvalid_1's binary_logloss: 0.414405\n",
      "[1400]\tvalid_0's binary_logloss: 0.406542\tvalid_1's binary_logloss: 0.414324\n",
      "[1600]\tvalid_0's binary_logloss: 0.405334\tvalid_1's binary_logloss: 0.414272\n",
      "[1800]\tvalid_0's binary_logloss: 0.404164\tvalid_1's binary_logloss: 0.414242\n",
      "[2000]\tvalid_0's binary_logloss: 0.403034\tvalid_1's binary_logloss: 0.414237\n",
      "Early stopping, best iteration is:\n",
      "[1864]\tvalid_0's binary_logloss: 0.4038\tvalid_1's binary_logloss: 0.414222\n",
      "[0.4142704934877704, 0.4142221459780299]\n",
      "cv: 0.41424631973290016\n",
      "test mean: 0.21200010081836998\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415625\tvalid_1's binary_logloss: 0.415828\n",
      "[400]\tvalid_0's binary_logloss: 0.413504\tvalid_1's binary_logloss: 0.414823\n",
      "[600]\tvalid_0's binary_logloss: 0.411908\tvalid_1's binary_logloss: 0.414441\n",
      "[800]\tvalid_0's binary_logloss: 0.41048\tvalid_1's binary_logloss: 0.414236\n",
      "[1000]\tvalid_0's binary_logloss: 0.40914\tvalid_1's binary_logloss: 0.414116\n",
      "[1200]\tvalid_0's binary_logloss: 0.407846\tvalid_1's binary_logloss: 0.414011\n",
      "[1400]\tvalid_0's binary_logloss: 0.406614\tvalid_1's binary_logloss: 0.413947\n",
      "[1600]\tvalid_0's binary_logloss: 0.405425\tvalid_1's binary_logloss: 0.413934\n",
      "[1800]\tvalid_0's binary_logloss: 0.404248\tvalid_1's binary_logloss: 0.4139\n",
      "[2000]\tvalid_0's binary_logloss: 0.403119\tvalid_1's binary_logloss: 0.413883\n",
      "[2200]\tvalid_0's binary_logloss: 0.402003\tvalid_1's binary_logloss: 0.41387\n",
      "[2400]\tvalid_0's binary_logloss: 0.400872\tvalid_1's binary_logloss: 0.413871\n",
      "Early stopping, best iteration is:\n",
      "[2344]\tvalid_0's binary_logloss: 0.401181\tvalid_1's binary_logloss: 0.413866\n",
      "[0.4142704934877704, 0.4142221459780299, 0.41386587887742793]\n",
      "cv: 0.4141195061144094\n",
      "test mean: 0.20735047249050295\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415441\tvalid_1's binary_logloss: 0.416651\n",
      "[400]\tvalid_0's binary_logloss: 0.413291\tvalid_1's binary_logloss: 0.415704\n",
      "[600]\tvalid_0's binary_logloss: 0.411685\tvalid_1's binary_logloss: 0.415328\n",
      "[800]\tvalid_0's binary_logloss: 0.410231\tvalid_1's binary_logloss: 0.415138\n",
      "[1000]\tvalid_0's binary_logloss: 0.408896\tvalid_1's binary_logloss: 0.415011\n",
      "[1200]\tvalid_0's binary_logloss: 0.407611\tvalid_1's binary_logloss: 0.414884\n",
      "[1400]\tvalid_0's binary_logloss: 0.406355\tvalid_1's binary_logloss: 0.414841\n",
      "[1600]\tvalid_0's binary_logloss: 0.405141\tvalid_1's binary_logloss: 0.414804\n",
      "[1800]\tvalid_0's binary_logloss: 0.403965\tvalid_1's binary_logloss: 0.414784\n",
      "[2000]\tvalid_0's binary_logloss: 0.40282\tvalid_1's binary_logloss: 0.41476\n",
      "[2200]\tvalid_0's binary_logloss: 0.401726\tvalid_1's binary_logloss: 0.414759\n",
      "[2400]\tvalid_0's binary_logloss: 0.400617\tvalid_1's binary_logloss: 0.414743\n",
      "[2600]\tvalid_0's binary_logloss: 0.399522\tvalid_1's binary_logloss: 0.41473\n",
      "[2800]\tvalid_0's binary_logloss: 0.398425\tvalid_1's binary_logloss: 0.414738\n",
      "Early stopping, best iteration is:\n",
      "[2617]\tvalid_0's binary_logloss: 0.399426\tvalid_1's binary_logloss: 0.414723\n",
      "[0.4142704934877704, 0.4142221459780299, 0.41386587887742793, 0.41472296743522935]\n",
      "cv: 0.41427037144461437\n",
      "test mean: 0.20674727185830294\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415476\tvalid_1's binary_logloss: 0.416559\n",
      "[400]\tvalid_0's binary_logloss: 0.413337\tvalid_1's binary_logloss: 0.415532\n",
      "[600]\tvalid_0's binary_logloss: 0.411739\tvalid_1's binary_logloss: 0.41515\n",
      "[800]\tvalid_0's binary_logloss: 0.410323\tvalid_1's binary_logloss: 0.414951\n",
      "[1000]\tvalid_0's binary_logloss: 0.409002\tvalid_1's binary_logloss: 0.414817\n",
      "[1200]\tvalid_0's binary_logloss: 0.407726\tvalid_1's binary_logloss: 0.414712\n",
      "[1400]\tvalid_0's binary_logloss: 0.406491\tvalid_1's binary_logloss: 0.414626\n",
      "[1600]\tvalid_0's binary_logloss: 0.405283\tvalid_1's binary_logloss: 0.414562\n",
      "[1800]\tvalid_0's binary_logloss: 0.404104\tvalid_1's binary_logloss: 0.414541\n",
      "Early stopping, best iteration is:\n",
      "[1665]\tvalid_0's binary_logloss: 0.404884\tvalid_1's binary_logloss: 0.41453\n",
      "[0.4142704934877704, 0.4142221459780299, 0.41386587887742793, 0.41472296743522935, 0.41452996682730264]\n",
      "cv: 0.41432229052115205\n",
      "test mean: 0.20553533754063716\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_result = predicted_file[['instance_id']].copy()\n",
    "predict_result['predicted_score'] = 0\n",
    "\n",
    "n_fold = 5\n",
    "seed=np.random.randint(1000)\n",
    "seed=41\n",
    "gc.collect()\n",
    "skf = StratifiedKFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "best_score = []\n",
    "oof = np.zeros(len(train_y))\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_csr, train_y)):\n",
    "    lgb_model.fit(train_csr[train_index], train_y[train_index],\n",
    "                      eval_set=[(train_csr[train_index], train_y[train_index]),\n",
    "                                (train_csr[test_index], train_y[test_index])], early_stopping_rounds=200,verbose=200)\n",
    "    best_score.append(lgb_model.best_score_['valid_1']['binary_logloss'])\n",
    "    print(best_score)\n",
    "    print('cv:',np.mean(best_score))\n",
    "    test_pred = lgb_model.predict_proba(predict_csr, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    print('test mean:', test_pred.mean())\n",
    "    predict_result['predicted_score'] = predict_result['predicted_score'] + test_pred\n",
    "    oof[test_index] = lgb_model.predict_proba(train_csr[test_index], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    gc.collect()\n",
    "\n",
    "predict_result['predicted_score'] = predict_result['predicted_score']/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T01:52:13.154139Z",
     "start_time": "2018-10-17T01:52:12.920706Z"
    }
   },
   "outputs": [],
   "source": [
    "colnum = train_csr.shape[1]\n",
    "cv_loss = np.mean(best_score)\n",
    "now = str(np.random.randint(1000000))\n",
    "predict_result[['instance_id', 'predicted_score']].to_csv( \"submission/%s_lgbUtagAdidTargetMean_n%d_b%d_1h_col%d.csv\" % (now, n_fold, 70, colnum), index=False)\n",
    "np.save('submission/oof_%s_%.5f'%(now, cv_loss), oof) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T12:50:26.306050Z",
     "start_time": "2018-10-17T11:22:06.781090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "data load\n",
      "indices load\n",
      "indptr load\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:00<00:04,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072915, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:03<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2992639, 2363)\n",
      "(2992639, 2395)\n",
      "(80276, 2395)\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415923\tvalid_1's binary_logloss: 0.415641\n",
      "[400]\tvalid_0's binary_logloss: 0.41376\tvalid_1's binary_logloss: 0.414534\n",
      "[600]\tvalid_0's binary_logloss: 0.412128\tvalid_1's binary_logloss: 0.414094\n",
      "[800]\tvalid_0's binary_logloss: 0.410709\tvalid_1's binary_logloss: 0.413912\n",
      "[1000]\tvalid_0's binary_logloss: 0.409347\tvalid_1's binary_logloss: 0.413752\n",
      "[1200]\tvalid_0's binary_logloss: 0.408032\tvalid_1's binary_logloss: 0.413634\n",
      "[1400]\tvalid_0's binary_logloss: 0.406814\tvalid_1's binary_logloss: 0.413577\n",
      "[1600]\tvalid_0's binary_logloss: 0.405605\tvalid_1's binary_logloss: 0.413533\n",
      "[1800]\tvalid_0's binary_logloss: 0.404428\tvalid_1's binary_logloss: 0.413511\n",
      "[2000]\tvalid_0's binary_logloss: 0.403259\tvalid_1's binary_logloss: 0.413505\n",
      "[2200]\tvalid_0's binary_logloss: 0.402121\tvalid_1's binary_logloss: 0.413509\n",
      "Early stopping, best iteration is:\n",
      "[2068]\tvalid_0's binary_logloss: 0.402864\tvalid_1's binary_logloss: 0.413499\n",
      "[0.41349897647104755]\n",
      "cv: 0.41349897647104755\n",
      "test mean: 0.21385090417289063\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415598\tvalid_1's binary_logloss: 0.416712\n",
      "[400]\tvalid_0's binary_logloss: 0.413444\tvalid_1's binary_logloss: 0.41563\n",
      "[600]\tvalid_0's binary_logloss: 0.411842\tvalid_1's binary_logloss: 0.415242\n",
      "[800]\tvalid_0's binary_logloss: 0.410389\tvalid_1's binary_logloss: 0.415036\n",
      "[1000]\tvalid_0's binary_logloss: 0.40904\tvalid_1's binary_logloss: 0.414893\n",
      "[1200]\tvalid_0's binary_logloss: 0.407765\tvalid_1's binary_logloss: 0.414811\n",
      "[1400]\tvalid_0's binary_logloss: 0.406515\tvalid_1's binary_logloss: 0.414732\n",
      "[1600]\tvalid_0's binary_logloss: 0.405301\tvalid_1's binary_logloss: 0.414687\n",
      "[1800]\tvalid_0's binary_logloss: 0.404122\tvalid_1's binary_logloss: 0.414641\n",
      "[2000]\tvalid_0's binary_logloss: 0.402955\tvalid_1's binary_logloss: 0.414607\n",
      "[2200]\tvalid_0's binary_logloss: 0.401827\tvalid_1's binary_logloss: 0.414604\n",
      "Early stopping, best iteration is:\n",
      "[2072]\tvalid_0's binary_logloss: 0.402546\tvalid_1's binary_logloss: 0.414598\n",
      "[0.41349897647104755, 0.4145976603523571]\n",
      "cv: 0.4140483184117023\n",
      "test mean: 0.21558144511057442\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415677\tvalid_1's binary_logloss: 0.41664\n",
      "[400]\tvalid_0's binary_logloss: 0.413497\tvalid_1's binary_logloss: 0.415579\n",
      "[600]\tvalid_0's binary_logloss: 0.411873\tvalid_1's binary_logloss: 0.415179\n",
      "[800]\tvalid_0's binary_logloss: 0.410452\tvalid_1's binary_logloss: 0.414922\n",
      "[1000]\tvalid_0's binary_logloss: 0.409114\tvalid_1's binary_logloss: 0.414819\n",
      "[1200]\tvalid_0's binary_logloss: 0.407847\tvalid_1's binary_logloss: 0.414751\n",
      "[1400]\tvalid_0's binary_logloss: 0.4066\tvalid_1's binary_logloss: 0.414697\n",
      "[1600]\tvalid_0's binary_logloss: 0.405387\tvalid_1's binary_logloss: 0.414641\n",
      "[1800]\tvalid_0's binary_logloss: 0.404212\tvalid_1's binary_logloss: 0.414603\n",
      "[2000]\tvalid_0's binary_logloss: 0.403061\tvalid_1's binary_logloss: 0.414564\n",
      "[2200]\tvalid_0's binary_logloss: 0.401919\tvalid_1's binary_logloss: 0.414547\n",
      "Early stopping, best iteration is:\n",
      "[2177]\tvalid_0's binary_logloss: 0.402044\tvalid_1's binary_logloss: 0.41454\n",
      "[0.41349897647104755, 0.4145976603523571, 0.41453999265413055]\n",
      "cv: 0.414212209825845\n",
      "test mean: 0.21359966263417568\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415642\tvalid_1's binary_logloss: 0.416688\n",
      "[400]\tvalid_0's binary_logloss: 0.413469\tvalid_1's binary_logloss: 0.415599\n",
      "[600]\tvalid_0's binary_logloss: 0.411871\tvalid_1's binary_logloss: 0.415209\n",
      "[800]\tvalid_0's binary_logloss: 0.410433\tvalid_1's binary_logloss: 0.414975\n",
      "[1000]\tvalid_0's binary_logloss: 0.40911\tvalid_1's binary_logloss: 0.414832\n",
      "[1200]\tvalid_0's binary_logloss: 0.407816\tvalid_1's binary_logloss: 0.414765\n",
      "[1400]\tvalid_0's binary_logloss: 0.406563\tvalid_1's binary_logloss: 0.414709\n",
      "[1600]\tvalid_0's binary_logloss: 0.405345\tvalid_1's binary_logloss: 0.414671\n",
      "[1800]\tvalid_0's binary_logloss: 0.404146\tvalid_1's binary_logloss: 0.41465\n",
      "[2000]\tvalid_0's binary_logloss: 0.402993\tvalid_1's binary_logloss: 0.414616\n",
      "[2200]\tvalid_0's binary_logloss: 0.401852\tvalid_1's binary_logloss: 0.414607\n",
      "Early stopping, best iteration is:\n",
      "[2120]\tvalid_0's binary_logloss: 0.402301\tvalid_1's binary_logloss: 0.414598\n",
      "[0.41349897647104755, 0.4145976603523571, 0.41453999265413055, 0.41459764310576364]\n",
      "cv: 0.4143085681458247\n",
      "test mean: 0.21617751917065473\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415739\tvalid_1's binary_logloss: 0.416208\n",
      "[400]\tvalid_0's binary_logloss: 0.413562\tvalid_1's binary_logloss: 0.415162\n",
      "[600]\tvalid_0's binary_logloss: 0.411949\tvalid_1's binary_logloss: 0.4148\n",
      "[800]\tvalid_0's binary_logloss: 0.410491\tvalid_1's binary_logloss: 0.414642\n",
      "[1000]\tvalid_0's binary_logloss: 0.409152\tvalid_1's binary_logloss: 0.414539\n",
      "[1200]\tvalid_0's binary_logloss: 0.40785\tvalid_1's binary_logloss: 0.414467\n",
      "[1400]\tvalid_0's binary_logloss: 0.406625\tvalid_1's binary_logloss: 0.414412\n",
      "[1600]\tvalid_0's binary_logloss: 0.405413\tvalid_1's binary_logloss: 0.414367\n",
      "[1800]\tvalid_0's binary_logloss: 0.404226\tvalid_1's binary_logloss: 0.414356\n",
      "[2000]\tvalid_0's binary_logloss: 0.403075\tvalid_1's binary_logloss: 0.414359\n",
      "Early stopping, best iteration is:\n",
      "[1897]\tvalid_0's binary_logloss: 0.403668\tvalid_1's binary_logloss: 0.414346\n",
      "[0.41349897647104755, 0.4145976603523571, 0.41453999265413055, 0.41459764310576364, 0.4143462905853219]\n",
      "cv: 0.41431611263372414\n",
      "test mean: 0.2149172140197307\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for add_fe in ['slotId_cnt']:\n",
    "    train_csr = load_csr('../../data/features/xgb/train_csr_2500')\n",
    "    predict_csr = load_csr('../../data/features/xgb/predict_csr_2500')\n",
    "    train_instance = pd.read_pickle('../../data/features/xgb/train_id.pkl')[['instance_id']].copy()\n",
    "    train_y = np.load('../../data/features/xgb/train_y.npy')\n",
    "    predicted_file = pd.read_pickle('../../data/features/xgb/predict_id.pkl')\n",
    "    test_instance = predicted_file[['instance_id']].copy()\n",
    "    all_instance = pd.concat([train_instance,test_instance],sort=False)\n",
    "\n",
    "    X_u = pd.read_pickle('../../data/features/agg/svd_utag_{}.pkl'.format(add_fe))\n",
    "\n",
    "    X_u = all_instance.merge(X_u,on='instance_id',how='inner')\n",
    "    X_u.drop('instance_id',inplace=True,axis=1)\n",
    "    print(X_u.shape)\n",
    "\n",
    "    cut_bin = 30\n",
    "    # selected_col = [col for col in X_u.columns if 'utagsIndividual_svd' not in col]\n",
    "    # X_u = X_u[selected_col]\n",
    "    for col in tqdm(X_u.columns):\n",
    "            X_u[col] = pd.cut(X_u[col], bins=cut_bin, labels=False, retbins=True, right=False)[0]  \n",
    "\n",
    "    print(train_csr.shape)\n",
    "    train_csr = sparse.hstack(\n",
    "        (sparse.csr_matrix(X_u.iloc[:train_csr.shape[0]]), train_csr), 'csr').astype(\n",
    "        'float32')\n",
    "    predict_csr = sparse.hstack(\n",
    "        (sparse.csr_matrix(X_u.iloc[train_csr.shape[0]:]), predict_csr), 'csr').astype('float32')\n",
    "    print(train_csr.shape)\n",
    "    print(predict_csr.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=32, reg_alpha=0, reg_lambda=0.1,\n",
    "    max_depth=-1, n_estimators=5000, objective='binary',\n",
    "    subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "    learning_rate=0.05, random_state=1001, n_jobs=16)\n",
    "\n",
    "    \n",
    "    predict_result = predicted_file[['instance_id']].copy()\n",
    "    predict_result['predicted_score'] = 0\n",
    "\n",
    "    n_fold = 5\n",
    "    seed=np.random.randint(1000)\n",
    "#     seed=41\n",
    "    gc.collect()\n",
    "    skf = StratifiedKFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "    best_score = []\n",
    "    oof = np.zeros(len(train_y))\n",
    "    for index, (train_index, test_index) in enumerate(skf.split(train_csr, train_y)):\n",
    "        lgb_model.fit(train_csr[train_index], train_y[train_index],\n",
    "                          eval_set=[(train_csr[train_index], train_y[train_index]),\n",
    "                                    (train_csr[test_index], train_y[test_index])], early_stopping_rounds=200,verbose=200)\n",
    "        best_score.append(lgb_model.best_score_['valid_1']['binary_logloss'])\n",
    "        print(best_score)\n",
    "        print('cv:',np.mean(best_score))\n",
    "        test_pred = lgb_model.predict_proba(predict_csr, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "        print('test mean:', test_pred.mean())\n",
    "        predict_result['predicted_score'] = predict_result['predicted_score'] + test_pred\n",
    "        oof[test_index] = lgb_model.predict_proba(train_csr[test_index], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "        gc.collect()\n",
    "\n",
    "    predict_result['predicted_score'] = predict_result['predicted_score']/n_fold\n",
    "    \n",
    "    \n",
    "    colnum = train_csr.shape[1]\n",
    "    cv_loss = np.mean(best_score)\n",
    "    now = str(np.random.randint(1000000))\n",
    "    fileName = re.sub(r'_','',add_fe)\n",
    "    predict_result[['instance_id', 'predicted_score']].to_csv( \"submission/%s_lgbUtag%s_n%d_b%d_1h_col%d.csv\" % (now, fileName,n_fold, 70, colnum), index=False)\n",
    "    np.save('submission/oof_%s_%.5f'%(now, cv_loss), oof) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
