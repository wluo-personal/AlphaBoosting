{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T00:20:00.326359Z",
     "start_time": "2018-10-17T00:19:59.980144Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "__file__=''\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../LIB/'))\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../../../../automl/automl_libs/'))\n",
    "from env import FILE\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse \n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import chi2, SelectPercentile,SelectKBest\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T00:20:03.298804Z",
     "start_time": "2018-10-17T00:20:03.290294Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "def save_csr(matrix,file_prefix='csr'):\n",
    "    data_file = file_prefix + '_data.npy'\n",
    "    indices_file = file_prefix + '_indices.npy'\n",
    "    indptr_file = file_prefix + '_indptr.npy'\n",
    "    np.save(data_file,matrix.data)\n",
    "    print('data save')\n",
    "    np.save(indices_file,matrix.indices)\n",
    "    print('indices save')\n",
    "    np.save(indptr_file,matrix.indptr)\n",
    "    print('indptr save')\n",
    "    print('save done!')\n",
    "    \n",
    "def load_csr(file_prefix='csr'):\n",
    "    data_file = file_prefix + '_data.npy'\n",
    "    indices_file = file_prefix + '_indices.npy'\n",
    "    indptr_file = file_prefix + '_indptr.npy'\n",
    "    data = np.load(data_file)\n",
    "    print('data load')\n",
    "    indices = np.load(indices_file)\n",
    "    print('indices load')\n",
    "    indptr = np.load(indptr_file)\n",
    "    print('indptr load')\n",
    "    csr = csr_matrix((data, indices, indptr))\n",
    "    return csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = 2500,2400,2300,2700,3000,3500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T00:20:41.093004Z",
     "start_time": "2018-10-17T00:20:37.958311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "(2992639, 2363)\n"
     ]
    }
   ],
   "source": [
    "first = 2500\n",
    "train_csr = load_csr('../../data/features/xgb/train_csr_{}'.format(first))\n",
    "predict_csr = load_csr('../../data/features/xgb/predict_csr_{}'.format(first))\n",
    "train_y = np.load('../../data/features/xgb/train_y.npy')\n",
    "predicted_file = pd.read_pickle('../../data/features/xgb/predict_id.pkl')\n",
    "print(train_csr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slot_mean\n",
    "# fchannel\n",
    "# appid\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T00:24:32.719742Z",
     "start_time": "2018-10-17T00:23:06.529573Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load\n",
      "indices load\n",
      "indptr load\n",
      "data load\n",
      "indices load\n",
      "indptr load\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:00<00:04,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072915, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:03<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2992639, 2363)\n",
      "(2992639, 2395)\n",
      "(80276, 2395)\n"
     ]
    }
   ],
   "source": [
    "train_csr = load_csr('../../data/features/xgb/train_csr_2500')\n",
    "predict_csr = load_csr('../../data/features/xgb/predict_csr_2500')\n",
    "train_instance = pd.read_pickle('../../data/features/xgb/train_id.pkl')[['instance_id']].copy()\n",
    "train_y = np.load('../../data/features/xgb/train_y.npy')\n",
    "predicted_file = pd.read_pickle('../../data/features/xgb/predict_id.pkl')\n",
    "test_instance = predicted_file[['instance_id']].copy()\n",
    "all_instance = pd.concat([train_instance,test_instance],sort=False)\n",
    "\n",
    "X_u = pd.read_pickle('../../data/features/agg/svd_utag_adid_mean.pkl')\n",
    "\n",
    "X_u = all_instance.merge(X_u,on='instance_id',how='inner')\n",
    "X_u.drop('instance_id',inplace=True,axis=1)\n",
    "print(X_u.shape)\n",
    "\n",
    "cut_bin = 30\n",
    "# selected_col = [col for col in X_u.columns if 'utagsIndividual_svd' not in col]\n",
    "# X_u = X_u[selected_col]\n",
    "for col in tqdm(X_u.columns):\n",
    "        X_u[col] = pd.cut(X_u[col], bins=cut_bin, labels=False, retbins=True, right=False)[0]  \n",
    "        \n",
    "print(train_csr.shape)\n",
    "train_csr = sparse.hstack(\n",
    "    (sparse.csr_matrix(X_u.iloc[:train_csr.shape[0]]), train_csr), 'csr').astype(\n",
    "    'float32')\n",
    "predict_csr = sparse.hstack(\n",
    "    (sparse.csr_matrix(X_u.iloc[train_csr.shape[0]:]), predict_csr), 'csr').astype('float32')\n",
    "print(train_csr.shape)\n",
    "print(predict_csr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-17T00:24:48.747986Z",
     "start_time": "2018-10-17T00:24:48.741972Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', num_leaves=32, reg_alpha=0, reg_lambda=0.1,\n",
    "    max_depth=-1, n_estimators=5000, objective='binary',\n",
    "    subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "    learning_rate=0.05, random_state=1001, n_jobs=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-17T00:26:03.756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415537\tvalid_1's binary_logloss: 0.416211\n",
      "[400]\tvalid_0's binary_logloss: 0.413405\tvalid_1's binary_logloss: 0.41523\n",
      "[600]\tvalid_0's binary_logloss: 0.411809\tvalid_1's binary_logloss: 0.414866\n",
      "[800]\tvalid_0's binary_logloss: 0.410391\tvalid_1's binary_logloss: 0.414669\n",
      "[1000]\tvalid_0's binary_logloss: 0.409061\tvalid_1's binary_logloss: 0.414559\n",
      "[1200]\tvalid_0's binary_logloss: 0.407779\tvalid_1's binary_logloss: 0.414456\n",
      "[1400]\tvalid_0's binary_logloss: 0.406516\tvalid_1's binary_logloss: 0.414384\n",
      "[1600]\tvalid_0's binary_logloss: 0.405297\tvalid_1's binary_logloss: 0.414341\n",
      "[1800]\tvalid_0's binary_logloss: 0.404105\tvalid_1's binary_logloss: 0.414324\n",
      "[2000]\tvalid_0's binary_logloss: 0.402978\tvalid_1's binary_logloss: 0.414303\n",
      "[2200]\tvalid_0's binary_logloss: 0.401857\tvalid_1's binary_logloss: 0.414274\n",
      "Early stopping, best iteration is:\n",
      "[2196]\tvalid_0's binary_logloss: 0.401878\tvalid_1's binary_logloss: 0.41427\n",
      "[0.4142704934877704]\n",
      "cv: 0.4142704934877704\n",
      "test mean: 0.20635772994269608\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415531\tvalid_1's binary_logloss: 0.416164\n",
      "[400]\tvalid_0's binary_logloss: 0.41341\tvalid_1's binary_logloss: 0.415177\n",
      "[600]\tvalid_0's binary_logloss: 0.411833\tvalid_1's binary_logloss: 0.414828\n"
     ]
    }
   ],
   "source": [
    "predict_result = predicted_file[['instance_id']].copy()\n",
    "predict_result['predicted_score'] = 0\n",
    "\n",
    "n_fold = 5\n",
    "seed=np.random.randint(1000)\n",
    "seed=41\n",
    "gc.collect()\n",
    "skf = StratifiedKFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "best_score = []\n",
    "oof = np.zeros(len(train_y))\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_csr, train_y)):\n",
    "    lgb_model.fit(train_csr[train_index], train_y[train_index],\n",
    "                      eval_set=[(train_csr[train_index], train_y[train_index]),\n",
    "                                (train_csr[test_index], train_y[test_index])], early_stopping_rounds=200,verbose=200)\n",
    "    best_score.append(lgb_model.best_score_['valid_1']['binary_logloss'])\n",
    "    print(best_score)\n",
    "    print('cv:',np.mean(best_score))\n",
    "    test_pred = lgb_model.predict_proba(predict_csr, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    print('test mean:', test_pred.mean())\n",
    "    predict_result['predicted_score'] = predict_result['predicted_score'] + test_pred\n",
    "    oof[test_index] = lgb_model.predict_proba(train_csr[test_index], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    gc.collect()\n",
    "\n",
    "predict_result['predicted_score'] = predict_result['predicted_score']/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T13:36:49.243174Z",
     "start_time": "2018-10-16T12:02:22.104129Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415528\tvalid_1's binary_logloss: 0.416103\n",
      "[400]\tvalid_0's binary_logloss: 0.413341\tvalid_1's binary_logloss: 0.415082\n",
      "[600]\tvalid_0's binary_logloss: 0.411732\tvalid_1's binary_logloss: 0.414761\n",
      "[800]\tvalid_0's binary_logloss: 0.410259\tvalid_1's binary_logloss: 0.414549\n",
      "[1000]\tvalid_0's binary_logloss: 0.408867\tvalid_1's binary_logloss: 0.414407\n",
      "[1200]\tvalid_0's binary_logloss: 0.407566\tvalid_1's binary_logloss: 0.414327\n",
      "[1400]\tvalid_0's binary_logloss: 0.406291\tvalid_1's binary_logloss: 0.414239\n",
      "[1600]\tvalid_0's binary_logloss: 0.405052\tvalid_1's binary_logloss: 0.414185\n",
      "[1800]\tvalid_0's binary_logloss: 0.403852\tvalid_1's binary_logloss: 0.41418\n",
      "[2000]\tvalid_0's binary_logloss: 0.402688\tvalid_1's binary_logloss: 0.414175\n",
      "[2200]\tvalid_0's binary_logloss: 0.401513\tvalid_1's binary_logloss: 0.414151\n",
      "[2400]\tvalid_0's binary_logloss: 0.400382\tvalid_1's binary_logloss: 0.414153\n",
      "Early stopping, best iteration is:\n",
      "[2336]\tvalid_0's binary_logloss: 0.400749\tvalid_1's binary_logloss: 0.414148\n",
      "[0.41414849927137026]\n",
      "cv: 0.41414849927137026\n",
      "test mean: 0.25827581812772227\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415608\tvalid_1's binary_logloss: 0.415772\n",
      "[400]\tvalid_0's binary_logloss: 0.413456\tvalid_1's binary_logloss: 0.414804\n",
      "[600]\tvalid_0's binary_logloss: 0.411814\tvalid_1's binary_logloss: 0.414435\n",
      "[800]\tvalid_0's binary_logloss: 0.410373\tvalid_1's binary_logloss: 0.414273\n",
      "[1000]\tvalid_0's binary_logloss: 0.409008\tvalid_1's binary_logloss: 0.414155\n",
      "[1200]\tvalid_0's binary_logloss: 0.407706\tvalid_1's binary_logloss: 0.414101\n",
      "[1400]\tvalid_0's binary_logloss: 0.406425\tvalid_1's binary_logloss: 0.414021\n",
      "[1600]\tvalid_0's binary_logloss: 0.405185\tvalid_1's binary_logloss: 0.413961\n",
      "[1800]\tvalid_0's binary_logloss: 0.40398\tvalid_1's binary_logloss: 0.413936\n",
      "[2000]\tvalid_0's binary_logloss: 0.402806\tvalid_1's binary_logloss: 0.413891\n",
      "[2200]\tvalid_0's binary_logloss: 0.401628\tvalid_1's binary_logloss: 0.413886\n",
      "[2400]\tvalid_0's binary_logloss: 0.400489\tvalid_1's binary_logloss: 0.413875\n",
      "Early stopping, best iteration is:\n",
      "[2311]\tvalid_0's binary_logloss: 0.400987\tvalid_1's binary_logloss: 0.413869\n",
      "[0.41414849927137026, 0.4138688624045797]\n",
      "cv: 0.414008680837975\n",
      "test mean: 0.25205618422780945\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415334\tvalid_1's binary_logloss: 0.416922\n",
      "[400]\tvalid_0's binary_logloss: 0.413149\tvalid_1's binary_logloss: 0.415908\n",
      "[600]\tvalid_0's binary_logloss: 0.411535\tvalid_1's binary_logloss: 0.41556\n",
      "[800]\tvalid_0's binary_logloss: 0.410057\tvalid_1's binary_logloss: 0.41535\n",
      "[1000]\tvalid_0's binary_logloss: 0.408662\tvalid_1's binary_logloss: 0.415195\n",
      "[1200]\tvalid_0's binary_logloss: 0.407348\tvalid_1's binary_logloss: 0.415118\n",
      "[1400]\tvalid_0's binary_logloss: 0.406091\tvalid_1's binary_logloss: 0.41506\n",
      "[1600]\tvalid_0's binary_logloss: 0.404842\tvalid_1's binary_logloss: 0.414998\n",
      "[1800]\tvalid_0's binary_logloss: 0.403649\tvalid_1's binary_logloss: 0.414968\n",
      "[2000]\tvalid_0's binary_logloss: 0.402465\tvalid_1's binary_logloss: 0.414947\n",
      "[2200]\tvalid_0's binary_logloss: 0.401302\tvalid_1's binary_logloss: 0.414947\n",
      "Early stopping, best iteration is:\n",
      "[2126]\tvalid_0's binary_logloss: 0.40172\tvalid_1's binary_logloss: 0.414932\n",
      "[0.41414849927137026, 0.4138688624045797, 0.41493246575796994]\n",
      "cv: 0.41431660914463997\n",
      "test mean: 0.2218735721943516\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.41544\tvalid_1's binary_logloss: 0.416384\n",
      "[400]\tvalid_0's binary_logloss: 0.413289\tvalid_1's binary_logloss: 0.415417\n",
      "[600]\tvalid_0's binary_logloss: 0.411653\tvalid_1's binary_logloss: 0.415063\n",
      "[800]\tvalid_0's binary_logloss: 0.410205\tvalid_1's binary_logloss: 0.414861\n",
      "[1000]\tvalid_0's binary_logloss: 0.408843\tvalid_1's binary_logloss: 0.414783\n",
      "[1200]\tvalid_0's binary_logloss: 0.407514\tvalid_1's binary_logloss: 0.414687\n",
      "[1400]\tvalid_0's binary_logloss: 0.406241\tvalid_1's binary_logloss: 0.414615\n",
      "[1600]\tvalid_0's binary_logloss: 0.404982\tvalid_1's binary_logloss: 0.414569\n",
      "Early stopping, best iteration is:\n",
      "[1569]\tvalid_0's binary_logloss: 0.405181\tvalid_1's binary_logloss: 0.414567\n",
      "[0.41414849927137026, 0.4138688624045797, 0.41493246575796994, 0.41456689266685787]\n",
      "cv: 0.41437918002519447\n",
      "test mean: 0.24163114788189816\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[200]\tvalid_0's binary_logloss: 0.415508\tvalid_1's binary_logloss: 0.416112\n",
      "[400]\tvalid_0's binary_logloss: 0.413325\tvalid_1's binary_logloss: 0.415167\n",
      "[800]\tvalid_0's binary_logloss: 0.410232\tvalid_1's binary_logloss: 0.414615\n",
      "[1000]\tvalid_0's binary_logloss: 0.408837\tvalid_1's binary_logloss: 0.414487\n",
      "[1200]\tvalid_0's binary_logloss: 0.40753\tvalid_1's binary_logloss: 0.414431\n",
      "[1400]\tvalid_0's binary_logloss: 0.406259\tvalid_1's binary_logloss: 0.414401\n",
      "[1600]\tvalid_0's binary_logloss: 0.405033\tvalid_1's binary_logloss: 0.414369\n",
      "[1800]\tvalid_0's binary_logloss: 0.403833\tvalid_1's binary_logloss: 0.414336\n",
      "[2000]\tvalid_0's binary_logloss: 0.402664\tvalid_1's binary_logloss: 0.414324\n",
      "[2200]\tvalid_0's binary_logloss: 0.4015\tvalid_1's binary_logloss: 0.414305\n",
      "Early stopping, best iteration is:\n",
      "[2189]\tvalid_0's binary_logloss: 0.40156\tvalid_1's binary_logloss: 0.414303\n",
      "[0.41414849927137026, 0.4138688624045797, 0.41493246575796994, 0.41456689266685787, 0.41430273267821055]\n",
      "cv: 0.4143638905557977\n",
      "test mean: 0.24316564104559524\n"
     ]
    }
   ],
   "source": [
    "predict_result = predicted_file[['instance_id']].copy()\n",
    "predict_result['predicted_score'] = 0\n",
    "\n",
    "n_fold = 5\n",
    "seed=np.random.randint(1000)\n",
    "gc.collect()\n",
    "skf = StratifiedKFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "best_score = []\n",
    "oof = np.zeros(len(train_y))\n",
    "for index, (train_index, test_index) in enumerate(skf.split(train_csr, train_y)):\n",
    "    lgb_model.fit(train_csr[train_index], train_y[train_index],\n",
    "                      eval_set=[(train_csr[train_index], train_y[train_index]),\n",
    "                                (train_csr[test_index], train_y[test_index])], early_stopping_rounds=200,verbose=200)\n",
    "    best_score.append(lgb_model.best_score_['valid_1']['binary_logloss'])\n",
    "    print(best_score)\n",
    "    print('cv:',np.mean(best_score))\n",
    "    test_pred = lgb_model.predict_proba(predict_csr, num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    print('test mean:', test_pred.mean())\n",
    "    predict_result['predicted_score'] = predict_result['predicted_score'] + test_pred\n",
    "    oof[test_index] = lgb_model.predict_proba(train_csr[test_index], num_iteration=lgb_model.best_iteration_)[:, 1]\n",
    "    gc.collect()\n",
    "\n",
    "predict_result['predicted_score'] = predict_result['predicted_score']/n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T14:02:26.475375Z",
     "start_time": "2018-10-16T14:02:26.244652Z"
    }
   },
   "outputs": [],
   "source": [
    "colnum = train_csr.shape[1]\n",
    "cv_loss = np.mean(best_score)\n",
    "now = str(np.random.randint(1000000))\n",
    "predict_result[['instance_id', 'predicted_score']].to_csv( \"submission/%s_lgbUtagAdidMean_n%d_b%d_1h_col%d.csv\" % (now, n_fold, 70, colnum), index=False)\n",
    "np.save('submission/oof_%s_%.5f'%(now, cv_loss), oof) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
