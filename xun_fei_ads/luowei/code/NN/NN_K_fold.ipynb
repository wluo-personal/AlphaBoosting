{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:48:03.584055Z",
     "start_time": "2018-09-24T15:48:01.972411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "__file__=''\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../LIB/'))\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../../../../automl/automl_libs/'))\n",
    "from env import FILE\n",
    "from sklearn.metrics import log_loss,roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "\n",
    "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU,CuDNNGRU,Flatten,BatchNormalization\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import numpy as np\n",
    "import gc\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:48:05.897880Z",
     "start_time": "2018-09-24T15:48:03.586955Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(FILE.train_ori.value)\n",
    "test = pd.read_pickle(FILE.test_ori.value)\n",
    "train_doc = pd.read_pickle('../../data/fe_doc/train_doc.pkl')\n",
    "test_doc = pd.read_pickle('../../data/fe_doc/test_doc.pkl')\n",
    "\n",
    "\n",
    "holdout_index = pickle.load(open(FILE.holdout_index.value,'rb'))\n",
    "train_index = pickle.load(open(FILE.train_index.value,'rb'))\n",
    "train_cv = train_doc.loc[train_index].copy()\n",
    "holdout = train_doc.loc[holdout_index].copy()\n",
    "\n",
    "test_matrix = pickle.load(open(FILE.countVectorize_format.value.format('test'),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:48:05.910910Z",
     "start_time": "2018-09-24T15:48:05.905471Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# for fold in range(5):\n",
    "#     index_name = FILE.Vectorize_index_format.value.format('val_fold_{}'.format(fold))\n",
    "#     index = pickle.load(open(index_name,'rb'))\n",
    "#     label_name = FILE.Vectorize_label_format.value.format('val_fold_{}'.format(fold))\n",
    "#     label = pickle.load(open(label_name,'rb'))\n",
    "#     dfc = pd.DataFrame({'idx':index,'label':label})\n",
    "#     df = pd.concat([df,dfc])\n",
    "# label_ho = pickle.load(open(FILE.Vectorize_label_format.value.format('holdout'),'rb'))\n",
    "# dfc = pd.DataFrame({'idx':holdout_index,'label':label_ho})\n",
    "# df = pd.concat([df,dfc])\n",
    "# df = df.sort_values('idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T15:48:05.946402Z",
     "start_time": "2018-09-24T15:48:05.915874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "param_list = []\n",
    "for layer1 in [4096,5120,6144]:\n",
    "    for layer2 in [None,1024,2048]:\n",
    "        for layer3 in [None]:\n",
    "            if layer2 is None and layer3 is not None:\n",
    "                continue\n",
    "            if layer2 is not None and layer3 is not None:\n",
    "                if layer2 < layer3:\n",
    "                    continue\n",
    "            param = {'input_shape':test_matrix.shape[1],\n",
    "                     'layer1':layer1,\n",
    "                     'layer2':layer2,\n",
    "                     'layer3':layer3}\n",
    "            param_list.append(param)\n",
    "print(len(param_list))\n",
    "\n",
    "train_batch = 2048\n",
    "test_batch = 20000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_nn_model(param):\n",
    "    layer1 = param.get('layer1')\n",
    "    layer2 = param.get('layer2')\n",
    "    layer3 = param.get('layer3')\n",
    "    input_shape = param.get('input_shape')\n",
    "    \n",
    "    sequence_input = Input(shape=(input_shape, ))\n",
    "    x = Dense(layer1, activation='relu')(sequence_input)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    if layer2 is not None:\n",
    "        x = Dense(layer2, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "    \n",
    "    if layer2 is not None and layer3 is not None:\n",
    "        x = Dense(layer3, activation='relu')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        \n",
    "    preds = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])    \n",
    "    return model\n",
    "\n",
    "def train_each_epoch(x,y,batch_size,model):\n",
    "    x,y = shuffle(x,y)\n",
    "    model.fit(x, y, \n",
    "              batch_size=batch_size, \n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              )\n",
    "    return model\n",
    "\n",
    "def get_file_name(param,vectorize='countVectorize'):\n",
    "    layer1 = param.get('layer1')\n",
    "    layer2 = param.get('layer2')\n",
    "    layer3 = param.get('layer3')\n",
    "    return '{}_layer1_{}_layer2_{}_layer3_{}.pkl'.format(vectorize,layer1,layer2,layer3)\n",
    "\n",
    "def save_report(params,report_path):\n",
    "    \"\"\"\n",
    "    params. dataframe report params.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        saved_report = pd.read_csv(report_path)\n",
    "    except:\n",
    "        saved_report = pd.DataFrame()\n",
    "    new_report = pd.DataFrame({'fileName':params['file_Name'],\n",
    "                               'cv_mean':params['cv_mean'],\n",
    "                               'holdout':params['holdout']})\n",
    "    saved_report = pd.concat([saved_report,new_report]).reset_index(drop=True)\n",
    "    saved_report.to_csv(report_path)\n",
    "    print('saved report to path {}'.format(report_path))\n",
    "    \n",
    "def save_preds(file_name,preds_params,path='../../data/nn/{}/{}'):\n",
    "    \"\"\"\n",
    "    param: nn layer info.\n",
    "    preds_params:key should be train/test/holdout and values should be coresponding predict dataframe\n",
    "    \"\"\"\n",
    "    for key in preds_params:\n",
    "        saving_path = path.format(key,file_name)\n",
    "        preds_params[key].to_pickle(saving_path)\n",
    "        print('saving preds {} done!'.format(key))\n",
    "        \n",
    "def train_each_fold(param,fold,mode='countVectorize',tolerance=2):\n",
    "    if mode != 'tfidf':\n",
    "        train_name = FILE.countVectorize_format.value.format('train_fold_{}'.format(fold))\n",
    "        val_name = FILE.countVectorize_format.value.format('val_fold_{}'.format(fold))\n",
    "        holdout_name = FILE.countVectorize_format.value.format('holdout')\n",
    "        test_name = FILE.countVectorize_format.value.format('test')\n",
    "        \n",
    "    else:\n",
    "        train_name = FILE.tfidfVectorize_format.value.format('train_fold_{}'.format(fold))\n",
    "        val_name = FILE.tfidfVectorize_format.value.format('val_fold_{}'.format(fold))\n",
    "        holdout_name = FILE.tfidfVectorize_format.value.format('holdout')\n",
    "        test_name = FILE.tfidfVectorize_format.value.format('test')\n",
    "        \n",
    "    y_train_name = FILE.Vectorize_label_format.value.format('train_fold_{}'.format(fold))\n",
    "    y_val_name = FILE.Vectorize_label_format.value.format('val_fold_{}'.format(fold))\n",
    "    y_holdout_name = FILE.Vectorize_label_format.value.format('holdout')\n",
    "        \n",
    "    x_train = pickle.load(open(train_name,'rb'))\n",
    "    x_val = pickle.load(open(val_name,'rb'))\n",
    "    x_holdout = pickle.load(open(holdout_name,'rb'))\n",
    "    x_test = pickle.load(open(test_name,'rb'))\n",
    "    y_train =   pickle.load(open(y_train_name,'rb'))\n",
    "    y_val =   pickle.load(open(y_val_name,'rb'))\n",
    "    y_holdout =   pickle.load(open(y_holdout_name,'rb'))\n",
    "    tol = 0\n",
    "    model = get_nn_model(param)\n",
    "    best_loss = None\n",
    "    while True:\n",
    "        model = train_each_epoch(x_train,y_train,train_batch,model)\n",
    "        val_pred = model.predict(x_val,test_batch,verbose=1)\n",
    "        score = log_loss(y_val,val_pred)\n",
    "        print('current validation loss: {}'.format(score))\n",
    "        \n",
    "        if best_loss is None:\n",
    "            tol = 0\n",
    "            best_loss = score\n",
    "            holdout_preds = model.predict(x_holdout,test_batch,verbose=1)\n",
    "            holdout_score = log_loss(y_holdout,holdout_preds)\n",
    "            print('holdout loss is: {}'.format(holdout_score))\n",
    "            test_preds = model.predict(x_test,test_batch,verbose=1)\n",
    "            continue\n",
    "        if score < best_loss:\n",
    "            tol = 0\n",
    "            best_loss = score\n",
    "            holdout_preds = model.predict(x_holdout,test_batch,verbose=1)\n",
    "            holdout_score = log_loss(y_holdout,holdout_preds)\n",
    "            print('holdout loss is: {}'.format(holdout_score))\n",
    "            test_preds = model.predict(x_test,test_batch,verbose=1)\n",
    "        else:\n",
    "            tol += 1\n",
    "            if tol == tolerance:\n",
    "                break\n",
    "        print('best validation loss: {}'.format(best_loss))\n",
    "    return best_loss,val_pred,holdout_preds,test_preds\n",
    "\n",
    "def train_5_fold(train,test,param,vectorize='countVectorize',report_path='../../data/nn/report.csv'):\n",
    "    train_oof = train[['instance_id']].copy()\n",
    "    test_oof = test[['instance_id']].copy()\n",
    "    train_oof['predicted_score'] = np.nan\n",
    "    file_name = get_file_name(param,vectorize)\n",
    "    cv_list = []\n",
    "    holdout_list = []\n",
    "    test_list = []\n",
    "    try:\n",
    "        saved_report = pd.read_csv(report_path)\n",
    "        if file_name in saved_report['fileName'].values:\n",
    "            return None\n",
    "    except:\n",
    "        print('no saved report found. create a new one')\n",
    "        saved_report = pd.DataFrame()\n",
    "    for fold in range(7):\n",
    "        print('start fold {}...'.format(fold))\n",
    "        score,val_pred,holdout_preds,test_preds =  train_each_fold(param,fold,mode=vectorize,tolerance=2)\n",
    "        cv_list.append(score)\n",
    "        holdout_list.append(holdout_preds)\n",
    "        test_list.append(test_preds)\n",
    "        index_name = FILE.Vectorize_index_format.value.format('val_fold_{}'.format(fold))\n",
    "        val_index = pickle.load(open(index_name,'rb'))\n",
    "        train_oof.loc[val_index,'predicted_score'] = val_pred\n",
    "        gc.collect()\n",
    "        time.sleep(5)\n",
    "        \n",
    "    \n",
    "    holdout = np.mean(holdout_list,axis=0)\n",
    "    test = np.mean(test_list,axis=0)\n",
    "    cv_mean = np.mean(cv_list)\n",
    "    y_holdout_name = FILE.Vectorize_label_format.value.format('holdout')\n",
    "    y_holdout =   pickle.load(open(y_holdout_name,'rb'))\n",
    "    holdout_index = pickle.load(open(FILE.holdout_index.value,'rb'))\n",
    "    train_oof.loc[holdout_index,'predicted_score'] = holdout\n",
    "    test_oof['predicted_score'] = test\n",
    "    holdout_df =  train_oof.loc[holdout_index].copy()\n",
    "    \n",
    "    holdout_score = log_loss(y_holdout,holdout)\n",
    "    print('cv mean: {}, overall holdout: {}'.format(cv_mean,holdout_score))\n",
    "    \n",
    "    \n",
    "    new_report = pd.DataFrame({'fileName':[file_name],\n",
    "                               'cv_mean':[cv_mean],\n",
    "                               'holdout':[holdout_score]})\n",
    "   \n",
    "    saved_report = pd.concat([saved_report,new_report],sort=False).reset_index(drop=True)\n",
    "    saved_report.to_csv(report_path,index=False)\n",
    "    print('saved report to path {}'.format(report_path))\n",
    "    \n",
    "    preds_param = {'train':train_oof,'test':test_oof,'holdout':holdout_df}\n",
    "    \n",
    "    save_preds(file_name,preds_param)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T16:35:44.156684Z",
     "start_time": "2018-09-24T15:48:05.948569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer1': 4096, 'layer2': None, 'layer3': None, 'input_shape': 25422}\n",
      "start fold 0...\n",
      "Epoch 1/1\n",
      "826135/826135 [==============================] - 164s 198us/step - loss: 0.4238 - acc: 0.8045\n",
      "135491/135491 [==============================] - 21s 152us/step\n",
      "current validation loss: 0.4114878781143221\n",
      "40024/40024 [==============================] - 6s 154us/step\n",
      "holdout loss is: 0.4276503681903065\n",
      "40024/40024 [==============================] - 6s 150us/step\n",
      "Epoch 1/1\n",
      "826135/826135 [==============================] - 160s 194us/step - loss: 0.4156 - acc: 0.8062\n",
      "135491/135491 [==============================] - 21s 152us/step\n",
      "current validation loss: 0.4117469063793765\n",
      "best validation loss: 0.4114878781143221\n",
      "Epoch 1/1\n",
      "826135/826135 [==============================] - 159s 193us/step - loss: 0.4117 - acc: 0.8077\n",
      "135491/135491 [==============================] - 21s 154us/step\n",
      "current validation loss: 0.411922317119572\n",
      "start fold 1...\n",
      "Epoch 1/1\n",
      "818892/818892 [==============================] - 159s 194us/step - loss: 0.4224 - acc: 0.8048\n",
      "142734/142734 [==============================] - 21s 150us/step\n",
      "current validation loss: 0.4216130411413319\n",
      "40024/40024 [==============================] - 6s 156us/step\n",
      "holdout loss is: 0.42865379437322065\n",
      "40024/40024 [==============================] - 6s 154us/step\n",
      "Epoch 1/1\n",
      "818892/818892 [==============================] - 160s 195us/step - loss: 0.4141 - acc: 0.8070\n",
      "142734/142734 [==============================] - 22s 152us/step\n",
      "current validation loss: 0.4195374221109574\n",
      "40024/40024 [==============================] - 6s 153us/step\n",
      "holdout loss is: 0.42666087326434576\n",
      "40024/40024 [==============================] - 6s 152us/step\n",
      "best validation loss: 0.4195374221109574\n",
      "Epoch 1/1\n",
      "818892/818892 [==============================] - 159s 194us/step - loss: 0.4102 - acc: 0.8083\n",
      "142734/142734 [==============================] - 22s 153us/step\n",
      "current validation loss: 0.4209444733239301\n",
      "best validation loss: 0.4195374221109574\n",
      "Epoch 1/1\n",
      "818892/818892 [==============================] - 158s 193us/step - loss: 0.4049 - acc: 0.8101\n",
      "142734/142734 [==============================] - 22s 151us/step\n",
      "current validation loss: 0.42206245578140494\n",
      "start fold 2...\n",
      "Epoch 1/1\n",
      "816463/816463 [==============================] - 160s 195us/step - loss: 0.4224 - acc: 0.8045\n",
      "145163/145163 [==============================] - 22s 152us/step\n",
      "current validation loss: 0.42117108699985795\n",
      "40024/40024 [==============================] - 6s 157us/step\n",
      "holdout loss is: 0.4284812923067745\n",
      "40024/40024 [==============================] - 6s 154us/step\n",
      "Epoch 1/1\n",
      "816463/816463 [==============================] - 158s 194us/step - loss: 0.4140 - acc: 0.8070\n",
      "145163/145163 [==============================] - 22s 153us/step\n",
      "current validation loss: 0.420893091711846\n",
      "40024/40024 [==============================] - 6s 153us/step\n",
      "holdout loss is: 0.4273435647152684\n",
      "40024/40024 [==============================] - 6s 151us/step\n",
      "best validation loss: 0.420893091711846\n",
      "Epoch 1/1\n",
      "816463/816463 [==============================] - 158s 193us/step - loss: 0.4099 - acc: 0.8085\n",
      "145163/145163 [==============================] - 22s 153us/step\n",
      "current validation loss: 0.420915855346628\n",
      "best validation loss: 0.420893091711846\n",
      "Epoch 1/1\n",
      "816463/816463 [==============================] - 158s 193us/step - loss: 0.4047 - acc: 0.8102\n",
      "145163/145163 [==============================] - 22s 153us/step\n",
      "current validation loss: 0.42320581436892635\n",
      "start fold 3...\n",
      "Epoch 1/1\n",
      "832563/832563 [==============================] - 161s 193us/step - loss: 0.4241 - acc: 0.8037\n",
      "129063/129063 [==============================] - 20s 153us/step\n",
      "current validation loss: 0.4110979774726924\n",
      "40024/40024 [==============================] - 6s 155us/step\n",
      "holdout loss is: 0.4275848595681279\n",
      "40024/40024 [==============================] - 6s 154us/step\n",
      "Epoch 1/1\n",
      "832563/832563 [==============================] - 163s 195us/step - loss: 0.4156 - acc: 0.8068\n",
      "129063/129063 [==============================] - 20s 151us/step\n",
      "current validation loss: 0.41052654230737257\n",
      "40024/40024 [==============================] - 6s 151us/step\n",
      "holdout loss is: 0.4279678740780991\n",
      "40024/40024 [==============================] - 6s 150us/step\n",
      "best validation loss: 0.41052654230737257\n",
      "Epoch 1/1\n",
      "832563/832563 [==============================] - 161s 193us/step - loss: 0.4118 - acc: 0.8082\n",
      "129063/129063 [==============================] - 19s 149us/step\n",
      "current validation loss: 0.41124115968845903\n",
      "best validation loss: 0.41052654230737257\n",
      "Epoch 1/1\n",
      "832563/832563 [==============================] - 161s 193us/step - loss: 0.4067 - acc: 0.8100\n",
      "129063/129063 [==============================] - 20s 153us/step\n",
      "current validation loss: 0.41264122191740665\n",
      "start fold 4...\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[25422,4096]\n\t [[Node: training_4/Adam/mul_2 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/sub_2, training_4/Adam/gradients/dense_9/MatMul_grad/MatMul_1)]]\n\nCaused by op 'training_4/Adam/mul_2', defined at:\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-441ae2bafe6d>\", line 3, in <module>\n    train_5_fold(train,test,param,vectorize='countVectorize',report_path='../../data/nn/report.csv')\n  File \"<ipython-input-4-bf54e6dd9e61>\", line 158, in train_5_fold\n    score,val_pred,holdout_preds,test_preds =  train_each_fold(param,fold,mode=vectorize,tolerance=2)\n  File \"<ipython-input-4-bf54e6dd9e61>\", line 114, in train_each_fold\n    model = train_each_epoch(x_train,y_train,train_batch,model)\n  File \"<ipython-input-4-bf54e6dd9e61>\", line 51, in train_each_epoch\n    verbose=1,\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\", line 1008, in fit\n    self._make_train_function()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\", line 498, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/optimizers.py\", line 491, in get_updates\n    m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25422,4096]\n\t [[Node: training_4/Adam/mul_2 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/sub_2, training_4/Adam/gradients/dense_9/MatMul_grad/MatMul_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25422,4096]\n\t [[Node: training_4/Adam/mul_2 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/sub_2, training_4/Adam/gradients/dense_9/MatMul_grad/MatMul_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m?\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_5_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'countVectorize'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreport_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../../data/nn/report.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m?\u001b[0m in \u001b[0;36mtrain_5_fold\u001b[0;34m(train, test, param, vectorize, report_path)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start fold {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mholdout_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain_each_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mcv_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mholdout_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m?\u001b[0m in \u001b[0;36mtrain_each_fold\u001b[0;34m(param, fold, mode, tolerance)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_each_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m?\u001b[0m in \u001b[0;36mtrain_each_epoch\u001b[0;34m(x, y, batch_size, model)\u001b[0m\n\u001b[1;32m     49\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m               )\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2654\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25422,4096]\n\t [[Node: training_4/Adam/mul_2 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/sub_2, training_4/Adam/gradients/dense_9/MatMul_grad/MatMul_1)]]\n\nCaused by op 'training_4/Adam/mul_2', defined at:\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-441ae2bafe6d>\", line 3, in <module>\n    train_5_fold(train,test,param,vectorize='countVectorize',report_path='../../data/nn/report.csv')\n  File \"<ipython-input-4-bf54e6dd9e61>\", line 158, in train_5_fold\n    score,val_pred,holdout_preds,test_preds =  train_each_fold(param,fold,mode=vectorize,tolerance=2)\n  File \"<ipython-input-4-bf54e6dd9e61>\", line 114, in train_each_fold\n    model = train_each_epoch(x_train,y_train,train_batch,model)\n  File \"<ipython-input-4-bf54e6dd9e61>\", line 51, in train_each_epoch\n    verbose=1,\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\", line 1008, in fit\n    self._make_train_function()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\", line 498, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/optimizers.py\", line 491, in get_updates\n    m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[25422,4096]\n\t [[Node: training_4/Adam/mul_2 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_4/Adam/sub_2, training_4/Adam/gradients/dense_9/MatMul_grad/MatMul_1)]]\n"
     ]
    }
   ],
   "source": [
    "for param in param_list:\n",
    "    print(param)\n",
    "    train_5_fold(train,test,param,vectorize='countVectorize',report_path='../../data/nn/report.csv')\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T16:35:44.157665Z",
     "start_time": "2018-09-24T15:48:02.004Z"
    }
   },
   "outputs": [],
   "source": [
    "report_path='../../data/nn/report.csv'\n",
    "saved_report = pd.read_csv(report_path)\n",
    "saved_report1 = pd.read_csv(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T16:35:44.158678Z",
     "start_time": "2018-09-24T15:48:02.009Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([saved_report,saved_report1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T16:35:44.159419Z",
     "start_time": "2018-09-24T15:48:02.012Z"
    }
   },
   "outputs": [],
   "source": [
    "new_report = pd.DataFrame({'fileName':['123.csv'],\n",
    "                               'cv_mean':[0.23232],\n",
    "                               'holdout':[0.12121]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T16:35:44.160141Z",
     "start_time": "2018-09-24T15:48:02.016Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat([saved_report,new_report]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
