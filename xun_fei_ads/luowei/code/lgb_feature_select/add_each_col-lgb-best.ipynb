{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:45:26.410921Z",
     "start_time": "2018-09-28T15:45:26.043438Z"
    }
   },
   "outputs": [],
   "source": [
    "__file__=''\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../LIB/'))\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../../../../automl/automl_libs/'))\n",
    "from env import FILE\n",
    "import utils\n",
    "from itertools import combinations\n",
    "from feature_engineering import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "from sklearn.metrics import log_loss\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:45:38.655258Z",
     "start_time": "2018-09-28T15:45:38.241259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: (1001650, 71)\n",
      "test shape is: (40024, 70)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle('../../data/lgb_feature/train_lgb_baseline.pkl')\n",
    "print('train shape is: {}'.format(train.shape))\n",
    "test = pd.read_pickle('../../data/lgb_feature/test_lgb_baseline.pkl')\n",
    "print('test shape is: {}'.format(test.shape))\n",
    "tags = pd.read_pickle('../../data/lgb_feature/tags_gesim_window3_size10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:45:45.339440Z",
     "start_time": "2018-09-28T15:45:43.100013Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:01<00:00, 61.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: (1001650, 76)\n",
      "test shape is: (40024, 75)\n"
     ]
    }
   ],
   "source": [
    "all_cols = list(train.columns)\n",
    "for col in tqdm(all_cols):\n",
    "    if 'tags' in col:\n",
    "        train.drop(col,axis=1,inplace=True)\n",
    "        test.drop(col,axis=1,inplace=True)\n",
    "train = train.merge(tags,how='inner',on='instance_id')\n",
    "print('train shape is: {}'.format(train.shape))\n",
    "test = test.merge(tags,how='inner',on='instance_id')\n",
    "print('test shape is: {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:45:49.348898Z",
     "start_time": "2018-09-28T15:45:48.694755Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print_to_file = False \n",
    "test_run = False \n",
    "\n",
    "def get_time(timezone='America/New_York', time_format='%Y-%m-%d %H:%M:%S'):\n",
    "    from datetime import datetime\n",
    "    from dateutil import tz\n",
    "\n",
    "    # METHOD 1: Hardcode zones:\n",
    "    from_zone = tz.gettz('UTC')\n",
    "    to_zone = tz.gettz(timezone)\n",
    "\n",
    "    utc = datetime.utcnow()\n",
    "\n",
    "    # Tell the datetime object that it's in UTC time zone since \n",
    "    # datetime objects are 'naive' by default\n",
    "    utc = utc.replace(tzinfo=from_zone)\n",
    "\n",
    "    # Convert time zone\n",
    "    est = utc.astimezone(to_zone)\n",
    "\n",
    "    return est.strftime(time_format)\n",
    "\n",
    "import sys, time\n",
    "class Logger(object):\n",
    "    def __init__(self, logtofile=True, logfilename='log'):\n",
    "        self.terminal = sys.stdout\n",
    "        self.logfile = \"{}_{}.log\".format(logfilename, int(time.time()))\n",
    "        self.logtofile = logtofile\n",
    "\n",
    "    def write(self, message):\n",
    "        #         self.terminal.write(message)\n",
    "        if self.logtofile:\n",
    "            self.log = open(self.logfile, \"a\")\n",
    "            self.log.write('[' + get_time() + '] ' + message)\n",
    "            self.log.close()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass\n",
    "\n",
    "\n",
    "def divert_printout_to_file():\n",
    "    sys.stdout = Logger(logfilename='logfile')\n",
    "\n",
    "if print_to_file:\n",
    "    divert_printout_to_file()  # note: comment this to use pdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, train_df, test_df, holdout, num_folds, submission_file_name, fe_img_name, stratified = False, debug= False, colsample=0.67, max_depth=8, num_leaves=31, min_child_samples=20, subsample=0.7, reg_lambda=0.3, lr=0.04, seed=1001, verbose=100, rounds=None, target='click'):\n",
    "    print(train_df.shape, test_df.shape, holdout.shape)\n",
    "    print('MEAN: train({}) vs holdout({}): '.format(len(train_df), len(holdout)), train_df[target].mean(), holdout[target].mean())\n",
    "    # Divide in training/validation and test data\n",
    "    if df is not None:\n",
    "        train_df = df[df[target].notnull()]\n",
    "        test_df = df[df[target].isnull()]\n",
    "        print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "        del df\n",
    "        gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "        \n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    holdout_final_preds = np.zeros(holdout.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feature_importance_gain_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in [target,'time','instance_id','index']]\n",
    "    train_scores = []\n",
    "    holdout_scores = []\n",
    "    scores = []\n",
    "    diff_val_holdout = []\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df[target])):\n",
    "#         print('valid index : ',list(valid_idx)[:5])\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df[target].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df[target].iloc[valid_idx]\n",
    "#         print('MEAN: train({}) vs valid({}): '.format(len(train_y), len(valid_y)), np.mean(train_y), np.mean(valid_y))\n",
    "\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=12,\n",
    "            n_estimators=30000,\n",
    "            learning_rate=lr,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "        if rounds is not None:\n",
    "            clf.n_estimators = rounds\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric= 'logloss', verbose=verbose)\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "            sub_preds += clf.predict_proba(test_df[feats])[:, 1] / folds.n_splits\n",
    "            holdout_preds = clf.predict_proba(holdout[feats])[:, 1] \n",
    "        else:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric= 'logloss', verbose=verbose, early_stopping_rounds= 200)\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "            sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "            holdout_preds = clf.predict_proba(holdout[feats], num_iteration=clf.best_iteration_)[:, 1] \n",
    "            \n",
    "        holdout_final_preds += holdout_preds / folds.n_splits\n",
    "        score = log_loss(valid_y, oof_preds[valid_idx])\n",
    "        train_score = clf.best_score_['training']['binary_logloss']\n",
    "        holdout_score = log_loss(holdout[target], holdout_preds)\n",
    "        diff = abs(score - holdout_score)\n",
    "        best_rounds = rounds if rounds is not None else clf.best_iteration_\n",
    "        print('Fold %2d [%5d] AUC : ho: %.6f / te: %.6f / tr: %.6f (diff: %.6f)' % (n_fold + 1, best_rounds, holdout_score, score,  train_score, diff))\n",
    "        scores.append(score)\n",
    "        train_scores.append(train_score)\n",
    "        holdout_scores.append(holdout_score)\n",
    "        diff_val_holdout.append(diff)\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        fold_importance_gain_df = pd.DataFrame()\n",
    "        fold_importance_gain_df[\"feature\"] = feats\n",
    "        fold_importance_gain_df[\"importance\"] = clf.booster_.feature_importance(importance_type='gain')\n",
    "        fold_importance_gain_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_gain_df = pd.concat([feature_importance_gain_df, fold_importance_gain_df], axis=0)\n",
    "        \n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "    holdout_roc = log_loss(holdout[target], holdout_final_preds)\n",
    "    holdout_mean = np.mean(holdout_scores)\n",
    "    full_te_mean = np.mean(scores)\n",
    "    full_tr_mean = np.mean(train_scores)\n",
    "#     print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    print('Full HO score %.6f' % holdout_roc)\n",
    "    print('FULL HO mean {:.6f}, std {:.6f}'.format(holdout_mean, np.std(holdout_scores)))\n",
    "    print('FULL TE mean {:.6f}, std {:.6f}'.format(full_te_mean, np.std(scores)))\n",
    "    print('FULL TR mean {:.6f}, std {:.6f}'.format(full_tr_mean, np.std(train_scores)))\n",
    "    print('FULL DIFF mean {:.6f}, std {:.6f}'.format(np.mean(diff_val_holdout), np.std(diff_val_holdout)))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        print('saving...')\n",
    "        test_df['predicted_score'] = sub_preds\n",
    "        test_df[['instance_id', 'predicted_score']].to_csv(submission_file_name, index= False)\n",
    "#     if not print_to_file:\n",
    "#         display_importances(feature_importance_df, fe_img_name)\n",
    "    feature_importance_df = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    feature_importance_gain_df = feature_importance_gain_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    return feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds,holdout_final_preds\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_, fe_img_name):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fe_img_name+'.png')\n",
    "\n",
    "\n",
    "def convert_and_save_imp_df(fe_imp_df, dumpfilename):\n",
    "    fe_imp_df_mean = fe_imp_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    pickle.dump(fe_imp_df_mean, open(dumpfilename,'wb'))\n",
    "    \n",
    "    \n",
    "\n",
    "def select_holdout(train,test,shift=1,seed=41):\n",
    "    samples_size = int(len(test) )\n",
    "    assert shift in range(1,8)\n",
    "    test_time_min = test.time.min()\n",
    "    test_time_max = test.time.max()\n",
    "    train_time_min = train.time.min()\n",
    "    train_time_max = train.time.max()\n",
    "    window_lower_bound = test_time_min - shift*60*60*24\n",
    "    window_upper_bound = test_time_max - shift*60*60*24\n",
    "    available_train = train[(train.time<=window_upper_bound) & (train.time>=window_lower_bound)]\n",
    "    holdout = available_train.sample(n=samples_size,random_state=seed).copy()\n",
    "    train_split_index = list(set(train.index) - set(holdout.index))\n",
    "    train_split = train.iloc[train_split_index].copy()\n",
    "    return train_split,holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:45:49.723707Z",
     "start_time": "2018-09-28T15:45:49.711691Z"
    }
   },
   "outputs": [],
   "source": [
    "def runlgb(train, test, holdout):\n",
    "    colsamples = [0.07]#[0.1,0.15,0.2]#[0.03,0.04,0.05,0.06,0.07,0.08]\n",
    "    seeds = [1001]#[300,4000,50000,600000,7000000,80000000,523445,31275479] # 20\n",
    "    depth = [5]\n",
    "    leaves = [16]\n",
    "    min_child_sam = [20]#, 800]\n",
    "    subsamples = [1]#0.8, 0.7, 0.6, 0.5, 0.4] # was 1\n",
    "    reg_lambdas = [0.5]\n",
    "    # lrs = lrs.tolist()\n",
    "    lrs2 = [0.1]\n",
    "    nfolds = 7\n",
    "    rounds = [None] #[1000]#, 1300, 1600, 1900, 2200, 2500]\n",
    "    for seed in seeds:\n",
    "        for colsample in colsamples:\n",
    "            for d in depth:\n",
    "                for l in leaves:\n",
    "                    for mcs in min_child_sam:\n",
    "                        for subsample in subsamples:\n",
    "                            for reg_lambda in reg_lambdas:\n",
    "                                for lr in lrs2:\n",
    "                                    for r in rounds:\n",
    "                                        filename = 'fe_936_col{}_lr{}_n{}'.format(len(train.columns), lr, nfolds)\n",
    "                                        print('#############################################')\n",
    "                                        print(colsample, seed, d, l, mcs, subsample, reg_lambda, lr, 'nfolds:', nfolds)\n",
    "                                        print('#############################################')\n",
    "                                        numfeats = len(train.columns)\n",
    "                                        with timer(\"Run LightGBM with kfold\"):\n",
    "                                            return kfold_lightgbm(None, train, test, holdout, nfolds, filename+'.csv', filename, colsample=colsample, verbose=None, max_depth=d, num_leaves=l, min_child_samples=mcs, subsample=subsample, reg_lambda=reg_lambda, lr=lr, seed=seed, stratified=True, rounds=r,debug=True)                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-28T15:47:50.989135Z",
     "start_time": "2018-09-28T15:45:50.715007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (961626, 76), holdout shape: (40024, 76)\n",
      "train mean: 0.19797613625255556, holdout mean: 0.21007395562662404\n",
      "#############################################\n",
      "0.07 1001 5 16 20 1 0.5 0.1 nfolds: 7\n",
      "#############################################\n",
      "(961626, 76) (40024, 75) (40024, 76)\n",
      "MEAN: train(961626) vs holdout(40024):  0.19797613625255556 0.21007395562662404\n",
      "Fold  1 [  381] AUC : ho: 0.427422 / te: 0.416178 / tr: 0.404988 (diff: 0.011245)\n",
      "Fold  2 [  324] AUC : ho: 0.426996 / te: 0.415898 / tr: 0.406488 (diff: 0.011098)\n",
      "Fold  3 [  335] AUC : ho: 0.427332 / te: 0.415563 / tr: 0.406436 (diff: 0.011769)\n",
      "Fold  4 [  342] AUC : ho: 0.427020 / te: 0.415926 / tr: 0.406064 (diff: 0.011094)\n",
      "Fold  5 [  376] AUC : ho: 0.426942 / te: 0.417014 / tr: 0.404837 (diff: 0.009928)\n",
      "Fold  6 [  379] AUC : ho: 0.427579 / te: 0.416557 / tr: 0.404855 (diff: 0.011022)\n",
      "Fold  7 [  328] AUC : ho: 0.427094 / te: 0.416177 / tr: 0.406420 (diff: 0.010917)\n",
      "Full HO score 0.426533\n",
      "FULL HO mean 0.427198, std 0.000227\n",
      "FULL TE mean 0.416187, std 0.000441\n",
      "FULL TR mean 0.405727, std 0.000734\n",
      "FULL DIFF mean 0.011010, std 0.000511\n",
      "Run LightGBM with kfold - done in 120s\n"
     ]
    }
   ],
   "source": [
    "train_index = pickle.load(open(FILE.train_index.value,'rb'))\n",
    "holdout_index = pickle.load(open(FILE.holdout_index.value,'rb'))\n",
    "train_df = train.loc[train_index].copy()\n",
    "holdout = train.loc[holdout_index].copy()\n",
    "print('train shape: {}, holdout shape: {}'.format(train_df.shape,holdout.shape))\n",
    "print('train mean: {}, holdout mean: {}'.format(train_df.click.mean(),holdout.click.mean()))\n",
    "split_all, gain_all,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds,holdout_preds = runlgb(train_df, test, holdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T00:35:03.687603Z",
     "start_time": "2018-09-24T00:35:03.558146Z"
    }
   },
   "outputs": [],
   "source": [
    "train_save = train[['instance_id']].copy()\n",
    "# train_save = pd.DataFrame()\n",
    "train_save.loc[train_df.index,'instance_id'] = train_df.instance_id.values\n",
    "train_save.loc[train_df.index,'predicted_score'] = oof_preds\n",
    "train_save.loc[holdout_index,'instance_id'] = holdout.instance_id.values\n",
    "train_save.loc[holdout_index,'predicted_score'] = holdout_preds\n",
    "\n",
    "train_save.to_pickle('../../data/oof/train/lgb_libFM_ho_81col.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-24T00:30:55.662329Z",
     "start_time": "2018-09-24T00:30:55.651421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86294719979897807</td>\n",
       "      <td>0.321591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2699289844928136052</td>\n",
       "      <td>0.412990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3117527168445845752</td>\n",
       "      <td>0.359213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3398484891050993371</td>\n",
       "      <td>0.028753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2035477570591176488</td>\n",
       "      <td>0.324440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           instance_id  predicted_score\n",
       "0    86294719979897807         0.321591\n",
       "1  2699289844928136052         0.412990\n",
       "2  3117527168445845752         0.359213\n",
       "3  3398484891050993371         0.028753\n",
       "4  2035477570591176488         0.324440"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_save.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
