{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T19:43:01.905596Z",
     "start_time": "2018-10-11T19:43:01.901847Z"
    }
   },
   "outputs": [],
   "source": [
    "__file__=''\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../LIB/'))\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../../../../automl/automl_libs/'))\n",
    "from env import FILE\n",
    "from keras.preprocessing import text, sequence\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T19:43:11.562942Z",
     "start_time": "2018-10-11T19:43:07.351262Z"
    }
   },
   "outputs": [],
   "source": [
    "tt = pd.read_pickle(FILE.train_final.value)\n",
    "te = pd.read_pickle(FILE.test_final.value)\n",
    "tt.drop('time_hour',axis = 1,inplace=True)\n",
    "te.drop('time_hour',axis = 1,inplace=True)\n",
    "da = pd.concat([tt, te], axis=0, ignore_index=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T19:44:47.297327Z",
     "start_time": "2018-10-11T19:43:23.483574Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3072915/3072915 [00:31<00:00, 98763.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2992639, 13611)\n"
     ]
    }
   ],
   "source": [
    "col = 'model'\n",
    "da[col] = da[col].astype(str)\n",
    "tt[col] = tt[col].astype(str)\n",
    "te[col] = te[col].astype(str)\n",
    "tok=text.Tokenizer(num_words=da[col].nunique(),lower=False)\n",
    "tok.fit_on_texts(list(da[col]))\n",
    "seq = tok.texts_to_sequences(list(da[col]))\n",
    "\n",
    "csr_save = sparse.lil_matrix((len(da),len(tok.index_word)+1))\n",
    "for row in tqdm(range(csr_save.shape[0])):\n",
    "    for col in seq[row]:\n",
    "        csr_save[row,col] += 1\n",
    "        \n",
    "csr_train = sparse.csr_matrix(csr_save[:len(tt),:])\n",
    "csr_test = sparse.csr_matrix(csr_save[len(tt):,:])\n",
    "print(csr_train.shape)\n",
    "col = 'model'\n",
    "pickle.dump(csr_train,open(FILE.one_hot_train_formatter.value.format(col),'wb'))\n",
    "pickle.dump(csr_test,open(FILE.one_hot_test_formatter.value.format(col),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2 - original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:59:24.887591Z",
     "start_time": "2018-10-11T20:59:14.954907Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "tt = pd.read_pickle(FILE.train_final.value)\n",
    "te = pd.read_pickle(FILE.test_final.value)\n",
    "tt.drop('time_hour',axis = 1,inplace=True)\n",
    "te.drop('time_hour',axis = 1,inplace=True)\n",
    "da = pd.concat([tt, te], axis=0, ignore_index=True,sort=False)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "da = da.fillna(-1)\n",
    "special = ['model']\n",
    "for i in special:\n",
    "    da[i] = da[i].map(dict(zip(da[i].unique(), range(0, da[i].nunique()))))\n",
    "tt_x = da[special].iloc[:len(tt)].copy()\n",
    "te_x = da[special].iloc[len(tt):].copy()\n",
    "for feature in tqdm(special):\n",
    "\n",
    "    print('build new')\n",
    "\n",
    "    enc.fit(da[feature].values.reshape(-1, 1))\n",
    "    onehot_train = enc.transform(tt_x[feature].values.reshape(-1, 1))\n",
    "    onehot_test = enc.transform(te_x[feature].values.reshape(-1, 1))\n",
    "    pickle.dump(onehot_train,open(FILE.one_hot_train_formatter.value.format(feature),'wb'))\n",
    "    pickle.dump(onehot_test,open(FILE.one_hot_test_formatter.value.format(feature),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V3 - clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:40:53.371580Z",
     "start_time": "2018-10-11T20:40:49.442574Z"
    }
   },
   "outputs": [],
   "source": [
    "tt = pd.read_pickle(FILE.train_final.value)\n",
    "te = pd.read_pickle(FILE.test_final.value)\n",
    "tt.drop('time_hour',axis = 1,inplace=True)\n",
    "te.drop('time_hour',axis = 1,inplace=True)\n",
    "da = pd.concat([tt, te], axis=0, ignore_index=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:41:00.747876Z",
     "start_time": "2018-10-11T20:40:55.514205Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pattern1=r'%2522|%(25){0,}2B|%20|%(25){0,}28|%(25){0,}29|%(25){0,}2C'\n",
    "#用空格替代连字符\"-或者+或者_\"\n",
    "pattern2=r'-{1,}|(?<=[a-zA-Z\\d])\\+{1,}\\s{0,}(?=[a-zA-Z\\d])|_{1,}'\n",
    "#两个以上的空格都替换成一个\n",
    "pattern3='\\s{2,}'\n",
    "#去掉括号\n",
    "pattern4='\\(|\\)'\n",
    "\n",
    "def reg(input_string):\n",
    "    if isinstance(input_string, str):\n",
    "        new_string=urllib.parse.unquote(input_string)\n",
    "#         new_string=re.sub(pattern1,' ',new_string)\n",
    "        new_string=re.sub(r' +',' ',new_string)\n",
    "#         new_string = re.sub(pattern2,' ',new_string)\n",
    "#         new_string = re.sub(pattern3,' ', new_string)\n",
    "#         new_string = re.sub(pattern4,'', new_string)\n",
    "        # 全部转为大写\n",
    "        new_string = new_string.upper()\n",
    "        if '%' in  new_string:\n",
    "            pass\n",
    "#             print(input_string,new_string)\n",
    "#             new_string=np.nan\n",
    "        return new_string\n",
    "    else:\n",
    "        # print(input_string)\n",
    "        return input_string\n",
    "\n",
    "da['model']=da['model'].astype(str).apply(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:41:08.812069Z",
     "start_time": "2018-10-11T20:41:02.903970Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build new\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "da = da.fillna(-1)\n",
    "special = ['model']\n",
    "for i in special:\n",
    "    da[i] = da[i].map(dict(zip(da[i].unique(), range(0, da[i].nunique()))))\n",
    "tt_x = da[special].iloc[:len(tt)].copy()\n",
    "te_x = da[special].iloc[len(tt):].copy()\n",
    "for feature in tqdm(special):\n",
    "\n",
    "    print('build new')\n",
    "\n",
    "    enc.fit(da[feature].values.reshape(-1, 1))\n",
    "    onehot_train = enc.transform(tt_x[feature].values.reshape(-1, 1))\n",
    "    onehot_test = enc.transform(te_x[feature].values.reshape(-1, 1))\n",
    "    pickle.dump(onehot_train,open(FILE.one_hot_train_formatter.value.format(feature),'wb'))\n",
    "    pickle.dump(onehot_test,open(FILE.one_hot_test_formatter.value.format(feature),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-11T20:58:38.321111Z",
     "start_time": "2018-10-11T20:56:22.073052Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tt = pd.read_pickle(FILE.train_final.value)\n",
    "te = pd.read_pickle(FILE.test_final.value)\n",
    "tt.drop('time_hour',axis = 1,inplace=True)\n",
    "te.drop('time_hour',axis = 1,inplace=True)\n",
    "da = pd.concat([tt, te], axis=0, ignore_index=True,sort=False)\n",
    "\n",
    "cv = CountVectorizer(min_df=1)\n",
    "    \n",
    "for feature in ['user_tags']:\n",
    "\n",
    "        da[feature] = da[feature].astype(str)\n",
    "        cv.fit(da[feature])\n",
    "        onehot_train = cv.transform(tt[feature].astype(str))\n",
    "        onehot_test = cv.transform(te[feature].astype(str))\n",
    "        pickle.dump(onehot_train,open(FILE.one_hot_train_formatter.value.format(feature),'wb'))\n",
    "        pickle.dump(onehot_test,open(FILE.one_hot_test_formatter.value.format(feature),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
