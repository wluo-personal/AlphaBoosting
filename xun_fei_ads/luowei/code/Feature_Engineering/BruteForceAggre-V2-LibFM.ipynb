{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:38:19.536050Z",
     "start_time": "2018-10-14T02:38:19.527595Z"
    }
   },
   "outputs": [],
   "source": [
    "__file__=''\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../LIB/'))\n",
    "sys.path.append(os.path.join(os.path.dirname(__file__),'../../../../automl/automl_libs/'))\n",
    "from env import FILE\n",
    "import utils\n",
    "from itertools import combinations\n",
    "from feature_engineering import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:15.321668Z",
     "start_time": "2018-10-14T02:35:11.872918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: (2992639, 36)\n",
      "test shape is: (80276, 35)\n",
      "(3072915, 36)\n",
      "(3072915, 36)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle(FILE.train_final.value)\n",
    "print('train shape is: {}'.format(train.shape))\n",
    "test = pd.read_pickle(FILE.test_final.value)\n",
    "print('test shape is: {}'.format(test.shape))\n",
    "\n",
    "X = pd.concat([train,test],sort=False)\n",
    "print(X.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1, change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:21.493934Z",
     "start_time": "2018-10-14T02:35:15.323177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.351760576479137\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    if X[col].dtype == 'float64':\n",
    "        X[col] = X[col].astype(utils.set_type(X[col],'float'))\n",
    "    if X[col].dtype == 'int64':\n",
    "        X[col] = X[col].astype(utils.set_type(X[col],'int'))\n",
    "        \n",
    "print(sys.getsizeof(X)/1024**3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4, drop those only has 1 unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:25.721119Z",
     "start_time": "2018-10-14T02:35:21.495720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creative_is_js', 'creative_is_voicead', 'app_paid']\n"
     ]
    }
   ],
   "source": [
    "drop_col = []\n",
    "for col in X.columns:\n",
    "    if X[col].nunique() == 1:\n",
    "        drop_col.append(col)\n",
    "        \n",
    "print(drop_col)\n",
    "\n",
    "X.drop(drop_col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:53.365647Z",
     "start_time": "2018-10-14T02:35:25.722996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:27<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "not_categorical = ['instance_id','time', 'datetime','click']\n",
    "categorical_cols = list(set(X.columns) - set(not_categorical))\n",
    "print(len(categorical_cols))\n",
    "\n",
    "\n",
    "for col in tqdm(categorical_cols):\n",
    "    if X[col].dtype == 'object':\n",
    "        X[col] = X[col].fillna('FillNAValue')\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "    else:\n",
    "        pass\n",
    "#         X[col] = X[col].fillna(-100000)\n",
    "#         X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:53.370835Z",
     "start_time": "2018-10-14T02:35:53.367871Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "userid_col = {\n",
    "'uid1':['model'],\n",
    "'uid2':['model','city','province'],\n",
    "'uid3':['model','make','os_name','osv','os']}\n",
    "\n",
    "userraw_col = {\n",
    "'uraw1':['app_id'],\n",
    "'uraw2':['carrier','nnt'],\n",
    "'uraw3':['app_cate_id','f_channel','app_id']}\n",
    "item_col = {\n",
    "'itemc1':['adid','creative_width','creative_height','inner_slot_id'],\n",
    "'itemc2':['adid','orderid','campaign_id','creative_id','creative_type','creative_tp_dnf','creative_width','creative_height','inner_slot_id'],\n",
    "'itemc3':['adid','advert_id','orderid','advert_industry_inner','advert_name','campaign_id','creative_id','creative_type','creative_tp_dnf','creative_width','creative_height']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:53.382979Z",
     "start_time": "2018-10-14T02:35:53.372997Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_new_name(cob_col,func):\n",
    "    return '+'.join(cob_col)+'_'+func.__name__\n",
    "\n",
    "def matrix_factorization(df_history, df, target, item_col, userid_col, userraw_col):\n",
    "    \"\"\"\n",
    "    userid_col is unique user id\n",
    "    item_col is unique itme id\n",
    "    userraw_col is used to construct user feature. dim: user_id*userraw\n",
    "    \"\"\"\n",
    "    dff = pd.DataFrame()\n",
    "    dff_history = pd.DataFrame()\n",
    "\n",
    "\n",
    "    #1. process item\n",
    "    if item_col is None:\n",
    "        dff['item'] = np.zeros(len(df))\n",
    "        dff_history['item'] = np.zeros(len(df_history))\n",
    "    else:\n",
    "        encoder = LabelEncoder()\n",
    "        group = get_group(df, item_col)\n",
    "        group_history = get_group(df_history, item_col)\n",
    "        encoder.fit(pd.concat([group, group_history]))\n",
    "        dff['item'] = encoder.transform(group)\n",
    "        dff_history['item'] = encoder.transform(group_history)\n",
    "#     print('processing item done!')\n",
    "\n",
    "    #2. user raw\n",
    "    group = get_group(df, userraw_col)\n",
    "    group_history = get_group(df_history, userraw_col)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    dff['userraw'] = encoder.transform(group)\n",
    "    dff_history['userraw'] = encoder.transform(group_history)\n",
    "#     print('processing user raw done')\n",
    "\n",
    "\n",
    "    #3. user_id\n",
    "    group = get_group(df, userid_col)\n",
    "    group_history = get_group(df_history, userid_col)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    dff['user_id'] = encoder.transform(group)\n",
    "    dff_history['user_id'] = encoder.transform(group_history)\n",
    "#     print('processing user id done')\n",
    "\n",
    "\n",
    "\n",
    "    num_users = max(dff.user_id.max(), dff_history.user_id.max()) + 1\n",
    "    num_items = max(dff.item.max(), dff_history.item.max()) + 1\n",
    "    num_userraw = max(dff.userraw.max(), dff_history.userraw.max()) + 1\n",
    "\n",
    "    M = coo_matrix(\n",
    "            (df_history[target], ( dff_history.user_id, dff_history.item)),\n",
    "            shape=(num_users, num_items)\n",
    "        )\n",
    "\n",
    "    user_features = pd.concat([dff, dff_history])[['userraw', 'user_id']].drop_duplicates()\n",
    "\n",
    "    user_features = coo_matrix(\n",
    "        (np.ones(len(user_features)), (user_features.user_id, user_features.userraw)),\n",
    "        shape=(num_users, num_userraw)\n",
    "    )\n",
    "\n",
    "    user_features = sp.hstack([sp.eye(num_users), user_features])\n",
    "\n",
    "    model = LightFM(no_components=50, learning_rate=0.1)\n",
    "    print('fitting lightFM')\n",
    "    model.fit(\n",
    "            M, \n",
    "            epochs=2, \n",
    "            num_threads=18, \n",
    "            user_features=user_features,\n",
    "        )\n",
    "    print('predicting lightFM')\n",
    "    result = model.predict(\n",
    "        dff.user_id.values, \n",
    "        dff.item.values, \n",
    "        user_features=user_features,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_group(df,cols):\n",
    "    group = df[cols[0]].astype(str).copy()\n",
    "    for col in cols[1:]:\n",
    "        group += '_' + df[col].astype(str)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:53.392868Z",
     "start_time": "2018-10-14T02:35:53.384649Z"
    }
   },
   "outputs": [],
   "source": [
    "# ss = matrix_factorization(train,train,'click',\n",
    "#                      item_col=ads_list[3],\n",
    "#                      userid_col=['model'],userraw_col=user_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:53.684587Z",
     "start_time": "2018-10-14T02:35:53.394436Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_length = len(train)\n",
    "train = X.iloc[:train_length].copy()\n",
    "test = X.iloc[train_length:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T07:52:15.521862Z",
     "start_time": "2018-10-14T03:08:02.199621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####0  uid1+uraw1+itemc1_matrix_factorization\n",
      "####0  uid1+uraw1+itemc2_matrix_factorization\n",
      "####0  uid1+uraw1+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####1  uid1+uraw2+itemc1_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####2  uid1+uraw2+itemc2_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####3  uid1+uraw2+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####4  uid1+uraw3+itemc1_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####5  uid1+uraw3+itemc2_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####6  uid1+uraw3+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####7  uid2+uraw1+itemc1_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####8  uid2+uraw1+itemc2_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####9  uid2+uraw1+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####10  uid2+uraw2+itemc1_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####11  uid2+uraw2+itemc2_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####12  uid2+uraw2+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####13  uid2+uraw3+itemc1_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####14  uid2+uraw3+itemc2_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####15  uid2+uraw3+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####16  uid3+uraw1+itemc1_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####17  uid3+uraw1+itemc2_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####18  uid3+uraw1+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####19  uid3+uraw2+itemc1_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####20  uid3+uraw2+itemc2_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####21  uid3+uraw2+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####22  uid3+uraw3+itemc1_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####23  uid3+uraw3+itemc2_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "####24  uid3+uraw3+itemc3_matrix_factorization\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "fitting lightFM\n",
      "predicting lightFM\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "seed = 19\n",
    "skf = StratifiedKFold(n_splits=n_fold, random_state=seed, shuffle=True)\n",
    "try:\n",
    "    X_train = pd.read_pickle(FILE.X_fe_train_libfm.value)\n",
    "    X_test = pd.read_pickle(FILE.X_fe_test_libfm.value)\n",
    "except:\n",
    "    print('no libfm feature found. create new one')\n",
    "    X_train = pd.DataFrame()\n",
    "    X_train['instance_id'] = train['instance_id'].values\n",
    "    X_test = pd.DataFrame()\n",
    "    X_test['instance_id'] = test['instance_id'].values\n",
    "count = 0\n",
    "for uid in userid_col:\n",
    "    for uraw in userraw_col:\n",
    "        for ic in item_col:\n",
    "            test_list = []\n",
    "            feature_name = get_new_name((uid,uraw,ic),matrix_factorization)\n",
    "            print('####{}  {}'.format(count,feature_name))\n",
    "            if feature_name in X_train.columns and feature_name in X_test.columns:\n",
    "                continue\n",
    "            X_train[feature_name] = np.nan\n",
    "            X_test[feature_name] = np.nan\n",
    "            for t,v in skf.split(train, train.click):\n",
    "                history = train.loc[t].copy()\n",
    "                val = train.loc[v].copy()\n",
    "                df_now = pd.concat([val,test],sort=False)\n",
    "                ppreds = matrix_factorization(history,df_now,target='click',\n",
    "                                                     item_col=item_col[ic],\n",
    "                                                     userid_col=userid_col[uid],\n",
    "                                                     userraw_col=userraw_col[uraw])\n",
    "\n",
    "                test_preds = ppreds[len(val):]\n",
    "                test_list.append(test_preds)\n",
    "                val_preds = ppreds[:len(val)]\n",
    "                \n",
    "#                 holdout_preds = matrix_factorization(history,holdout,target='click',\n",
    "#                                                      item_col=item_col[ic],\n",
    "#                                                      userid_col=userid_col[uid],\n",
    "#                                                      userraw_col=userraw_col[uraw])\n",
    "#                 holdout_preds_list.append(holdout_preds)\n",
    "#                 test_preds = matrix_factorization(history,test,target='click',\n",
    "#                                                      item_col=item_col[ic],\n",
    "#                                                      userid_col=userid_col[uid],\n",
    "#                                                      userraw_col=userraw_col[uraw])\n",
    "#                 test_list.append(test_preds)\n",
    "#                 val_preds = matrix_factorization(history,val,target='click',\n",
    "#                                                      item_col=item_col[ic],\n",
    "#                                                      userid_col=userid_col[uid],\n",
    "#                                                      userraw_col=userraw_col[uraw])\n",
    "                X_train.loc[v,feature_name] = val_preds\n",
    "            test_list = np.array(test_list)\n",
    "            test_preds_final = np.mean(test_list,axis=0)\n",
    "            X_test[feature_name] = test_preds_final\n",
    "            X_train.to_pickle(FILE.X_fe_train_libfm.value)\n",
    "            X_test.to_pickle(FILE.X_fe_test_libfm.value)\n",
    "            count+=1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:53.964919Z",
     "start_time": "2018-10-14T02:35:11.477Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    X_train = pd.read_pickle(FILE.X_fe_train_libfm.value)\n",
    "    X_test = pd.read_pickle(FILE.X_fe_test_libfm.value)\n",
    "except:\n",
    "    print('no libfm feature found. create new one')\n",
    "    X_train = pd.DataFrame()\n",
    "    X_train['instance_id'] = train['instance_id'].values\n",
    "    X_test = pd.DataFrame()\n",
    "    X_test['instance_id'] = test['instance_id'].values\n",
    "count = 0\n",
    "for uid in userid_col:\n",
    "    for uraw in userraw_col:\n",
    "        for ic in item_col:\n",
    "            holdout_preds_list = []\n",
    "            test_list = []\n",
    "            feature_name = get_new_name((uid,uraw,ic),matrix_factorization)\n",
    "            print('####{}  {}'.format(count,feature_name))\n",
    "            if feature_name in X_train.columns and feature_name in X_test.columns:\n",
    "                continue\n",
    "            X_train[feature_name] = np.nan\n",
    "            X_test[feature_name] = np.nan\n",
    "            for fold,(v,t) in day_index.items():\n",
    "                history = train.loc[t].copy()\n",
    "                holdout = train.loc[holdout_index].copy()\n",
    "                val = train.loc[v].copy()\n",
    "                df_now = pd.concat([val,holdout,test],sort=False)\n",
    "                ppreds = matrix_factorization(history,df_now,target='click',\n",
    "                                                     item_col=item_col[ic],\n",
    "                                                     userid_col=userid_col[uid],\n",
    "                                                     userraw_col=userraw_col[uraw])\n",
    "                holdout_preds = ppreds[len(val):len(val)+len(holdout)]\n",
    "                holdout_preds_list.append(holdout_preds)\n",
    "                test_preds = ppreds[len(val)+len(holdout):]\n",
    "                test_list.append(test_preds)\n",
    "                val_preds = ppreds[:len(val)]\n",
    "                \n",
    "#                 holdout_preds = matrix_factorization(history,holdout,target='click',\n",
    "#                                                      item_col=item_col[ic],\n",
    "#                                                      userid_col=userid_col[uid],\n",
    "#                                                      userraw_col=userraw_col[uraw])\n",
    "#                 holdout_preds_list.append(holdout_preds)\n",
    "#                 test_preds = matrix_factorization(history,test,target='click',\n",
    "#                                                      item_col=item_col[ic],\n",
    "#                                                      userid_col=userid_col[uid],\n",
    "#                                                      userraw_col=userraw_col[uraw])\n",
    "#                 test_list.append(test_preds)\n",
    "#                 val_preds = matrix_factorization(history,val,target='click',\n",
    "#                                                      item_col=item_col[ic],\n",
    "#                                                      userid_col=userid_col[uid],\n",
    "#                                                      userraw_col=userraw_col[uraw])\n",
    "                X_train.loc[v,feature_name] = val_preds\n",
    "            holdout_preds_list = np.array(holdout_preds_list)\n",
    "            test_list = np.array(test_list)\n",
    "            holdout_preds_final = np.mean(holdout_preds_list,axis=0)\n",
    "            test_preds_final = np.mean(test_list,axis=0)\n",
    "            X_train.loc[holdout_index,feature_name] = holdout_preds_final\n",
    "            X_test[feature_name] = test_preds_final\n",
    "            X_train.to_pickle(FILE.X_fe_train_libfm.value)\n",
    "            X_test.to_pickle(FILE.X_fe_test_libfm.value)\n",
    "            count+=1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T02:35:53.966147Z",
     "start_time": "2018-10-14T02:35:11.483Z"
    }
   },
   "outputs": [],
   "source": [
    "history['click']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
