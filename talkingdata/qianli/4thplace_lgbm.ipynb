{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:37:20.513981Z",
     "start_time": "2018-05-23T15:37:20.509310Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:38:25.597847Z",
     "start_time": "2018-05-23T15:37:21.622179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sup read done\n",
      "slicing without correction done\n",
      "(18790469, 106)\n"
     ]
    }
   ],
   "source": [
    "# Load test_sup and find index\n",
    "/home/kai/data/kaggle/homecredit\n",
    "load_path = '/home/kai/data/kaggle/talkingdata/downsampling/'                     \n",
    "test_supplement = pd.read_feather(load_path + 'test_cleaned.ftr')\n",
    "print('sup read done')\n",
    "test_index = np.load('/home/kai/data/kaggle/talkingdata/data/supplement2testInexFinal.npy')\n",
    "print('slicing without correction done')\n",
    "test = test_supplement.iloc[test_index]\n",
    "print(test.shape)\n",
    "\n",
    "# # Test_id correction\n",
    "# test_clickid = pd.read_csv('/home/kai/data/kaggle/talkingdata/data/test.csv', usecols=['click_id'])\n",
    "# print('test_clickid done')\n",
    "# test['click_id'] = test_clickid['click_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:38:58.353730Z",
     "start_time": "2018-05-23T15:38:58.350865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57537505, 106)\n"
     ]
    }
   ],
   "source": [
    "print(test_supplement.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:40:09.757924Z",
     "start_time": "2018-05-23T15:39:30.992392Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "train(downsampled) done\n",
      "val done\n"
     ]
    }
   ],
   "source": [
    "load_path = '/home/kai/data/kaggle/talkingdata/downsampling/'\n",
    "file_format = '{}.ftr'\n",
    "train_dict = {}\n",
    "train_indexlist = ['0', '1', '2', '3', '4']\n",
    "    \n",
    "for file in train_indexlist:\n",
    "    print(file)\n",
    "    train_dict[file] = pd.read_feather(load_path + file_format.format(file))\n",
    "    \n",
    "print('train(downsampled) done')\n",
    "val = pd.read_feather(load_path + 'val.ftr')\n",
    "print('val done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T15:40:53.721360Z",
     "start_time": "2018-05-23T15:40:53.718493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(794952, 106)\n"
     ]
    }
   ],
   "source": [
    "print((train_dict['0'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T18:59:13.482402Z",
     "start_time": "2018-05-23T18:59:13.434877Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "['app', 'device', 'os', 'channel', 'day', 'hour', 'minute', 'hourminute', 'nunique_day_ip_app', 'woe_ip_channel_nextClickLeakDayFlt', 'woe_app_device_nextClickLeakDayFlt', 'variance_ip_device_hour', 'woe_ip_app', 'count_ip_app_os_channel_day', 'woe_ip_nextClickLeakDayFlt', 'com1_ip', 'woe_app_channel', 'woe_ip_app_device_os', 'nunique_day_ip_machine', 'rang_count_ip_device_os_dayhourminute', 'count_ratio_channel_app', 'woe_os_channel_nextClickLeakDayFlt', 'woe_app_device_channel', 'woe_os_nextClickLeakDayFlt', 'woe_channel', 'count_ip', 'woe_app_device', 'woe_app_os', 'woe_app_device_os', 'woe_ip_device_os', 'woe_app_device_os_channel', 'rang_count_ip_day', 'nunique_machine_channel', 'woe_ip', 'count_ip_app_device_day', 'cumcount_ip_day', 'rang_count_ip_hour', 'cumcount_ip_app_device_os_day_hour', 'rang_count_ip_channel_dayhourminute10', 'nunique_day_ip_os', 'woe_ip_device_channel', 'woe_ip_app_device', 'count_app_os_channel_day_hour', 'woe_device_channel_nextClickLeakDayFlt', 'cumcount_ratio_ip_day', 'woe_ip_device_nextClickLeakDayFlt', 'count_app_device_channel_day_hour', 'woe_app_nextClickLeakDayFlt', 'woe_ip_app_channel', 'rang_count_app_os_channel_dayhourminute', 'woe_app_os_channel', 'cumcount_app_device_os_day', 'rang_count_ip_channel_dayhourminute', 'nunique_day_ip_channel', 'nunique_machine_ip', 'count_ratio_ip_machine', 'woe_ip_os', 'woe_device_nextClickLeakDayFlt', 'rang_count_ip_dayhourminute10', 'rang_count_app_os_channel_dayhourminute10', 'woe_device', 'woe_app', 'rang_count_ip_dayhourminute', 'woe_ip_os_channel', 'count_device_os_day_hourminute10', 'woe_ip_channel', 'count_ratio_machine_ip', 'filter_time_to_n_next_click_2_day_ip_app_device_os', 'woe_channel_nextClickLeakDayFlt', 'time_to_n_next_click_2_day_ip_app_device_os', 'time_to_n_next_click_1_day_ip_app_device_os', 'woe_app_channel_nextClickLeakDayFlt', 'count_ip_app_device_os_day_hour', 'woe_device_os_nextClickLeakDayFlt', 'count_ip_app_device_channel_day', 'woe_ip_app_nextClickLeakDayFlt', 'rang_count_ip_device_os_dayhourminute10', 'woe_app_os_nextClickLeakDayFlt', 'woe_ip_os_nextClickLeakDayFlt', 'filter_time_to_n_next_click_1_day_ip_app_device_os', 'com_ip', 'count_ratio_app_channel', 'count_app_device_day_hour', 'woe_ip_app_os_channel', 'nunique_machine_app', 'woe_ip_app_os', 'nunique_day_ip_device', 'woe_ip_device_os_channel', 'woe_os', 'count_ip_device_os_day_hourminute10', 'count_ip_app_os_channel', 'count_ratio_ip_channel', 'woe_ip_device', 'woe_ip_app_device_channel']\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "target = 'is_attributed'\n",
    "\n",
    "combine = 0\n",
    "\n",
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_rounds': 4000,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 61,\n",
    "        'num_threads': 16, # best speed: set to number of real cpu cores, which is vCPU/2\n",
    "        'device': 'cpu',\n",
    "        'max_depth': -1, # no limit. This is used to deal with over-fitting when #data is small.\n",
    "        'min_data_in_leaf': 390,  #minimal number of data in one leaf. Can be used to deal with over-fitting\n",
    "        'feature_fraction': 0.7, #For example, if set to 0.8, will select 80% features before training each tree.  speed up training / deal with over-fitting\n",
    "        'feature_fraction_seed': 1,\n",
    "        'early_stopping_round':60,\n",
    "        'bagging_fraction': 0.7, #Randomly select part of data without resampling\n",
    "        'bagging_freq': 1, #frequency for bagging, 0 means disable bagging. k means will perform bagging at every k iteration. to enable bagging, bagging_fraction should be set as well\n",
    "        'bagging_seed': 1,\n",
    "        'verbose': 0,\n",
    "        'scale_pos_weight': 1,\n",
    "        'metric' : [ 'auc']\n",
    "    }\n",
    "\n",
    "# params = {\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'colsample_bytree':0.39,\n",
    "#     'learning_rate': 0.05,\n",
    "#     'max_bin': 305,\n",
    "#     'metric': ['auc'], ##\n",
    "#     'min_child_samples': 20,\n",
    "#     'min_child_weight': 5,\n",
    "#     'min_split_gain': 0,\n",
    "#     'num_threads': 16,\n",
    "#     'num_leaves': 74,\n",
    "#     'objective':'binary',\n",
    "#     'reg_alpha':0,\n",
    "#     'reg_lambda':0.5,\n",
    "#     'scale_pos_weight': 1,\n",
    "#     'subsample':1.0,\n",
    "#     'subsample_for_bin':200000,\n",
    "#     'subsample_freq':1,\n",
    "#     'verbose':0,\n",
    "#     'num_boost_round': 2000,\n",
    "#     'early_stopping_round': 100,\n",
    "#     'verbose_eval': 10\n",
    "    \n",
    "#     }\n",
    "# categorical_col = ['os', 'hour', 'device', 'channel', 'app', 'com1_ip']\n",
    "categorical_col = [ 'app', 'device', 'os', 'channel', 'hour']\n",
    "feature_cols = list(test.columns.values)\n",
    "print(len(feature_cols))\n",
    "remove_list = ['index', 'ip', 'click_id', 'click_time', 'is_test', 'minute10', 'hourminute10', 'dayhourminute', 'dayhourminute10',\\\n",
    "              'machine', 'click_timestamp', target]\n",
    "feature_cols = [x for x in feature_cols if x not in remove_list]\n",
    "print(feature_cols)\n",
    "print(len(feature_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T18:59:36.121269Z",
     "start_time": "2018-05-23T18:59:36.094686Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lightgbm(x_train, x_val, feature_cols, categorical_feature, params, best_round = None, target='is_attributed'):\n",
    "    param = params.copy()\n",
    "    y_train = x_train[target].values\n",
    "    y_val = x_val[target].values\n",
    "    \n",
    "    lgb_train = lgb.Dataset(x_train[feature_cols], y_train, categorical_feature = categorical_feature)\n",
    "    lgb_val = lgb.Dataset(x_val[feature_cols], y_val, categorical_feature = categorical_feature)\n",
    "#     if best_round is not None:\n",
    "#         param['num_rounds'] = best_round\n",
    "#         del param['early_stopping_round']\n",
    "    print('start training')\n",
    "    model = lgb.train(param, train_set=lgb_train, valid_sets=lgb_val, verbose_eval=10)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T19:49:44.878154Z",
     "start_time": "2018-05-23T18:59:57.137496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:104: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:668: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 60 rounds.\n",
      "[10]\tvalid_0's auc: 0.981794\n",
      "[20]\tvalid_0's auc: 0.983339\n",
      "[30]\tvalid_0's auc: 0.984358\n",
      "[40]\tvalid_0's auc: 0.985049\n",
      "[50]\tvalid_0's auc: 0.985391\n",
      "[60]\tvalid_0's auc: 0.985628\n",
      "[70]\tvalid_0's auc: 0.985862\n",
      "[80]\tvalid_0's auc: 0.985982\n",
      "[90]\tvalid_0's auc: 0.98608\n",
      "[100]\tvalid_0's auc: 0.986106\n",
      "[110]\tvalid_0's auc: 0.986112\n",
      "[120]\tvalid_0's auc: 0.986115\n",
      "[130]\tvalid_0's auc: 0.986099\n",
      "[140]\tvalid_0's auc: 0.986094\n",
      "[150]\tvalid_0's auc: 0.986123\n",
      "[160]\tvalid_0's auc: 0.986098\n",
      "[170]\tvalid_0's auc: 0.986087\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's auc: 0.986146\n",
      "0thmodel trained\n",
      "1\n",
      "start training\n",
      "Training until validation scores don't improve for 60 rounds.\n",
      "[10]\tvalid_0's auc: 0.98193\n",
      "[20]\tvalid_0's auc: 0.983328\n",
      "[30]\tvalid_0's auc: 0.984365\n",
      "[40]\tvalid_0's auc: 0.985016\n",
      "[50]\tvalid_0's auc: 0.985368\n",
      "[60]\tvalid_0's auc: 0.985588\n",
      "[70]\tvalid_0's auc: 0.98576\n",
      "[80]\tvalid_0's auc: 0.985841\n",
      "[90]\tvalid_0's auc: 0.985925\n",
      "[100]\tvalid_0's auc: 0.985953\n",
      "[110]\tvalid_0's auc: 0.985977\n",
      "[120]\tvalid_0's auc: 0.986007\n",
      "[130]\tvalid_0's auc: 0.986008\n",
      "[140]\tvalid_0's auc: 0.986034\n",
      "[150]\tvalid_0's auc: 0.986066\n",
      "[160]\tvalid_0's auc: 0.986084\n",
      "[170]\tvalid_0's auc: 0.986087\n",
      "[180]\tvalid_0's auc: 0.986067\n",
      "[190]\tvalid_0's auc: 0.986071\n",
      "[200]\tvalid_0's auc: 0.986072\n",
      "[210]\tvalid_0's auc: 0.986069\n",
      "[220]\tvalid_0's auc: 0.986054\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.986091\n",
      "1thmodel trained\n",
      "2\n",
      "start training\n",
      "Training until validation scores don't improve for 60 rounds.\n",
      "[10]\tvalid_0's auc: 0.982016\n",
      "[20]\tvalid_0's auc: 0.983366\n",
      "[30]\tvalid_0's auc: 0.984267\n",
      "[40]\tvalid_0's auc: 0.98497\n",
      "[50]\tvalid_0's auc: 0.985368\n",
      "[60]\tvalid_0's auc: 0.985572\n",
      "[70]\tvalid_0's auc: 0.985789\n",
      "[80]\tvalid_0's auc: 0.985838\n",
      "[90]\tvalid_0's auc: 0.985947\n",
      "[100]\tvalid_0's auc: 0.986003\n",
      "[110]\tvalid_0's auc: 0.986019\n",
      "[120]\tvalid_0's auc: 0.986051\n",
      "[130]\tvalid_0's auc: 0.986069\n",
      "[140]\tvalid_0's auc: 0.98609\n",
      "[150]\tvalid_0's auc: 0.986114\n",
      "[160]\tvalid_0's auc: 0.986141\n",
      "[170]\tvalid_0's auc: 0.986146\n",
      "[180]\tvalid_0's auc: 0.986141\n",
      "[190]\tvalid_0's auc: 0.986152\n",
      "[200]\tvalid_0's auc: 0.986153\n",
      "[210]\tvalid_0's auc: 0.986166\n",
      "[220]\tvalid_0's auc: 0.986154\n",
      "[230]\tvalid_0's auc: 0.986153\n",
      "[240]\tvalid_0's auc: 0.986138\n",
      "[250]\tvalid_0's auc: 0.986124\n",
      "[260]\tvalid_0's auc: 0.986113\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's auc: 0.986173\n",
      "2thmodel trained\n",
      "3\n",
      "start training\n",
      "Training until validation scores don't improve for 60 rounds.\n",
      "[10]\tvalid_0's auc: 0.981939\n",
      "[20]\tvalid_0's auc: 0.983404\n",
      "[30]\tvalid_0's auc: 0.984264\n",
      "[40]\tvalid_0's auc: 0.984985\n",
      "[50]\tvalid_0's auc: 0.985325\n",
      "[60]\tvalid_0's auc: 0.985478\n",
      "[70]\tvalid_0's auc: 0.985637\n",
      "[80]\tvalid_0's auc: 0.985737\n",
      "[90]\tvalid_0's auc: 0.985825\n",
      "[100]\tvalid_0's auc: 0.985853\n",
      "[110]\tvalid_0's auc: 0.985923\n",
      "[120]\tvalid_0's auc: 0.985951\n",
      "[130]\tvalid_0's auc: 0.985959\n",
      "[140]\tvalid_0's auc: 0.985962\n",
      "[150]\tvalid_0's auc: 0.986002\n",
      "[160]\tvalid_0's auc: 0.986017\n",
      "[170]\tvalid_0's auc: 0.986026\n",
      "[180]\tvalid_0's auc: 0.986019\n",
      "[190]\tvalid_0's auc: 0.986043\n",
      "[200]\tvalid_0's auc: 0.986029\n",
      "[210]\tvalid_0's auc: 0.986021\n",
      "[220]\tvalid_0's auc: 0.98602\n",
      "[230]\tvalid_0's auc: 0.986029\n",
      "[240]\tvalid_0's auc: 0.986005\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's auc: 0.986049\n",
      "3thmodel trained\n",
      "4\n",
      "start training\n",
      "Training until validation scores don't improve for 60 rounds.\n",
      "[10]\tvalid_0's auc: 0.981669\n",
      "[20]\tvalid_0's auc: 0.983323\n",
      "[30]\tvalid_0's auc: 0.984244\n",
      "[40]\tvalid_0's auc: 0.984894\n",
      "[50]\tvalid_0's auc: 0.985258\n",
      "[60]\tvalid_0's auc: 0.985512\n",
      "[70]\tvalid_0's auc: 0.985705\n",
      "[80]\tvalid_0's auc: 0.985819\n",
      "[90]\tvalid_0's auc: 0.985911\n",
      "[100]\tvalid_0's auc: 0.985942\n",
      "[110]\tvalid_0's auc: 0.986009\n",
      "[120]\tvalid_0's auc: 0.986011\n",
      "[130]\tvalid_0's auc: 0.986053\n",
      "[140]\tvalid_0's auc: 0.986066\n",
      "[150]\tvalid_0's auc: 0.986076\n",
      "[160]\tvalid_0's auc: 0.986075\n",
      "[170]\tvalid_0's auc: 0.98608\n",
      "[180]\tvalid_0's auc: 0.98607\n",
      "[190]\tvalid_0's auc: 0.986069\n",
      "[200]\tvalid_0's auc: 0.986063\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.986089\n",
      "4thmodel trained\n",
      "prediction done\n"
     ]
    }
   ],
   "source": [
    "pred = {}\n",
    "for i in train_indexlist:\n",
    "    print(i)\n",
    "    model = train_lightgbm(train_dict[i], val, feature_cols, categorical_col, params)\n",
    "    # best_round = model.best_iteration\n",
    "    print(i + 'th' +'model trained' )\n",
    "    # pred = model.predict(test)\n",
    "    pred[i] = model.predict(test[feature_cols])\n",
    "print('prediction done')\n",
    "# np.save(load_path+file_name, pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T19:51:02.450686Z",
     "start_time": "2018-05-23T19:51:00.693382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.21756248  0.01050822  0.00486002 ...,  0.08707854  0.03200448\n",
      "  0.00397106]\n"
     ]
    }
   ],
   "source": [
    "pred_blend = (pred['1'] + pred['0'] + pred['2'] + pred['3'] + pred['4'])/5\n",
    "print(pred_blend)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-23T19:53:52.216100Z",
     "start_time": "2018-05-23T19:51:23.652982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "predicting file done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prediction\n",
    "# df_test_raw = pd.read_feather('/home/kai/data/talkingdata/downsampling/test_cleaned.ftr')\n",
    "# print('loading file done!')\n",
    "# df_test_raw = pd.read_csv('/home/kai/talkingdata/data/test.csv')\n",
    "sub_dict = {}\n",
    "df_sub = pd.DataFrame()\n",
    "test_clickid = pd.read_csv('/home/kai/data/kaggle/talkingdata/data/test.csv', usecols=['click_id'])\n",
    "print('done')\n",
    "df_sub['click_id'] = test_clickid['click_id']\n",
    "df_sub['is_attributed'] = pred_blend\n",
    "print('predicting file done!')\n",
    "df_sub.to_csv('/home/kai/data/kaggle/talkingdata/downsampling/4th_subblend1.csv.gz', compression='gzip', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-23T15:36:56.297Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sub.to_csv('/home/kai/data/kaggle/talkingdata/downsampling/4th_sub.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-23T15:36:56.433Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = df_sub.head(10)\n",
    "# a = df_sub.sort_values(by=['click_id'])\n",
    "\n",
    "# df_sub.to_csv('/home/kai/data/kaggle/talkingdata/downsampling/4th_sub.csv.gz', compression='gzip', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-23T15:36:56.579Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "xxx = pd.read_csv('/home/kai/data/kaggle/talkingdata/downsampling/4th_sub.csv.gz')\n",
    "print('done')\n",
    "test_clickid = pd.read_csv('/home/kai/data/kaggle/talkingdata/data/test.csv', usecols=['click_id'])\n",
    "print('done')\n",
    "xxx['click_id'] = test_clickid['click_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T13:40:15.191534Z",
     "start_time": "2018-05-22T13:37:55.158285Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xxx.to_csv('/home/kai/data/kaggle/talkingdata/downsampling/4th_sub.csv.gz', compression='gzip', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
