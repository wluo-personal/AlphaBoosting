{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jiangning WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/kai/talkingdata/data/'\n",
    "train = pd.read_feather(path + 'jchen/train_cleaned_final.ftr')\n",
    "test = pd.read_feather(path + 'jchen/test_supplement_cleaned_final.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Train on Day7 Day8 Day9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_hour = pd.read_csv(path+'hourdistri.csv', index_col='Unnamed: 0')\n",
    "index = {}\n",
    "for day in ['day7', 'day8','day9']:\n",
    "    index[day] = list(np.load(path+'{}_index.npy'.format(day)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Equal Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_hour = pd.read_csv(path+'hourdistri.csv', index_col='Unnamed: 0')\n",
    "# index = {}\n",
    "# for day in ['day7', 'day8','day9']:\n",
    "#     index[day] = list(range(df_hour.loc[day,'4start'], df_hour.loc[day,'6end0sec'])) + \\\n",
    "#     list(range(df_hour.loc[day,'9start'], df_hour.loc[day,'11end0sec'])) + \\\n",
    "#     list(range(df_hour.loc[day,'13start'], df_hour.loc[day,'15end0sec'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'is_attributed'\n",
    "feature_count =  [\n",
    "                    'ip_day_hour_count',\n",
    "                    'ip_os_day_hour_count',\n",
    "                    'ip_app_day_hour_count',\n",
    "                    'ip_app_os_day_hour_count',\n",
    "                    'app_day_hour_count',\n",
    "                    'ip_device_os_count',\n",
    "                    'ip_app_device_os_count']\n",
    "\n",
    "\n",
    "feature_mean = ['ip_device_os_mean',\n",
    "                'ip_app_device_os_mean', 'ip_app_device_mean', 'app_device_os_mean']\n",
    "\n",
    "\n",
    "\n",
    "feature_time2nextclick = ['ip_device_os_time2nextclick',\n",
    "                            'ip_app_device_os_time2nextclick',\n",
    "                          'ip_app_device_time2nextclick']\n",
    "\n",
    "feature_time2previousclick = ['ip_device_os_time2previousclick', \n",
    "                                'ip_app_device_os_time2previousclick', \n",
    "                              'ip_app_device_time2previousclick']\n",
    "    \n",
    "    \n",
    "feature_countfromfuture = ['ip_device_os_countfromfuture',\n",
    "                            'ip_app_device_os_countfromfuture', \n",
    "                           'ip_app_device_countfromfuture',]\n",
    "\n",
    "feature_countfrompast = ['ip_device_os_countfrompast',\n",
    "                            'ip_app_device_os_countfrompast', \n",
    "                         'ip_app_device_countfrompast']\n",
    "    \n",
    "feature_lasttimediff =  ['ip_device_os_lasttimediff',\n",
    "                             'ip_app_device_os_lasttimediff', \n",
    "                         'ip_app_device_lasttimediff']\n",
    "\n",
    "feature_firsttimediff =  ['ip_device_os_firsttimediff',\n",
    "                             'ip_app_device_os_firsttimediff', \n",
    "                         'ip_app_device_firsttimediff']\n",
    "\n",
    "\n",
    "feature_matrixfac = [ 'matrixFact_user_iposdeviceapp_item_app', \n",
    "                     'matrixFact_user_ip_item_appdeviceos',\n",
    "                    'matrixFact_user_ipchannel_item_appdeviceos', \n",
    "                     'matrixFact_user_ipappdeviceos_item_channel']\n",
    "\n",
    "\n",
    "\n",
    "feature_regression = ['ip_device_os_regression', \n",
    "                      'ip_app_device_os_regression', \n",
    "                      'ip_app_device_regression', 'ip_app_device_os_channel_regression']\n",
    "feature_regression = []\n",
    "\n",
    "feature_ori = ['app', 'channel', 'device', 'os', 'hour']\n",
    "\n",
    "feature_extra = ['attributed_timediff']\n",
    "feature_extra = []\n",
    "\n",
    "feature_cols = []\n",
    "added_feature = []\n",
    "\n",
    "added_feature.extend(feature_count)\n",
    "added_feature.extend(feature_mean)\n",
    "added_feature.extend(feature_time2nextclick)\n",
    "added_feature.extend(feature_time2previousclick)\n",
    "added_feature.extend(feature_countfromfuture)\n",
    "added_feature.extend(feature_countfrompast)\n",
    "added_feature.extend(feature_lasttimediff)\n",
    "added_feature.extend(feature_firsttimediff)\n",
    "added_feature.extend(feature_matrixfac)\n",
    "added_feature.extend(feature_regression)\n",
    "added_feature.extend(feature_extra)\n",
    "feature_cols.extend(added_feature)\n",
    "feature_cols.extend(feature_ori)\n",
    "\n",
    "train_cols = feature_cols.copy()\n",
    "train_cols.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(df_history, df_train, cols, target=None):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df.count the number of records for each feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    group_all = get_group(df_history, cols)\n",
    "    \n",
    "    count_map = group_all.value_counts()\n",
    "    \n",
    "    return group.map(count_map).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mean(df_history, df_train, cols, target):\n",
    "    \"\"\"\n",
    "    Purpose: add a new feature to training df. conditional probability P(replay (target) | feature combination (eg, artist_name_composer)) \n",
    "    \"\"\"\n",
    "  \n",
    "\n",
    "    group = get_group(df_train, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "    mean_map = df_history.groupby(group_history)[target].mean()\n",
    "    return group.map(mean_map).fillna(-0.01)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def time2nextclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    next_heard = {}\n",
    "    for g, t in zip(group, df_reverse[timecol]):\n",
    "        if g in next_heard:\n",
    "            result.append(next_heard[g] - t)\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        next_heard[g] = t\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def time2previousclick(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    group = get_group(df_train, cols)\n",
    "\n",
    "    last_heard = {}\n",
    "    for t, g in zip(df_train[timecol], group):\n",
    "        if g in last_heard:\n",
    "            result.append(t - last_heard[g])\n",
    "        else:\n",
    "            result.append(-1)\n",
    "        last_heard[g] = t\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "def countfrompast(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "    \n",
    "    count = {}\n",
    "    result = []\n",
    "    for g in group.values:\n",
    "        if g not in count:\n",
    "            count[g] = 0\n",
    "        else:\n",
    "            count[g] += 1\n",
    "        result.append(count[g])\n",
    "        \n",
    "    return result\n",
    "\n",
    "def countfromfuture(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    result = []\n",
    "    df_reverse = df_train.sort_index(ascending=False)\n",
    "    group = get_group(df_reverse,  cols)\n",
    "    \n",
    "    count = {}\n",
    "    for g in group.values:\n",
    "        if g in count:\n",
    "            result.append(count[g])\n",
    "            count[g] += 1 \n",
    "        else:\n",
    "            result.append(0)\n",
    "            count[g] = 1\n",
    "    \n",
    "    result.reverse()\n",
    "    return result\n",
    "\n",
    "def lasttimediff(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "        \n",
    "    last_time = df_train.groupby(group)[timecol].last()\n",
    "    \n",
    "    return group.map(last_time) - df_train[timecol]\n",
    "\n",
    "def firsttimediff(df_history, df_train, cols, target, timecol='timestamp'):\n",
    "    \n",
    "    group = get_group(df_train, cols)\n",
    "        \n",
    "    first_time = df_train.groupby(group)[timecol].first()\n",
    "    \n",
    "    return  df_train[timecol] - group.map(first_time)\n",
    "\n",
    "\n",
    "def col_name(cols, func=None):\n",
    "    if func is None:\n",
    "        return '_'.join(cols)\n",
    "    else:\n",
    "        return '_'.join(cols) + '_' + func.__name__\n",
    "    \n",
    "    \n",
    "from lightfm import LightFM\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "from lightfm import LightFM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def get_var(df_history, df, group_col, agg_col):\n",
    "    group = get_group(df, group_col)\n",
    "    group_history = get_group(df_history, group_col)\n",
    "    df_temp = pd.DataFrame()\n",
    "    df_temp['group'] = group_history.values\n",
    "    df_temp['agg'] = df_history[agg_col].values\n",
    "    group_map =df_temp.groupby('group')['agg'].var()\n",
    "    result = group.map(group_map).fillna(0)\n",
    "    return result\n",
    "\n",
    "def matrix_factorization(df_history, df, target, item_col, userid_col, userraw_col):\n",
    "    \"\"\"\n",
    "    userid_col is unique user id\n",
    "    item_col is unique itme id\n",
    "    userraw_col is used to construct user feature. dim: user_id*userraw\n",
    "    \"\"\"\n",
    "    dff = pd.DataFrame()\n",
    "    dff_history = pd.DataFrame()\n",
    "\n",
    "\n",
    "    #1. process item\n",
    "    if item_col is None:\n",
    "        dff['item'] = np.zeros(len(df))\n",
    "        dff_history['item'] = np.zeros(len(df_history))\n",
    "    else:\n",
    "        encoder = LabelEncoder()\n",
    "        group = get_group(df, item_col)\n",
    "        group_history = get_group(df_history, item_col)\n",
    "        encoder.fit(pd.concat([group, group_history]))\n",
    "        dff['item'] = encoder.transform(group)\n",
    "        dff_history['item'] = encoder.transform(group_history)\n",
    "#     print('processing item done!')\n",
    "\n",
    "    #2. user raw\n",
    "    group = get_group(df, userraw_col)\n",
    "    group_history = get_group(df_history, userraw_col)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    dff['userraw'] = encoder.transform(group)\n",
    "    dff_history['userraw'] = encoder.transform(group_history)\n",
    "#     print('processing user raw done')\n",
    "\n",
    "\n",
    "    #3. user_id\n",
    "    group = get_group(df, userid_col)\n",
    "    group_history = get_group(df_history, userid_col)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(pd.concat([group, group_history]))\n",
    "    dff['user_id'] = encoder.transform(group)\n",
    "    dff_history['user_id'] = encoder.transform(group_history)\n",
    "#     print('processing user id done')\n",
    "\n",
    "\n",
    "\n",
    "    num_users = max(dff.user_id.max(), dff_history.user_id.max()) + 1\n",
    "    num_items = max(dff.item.max(), dff_history.item.max()) + 1\n",
    "    num_userraw = max(dff.userraw.max(), dff_history.userraw.max()) + 1\n",
    "\n",
    "    M = coo_matrix(\n",
    "            (df_history[target], ( dff_history.user_id, dff_history.item)),\n",
    "            shape=(num_users, num_items)\n",
    "        )\n",
    "\n",
    "    user_features = pd.concat([dff, dff_history])[['userraw', 'user_id']].drop_duplicates()\n",
    "\n",
    "    user_features = coo_matrix(\n",
    "        (np.ones(len(user_features)), (user_features.user_id, user_features.userraw)),\n",
    "        shape=(num_users, num_userraw)\n",
    "    )\n",
    "\n",
    "    user_features = sp.hstack([sp.eye(num_users), user_features])\n",
    "\n",
    "    model = LightFM(no_components=50, learning_rate=0.1)\n",
    "    print('fitting lightFM')\n",
    "    model.fit(\n",
    "            M, \n",
    "            epochs=2, \n",
    "            num_threads=36, \n",
    "            user_features=user_features,\n",
    "        )\n",
    "    print('predicting lightFM')\n",
    "    result = model.predict(\n",
    "        dff.user_id.values, \n",
    "        dff.item.values, \n",
    "        user_features=user_features,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def regression(df_history, df, cols, target= 'is_attributed', time_col='timestamp', shift=1500000000):\n",
    "    df = df.copy()\n",
    "    df_history = df_history.copy()\n",
    "    df.loc[:,time_col] = df.loc[:,time_col] - shift\n",
    "    df_history.loc[:,time_col] = df_history.loc[:,time_col] - shift\n",
    "    group = get_group(df, cols)\n",
    "    group_history = get_group(df_history, cols)\n",
    "\n",
    "    targets = {}\n",
    "    times = {}\n",
    "    for (y, t), u in zip(df_history[[target, time_col]].values, group_history):\n",
    "        if u not in targets:\n",
    "            targets[u] = [y]\n",
    "            times[u] = [t]\n",
    "        else:\n",
    "            targets[u].append(y)\n",
    "            times[u].append(t)\n",
    "\n",
    "    linal_user = {}\n",
    "    for u in times:\n",
    "        if len(times[u]) > 1:\n",
    "            A = np.vstack([times[u], np.ones(len(times[u]))]).T\n",
    "            linal_user[u] = np.linalg.inv(A.T.dot(A)).dot(A.T).dot(targets[u])\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for t, u in zip(df[time_col], group):\n",
    "        if u not in times:\n",
    "            result.append(-0.5)\n",
    "        else:\n",
    "            if len(times[u]) < 2:\n",
    "                result.append(-0.5)\n",
    "            else:\n",
    "                result.append(linal_user[u].dot([t, 1]))\n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "# feature_col = ['ip', \n",
    "#               'app', \n",
    "#               'device', \n",
    "#               'os', \n",
    "#               'channel']\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(max(train[col].max(),test[col].max() ) + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering on Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 3.6146086864173412 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 4.059483598917723 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 4.504358511418104 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 4.949233423918486 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 5.394108336418867 G.\n",
      "count function\n",
      "all 6:   ip_os_day_hour_count   \t\t\t size: 5.838983248919249 G.\n",
      "count function\n",
      "all 7:   ip_app_os_day_hour_count   \t\t\t size: 6.28385816141963 G.\n",
      "mean function\n",
      "all 8:   ip_app_device_mean   \t\t\t size: 6.7287330739200115 G.\n",
      "mean function\n",
      "all 9:   ip_device_os_mean   \t\t\t size: 7.173607986420393 G.\n",
      "mean function\n",
      "all 10:   app_device_os_mean   \t\t\t size: 7.6184828989207745 G.\n",
      "mean function\n",
      "all 11:   ip_app_device_os_mean   \t\t\t size: 8.063357811421156 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 12:   ip_app_device_time2nextclick   \t\t\t size: 8.508232723921537 G.\n",
      "time related function\n",
      "all 13:   ip_device_os_time2nextclick   \t\t\t size: 8.953107636421919 G.\n",
      "time related function\n",
      "all 14:   ip_app_device_os_time2nextclick   \t\t\t size: 9.3979825489223 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 15:   ip_app_device_time2previousclick   \t\t\t size: 9.842857461422682 G.\n",
      "time related function\n",
      "all 16:   ip_device_os_time2previousclick   \t\t\t size: 10.287732373923063 G.\n",
      "time related function\n",
      "all 17:   ip_app_device_os_time2previousclick   \t\t\t size: 10.732607286423445 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 18:   ip_app_device_countfromfuture   \t\t\t size: 11.177482198923826 G.\n",
      "time related function\n",
      "all 19:   ip_device_os_countfromfuture   \t\t\t size: 11.622357111424208 G.\n",
      "time related function\n",
      "all 20:   ip_app_device_os_countfromfuture   \t\t\t size: 12.06723202392459 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 21:   ip_app_device_countfrompast   \t\t\t size: 12.51210693642497 G.\n",
      "time related function\n",
      "all 22:   ip_device_os_countfrompast   \t\t\t size: 12.956981848925352 G.\n",
      "time related function\n",
      "all 23:   ip_app_device_os_countfrompast   \t\t\t size: 13.401856761425734 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 24:   ip_app_device_lasttimediff   \t\t\t size: 13.624294217675924 G.\n",
      "time related function\n",
      "all 25:   ip_device_os_lasttimediff   \t\t\t size: 13.846731673926115 G.\n",
      "time related function\n",
      "all 26:   ip_app_device_os_lasttimediff   \t\t\t size: 14.069169130176306 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 27:   ip_app_device_firsttimediff   \t\t\t size: 14.291606586426497 G.\n",
      "time related function\n",
      "all 28:   ip_device_os_firsttimediff   \t\t\t size: 14.514044042676687 G.\n",
      "time related function\n",
      "all 29:   ip_app_device_os_firsttimediff   \t\t\t size: 14.736481498926878 G.\n",
      "processing matrixFact_user_iposdeviceapp_item_app\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ip_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipchannel_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipappdeviceos_item_channel\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "all 33:   matrixFact_user_ipappdeviceos_item_channel   \t\t\t size: 16.515981148928404 G.\n",
      "------\n",
      "['ip_day_hour_count' 'ip_os_day_hour_count' 'ip_app_day_hour_count'\n",
      " 'ip_app_os_day_hour_count' 'app_day_hour_count' 'ip_device_os_count'\n",
      " 'ip_app_device_os_count' 'ip_device_os_mean' 'ip_app_device_os_mean'\n",
      " 'ip_app_device_mean' 'app_device_os_mean' 'ip_device_os_time2nextclick'\n",
      " 'ip_app_device_os_time2nextclick' 'ip_app_device_time2nextclick'\n",
      " 'ip_device_os_time2previousclick' 'ip_app_device_os_time2previousclick'\n",
      " 'ip_app_device_time2previousclick' 'ip_device_os_countfromfuture'\n",
      " 'ip_app_device_os_countfromfuture' 'ip_app_device_countfromfuture'\n",
      " 'ip_device_os_countfrompast' 'ip_app_device_os_countfrompast'\n",
      " 'ip_app_device_countfrompast' 'ip_device_os_lasttimediff'\n",
      " 'ip_app_device_os_lasttimediff' 'ip_app_device_lasttimediff'\n",
      " 'ip_device_os_firsttimediff' 'ip_app_device_os_firsttimediff'\n",
      " 'ip_app_device_firsttimediff' 'matrixFact_user_iposdeviceapp_item_app'\n",
      " 'matrixFact_user_ip_item_appdeviceos'\n",
      " 'matrixFact_user_ipchannel_item_appdeviceos'\n",
      " 'matrixFact_user_ipappdeviceos_item_channel' 'app' 'channel' 'device' 'os'\n",
      " 'hour' 'is_attributed']\n",
      "/home/kai/talkingdata/data/jchen/day7_features_supplementV1.ftr\n",
      "======================================================\n",
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 3.7750834822654724 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 4.239709138870239 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 4.704334795475006 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 5.168960452079773 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 5.63358610868454 G.\n",
      "count function\n",
      "all 6:   ip_os_day_hour_count   \t\t\t size: 6.098211765289307 G.\n",
      "count function\n",
      "all 7:   ip_app_os_day_hour_count   \t\t\t size: 6.5628374218940735 G.\n",
      "mean function\n",
      "all 8:   ip_app_device_mean   \t\t\t size: 7.02746307849884 G.\n",
      "mean function\n",
      "all 9:   ip_device_os_mean   \t\t\t size: 7.492088735103607 G.\n",
      "mean function\n",
      "all 10:   app_device_os_mean   \t\t\t size: 7.956714391708374 G.\n",
      "mean function\n",
      "all 11:   ip_app_device_os_mean   \t\t\t size: 8.42134004831314 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 12:   ip_app_device_time2nextclick   \t\t\t size: 8.885965704917908 G.\n",
      "time related function\n",
      "all 13:   ip_device_os_time2nextclick   \t\t\t size: 9.350591361522675 G.\n",
      "time related function\n",
      "all 14:   ip_app_device_os_time2nextclick   \t\t\t size: 9.815217018127441 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 15:   ip_app_device_time2previousclick   \t\t\t size: 10.279842674732208 G.\n",
      "time related function\n",
      "all 16:   ip_device_os_time2previousclick   \t\t\t size: 10.744468331336975 G.\n",
      "time related function\n",
      "all 17:   ip_app_device_os_time2previousclick   \t\t\t size: 11.209093987941742 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 18:   ip_app_device_countfromfuture   \t\t\t size: 11.673719644546509 G.\n",
      "time related function\n",
      "all 19:   ip_device_os_countfromfuture   \t\t\t size: 12.138345301151276 G.\n",
      "time related function\n",
      "all 20:   ip_app_device_os_countfromfuture   \t\t\t size: 12.602970957756042 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 21:   ip_app_device_countfrompast   \t\t\t size: 13.06759661436081 G.\n",
      "time related function\n",
      "all 22:   ip_device_os_countfrompast   \t\t\t size: 13.532222270965576 G.\n",
      "time related function\n",
      "all 23:   ip_app_device_os_countfrompast   \t\t\t size: 13.996847927570343 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 24:   ip_app_device_lasttimediff   \t\t\t size: 14.229160755872726 G.\n",
      "time related function\n",
      "all 25:   ip_device_os_lasttimediff   \t\t\t size: 14.46147358417511 G.\n",
      "time related function\n",
      "all 26:   ip_app_device_os_lasttimediff   \t\t\t size: 14.693786412477493 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 27:   ip_app_device_firsttimediff   \t\t\t size: 14.926099240779877 G.\n",
      "time related function\n",
      "all 28:   ip_device_os_firsttimediff   \t\t\t size: 15.15841206908226 G.\n",
      "time related function\n",
      "all 29:   ip_app_device_os_firsttimediff   \t\t\t size: 15.390724897384644 G.\n",
      "processing matrixFact_user_iposdeviceapp_item_app\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ip_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipchannel_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipappdeviceos_item_channel\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "all 33:   matrixFact_user_ipappdeviceos_item_channel   \t\t\t size: 17.24922752380371 G.\n",
      "------\n",
      "['ip_day_hour_count' 'ip_os_day_hour_count' 'ip_app_day_hour_count'\n",
      " 'ip_app_os_day_hour_count' 'app_day_hour_count' 'ip_device_os_count'\n",
      " 'ip_app_device_os_count' 'ip_device_os_mean' 'ip_app_device_os_mean'\n",
      " 'ip_app_device_mean' 'app_device_os_mean' 'ip_device_os_time2nextclick'\n",
      " 'ip_app_device_os_time2nextclick' 'ip_app_device_time2nextclick'\n",
      " 'ip_device_os_time2previousclick' 'ip_app_device_os_time2previousclick'\n",
      " 'ip_app_device_time2previousclick' 'ip_device_os_countfromfuture'\n",
      " 'ip_app_device_os_countfromfuture' 'ip_app_device_countfromfuture'\n",
      " 'ip_device_os_countfrompast' 'ip_app_device_os_countfrompast'\n",
      " 'ip_app_device_countfrompast' 'ip_device_os_lasttimediff'\n",
      " 'ip_app_device_os_lasttimediff' 'ip_app_device_lasttimediff'\n",
      " 'ip_device_os_firsttimediff' 'ip_app_device_os_firsttimediff'\n",
      " 'ip_app_device_firsttimediff' 'matrixFact_user_iposdeviceapp_item_app'\n",
      " 'matrixFact_user_ip_item_appdeviceos'\n",
      " 'matrixFact_user_ipchannel_item_appdeviceos'\n",
      " 'matrixFact_user_ipappdeviceos_item_channel' 'app' 'channel' 'device' 'os'\n",
      " 'hour' 'is_attributed']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kai/talkingdata/data/jchen/day8_features_supplementV1.ftr\n",
      "======================================================\n",
      "got train data\n",
      "got historical data\n",
      "count function\n",
      "all 1:   ip_device_os_count   \t\t\t size: 3.803643746301532 G.\n",
      "count function\n",
      "all 2:   ip_day_hour_count   \t\t\t size: 4.271784512326121 G.\n",
      "count function\n",
      "all 3:   app_day_hour_count   \t\t\t size: 4.739925278350711 G.\n",
      "count function\n",
      "all 4:   ip_app_device_os_count   \t\t\t size: 5.2080660443753 G.\n",
      "count function\n",
      "all 5:   ip_app_day_hour_count   \t\t\t size: 5.67620681039989 G.\n",
      "count function\n",
      "all 6:   ip_os_day_hour_count   \t\t\t size: 6.1443475764244795 G.\n",
      "count function\n",
      "all 7:   ip_app_os_day_hour_count   \t\t\t size: 6.612488342449069 G.\n",
      "mean function\n",
      "all 8:   ip_app_device_mean   \t\t\t size: 7.080629108473659 G.\n",
      "mean function\n",
      "all 9:   ip_device_os_mean   \t\t\t size: 7.548769874498248 G.\n",
      "mean function\n",
      "all 10:   app_device_os_mean   \t\t\t size: 8.016910640522838 G.\n",
      "mean function\n",
      "all 11:   ip_app_device_os_mean   \t\t\t size: 8.485051406547427 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 12:   ip_app_device_time2nextclick   \t\t\t size: 8.953192172572017 G.\n",
      "time related function\n",
      "all 13:   ip_device_os_time2nextclick   \t\t\t size: 9.421332938596606 G.\n",
      "time related function\n",
      "all 14:   ip_app_device_os_time2nextclick   \t\t\t size: 9.889473704621196 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 15:   ip_app_device_time2previousclick   \t\t\t size: 10.357614470645785 G.\n",
      "time related function\n",
      "all 16:   ip_device_os_time2previousclick   \t\t\t size: 10.825755236670375 G.\n",
      "time related function\n",
      "all 17:   ip_app_device_os_time2previousclick   \t\t\t size: 11.293896002694964 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 18:   ip_app_device_countfromfuture   \t\t\t size: 11.762036768719554 G.\n",
      "time related function\n",
      "all 19:   ip_device_os_countfromfuture   \t\t\t size: 12.230177534744143 G.\n",
      "time related function\n",
      "all 20:   ip_app_device_os_countfromfuture   \t\t\t size: 12.698318300768733 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 21:   ip_app_device_countfrompast   \t\t\t size: 13.166459066793323 G.\n",
      "time related function\n",
      "all 22:   ip_device_os_countfrompast   \t\t\t size: 13.634599832817912 G.\n",
      "time related function\n",
      "all 23:   ip_app_device_os_countfrompast   \t\t\t size: 14.102740598842502 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 24:   ip_app_device_lasttimediff   \t\t\t size: 14.336810981854796 G.\n",
      "time related function\n",
      "all 25:   ip_device_os_lasttimediff   \t\t\t size: 14.570881364867091 G.\n",
      "time related function\n",
      "all 26:   ip_app_device_os_lasttimediff   \t\t\t size: 14.804951747879386 G.\n",
      "df_all does not exist\n",
      "time related function\n",
      "all 27:   ip_app_device_firsttimediff   \t\t\t size: 15.03902213089168 G.\n",
      "time related function\n",
      "all 28:   ip_device_os_firsttimediff   \t\t\t size: 15.273092513903975 G.\n",
      "time related function\n",
      "all 29:   ip_app_device_os_firsttimediff   \t\t\t size: 15.50716289691627 G.\n",
      "processing matrixFact_user_iposdeviceapp_item_app\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ip_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipchannel_item_appdeviceos\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "processing matrixFact_user_ipappdeviceos_item_channel\n",
      "fitting lightFM\n",
      "predicting lightFM\n",
      "all 33:   matrixFact_user_ipappdeviceos_item_channel   \t\t\t size: 17.37972596101463 G.\n",
      "------\n",
      "['ip_day_hour_count' 'ip_os_day_hour_count' 'ip_app_day_hour_count'\n",
      " 'ip_app_os_day_hour_count' 'app_day_hour_count' 'ip_device_os_count'\n",
      " 'ip_app_device_os_count' 'ip_device_os_mean' 'ip_app_device_os_mean'\n",
      " 'ip_app_device_mean' 'app_device_os_mean' 'ip_device_os_time2nextclick'\n",
      " 'ip_app_device_os_time2nextclick' 'ip_app_device_time2nextclick'\n",
      " 'ip_device_os_time2previousclick' 'ip_app_device_os_time2previousclick'\n",
      " 'ip_app_device_time2previousclick' 'ip_device_os_countfromfuture'\n",
      " 'ip_app_device_os_countfromfuture' 'ip_app_device_countfromfuture'\n",
      " 'ip_device_os_countfrompast' 'ip_app_device_os_countfrompast'\n",
      " 'ip_app_device_countfrompast' 'ip_device_os_lasttimediff'\n",
      " 'ip_app_device_os_lasttimediff' 'ip_app_device_lasttimediff'\n",
      " 'ip_device_os_firsttimediff' 'ip_app_device_os_firsttimediff'\n",
      " 'ip_app_device_firsttimediff' 'matrixFact_user_iposdeviceapp_item_app'\n",
      " 'matrixFact_user_ip_item_appdeviceos'\n",
      " 'matrixFact_user_ipchannel_item_appdeviceos'\n",
      " 'matrixFact_user_ipappdeviceos_item_channel' 'app' 'channel' 'device' 'os'\n",
      " 'hour' 'is_attributed']\n",
      "/home/kai/talkingdata/data/jchen/day9_features_supplementV1.ftr\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from itertools import combinations\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for day in ['day7', 'day8', 'day9']:\n",
    "# for day in [ 'day9']:\n",
    "    counter = 0\n",
    "    df_train = train.iloc[index[day]].copy()\n",
    "    print('got train data')\n",
    "    history_index = list(set(train.index.values) - set(index[day]))\n",
    "    df_history = train.iloc[history_index].copy()\n",
    "    print('got historical data')\n",
    "    \n",
    "    ###########################################################################\n",
    "    for func in [count, mean, time2nextclick, time2previousclick, countfromfuture, countfrompast, lasttimediff, firsttimediff]:\n",
    "                if func.__name__ == count.__name__:\n",
    "                    df_all = pd.concat([train, test])\n",
    "                else:\n",
    "                    try:\n",
    "                        del df_all\n",
    "                        gc.collect()\n",
    "                    except Exception:\n",
    "                        print('df_all does not exist')\n",
    "               \n",
    "                for num_col in [1,2,3,4,5]:\n",
    "                    for cols in combinations(combine_col, num_col):\n",
    "                        feature_name = col_name(cols, func=func)\n",
    "                        if feature_name not in added_feature:\n",
    "                               continue\n",
    "                        counter += 1\n",
    "                        if func.__name__ == count.__name__:\n",
    "                                print('count function')\n",
    "                                df_train[feature_name] = func(df_all, df_train, cols, target='is_attributed')\n",
    "                                \n",
    "                        elif func.__name__ == mean.__name__:\n",
    "                                print('mean function')\n",
    "                                df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "\n",
    "                        else:\n",
    "                                print('time related function')\n",
    "                                df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "               \n",
    "                        all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "                        print(all_str)\n",
    "                        with open('feature_all.txt', 'w') as text_file:\n",
    "                            text_file.write(all_str + '\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "#     ### get val\n",
    "#     print('get val')\n",
    "#     df_all = pd.concat([train, test])\n",
    "#     df_train['ip_app_os_var_hour'] = get_var(df_all, df_train, ['ip','app', 'os'], 'hour')\n",
    "#     print('ip_app_os_var_hour done!')\n",
    "#     df_train['ip_app_channel_var_day'] = get_var(df_all, df_train, ['ip','app', 'channel'], 'day')\n",
    "#     print('ip_app_channel_var_day done!')\n",
    "#     del df_all\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    ### matrix - factorization\n",
    "    feature_name = 'matrixFact_user_iposdeviceapp_item_app'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app'], userid_col=['ip','os','device','app'], userraw_col=['ip'])\n",
    "    \n",
    "    feature_name = 'matrixFact_user_ip_item_appdeviceos'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip'], userraw_col=['ip'])\n",
    "\n",
    "    feature_name = 'matrixFact_user_ipchannel_item_appdeviceos'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip', 'channel'], userraw_col=['ip'])\n",
    "\n",
    "    feature_name = 'matrixFact_user_ipappdeviceos_item_channel'\n",
    "    print('processing {}'.format(feature_name))\n",
    "    counter += 1\n",
    "    df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['channel'], userid_col=['ip', 'app','device','os'], userraw_col=['ip'])\n",
    "\n",
    "############################# extra features\n",
    "#     feature_name = 'attributed_timediff'\n",
    "#     df_train[feature_name] = df_train.channel.map(diffmapp).fillna(-100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "    print(all_str)\n",
    "    with open('feature_all.txt', 'w') as text_file:\n",
    "        text_file.write(all_str + '\\n')\n",
    "               \n",
    "               \n",
    "    save_file_name = '{}_features_supplementV1.ftr'.format(day)\n",
    "    save_file_path = '/home/kai/talkingdata/data/jchen/' + save_file_name\n",
    "    df_train = df_train[train_cols]\n",
    "    print('------')\n",
    "    print(df_train.columns.values)\n",
    "#     df_train.to_feather(save_file_path)\n",
    "    df_train.reset_index().drop(['index',],axis=1).to_feather(save_file_path)\n",
    "    print(save_file_path)\n",
    "    print('======================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature engineering on test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sys\n",
    "from itertools import combinations\n",
    "combine_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "\n",
    "\n",
    "counter = 0\n",
    "df_train = test.copy()\n",
    "print('got train data')\n",
    "history_index = list(set(train.index.values) - set(index[day]))\n",
    "df_history = train.copy()\n",
    "print('got historical data')\n",
    "\n",
    "###########################################################################\n",
    "for func in [count, mean, time2nextclick, time2previousclick, countfromfuture, countfrompast, lasttimediff, firsttimediff]:\n",
    "# for func in [time2nextclick, time2previousclick]:\n",
    "             \n",
    "            if func.__name__ == count.__name__:\n",
    "                df_all = pd.concat([train, test])\n",
    "            else:\n",
    "                try:\n",
    "                    del df_all\n",
    "                    gc.collect()\n",
    "                except Exception:\n",
    "                    print('df_all does not exist')\n",
    "\n",
    "            for num_col in [1,2,3,4,5]:\n",
    "                for cols in combinations(combine_col, num_col):\n",
    "                    feature_name = col_name(cols, func=func)\n",
    "                    if feature_name not in added_feature:\n",
    "                           continue\n",
    "                    counter += 1\n",
    "                    if func.__name__ == count.__name__:\n",
    "                            print('count function')\n",
    "                            df_train[feature_name] = func(df_all, df_train, cols, target='is_attributed')\n",
    "                    \n",
    "                    elif func.__name__ == mean.__name__:\n",
    "                            print('mean function')\n",
    "                            df_train[feature_name] = func(df_history, df_train, cols, target='is_attributed')\n",
    "\n",
    "                    else:\n",
    "                            print('time related function')\n",
    "                            df_train[feature_name] = func(df_train, df_train, cols, target='is_attributed')\n",
    "\n",
    "                    all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "                    print(all_str)\n",
    "                    with open('feature_all.txt', 'w') as text_file:\n",
    "                        text_file.write(all_str + '\\n')\n",
    "                        \n",
    "                        \n",
    "# ### get val\n",
    "# print('get val')\n",
    "# df_all = pd.concat([train, test])\n",
    "# df_train['ip_app_os_var_hour'] = get_var(df_all, df_train, ['ip','app', 'os'], 'hour')\n",
    "# print('ip_app_os_var_hour done!')\n",
    "# df_train['ip_app_channel_var_day'] = get_var(df_all, df_train, ['ip','app', 'channel'], 'day')\n",
    "# print('ip_app_channel_var_day done!')\n",
    "# del df_all\n",
    "# gc.collect()\n",
    "                        \n",
    "### matrix - factorization\n",
    "feature_name = 'matrixFact_user_iposdeviceapp_item_app'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app'], userid_col=['ip','os','device','app'], userraw_col=['ip'])\n",
    "\n",
    "feature_name = 'matrixFact_user_ip_item_appdeviceos'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip'], userraw_col=['ip'])\n",
    "\n",
    "feature_name = 'matrixFact_user_ipchannel_item_appdeviceos'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['app', 'device', 'os'], userid_col=['ip', 'channel'], userraw_col=['ip'])\n",
    "\n",
    "\n",
    "feature_name = 'matrixFact_user_ipappdeviceos_item_channel'\n",
    "print('processing {}'.format(feature_name))\n",
    "counter += 1\n",
    "df_train[feature_name] = matrix_factorization(df_history, df_train,target, item_col=['channel'], userid_col=['ip', 'app','device','os'], userraw_col=['ip'])\n",
    "\n",
    "############################# extra features\n",
    "# feature_name = 'attributed_timediff'\n",
    "# df_train[feature_name] = df_train.channel.map(diffmapp).fillna(-100)\n",
    "\n",
    "all_str = 'all {}:   {}   \\t\\t\\t size: {} G.'.format(counter, feature_name, sys.getsizeof(df_train)/ 1024 **3)\n",
    "print(all_str)\n",
    "with open('feature_all.txt', 'w') as text_file:\n",
    "    text_file.write(all_str + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_file_name = '{}_features_supplementV1.ftr'.format('test')\n",
    "save_file_path = '/home/kai/talkingdata/data/jchen/' + save_file_name\n",
    "df_train = df_train[feature_cols]\n",
    "print(df_train.columns.values)\n",
    "df_train.to_feather(save_file_path)\n",
    "print(save_file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Saving equal hours for test')\n",
    "test_index = np.load('/home/kai/talkingdata/data/supplement2testInexFinal.npy')\n",
    "test_equal = df_train.iloc[test_index]\n",
    "save_file_name = save_file_name.format('test_equalhoursV2.ftr')\n",
    "save_file_path = '/home/kai/talkingdata/data/jchen/' + save_file_name\n",
    "test_equal.reset_index().drop(['index',],axis=1).to_feather(save_file_path)\n",
    "print(len(test_equal))\n",
    "print(save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
