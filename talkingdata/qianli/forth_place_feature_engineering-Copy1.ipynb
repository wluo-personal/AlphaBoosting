{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:54:23.848784Z",
     "start_time": "2018-05-24T19:54:23.843168Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_log(s, rewrite=False):\n",
    "    mode = 'w' if rewrite else 'a'\n",
    "    with open('log.txt', mode) as f:\n",
    "        f.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:54:24.563874Z",
     "start_time": "2018-05-24T19:54:24.540236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index     ip  app  device  os  channel           click_time  is_attributed  \\\n",
      "0      0  83230    3       1  13      379  2017-11-06 14:32:21              0   \n",
      "1      1  17357    3       1  19      379  2017-11-06 14:33:34              0   \n",
      "2      2  35810    3       1  13      379  2017-11-06 14:34:12              0   \n",
      "\n",
      "   click_id  is_test  \n",
      "0         0        0  \n",
      "1         0        0  \n",
      "2         0        0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "# nrows = 6\n",
    "nrows = None\n",
    "dtypes = {\n",
    "    'ip':            'uint32',\n",
    "    'app':           'uint16',\n",
    "    'device':        'uint16',\n",
    "    'os':            'uint16',\n",
    "    'channel':       'uint16',\n",
    "    'is_attributed': 'uint8',\n",
    "    'click_id':      'uint32'\n",
    "}\n",
    "nrows = 6000\n",
    "train = pd.read_csv(PATH + 'train.csv', nrows=nrows, dtype=dtypes,\n",
    "                    usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']).reset_index()\n",
    "test = pd.read_csv(PATH + 'test_supplement.csv', nrows=nrows, dtype=dtypes,\n",
    "                    usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id']).reset_index()\n",
    "train['click_id'] = 0\n",
    "train['is_test'] = 0\n",
    "test['is_test'] = 1\n",
    "test['is_attributed'] = 2\n",
    "print(train.head(3))\n",
    "write_log('data reading', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:54:25.110319Z",
     "start_time": "2018-05-24T19:54:25.107690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine = device + os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T14:36:12.737184Z",
     "start_time": "2018-05-24T14:36:12.728491Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:54:25.886115Z",
     "start_time": "2018-05-24T19:54:25.801097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'app': dtype('uint16'), 'channel': dtype('uint16'), 'click_id': dtype('int64'), 'click_time': datetime64[ns, Asia/Shanghai], 'click_timestamp': dtype('int32'), 'day': dtype('uint8'), 'dayhourminute': dtype('uint32'), 'dayhourminute10': dtype('uint32'), 'device': dtype('uint16'), 'hour': dtype('uint8'), 'hourminute': dtype('uint16'), 'hourminute10': dtype('uint16'), 'index': dtype('int64'), 'ip': dtype('uint32'), 'is_attributed': dtype('int64'), 'is_test': dtype('int64'), 'machine': dtype('uint16'), 'minute': dtype('uint8'), 'minute10': dtype('uint8'), 'os': dtype('uint16')}\n",
      "   app  channel  click_id                click_time  click_timestamp  day  \\\n",
      "0    3      379         0 2017-11-06 22:32:21+08:00       1509978741    6   \n",
      "1    3      379         0 2017-11-06 22:33:34+08:00       1509978814    6   \n",
      "2    3      379         0 2017-11-06 22:34:12+08:00       1509978852    6   \n",
      "\n",
      "   dayhourminute  dayhourminute10  device  hour  hourminute  hourminute10  \\\n",
      "0           9992             9990       1    22        1352          1350   \n",
      "1           9993             9990       1    22        1353          1350   \n",
      "2           9994             9990       1    22        1354          1350   \n",
      "\n",
      "   index     ip  is_attributed  is_test  machine  minute  minute10  os  \n",
      "0      0  83230              0        0     1013      32        30  13  \n",
      "1      1  17357              0        0     1019      33        30  19  \n",
      "2      2  35810              0        0     1013      34        30  13  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pytz\n",
    "\n",
    "# set time zone to be Shanghai time and split click_time into day, hour and minute\n",
    "def data_clean(df):\n",
    "    tz = pytz.timezone('Asia/Shanghai')\n",
    "    df['click_time'] = pd.to_datetime(df['click_time']).dt.tz_localize(pytz.utc).dt.tz_convert(tz)\n",
    "    df['day'] = df['click_time'].dt.day.astype('uint8')\n",
    "    df['hour'] = df['click_time'].dt.hour.astype('uint8')\n",
    "    df['minute'] = df['click_time'].dt.minute.astype('uint8')\n",
    "    df['minute10'] = (df['minute'] / 10).astype('uint8') * 10 # set to 10 minute\n",
    "    df['hourminute'] = (df['minute'].astype('uint16') + df['hour'].astype('uint16') * 60)\n",
    "    df['hourminute10'] = (df['minute10'].astype('uint16') + df['hour'].astype('uint16') * 60)\n",
    "    df['dayhourminute'] = (df['hourminute'].astype('uint32') + df['day'].astype('uint32') * 60 * 24)\n",
    "    df['dayhourminute10'] = (df['hourminute10'].astype('uint32') + df['day'].astype('uint32') * 60 * 24)\n",
    "    df['machine'] = 1000 * df['device'] + df['os']\n",
    "    df['click_timestamp'] = (df['click_time'].astype(np.int64) // 10 ** 9).astype(np.int32)\n",
    "\n",
    "    \n",
    "    \n",
    "data_clean(train)\n",
    "data_clean(test)\n",
    "df = pd.concat([train, test], ignore_index=True) # concat train and test\n",
    "\n",
    "data_type = df.dtypes.to_dict()\n",
    "print(data_type)\n",
    "\n",
    "label = 'is_attributed'\n",
    "train_len = train.shape[0]\n",
    "fdir = '/home/kai/data/kaggle/talkingdata/qianli1/'\n",
    "print(df.head(3))\n",
    "train.to_feather(fdir + 'train_cleaned.ftr')\n",
    "test.to_feather(fdir + 'test_cleaned.ftr')\n",
    "write_log('data cleaning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:54:27.117801Z",
     "start_time": "2018-05-24T19:54:27.111607Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(df, col_name, train_len):\n",
    "    df.reset_index(drop=True)\n",
    "    df[ : train_len].to_feather(fdir + 'train__' + col_name + '.ftr')\n",
    "    df[train_len : ].reset_index(drop=True).to_feather(fdir + 'test_supplement__' + col_name + '.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count the click number for each feature combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:54:28.661301Z",
     "start_time": "2018-05-24T19:54:28.590752Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Here df is [train test_supp]\n",
    "def count(df, cols, label, train_len):\n",
    "    col_name = 'count_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "#     print(df[d_cols])\n",
    "#     print(df[d_cols].groupby(cols).sum())\n",
    "#     print(list(df[d_cols].groupby(cols).sum().columns))\n",
    "#     print(df[d_cols].groupby(by = cols))\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "#     print(count_result)\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "#     print(type_map)\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "#     _df = df.merge(count_result,  how='left')\n",
    "    save(_df[[col_name]], col_name, train_len)\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "\n",
    "patterns = [\n",
    "    ['app','channel'],\n",
    "#     ['app','device','channel','day','hour'],##\n",
    "#     ['app','device','day','hour'],##\n",
    "#     ['app','os','channel','day','hour'],##\n",
    "#     ['ip','day'],\n",
    "#     ['ip'],#\n",
    "#     ['ip','app','device','channel','day'],##\n",
    "#     ['ip','app','device','day'],##\n",
    "#     ['ip','app','device','os','day','hour'],##\n",
    "#     ['ip','app','os','channel'],##\n",
    "#     ['ip','app','os','channel','day'],##\n",
    "#     ['ip','os'],\n",
    "#     ['app','day','hourminute'],\n",
    "#     ['device','os','day','hourminute10'],##\n",
    "#     ['ip','device','os','day','hourminute10']##\n",
    "]\n",
    "\n",
    "\n",
    "write_log('count')\n",
    "for p in patterns:\n",
    "    count(df, p, label, train_len)\n",
    "    write_log(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:54:29.701998Z",
     "start_time": "2018-05-24T19:54:29.698915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'click_id', 'ip', 'app', 'device', 'os', 'channel',\n",
      "       'click_time', 'is_test', 'is_attributed', 'day', 'hour', 'minute',\n",
      "       'minute10', 'hourminute', 'hourminute10', 'dayhourminute',\n",
      "       'dayhourminute10', 'machine', 'click_timestamp'],\n",
      "      dtype='object')\n",
      "(6000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(test.columns)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:54:50.979725Z",
     "start_time": "2018-05-24T19:54:50.790660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index      ip  app  device  os  channel                click_time  \\\n",
      "103     103  204158   35       1  13       21 2017-11-06 23:41:07+08:00   \n",
      "1504   1504   29692    9       1  22      215 2017-11-07 00:00:02+08:00   \n",
      "1798   1798   64516   35       1  13       21 2017-11-07 00:00:02+08:00   \n",
      "2102   2102  172429   35       1  46      274 2017-11-07 00:00:03+08:00   \n",
      "3056   3056  199085   35       1  13      274 2017-11-07 00:00:04+08:00   \n",
      "3220   3220   82917   19       0  24      210 2017-11-07 00:00:04+08:00   \n",
      "3939   3939  126647   72       1   6      101 2017-11-07 00:00:05+08:00   \n",
      "5282   5282   57546   29       1  41      213 2017-11-07 00:00:07+08:00   \n",
      "5377   5377  189682   35       1  13       21 2017-11-07 00:00:07+08:00   \n",
      "5438   5438   24200   19      88  24      213 2017-11-07 00:00:07+08:00   \n",
      "\n",
      "      is_attributed  click_id  is_test       ...         click_timestamp  \\\n",
      "103               1         0        0       ...              1509982867   \n",
      "1504              1         0        0       ...              1509984002   \n",
      "1798              1         0        0       ...              1509984002   \n",
      "2102              1         0        0       ...              1509984003   \n",
      "3056              1         0        0       ...              1509984004   \n",
      "3220              1         0        0       ...              1509984004   \n",
      "3939              1         0        0       ...              1509984005   \n",
      "5282              1         0        0       ...              1509984007   \n",
      "5377              1         0        0       ...              1509984007   \n",
      "5438              1         0        0       ...              1509984007   \n",
      "\n",
      "      n11_app_channel  n_12app_channel  n_21app_channel  n_22app_channel  \\\n",
      "103               3.0              0.0              7.0           5990.0   \n",
      "1504              1.0            136.0              9.0           5854.0   \n",
      "1798              3.0              0.0              7.0           5990.0   \n",
      "2102              2.0              1.0              8.0           5989.0   \n",
      "3056              2.0              1.0              8.0           5989.0   \n",
      "3220              1.0              1.0              9.0           5989.0   \n",
      "3939              1.0              0.0              9.0           5990.0   \n",
      "5282              1.0              1.0              9.0           5989.0   \n",
      "5377              3.0              0.0              7.0           5990.0   \n",
      "5438              1.0             13.0              9.0           5977.0   \n",
      "\n",
      "          e_11        e_12      e_21         e_22  chi_app_channel  \n",
      "103   0.005000    2.995000  9.995000  5987.005000      1797.898949  \n",
      "1504  0.228333  136.771667  9.771667  5853.228333         2.673289  \n",
      "1798  0.005000    2.995000  9.995000  5987.005000      1797.898949  \n",
      "2102  0.005000    2.995000  9.995000  5987.005000       797.732756  \n",
      "3056  0.005000    2.995000  9.995000  5987.005000       797.732756  \n",
      "3220  0.003333    1.996667  9.996667  5988.003333       298.600368  \n",
      "3939  0.001667    0.998333  9.998333  5989.001667       599.099850  \n",
      "5282  0.003333    1.996667  9.996667  5988.003333       298.600368  \n",
      "5377  0.005000    2.995000  9.995000  5987.005000      1797.898949  \n",
      "5438  0.023333   13.976667  9.976667  5976.023333        41.044495  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "train_1 = train[(train['is_attributed'] == 1)] #total pattern num\n",
    "train_0 = train[(train['is_attributed'] == 0)]\n",
    "def chi_count(df, cols, label, train_len, train_1, test):\n",
    "# Possible improvement:\n",
    "# Use historical data.\n",
    "    \n",
    "    \n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    \n",
    "    n_11 = 'n11_' + '_'.join(cols)\n",
    "    count_result = train_1[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: n_11}).reset_index()\n",
    "#     print(count_result)\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    df_1 = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "#     print('df_1', df_1.shape)\n",
    "    del df, count_result\n",
    "    gc.collect()\n",
    "    \n",
    "    n_12 = 'n_12' + '_'.join(cols)\n",
    "    count_result = train_0[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: n_12}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    df_2 = df_1.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    df_2.fillna(0, inplace = True)\n",
    "#     print('df_2', df_2.shape)\n",
    "    del df_1, count_result\n",
    "    gc.collect\n",
    "    \n",
    "    n_21 = 'n_21' + '_'.join(cols)\n",
    "    n_22 = 'n_22' + '_'.join(cols)\n",
    "    df_2[n_21] = len(train_1) - df_2[n_11]\n",
    "    df_2[n_22] = train_len - df_2[n_11] - df_2[n_12] - df_2[n_21] \n",
    "    \n",
    "    df_2['e_11'] = (df_2[n_11] + df_2[n_12])*(df_2[n_11] + df_2[n_21])/train_len\n",
    "    df_2['e_12'] = (df_2[n_11] + df_2[n_12])*(df_2[n_12] + df_2[n_22])/train_len\n",
    "    df_2['e_21'] = (df_2[n_21] + df_2[n_22])*(df_2[n_11] + df_2[n_21])/train_len\n",
    "    df_2['e_22'] = (df_2[n_21] + df_2[n_22])*(df_2[n_12] + df_2[n_22])/train_len\n",
    "    col_name = 'chi_' + '_'.join(cols)\n",
    "    df_2[col_name] = (df_2[n_11] - df_2['e_11'])*(df_2[n_11] - df_2['e_11'])/df_2['e_11'] + \\\n",
    "                    (df_2[n_12] - df_2['e_12'])*(df_2[n_12] - df_2['e_12'])/df_2['e_12']  + \\\n",
    "                    (df_2[n_21] - df_2['e_21'])*(df_2[n_21] - df_2['e_21'])/df_2['e_21']  + \\\n",
    "                    (df_2[n_22] - df_2['e_22'])*(df_2[n_22] - df_2['e_22'])/df_2['e_22']\n",
    "    df_2.fillna(0, inplace = True)\n",
    "    print(df_2[df_2['is_attributed'] == 1])\n",
    "    d_cols.append(col_name)\n",
    "#     print(d_cols)\n",
    "    count_result = df_2[d_cols].groupby(by=cols)[[col_name]].mean().rename(index=str, columns={label: col_name}).reset_index()\n",
    "\n",
    "    df_3 = test.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    df_3.fillna(0, inplace = True)\n",
    "    df_all = pd.concat([df_2, df_3], ignore_index = True)\n",
    "#     print(df_all[[col_name]][:10])\n",
    "    save(df_all[[col_name]], col_name, train_len)\n",
    "    del df_2, df_3, df_all, count_result\n",
    "    gc.collect\n",
    "    \n",
    "    \n",
    "    \n",
    "patterns = [\n",
    "    ['app','channel'],\n",
    "#     ['app','device','channel','day','hour'],##\n",
    "#     ['app','device','day','hour'],##\n",
    "#     ['app','os','channel','day','hour'],##\n",
    "#     ['ip','day'],\n",
    "#     ['ip'],#\n",
    "#     ['ip','app','device','channel','day'],##\n",
    "#     ['ip','app','device','day'],##\n",
    "#     ['ip','app','device','os','day','hour'],##\n",
    "#     ['ip','app','os','channel'],##\n",
    "#     ['ip','app','os','channel','day'],##\n",
    "#     ['ip','os'],\n",
    "#     ['app','day','hourminute'],\n",
    "#     ['device','os','day','hourminute10'],##\n",
    "#     ['ip','device','os','day','hourminute10']##\n",
    "]\n",
    "\n",
    "for p in patterns:\n",
    "    chi_count(train, p, label, train_len, train_1, test)\n",
    "    write_log(str(p)+'chi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T19:46:03.687862Z",
     "start_time": "2018-05-24T19:46:03.675705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      chi_app_channel\n",
      "0            0.746229\n",
      "1            0.746229\n",
      "2            0.746229\n",
      "3            0.025104\n",
      "4            0.746229\n",
      "5            0.746229\n",
      "6            0.746229\n",
      "7            0.746229\n",
      "8            0.746229\n",
      "9            0.272668\n",
      "10           0.746229\n",
      "11           0.746229\n",
      "12           0.746229\n",
      "13           0.746229\n",
      "14           0.746229\n",
      "15           0.746229\n",
      "16           0.746229\n",
      "17           0.746229\n",
      "18           0.746229\n",
      "19           0.746229\n",
      "20           0.746229\n",
      "21           0.746229\n",
      "22           0.025104\n",
      "23           0.746229\n",
      "24           0.746229\n",
      "25           0.746229\n",
      "26           0.746229\n",
      "27           0.746229\n",
      "28           0.746229\n",
      "29           0.746229\n",
      "...               ...\n",
      "5970         0.304474\n",
      "5971         0.586722\n",
      "5972         0.147379\n",
      "5973         0.272668\n",
      "5974         0.586722\n",
      "5975         0.311569\n",
      "5976         0.341831\n",
      "5977         2.673289\n",
      "5978         0.311569\n",
      "5979         0.218348\n",
      "5980         0.327568\n",
      "5981         0.586722\n",
      "5982         0.228816\n",
      "5983         0.089269\n",
      "5984         0.125082\n",
      "5985         0.341831\n",
      "5986         0.147379\n",
      "5987         0.135361\n",
      "5988         0.341831\n",
      "5989         0.028461\n",
      "5990         0.306247\n",
      "5991         0.341831\n",
      "5992         0.015048\n",
      "5993         0.220091\n",
      "5994         0.306247\n",
      "5995         0.306247\n",
      "5996         0.128506\n",
      "5997         0.341831\n",
      "5998         0.272668\n",
      "5999         0.306247\n",
      "\n",
      "[6000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "chi_d = pd.read_feather(fdir + 'train__chi_app_channel.ftr')\n",
    "print(chi_d.reset_index(drop=True))\n",
    "# print(chi_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unique count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group data by certain feature combination and count the number of different values of another feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T16:10:14.007185Z",
     "start_time": "2018-05-24T16:10:13.658402Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nunique_day_ip_machine\n",
      "0                           1\n",
      "1                           2\n",
      "2                           1\n",
      "3                           1\n",
      "4                           1\n",
      "5                           2\n",
      "6                           1\n",
      "7                           1\n",
      "8                           1\n",
      "9                           1\n",
      "10                          2\n",
      "11                          1\n",
      "12                          1\n",
      "13                          1\n",
      "14                          1\n",
      "15                          1\n",
      "16                          1\n",
      "17                          1\n",
      "18                          1\n",
      "19                          1\n",
      "20                          1\n",
      "21                          1\n",
      "22                          2\n",
      "23                          1\n",
      "24                          1\n",
      "25                          1\n",
      "26                          1\n",
      "27                          2\n",
      "28                          3\n",
      "29                          1\n",
      "...                       ...\n",
      "11970                       1\n",
      "11971                       1\n",
      "11972                       1\n",
      "11973                       2\n",
      "11974                       6\n",
      "11975                       1\n",
      "11976                       4\n",
      "11977                       1\n",
      "11978                       1\n",
      "11979                       6\n",
      "11980                       3\n",
      "11981                       1\n",
      "11982                       7\n",
      "11983                       8\n",
      "11984                       2\n",
      "11985                       1\n",
      "11986                       1\n",
      "11987                       1\n",
      "11988                       6\n",
      "11989                       1\n",
      "11990                       2\n",
      "11991                       2\n",
      "11992                       1\n",
      "11993                       1\n",
      "11994                       1\n",
      "11995                       4\n",
      "11996                       1\n",
      "11997                       2\n",
      "11998                       1\n",
      "11999                       1\n",
      "\n",
      "[12000 rows x 1 columns]\n",
      "       nunique_day_ip_os\n",
      "0                      1\n",
      "1                      2\n",
      "2                      1\n",
      "3                      1\n",
      "4                      1\n",
      "5                      2\n",
      "6                      1\n",
      "7                      1\n",
      "8                      1\n",
      "9                      1\n",
      "10                     2\n",
      "11                     1\n",
      "12                     1\n",
      "13                     1\n",
      "14                     1\n",
      "15                     1\n",
      "16                     1\n",
      "17                     1\n",
      "18                     1\n",
      "19                     1\n",
      "20                     1\n",
      "21                     1\n",
      "22                     2\n",
      "23                     1\n",
      "24                     1\n",
      "25                     1\n",
      "26                     1\n",
      "27                     2\n",
      "28                     3\n",
      "29                     1\n",
      "...                  ...\n",
      "11970                  1\n",
      "11971                  1\n",
      "11972                  1\n",
      "11973                  2\n",
      "11974                  6\n",
      "11975                  1\n",
      "11976                  3\n",
      "11977                  1\n",
      "11978                  1\n",
      "11979                  6\n",
      "11980                  3\n",
      "11981                  1\n",
      "11982                  7\n",
      "11983                  7\n",
      "11984                  2\n",
      "11985                  1\n",
      "11986                  1\n",
      "11987                  1\n",
      "11988                  6\n",
      "11989                  1\n",
      "11990                  2\n",
      "11991                  2\n",
      "11992                  1\n",
      "11993                  1\n",
      "11994                  1\n",
      "11995                  3\n",
      "11996                  1\n",
      "11997                  2\n",
      "11998                  1\n",
      "11999                  1\n",
      "\n",
      "[12000 rows x 1 columns]\n",
      "       nunique_day_ip_device\n",
      "0                          1\n",
      "1                          1\n",
      "2                          1\n",
      "3                          1\n",
      "4                          1\n",
      "5                          1\n",
      "6                          1\n",
      "7                          1\n",
      "8                          1\n",
      "9                          1\n",
      "10                         1\n",
      "11                         1\n",
      "12                         1\n",
      "13                         1\n",
      "14                         1\n",
      "15                         1\n",
      "16                         1\n",
      "17                         1\n",
      "18                         1\n",
      "19                         1\n",
      "20                         1\n",
      "21                         1\n",
      "22                         1\n",
      "23                         1\n",
      "24                         1\n",
      "25                         1\n",
      "26                         1\n",
      "27                         1\n",
      "28                         1\n",
      "29                         1\n",
      "...                      ...\n",
      "11970                      1\n",
      "11971                      1\n",
      "11972                      1\n",
      "11973                      1\n",
      "11974                      1\n",
      "11975                      1\n",
      "11976                      2\n",
      "11977                      1\n",
      "11978                      1\n",
      "11979                      1\n",
      "11980                      1\n",
      "11981                      1\n",
      "11982                      1\n",
      "11983                      2\n",
      "11984                      1\n",
      "11985                      1\n",
      "11986                      1\n",
      "11987                      1\n",
      "11988                      1\n",
      "11989                      1\n",
      "11990                      2\n",
      "11991                      1\n",
      "11992                      1\n",
      "11993                      1\n",
      "11994                      1\n",
      "11995                      2\n",
      "11996                      1\n",
      "11997                      1\n",
      "11998                      1\n",
      "11999                      1\n",
      "\n",
      "[12000 rows x 1 columns]\n",
      "       nunique_day_ip_app\n",
      "0                       1\n",
      "1                       1\n",
      "2                       1\n",
      "3                       1\n",
      "4                       1\n",
      "5                       1\n",
      "6                       1\n",
      "7                       1\n",
      "8                       1\n",
      "9                       1\n",
      "10                      1\n",
      "11                      1\n",
      "12                      1\n",
      "13                      1\n",
      "14                      1\n",
      "15                      1\n",
      "16                      1\n",
      "17                      1\n",
      "18                      1\n",
      "19                      1\n",
      "20                      1\n",
      "21                      1\n",
      "22                      2\n",
      "23                      1\n",
      "24                      1\n",
      "25                      1\n",
      "26                      1\n",
      "27                      1\n",
      "28                      1\n",
      "29                      1\n",
      "...                   ...\n",
      "11970                   1\n",
      "11971                   1\n",
      "11972                   3\n",
      "11973                   3\n",
      "11974                  11\n",
      "11975                   1\n",
      "11976                   9\n",
      "11977                   1\n",
      "11978                   1\n",
      "11979                  11\n",
      "11980                   7\n",
      "11981                   4\n",
      "11982                  12\n",
      "11983                  11\n",
      "11984                   3\n",
      "11985                   2\n",
      "11986                   1\n",
      "11987                   1\n",
      "11988                  11\n",
      "11989                   1\n",
      "11990                   3\n",
      "11991                   5\n",
      "11992                   1\n",
      "11993                   1\n",
      "11994                   2\n",
      "11995                   9\n",
      "11996                   1\n",
      "11997                   5\n",
      "11998                   1\n",
      "11999                   1\n",
      "\n",
      "[12000 rows x 1 columns]\n",
      "       nunique_day_ip_channel\n",
      "0                           1\n",
      "1                           1\n",
      "2                           1\n",
      "3                           1\n",
      "4                           1\n",
      "5                           1\n",
      "6                           1\n",
      "7                           1\n",
      "8                           1\n",
      "9                           1\n",
      "10                          1\n",
      "11                          1\n",
      "12                          1\n",
      "13                          1\n",
      "14                          1\n",
      "15                          1\n",
      "16                          1\n",
      "17                          1\n",
      "18                          1\n",
      "19                          1\n",
      "20                          1\n",
      "21                          1\n",
      "22                          2\n",
      "23                          1\n",
      "24                          1\n",
      "25                          1\n",
      "26                          1\n",
      "27                          1\n",
      "28                          1\n",
      "29                          1\n",
      "...                       ...\n",
      "11970                       1\n",
      "11971                       1\n",
      "11972                       7\n",
      "11973                       2\n",
      "11974                      20\n",
      "11975                       1\n",
      "11976                      16\n",
      "11977                       1\n",
      "11978                       1\n",
      "11979                      20\n",
      "11980                       7\n",
      "11981                       5\n",
      "11982                      21\n",
      "11983                      14\n",
      "11984                       3\n",
      "11985                       2\n",
      "11986                       1\n",
      "11987                       1\n",
      "11988                      20\n",
      "11989                       1\n",
      "11990                       3\n",
      "11991                       4\n",
      "11992                       1\n",
      "11993                       2\n",
      "11994                       2\n",
      "11995                      16\n",
      "11996                       1\n",
      "11997                       7\n",
      "11998                       1\n",
      "11999                       1\n",
      "\n",
      "[12000 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nunique_machine_app\n",
      "0                       41\n",
      "1                       41\n",
      "2                       41\n",
      "3                       41\n",
      "4                       41\n",
      "5                       25\n",
      "6                       17\n",
      "7                       41\n",
      "8                       41\n",
      "9                       28\n",
      "10                      25\n",
      "11                      41\n",
      "12                      41\n",
      "13                      32\n",
      "14                      32\n",
      "15                      41\n",
      "16                      41\n",
      "17                      41\n",
      "18                      41\n",
      "19                      41\n",
      "20                      32\n",
      "21                      32\n",
      "22                      25\n",
      "23                      41\n",
      "24                      28\n",
      "25                      41\n",
      "26                      28\n",
      "27                      41\n",
      "28                      28\n",
      "29                      41\n",
      "...                    ...\n",
      "11970                   27\n",
      "11971                   41\n",
      "11972                   19\n",
      "11973                   41\n",
      "11974                   41\n",
      "11975                   32\n",
      "11976                   26\n",
      "11977                   28\n",
      "11978                   41\n",
      "11979                   41\n",
      "11980                   41\n",
      "11981                   41\n",
      "11982                   41\n",
      "11983                   16\n",
      "11984                   41\n",
      "11985                   41\n",
      "11986                   41\n",
      "11987                   32\n",
      "11988                   41\n",
      "11989                   41\n",
      "11990                   41\n",
      "11991                   14\n",
      "11992                   18\n",
      "11993                    8\n",
      "11994                   24\n",
      "11995                   26\n",
      "11996                   28\n",
      "11997                   25\n",
      "11998                   41\n",
      "11999                   41\n",
      "\n",
      "[12000 rows x 1 columns]\n",
      "       nunique_machine_ip\n",
      "0                    1289\n",
      "1                    1437\n",
      "2                    1289\n",
      "3                    1289\n",
      "4                    1289\n",
      "5                     118\n",
      "6                      71\n",
      "7                    1437\n",
      "8                    1289\n",
      "9                     240\n",
      "10                    162\n",
      "11                   1289\n",
      "12                   1437\n",
      "13                    335\n",
      "14                    335\n",
      "15                   1437\n",
      "16                   1289\n",
      "17                   1437\n",
      "18                   1289\n",
      "19                   1437\n",
      "20                    335\n",
      "21                    335\n",
      "22                    102\n",
      "23                   1289\n",
      "24                    347\n",
      "25                   1437\n",
      "26                    347\n",
      "27                   1289\n",
      "28                    139\n",
      "29                   1437\n",
      "...                   ...\n",
      "11970                 164\n",
      "11971                1437\n",
      "11972                  39\n",
      "11973                1437\n",
      "11974                1289\n",
      "11975                 335\n",
      "11976                 167\n",
      "11977                 240\n",
      "11978                1437\n",
      "11979                1289\n",
      "11980                1289\n",
      "11981                1289\n",
      "11982                1437\n",
      "11983                  49\n",
      "11984                1289\n",
      "11985                1289\n",
      "11986                1437\n",
      "11987                 335\n",
      "11988                1289\n",
      "11989                1437\n",
      "11990                1437\n",
      "11991                  47\n",
      "11992                  53\n",
      "11993                   9\n",
      "11994                 119\n",
      "11995                 167\n",
      "11996                 347\n",
      "11997                 102\n",
      "11998                1437\n",
      "11999                1289\n",
      "\n",
      "[12000 rows x 1 columns]\n",
      "       nunique_machine_channel\n",
      "0                          111\n",
      "1                          112\n",
      "2                          111\n",
      "3                          111\n",
      "4                          111\n",
      "5                           65\n",
      "6                           41\n",
      "7                          112\n",
      "8                          111\n",
      "9                           85\n",
      "10                          68\n",
      "11                         111\n",
      "12                         112\n",
      "13                          90\n",
      "14                          90\n",
      "15                         112\n",
      "16                         111\n",
      "17                         112\n",
      "18                         111\n",
      "19                         112\n",
      "20                          90\n",
      "21                          90\n",
      "22                          70\n",
      "23                         111\n",
      "24                          88\n",
      "25                         112\n",
      "26                          88\n",
      "27                         111\n",
      "28                          63\n",
      "29                         112\n",
      "...                        ...\n",
      "11970                       75\n",
      "11971                      112\n",
      "11972                       45\n",
      "11973                      112\n",
      "11974                      111\n",
      "11975                       90\n",
      "11976                       68\n",
      "11977                       85\n",
      "11978                      112\n",
      "11979                      111\n",
      "11980                      111\n",
      "11981                      111\n",
      "11982                      112\n",
      "11983                       40\n",
      "11984                      111\n",
      "11985                      111\n",
      "11986                      112\n",
      "11987                       90\n",
      "11988                      111\n",
      "11989                      112\n",
      "11990                      112\n",
      "11991                       43\n",
      "11992                       41\n",
      "11993                       11\n",
      "11994                       66\n",
      "11995                       68\n",
      "11996                       88\n",
      "11997                       70\n",
      "11998                      112\n",
      "11999                      111\n",
      "\n",
      "[12000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def unique_count(df, cols, train_len):\n",
    "    col_name = 'nunique_' + '_'.join(cols)\n",
    "    count_result = df[cols].groupby(by=cols[:-1])[[cols[-1]]].nunique().rename(index=str,\\\n",
    "                                                                               columns={cols[-1]: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols[:-1], how='left')\n",
    "    print(_df[[col_name]])\n",
    "    save(_df[[col_name]], col_name, train_len)\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['day','ip','machine'],\n",
    "    ['day','ip','os'],\n",
    "    ['day','ip','device'],\n",
    "    ['day','ip','app'],\n",
    "    ['day','ip','channel'],\n",
    "    ['machine','app'],\n",
    "    ['machine','ip'],\n",
    "    ['machine','channel'],\n",
    "]\n",
    "\n",
    "write_log('unique count')\n",
    "for p in patterns:\n",
    "    unique_count(df, p, train_len)\n",
    "    write_log(str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cumulative count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## give an order number in each feature combination by each feature combination, sorted by [click_time, index, is_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:12:18.308310Z",
     "start_time": "2018-05-22T16:12:18.229300Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def cum_count(df, cols, train_len):\n",
    "    col_name = 'cumcount_' + '_'.join(cols)\n",
    "    result = df[cols].groupby(cols).cumcount().rename(col_name).to_frame().reset_index(drop=True)\n",
    "    save(result, col_name, train_len)\n",
    "    del result\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['ip','app','device','os','day','hour'],\n",
    "    ['ip','day'],\n",
    "    ['app','device','os','day']\n",
    "]\n",
    "\n",
    "write_log('cummulative count')\n",
    "df.sort_values(['click_time','index','is_test'], inplace=True)\n",
    "for p in patterns:\n",
    "    cum_count(df, p, train_len)\n",
    "    write_log(str(p))\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cols1 count / cols2 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:12:57.067120Z",
     "start_time": "2018-05-22T16:12:56.904326Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def _count(df, cols, label):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    result = _df[[col_name]].copy()\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    return result\n",
    "\n",
    "def count_ratio(df, cols1, cols2, label, train_len):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols1) + '_' + '_'.join(cols2)\n",
    "    x1 = _count(df, cols1, label)\n",
    "    x2 = _count(df, cols2, label)\n",
    "    x1[col_name] = x1[x1.columns.values[0]] / x2[x2.columns.values[0]] # or = round(x1 / x2, 4)\n",
    "    result = x1[[col_name]]\n",
    "    save(result, col_name, train_len)\n",
    "    del x1, x2\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    {'cols1':['ip'], 'cols2':['machine']},\n",
    "    {'cols1':['ip'], 'cols2':['channel']},\n",
    "    {'cols1':['machine'], 'cols2':['ip']},\n",
    "    {'cols1':['app'], 'cols2':['channel']},\n",
    "    {'cols1':['channel'], 'cols2':['app']}\n",
    "]\n",
    "\n",
    "write_log('count ratio')\n",
    "for p in patterns:\n",
    "    count_ratio(df, p['cols1'], p['cols2'], label, train_len)\n",
    "    write_log(str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cumulative count ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cols cumcount / (cols count-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:19:46.185475Z",
     "start_time": "2018-05-22T16:19:46.045993Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.000000\n",
      "1     1.000000\n",
      "2     0.000000\n",
      "3     0.333333\n",
      "4     0.666667\n",
      "5     1.000000\n",
      "6     0.000000\n",
      "7     0.500000\n",
      "8     1.000000\n",
      "9     0.000000\n",
      "10    0.333333\n",
      "11    0.000000\n",
      "12    0.500000\n",
      "13    1.000000\n",
      "14    0.000000\n",
      "15    1.000000\n",
      "16    0.000000\n",
      "17    1.000000\n",
      "18         NaN\n",
      "19    0.666667\n",
      "20    1.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def _count(df, cols, label):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    result = _df[[col_name]].copy()\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    return result\n",
    "\n",
    "def _cum_count(df, cols):\n",
    "    col_name = 'cumcount_ratio_' + '_'.join(cols)\n",
    "    result = df[cols].groupby(cols).cumcount().rename(col_name).to_frame()\n",
    "    return result.reset_index()[[col_name]]\n",
    "    \n",
    "def cum_count_ratio(df, cols, label, train_len):\n",
    "    col_name = 'cumcount_ratio_' + '_'.join(cols)\n",
    "    x1 = _cum_count(df, cols)\n",
    "    x2 = _count(df, cols, label)\n",
    "    x1[col_name] = round(x1[x1.columns.values[0]] / (x2[x2.columns.values[0]] - 1), 4).fillna(1.1)\n",
    "    result = x1[[col_name]]\n",
    "    save(result, col_name, train_len)\n",
    "    del x1, x2\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['ip','day']\n",
    "]\n",
    "\n",
    "write_log('cumulative count ratio')\n",
    "for p in patterns:\n",
    "    cum_count_ratio(df, p, label, train_len)\n",
    "    write_log(str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to n next click and its filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time delta from current click to the next same feature combination click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:23:48.303401Z",
     "start_time": "2018-05-22T16:23:48.144431Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def time_to_n_next_click(df, n, cols, time_col, train_len):\n",
    "    col_name = 'time_to_n_next_click_' + str(n) + '_' + '_'.join(cols)\n",
    "    total_cols = list(cols)\n",
    "    total_cols.append(time_col)\n",
    "    _df = df[total_cols].copy()\n",
    "    _df[col_name] = (_df.groupby(cols)[time_col].shift(-n) - _df[time_col] + 1).fillna(999999).astype(int)\n",
    "    out = _df[[col_name]].sort_index()\n",
    "    save(out, col_name, train_len)\n",
    "    del _df, out\n",
    "    gc.collect()\n",
    "    return col_name\n",
    "    \n",
    "def time_to_n_next_click_filter(name, train_len):\n",
    "    col_name = 'filter_' + name\n",
    "    in_func_train = pd.read_feather(fdir + 'train__' + name + '.ftr')\n",
    "    in_func_test = pd.read_feather(fdir + 'test_supplement__' + name + '.ftr')\n",
    "    in_func_df = pd.concat([in_func_train, in_func_test], ignore_index=True)\n",
    "    in_func_df[col_name] = 2\n",
    "    in_func_df[col_name] -= (in_func_df[name] < 1800) & (in_func_df[name] > 2)\n",
    "    in_func_df[col_name] -= (in_func_df[name] < 30) * 2\n",
    "    in_func_df\n",
    "    save(in_func_df[[col_name]], col_name, train_len)\n",
    "    del in_func_df, in_func_train, in_func_test\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['day','ip','app','device','os']\n",
    "]\n",
    "\n",
    "write_log('time to next')\n",
    "df.sort_values(['click_time','is_attributed','click_id'], inplace=True)\n",
    "for p in patterns:\n",
    "    time_to_n_next_click_filter(time_to_n_next_click(df, 1, p, 'click_timestamp', train_len), train_len)\n",
    "    time_to_n_next_click_filter(time_to_n_next_click(df, 2, p, 'click_timestamp', train_len), train_len)\n",
    "    write_log(str(p))\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# range count (same as unique count of certain time col group by feature combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:24:29.781001Z",
     "start_time": "2018-05-22T16:24:29.671383Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def unique_count(df, cols, train_len):\n",
    "    col_name = 'rang_count_' + '_'.join(cols)\n",
    "    count_result = df[cols].groupby(by=cols[:-1])[[cols[-1]]].nunique().rename(index=str,\\\n",
    "                                                                               columns={cols[-1]: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols[:-1], how='left')\n",
    "    save(_df[[col_name]], col_name, train_len)\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['ip','day'],\n",
    "    ['ip','hour'],\n",
    "    ['ip','dayhourminute'],\n",
    "    ['ip','dayhourminute10'],\n",
    "    ['app','os','channel','dayhourminute'],\n",
    "    ['app','os','channel','dayhourminute10'],\n",
    "    ['ip','channel','dayhourminute'],\n",
    "    ['ip','channel','dayhourminute10'],\n",
    "    ['ip','device','os','dayhourminute'],\n",
    "    ['ip','device','os','dayhourminute10'],\n",
    "]\n",
    "\n",
    "write_log('range count')\n",
    "for p in patterns:\n",
    "    unique_count(df, p, train_len)\n",
    "    write_log(str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variance (/(N-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variance for the last col element groupby the first several columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:25:36.398468Z",
     "start_time": "2018-05-22T16:25:36.311305Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variance(df, cols, train_len):\n",
    "    col_name = 'variance_' + '_'.join(cols)\n",
    "    group = df[cols].groupby(by=cols[:-1])[[cols[-1]]].var().reset_index().rename(index=str, columns={cols[-1]: col_name})\n",
    "    group[col_name] = group[col_name].fillna(0).astype(int)\n",
    "    type_map = {i: data_type[i] for i in group.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(group, on=cols[:-1], how='left')\n",
    "    save(_df[[col_name]], col_name, train_len)\n",
    "    del _df, group\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['ip','device','hour']\n",
    "]\n",
    "\n",
    "write_log('var')\n",
    "for p in patterns:\n",
    "    variance(df, p, train_len)\n",
    "    write_log(str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# common ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this part is to assume that std(count_ip/day)/mean(count_ip/day) will behave different when fraud comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T16:44:59.367781Z",
     "start_time": "2018-05-22T16:44:59.214517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "0\n",
      "1\n",
      "2\n",
      "5\n",
      "7\n",
      "9\n",
      "    ip\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    3\n",
      "10   3\n",
      "11   3\n",
      "12   3\n",
      "13   3\n",
      "14   3\n",
      "15   3\n",
      "16   3\n",
      "17   3\n",
      "18   3\n",
      "19   3\n",
      "20   3\n",
      "21   0\n",
      "22   0\n",
      "23   0\n",
      "24   0\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def get_com_ip(df, col, train_len):\n",
    "    fday = df[col].min()\n",
    "    lday = df[col].max()\n",
    "    if len(df[df.day==fday]) < 1000:\n",
    "        fday += 1\n",
    "    if len(df[df.day==lday]) < 1000:\n",
    "        lday -= 1\n",
    "        \n",
    "    name = 'com_ip'\n",
    "    com_set = set()\n",
    "    for d in range(fday,lday+1):\n",
    "        if d == fday:\n",
    "            com_set = set(df[df[col]==d]['ip'].unique())\n",
    "        else:\n",
    "            com_set = com_set & set(df[df[col]==d]['ip'].unique())\n",
    "    flt_ip = df.ip.isin(com_set)\n",
    "    com_ip = ((df['ip'] + 1) * flt_ip).to_frame()\n",
    "    print(com_ip)\n",
    "    save(com_ip, name, train_len)\n",
    "    \n",
    "    del com_ip\n",
    "    gc.collect()    \n",
    "    return flt_ip\n",
    "\n",
    "\n",
    "def dump_com_ip_feature(df, flt_ip, threshold, label, train_len):\n",
    "    com_df = df[flt_ip]\n",
    "    name = 'com' + str(threshold) + '_ip'\n",
    "    cols = ['ip', 'day']\n",
    "    total_cols = cols.copy()\n",
    "    total_cols.append(label)\n",
    "    group = com_df[total_cols].groupby(by=cols)[[label]].count().reset_index().rename(index=str, columns={label: 'count'})\n",
    "    result = group[['ip','count']].groupby('ip')[['count']].agg(['mean', 'std'])['count'].reset_index()\n",
    "    result['flg'] = (100 * result['std'] / result['mean']) <= threshold\n",
    "    type_map = {i: data_type[i] for i in result.columns.values if i in data_type.keys()}\n",
    "    _df = pd.merge(df, result[['ip','flg']], on='ip', how='left').fillna(False)\n",
    "    _df[name] = (_df['ip']+1) * _df['flg']\n",
    "    save(_df[[name]], name, train_len)\n",
    "\n",
    "    del _df\n",
    "    gc.collect()\n",
    "\n",
    "write_log('common ip')\n",
    "dump_com_ip_feature(df, get_com_ip(df, 'day', train_len), 1, label, train_len)\n",
    "write_log(str(['ip', 'day']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WOE (categorical feature encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use day 7,9 to get day 8, and same for other days on training and use all training to get woe on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-22T18:08:14.588Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "def _woe(calc_df, map_df, cols, label, col_name):\n",
    "    t_cols = list(cols)\n",
    "    t_cols.append(label)\n",
    "    group = calc_df[t_cols].groupby(by=cols)[[label]].agg(['count','sum'])[label].reset_index()\n",
    "    positive = calc_df[label].sum()\n",
    "    negative = calc_df.shape[0] - positive\n",
    "#     group[col_name] = np.log((group['sum']+0.5) / positive) / ((group['count']-group['sum']+0.5) / negative)\n",
    "    group[col_name] = np.log((group['sum'] / positive) / ((group['count']-group['sum']) / negative)) + 1\n",
    "    t_cols[-1] = col_name\n",
    "    type_map = {i: data_type[i] for i in group.columns.values if i in data_type.keys()}\n",
    "    return map_df.merge(group[t_cols], on=cols, how='left')\n",
    "\n",
    "def woe(train, test, cols, label):\n",
    "    fdf = train\n",
    "    fdf = train[train['hour']>=12]\n",
    "    fdf = fdf[fdf['hour']<=22]\n",
    "    fday = train['day'].min()\n",
    "    lday = train['day'].max()\n",
    "    total_cols = list(cols)\n",
    "    total_cols.append(label)\n",
    "    col_name = 'woe_' + '_'.join(cols)\n",
    "    _df_list = [_woe(fdf[fdf.day!=day], train[train.day==day], cols, label, col_name) for day in range(fday,lday+1)]\n",
    "    _df = pd.concat(_df_list).fillna(-1).reset_index(drop=True)\n",
    "    _df[[col_name]].to_feather(fdir + 'train__' + col_name + '.ftr')\n",
    "    del _df, _df_list\n",
    "    gc.collect()\n",
    "    \n",
    "    _df = _woe(fdf, test, cols, label, col_name).fillna(-1).reset_index()\n",
    "    _df[[col_name]].to_feather(fdir + 'test_supplement__' + col_name + '.ftr')\n",
    "    del _df\n",
    "    gc.collect()\n",
    "\n",
    "patterns = [\n",
    "    ['ip'],\n",
    "    ['app'],\n",
    "    ['device'],\n",
    "    ['os'],\n",
    "    ['channel'],\n",
    "    ['ip','app'],\n",
    "    ['ip','device'],\n",
    "    ['ip','os'],\n",
    "    ['ip','channel'],\n",
    "    ['app','device'],\n",
    "    ['app','os'],\n",
    "    ['app','channel'],\n",
    "    ['ip','app','device'],\n",
    "    ['ip','app','os'],\n",
    "    ['ip','app','channel'],\n",
    "    ['ip','device','os'],\n",
    "    ['ip','device','channel'],\n",
    "    ['ip','os','channel'],\n",
    "    ['app','device','os'],\n",
    "    ['app','device','channel'],\n",
    "    ['app','os','channel'],\n",
    "    ['ip','app','device','os'],\n",
    "    ['ip','app','device','channel'],\n",
    "    ['ip','app','os','channel'],\n",
    "    ['ip','device','os','channel'],\n",
    "    ['app','device','os','channel'],\n",
    "    ['ip','nextClickLeakDayFlt'],\n",
    "    ['app','nextClickLeakDayFlt'],\n",
    "    ['device','nextClickLeakDayFlt'],\n",
    "    ['os','nextClickLeakDayFlt'],\n",
    "    ['channel','nextClickLeakDayFlt'],\n",
    "    ['ip','app','nextClickLeakDayFlt'],\n",
    "    ['ip','device','nextClickLeakDayFlt'],\n",
    "    ['ip','os','nextClickLeakDayFlt'],\n",
    "    ['ip','channel','nextClickLeakDayFlt'],\n",
    "    ['app','device','nextClickLeakDayFlt'],\n",
    "    ['app','os','nextClickLeakDayFlt'],\n",
    "    ['app','channel','nextClickLeakDayFlt'],\n",
    "    ['device','os','nextClickLeakDayFlt'],\n",
    "    ['device','channel','nextClickLeakDayFlt'],\n",
    "    ['os','channel','nextClickLeakDayFlt']\n",
    "]\n",
    "woe_train = train\n",
    "woe_train['nextClickLeakDayFlt'] = pd.read_feather(fdir + 'train__filter_time_to_n_next_click_1_day_ip_app_device_os.ftr')\n",
    "woe_test = test\n",
    "woe_test['nextClickLeakDayFlt']=pd.read_feather\\\n",
    "        (fdir + 'test_supplement__filter_time_to_n_next_click_1_day_ip_app_device_os.ftr')\n",
    "\n",
    "write_log('woe')\n",
    "for p in patterns:\n",
    "    woe(woe_train, woe_test, p, label)\n",
    "    write_log(str(p))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T18:04:31.324067Z",
     "start_time": "2018-05-22T18:00:20.488Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_log('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-22T18:04:31.329633Z",
     "start_time": "2018-05-22T18:00:20.659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T12:55:16.531884Z",
     "start_time": "2018-05-24T12:55:16.518599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A   B key2\n",
      "key1             \n",
      "K0    A0  B0   K0\n",
      "K0    A1  B1   K1\n",
      "K1    A2  B2   K0\n",
      "K2    A3  B3   K1\n"
     ]
    }
   ],
   "source": [
    "left_index = pd.Index(['K0', 'K0', 'K1', 'K2'], name='key1')\n",
    "left = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                      'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'key2': ['K0', 'K1', 'K0', 'K1']},\n",
    "                   index=left_index)\n",
    "\n",
    "print(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T12:56:15.551736Z",
     "start_time": "2018-05-24T12:56:15.533583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       C   D key2\n",
      "key1             \n",
      "K0    C0  D0   K0\n",
      "K1    C1  D1   K0\n",
      "K2    C2  D2   K0\n",
      "K2    C3  D3   K1\n"
     ]
    }
   ],
   "source": [
    "right_index = pd.Index(['K0', 'K1', 'K2', 'K2'], name='key1')\n",
    "right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3'],\n",
    "                       'key2': ['K0', 'K0', 'K0', 'K1']},\n",
    "                     index=right_index)\n",
    "print(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T12:57:44.506229Z",
     "start_time": "2018-05-24T12:57:44.501360Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-30-a05afe5a9bd2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-a05afe5a9bd2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    left.merge(right, on=[key2'])\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "left.merge(right, on=[key2'])\n",
    "print(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T13:08:03.529797Z",
     "start_time": "2018-05-24T13:08:03.440372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    app  channel  is_attributed\n",
      "0     3      379              0\n",
      "1     3      379              0\n",
      "2     3      379              0\n",
      "3    14      478              0\n",
      "4     3      379              0\n",
      "5     3      379              0\n",
      "6     3      379              2\n",
      "7     3      379              2\n",
      "8     3      379              2\n",
      "9     3      379              2\n",
      "10   58      120              2\n",
      "11    3      379              2\n",
      "             is_attributed\n",
      "app channel               \n",
      "3   379                 10\n",
      "14  478                  1\n",
      "58  120                  1\n",
      "  app channel  count_app_channel\n",
      "0   3     379                 10\n",
      "1  14     478                  1\n",
      "2  58     120                  1\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Here df is [train test_supp]\n",
    "def count(df, cols, label, train_len): # label : is_attributed\n",
    "    col_name = 'count_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    print(df[d_cols])\n",
    "    print(df[d_cols].groupby(by=cols)[[label]].count())\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    print(count_result)\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "#     print(type_map)\n",
    "#     _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    _df = df.merge(count_result,  how='left')\n",
    "#     print(_df)\n",
    "    save(_df[[col_name]], col_name, train_len)\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "\n",
    "patterns = [\n",
    "    ['app','channel'],\n",
    "#     ['app','device','channel','day','hour'],##\n",
    "#     ['app','device','day','hour'],##\n",
    "#     ['app','os','channel','day','hour'],##\n",
    "#     ['ip','day'],\n",
    "#     ['ip'],#\n",
    "#     ['ip','app','device','channel','day'],##\n",
    "#     ['ip','app','device','day'],##\n",
    "#     ['ip','app','device','os','day','hour'],##\n",
    "#     ['ip','app','os','channel'],##\n",
    "#     ['ip','app','os','channel','day'],##\n",
    "#     ['ip','os'],\n",
    "#     ['app','day','hourminute'],\n",
    "#     ['device','os','day','hourminute10'],##\n",
    "#     ['ip','device','os','day','hourminute10']##\n",
    "]\n",
    "\n",
    "\n",
    "write_log('count')\n",
    "for p in patterns:\n",
    "    count(df, p, label, train_len)\n",
    "    write_log(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
