{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:21.169126Z",
     "start_time": "2018-07-17T18:02:21.146615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kai/data/shiyi/AlphaBoosting/automl/automl_app\n",
      "['', '/home/kai/anaconda3/envs/tf_gpu/lib/python35.zip', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/plat-linux', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/lib-dynload', '/home/kai/.local/lib/python3.5/site-packages', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/extensions', '/home/kai/.ipython', '/home/kai/data/shiyi/AlphaBoosting/automl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "print(nb_dir)\n",
    "#if nb_dir not in sys.path:\n",
    "#    sys.path.append(nb_dir)\n",
    "    \n",
    "# autolib_dir = '/home/kai/data/shiyi/AlphaBoosting/automl'\n",
    "autolib_dir = '/'.join(nb_dir.split('/')[:-1])\n",
    "if autolib_dir not in sys.path:\n",
    "    sys.path.append(autolib_dir)\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.222592Z",
     "start_time": "2018-07-17T18:02:21.170865Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from automl_libs import base_layer_utils, stacknet\n",
    "from automl_libs import feature_engineering as fe\n",
    "from automl_libs import encoding, kernels, nn_libs, utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.241690Z",
     "start_time": "2018-07-17T18:02:22.224135Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = ['Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'UniqueCarrier', 'Origin', 'Dest', 'Distance'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.270892Z",
     "start_time": "2018-07-17T18:02:22.243505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_cols': ['Month', 'DayofMonth'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'DayOfWeek'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'DepTime'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'UniqueCarrier'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'DayOfWeek'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'DepTime'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'UniqueCarrier'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'DepTime'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'UniqueCarrier'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DepTime', 'UniqueCarrier'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DepTime', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DepTime', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DepTime', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['UniqueCarrier', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['UniqueCarrier', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['UniqueCarrier', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Origin', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Origin', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Dest', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "#params = {'split_col': 't', 'coefficient': 10, 'n': 2, 'fillna': 22}\n",
    "def get_features_to_gen(function_list, low, high):\n",
    "    features_to_gen = []\n",
    "    for function in function_list:\n",
    "        for i in range(low, high+1):\n",
    "            for combine in itertools.combinations(categorical_features, i):\n",
    "                if function.__name__ == 'count_std_over_mean':\n",
    "                    features_to_gen.append({'params': {'coefficient': 10}, 'function': function, 'feature_cols': list(combine)})\n",
    "                else:\n",
    "                    features_to_gen.append({'params': {}, 'function': function, 'feature_cols': list(combine)})\n",
    "                \n",
    "    return features_to_gen\n",
    "\n",
    "# features_to_gen = get_features_to_gen([fe.count, fe.unique_count, \n",
    "#                                        fe.cumulative_count, \n",
    "#                                        fe.reverse_cumulative_count, \n",
    "#                                        fe.variance, fe.count_std_over_mean], \n",
    "#                                       2, 2)# len(categorical_features))\n",
    "# features_to_gen = get_features_to_gen([fe.count, fe.unique_count, fe.cumulative_count])\n",
    "features_to_gen = get_features_to_gen([fe.count], 2, 2)#len(categorical_features))\n",
    "\n",
    "features_to_gen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.290082Z",
     "start_time": "2018-07-17T18:02:22.272265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_to_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.308251Z",
     "start_time": "2018-07-17T18:02:22.291451Z"
    }
   },
   "outputs": [],
   "source": [
    "project_path = './' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.327238Z",
     "start_time": "2018-07-17T18:02:22.309606Z"
    }
   },
   "outputs": [],
   "source": [
    "from automl_app import logger_config\n",
    "import logging\n",
    "logger_config.config(project_path+'project.log', file_loglevel=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.372119Z",
     "start_time": "2018-07-17T18:02:22.328672Z"
    }
   },
   "outputs": [],
   "source": [
    "def params_gen(model='lgb'):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    seed = int(time.time()* 1000000) % 45234634\n",
    "    np.random.seed(seed)\n",
    "    if model == 'svc':\n",
    "        params = {\n",
    "            'C': 0.911#np.random.rand(),\n",
    "#             'metric': 'roc_auc'\n",
    "        }\n",
    "    elif model == 'logreg':\n",
    "        params = {\n",
    "            'penalty': np.random.choice(['l2']),\n",
    "            'dual': np.random.choice([True, False]),\n",
    "            'C': 1,#np.random.rand(),\n",
    "            'metric': 'roc_auc'\n",
    "        }\n",
    "    elif model == 'lgb':\n",
    "        params = {    \n",
    "            'objective': 'binary',\n",
    "            'boosting': 'gbdt',\n",
    "            'num_boost_round': 10, # ignored in params. extract it and put it in input arguments in train or cv explicitly\n",
    "                                   # seems to work fine as the upper limit when combined with early_stopping_round\n",
    "            'learning_rate': np.random.choice([0.1,0.03]),#0.001]),\n",
    "            'num_leaves': np.random.choice([15,31]),#,61,127]),\n",
    "            'num_threads': 8, # best speed: set to number of real cpu cores, which is vCPU/2\n",
    "            'max_depth': -1, # no limit. This is used to deal with over-fitting when #data is small.\n",
    "            'min_data_in_leaf': np.random.randint(20,50),  #minimal number of data in one leaf. \n",
    "            'feature_fraction': np.random.randint(9,11)/10,\n",
    "            'feature_fraction_seed': seed,\n",
    "            'early_stopping_round':10,\n",
    "            'bagging_freq': 1, #0 means disable bagging. k: perform bagging at every k iteration\n",
    "            'bagging_fraction': np.random.randint(4,11)/10, #Randomly select part of data \n",
    "            'bagging_seed': seed,\n",
    "            'scale_pos_weight': 1,\n",
    "            'metric': 'auc'\n",
    "#             'objective': 'binary',\n",
    "#             'boosting': 'gbdt',\n",
    "#             'num_boost_round': 10, # ignored in params. extract it and put it in input arguments in train or cv explicitly\n",
    "#                                    # seems to work fine as the upper limit when combined with early_stopping_round\n",
    "#             'learning_rate': 0.01,\n",
    "#             'num_leaves': 50,\n",
    "#             'num_threads': 8, # best speed: set to number of real cpu cores, which is vCPU/2\n",
    "#             'max_depth': 5, # no limit. This is used to deal with over-fitting when #data is small.\n",
    "#             'min_split_gain': 0.02,\n",
    "#             'min_child_weight': 18.6,\n",
    "#             'feature_fraction': 0.1,\n",
    "#             'feature_fraction_seed': 1992,\n",
    "#             'early_stopping_round':10,\n",
    "#             'bagging_freq': 1, #0 means disable bagging. k: perform bagging at every k iteration\n",
    "#             'bagging_fraction': np.random.randint(4,11)/10, #Randomly select part of data \n",
    "#             'bagging_seed': 1992,\n",
    "#             'scale_pos_weight': 1,\n",
    "#             'lambda_l1': 0.8,\n",
    "#             'lambda_l2': 0.6,\n",
    "#             'metric': 'auc'\n",
    "        }\n",
    "    elif model == 'xgb':\n",
    "        params = {\n",
    "            'eta': 0.1,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'booster': 'gbtree',\n",
    "            'tree_method': 'hist',\n",
    "            'max_bin': 8,\n",
    "            'scale_pos_weight': 1,\n",
    "            'seed': seed,\n",
    "            'nthread': 10,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 22,\n",
    "            'gamma': 0,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'colsample_bylevel': 0.675,\n",
    "            'alpha': 0,\n",
    "            'lambda': 0,\n",
    "            'num_boost_round': 50,\n",
    "            'early_stopping_rounds': 1\n",
    "        }\n",
    "    elif model == 'nn':\n",
    "        params = {\n",
    "            'nn_seed': int(time.time() * 1000000) % 45234634,\n",
    "            'ep_for_lr': np.random.randint(2,10),\n",
    "            'lr_init': 0.01,\n",
    "            'lr_fin': np.random.randint(1,5)/1000,  # if == lr_init, then no lr decay\n",
    "            'batch_size': np.random.choice([128, 256, 512, 1024]),\n",
    "            \"pred_batch_size\": 5000,\n",
    "            'max_ep': 100,\n",
    "            'patience': 10, #np.random.randint(10, 25),\n",
    "            'cat_emb_outdim': 30, # could be a constant or a dict (col name:embed out dim). e.g.:\n",
    "                                  # embed_outdim = [3, 3, 8, 8, 3]\n",
    "                                  # embed_outdim_dict = dict(zip(X_train.columns.values, embed_outdim))\n",
    "                                  # then assige embed_outdim_dict to cat_emb_outdim\n",
    "            'cat_emb_drop_rate': np.random.randint(1,4)/10, \n",
    "            'num_layers_dense_units': [1000, 500, 100],\n",
    "            'num_layers_drop_rate': np.random.randint(2,6)/10,\n",
    "            'combined_layers_dense_units': [100, 50],\n",
    "            'combined_layers_drop_rate': np.random.randint(1,3)/10,\n",
    "            'monitor': 'val_auc',  # or val_loss (MUST HAVE)\n",
    "            'mode': 'max',  # MUST HAVE\n",
    "            'int_list': ['num_layers_dense_units', 'combined_layers_dense_units']\n",
    "        }\n",
    "    elif model == 'stacknet_layer2_nn':\n",
    "        params = {\n",
    "            'nn_seed': int(time.time() * 1000000) % 45234634,\n",
    "            'ep_for_lr': 1,\n",
    "            'lr_init': 0.01,\n",
    "            'lr_fin': 0.01, # if == lr_init, then no lr decay\n",
    "            'batch_size': 128,\n",
    "            \"pred_batch_size\": 50000,\n",
    "            'best_epoch': 1,\n",
    "            'patience': 1,\n",
    "            'categorical_feature': [],\n",
    "            'cat_emb_outdim': 50, # could be a constant or a dict (col name:embed out dim). e.g.:\n",
    "                                  # embed_outdim = [3, 3, 8, 8, 3]\n",
    "                                  # embed_outdim_dict = dict(zip(X_train.columns.values, embed_outdim))\n",
    "            'num_layers_dense_units': [],\n",
    "            'combined_layers_dense_units': [10, 5],\n",
    "            'combined_layers_drop_rate': 0,\n",
    "            'monitor': 'val_auc',  # or val_loss (MUST HAVE)\n",
    "            'mode': 'max',  # MUST HAVE\n",
    "            'int_list': ['num_layers_dense_units', 'combined_layers_dense_units']\n",
    "        }\n",
    "    return params, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.391741Z",
     "start_time": "2018-07-17T18:02:22.373609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'batch_size': 128,\n",
       "  'best_epoch': 1,\n",
       "  'cat_emb_outdim': 50,\n",
       "  'categorical_feature': [],\n",
       "  'combined_layers_dense_units': [10, 5],\n",
       "  'combined_layers_drop_rate': 0,\n",
       "  'ep_for_lr': 1,\n",
       "  'int_list': ['num_layers_dense_units', 'combined_layers_dense_units'],\n",
       "  'lr_fin': 0.01,\n",
       "  'lr_init': 0.01,\n",
       "  'mode': 'max',\n",
       "  'monitor': 'val_auc',\n",
       "  'nn_seed': 17564270,\n",
       "  'num_layers_dense_units': [],\n",
       "  'patience': 1,\n",
       "  'pred_batch_size': 50000},\n",
       " 17564262)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, s = params_gen('stacknet_layer2_nn')\n",
    "p, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.411427Z",
     "start_time": "2018-07-17T18:02:22.393018Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, logtofile=True, logfilename='log'):\n",
    "        self.terminal = sys.stdout\n",
    "        self.logfile = \"{}_{}.log\".format(logfilename, int(time.time()))\n",
    "        self.logtofile = logtofile\n",
    "\n",
    "    def write(self, message):\n",
    "#         self.terminal.write(message)\n",
    "        if self.logtofile:\n",
    "            self.log = open(self.logfile, \"a\")\n",
    "            self.log.write('['+utils.get_time()+'] '+message)  \n",
    "            self.log.close()\n",
    "\n",
    "\n",
    "    def flush(self):\n",
    "        #this flush method is needed for python 3 compatibility.\n",
    "        #this handles the flush command by doing nothing.\n",
    "        #you might want to specify some extra behavior here.\n",
    "        pass    \n",
    "\n",
    "def divert_printout_to_file():\n",
    "    sys.stdout = Logger(logfilename='logfile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:22.429284Z",
     "start_time": "2018-07-17T18:02:22.412817Z"
    }
   },
   "outputs": [],
   "source": [
    "# divert_printout_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T18:02:29.431972Z",
     "start_time": "2018-07-17T18:02:22.430440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting.__init__             | #22  | ==========START==========\n",
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting.__init__             | #67  | Run record file [./output/last_run_record.json] found. Continue from the previous run...\n",
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting.__init__             | #96  | generate todo list\n",
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting.__init__             | #112 | STAGE: FEATURE_ENGINEERING\n",
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting.__init__             | #116 | STAGE: VALIDATION_DOWNSAMPLING_GEN\n",
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting.__init__             | #120 | STAGE: CONCAT_DATA\n",
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting.__init__             | #124 | STAGE: GRID_SEARCH\n",
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting._get_final_data      | #337 | DEBUG mode is on, 5.0% of train,val data are chosen\n",
      "2018-07-17 14:02:22 | INFO    | automl_app.app.AlphaBoosting._get_final_data      | #346 | Data <ordinal2> retrieved. Shape: train (42500, 37) | val (7500, 37) | test (100000, 36) | contain test label: True | 8 cat features | 36 total features | y name: label\n",
      "2018-07-17 14:02:22 | INFO    | automl_libs.grid_search.gs                   | #35  | Grid search xgb. round 1 of 2\n",
      "2018-07-17 14:02:23 | INFO    | automl_libs.grid_search._xgb_gs              | #320 | val_auc: 0.70498 | train_auc: 0.72018 (cv)\n",
      "2018-07-17 14:02:23 | INFO    | automl_libs.grid_search._xgb_gs              | #342 | [do_preds] is True, generating predictions ...\n",
      "2018-07-17 14:02:23 | INFO    | automl_libs.grid_search._xgb_gs              | #344 | Retrain model using best_round [7] and all data...\n",
      "2018-07-17 14:02:23 | INFO    | automl_libs.grid_search._xgb_gs              | #352 | Training done. Iteration: 7 | train_auc: 0.71986\n",
      "2018-07-17 14:02:23 | INFO    | automl_libs.grid_search._xgb_gs              | #357 | (_nn_gs) roc of test: 0.6976605646392475\n",
      "2018-07-17 14:02:23 | INFO    | automl_libs.grid_search._xgb_gs              | #362 | XGB predictions(1B80) saved in ./output/gs_saved_preds/.\n",
      "2018-07-17 14:02:23 | INFO    | automl_libs.grid_search.gs                   | #70  | ./output/xgb_ordinal2_grid_search.csv updated\n",
      "2018-07-17 14:02:23 | INFO    | automl_libs.grid_search.gs                   | #35  | Grid search xgb. round 2 of 2\n",
      "2018-07-17 14:02:25 | INFO    | automl_libs.grid_search._xgb_gs              | #320 | val_auc: 0.72402 | train_auc: 0.76343 (cv)\n",
      "2018-07-17 14:02:25 | INFO    | automl_libs.grid_search._xgb_gs              | #342 | [do_preds] is True, generating predictions ...\n",
      "2018-07-17 14:02:25 | INFO    | automl_libs.grid_search._xgb_gs              | #344 | Retrain model using best_round [50] and all data...\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.grid_search._xgb_gs              | #352 | Training done. Iteration: 50 | train_auc: 0.75871\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.grid_search._xgb_gs              | #357 | (_nn_gs) roc of test: 0.7151210151040419\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.grid_search._xgb_gs              | #362 | XGB predictions(sxgy) saved in ./output/gs_saved_preds/.\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.grid_search.gs                   | #70  | ./output/xgb_ordinal2_grid_search.csv updated\n",
      "2018-07-17 14:02:26 | INFO    | automl_app.app.AlphaBoosting.__init__             | #128 | STAGE: STACKNET\n",
      "2018-07-17 14:02:26 | INFO    | automl_app.app.AlphaBoosting._get_final_data      | #337 | DEBUG mode is on, 5.0% of train,val data are chosen\n",
      "2018-07-17 14:02:26 | INFO    | automl_app.app.AlphaBoosting._get_final_data      | #346 | Data <ordinal2> retrieved. Shape: train (42500, 37) | val (7500, 37) | test (100000, 36) | contain test label: True | 8 cat features | 36 total features | y name: label\n",
      "2018-07-17 14:02:26 | INFO    | automl_app.app.AlphaBoosting._stacknet            | #301 | layers to be built: [1]\n",
      "2018-07-17 14:02:26 | DEBUG   | automl_libs.stacknet.layer1               | #42  | data_id: ordinal2             \n",
      "\tx_train: (50000, 36)\tx_test: (100000, 36)\n",
      "\ty_train type: <class 'dict'>\n",
      "\tcompatible_models: set()\n",
      " \n",
      "2018-07-17 14:02:26 | DEBUG   | automl_libs.base_layer_utils.BaseLayerResultsRepo.__init__             | #235 | load StackNet saves from file\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.stacknet.layer1               | #67  | syXQ already processed in StackNet, so removed it from chosen_gs_results\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.stacknet.layer1               | #67  | LPQG already processed in StackNet, so removed it from chosen_gs_results\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.stacknet.layer1               | #74  | using xgb params: sxgy to do oof\n",
      "2018-07-17 14:02:26 | DEBUG   | automl_libs.stacknet.layer1               | #75  | {'lambda': 0, 'gamma': 0, 'early_stopping_rounds': 1, 'max_depth': 6, 'scale_pos_weight': 1, 'colsample_bylevel': 0.675, 'subsample': 0.7, 'max_bin': 8, 'cv': True, 'val_auc': 0.7240238, 'booster': 'gbtree', 'num_boost_round': 50, 'pred_timespent': '0:00:00', 'alpha': 0, 'nthread': 10, 'data_name': 'ordinal2', 'eta': 0.1, 'eval_metric': 'auc', 'best_round': 50, 'seed': 18976335, 'min_child_weight': 22, 'objective': 'binary:logistic', 'train_auc': 0.763429, 'gs_timespent': '0:00:02', 'colsample_bytree': 0.7, 'tree_method': 'hist', 'timestamp': '2018-07-17 14:02:23'}\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.base_layer_utils.compute_layer1_oof   | #499 | StackNet layer1: label: label    model_data_id: sxgy__XGB_ordinal2_layer1\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.base_layer_utils.get_oof              | #435 | processing fold 1 of 5...\n",
      "2018-07-17 14:02:26 | INFO    | automl_libs.stack_layer_estimator.XgboostBLE.train                | #208 | No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "2018-07-17 14:02:27 | INFO    | automl_libs.base_layer_utils.get_oof              | #449 | metric of fold 1: 0.7241303934661945\n",
      "2018-07-17 14:02:27 | INFO    | automl_libs.base_layer_utils.get_oof              | #435 | processing fold 2 of 5...\n",
      "2018-07-17 14:02:27 | INFO    | automl_libs.stack_layer_estimator.XgboostBLE.train                | #208 | No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "2018-07-17 14:02:27 | INFO    | automl_libs.base_layer_utils.get_oof              | #449 | metric of fold 2: 0.7106562980829529\n",
      "2018-07-17 14:02:27 | INFO    | automl_libs.base_layer_utils.get_oof              | #435 | processing fold 3 of 5...\n",
      "2018-07-17 14:02:27 | INFO    | automl_libs.stack_layer_estimator.XgboostBLE.train                | #208 | No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.base_layer_utils.get_oof              | #449 | metric of fold 3: 0.7276138074811309\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.base_layer_utils.get_oof              | #435 | processing fold 4 of 5...\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.stack_layer_estimator.XgboostBLE.train                | #208 | No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.base_layer_utils.get_oof              | #449 | metric of fold 4: 0.7275991623979401\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.base_layer_utils.get_oof              | #435 | processing fold 5 of 5...\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.stack_layer_estimator.XgboostBLE.train                | #208 | No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.base_layer_utils.get_oof              | #449 | metric of fold 5: 0.7215190019610606\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.base_layer_utils.compute_layer1_oof   | #528 | oof is done\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.base_layer_utils.compute_layer1_oof   | #532 | Training using all data and gen prediction for submission...\n",
      "2018-07-17 14:02:28 | INFO    | automl_libs.stack_layer_estimator.XgboostBLE.train                | #208 | No evaluation set, thus not possible to use early stopping. Please train with your best params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-17 14:02:29 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.update_report        | #280 | StackNet report updated: sxgy__XGB_ordinal2_layer1: oof_cv_score => 0.7223037326778557\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.add_score            | #299 | sxgy__XGB_ordinal2_layer1 found in repo. Update score from 0 to 0.72402\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.update_report        | #280 | StackNet report updated: sxgy__XGB_ordinal2_layer1: gs_val_auc => 0.7240238\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.update_report        | #280 | StackNet report updated: sxgy__XGB_ordinal2_layer1: test_score => 0.7151210151040419\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.save                 | #393 | StackNet data saved for: ['Ffk4__LGB_ordinal_layer1', '8jnJ__LGB_ordinal_layer1', 'GBVc__XGB_ordinal_layer1', '6XfZ__XGB_ordinal_layer1', '5tVU__LOGREG_layer2', '38jO__XGB_ordinal2_layer1', 'Gy79__LOGREG_layer2', 'syXQ__XGB_ordinal2_layer1', 'bNsu__XGB_ordinal2_layer1', 'LPQG__XGB_ordinal2_layer1', '4IJJ__NN_layer2', 'HH37__LOGREG_layer2', 'sxgy__XGB_ordinal2_layer1']\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.save                 | #397 | StackNet report saved at ./output/oof/stacknet_report.csv\n",
      "2018-07-17 14:02:29 | DEBUG   | automl_libs.base_layer_utils.BaseLayerResultsRepo.__init__             | #235 | load StackNet saves from file\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.stacknet.layer1               | #67  | Ffk4 already processed in StackNet, so removed it from chosen_gs_results\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.stacknet.layer1               | #67  | 8jnJ already processed in StackNet, so removed it from chosen_gs_results\n",
      "2018-07-17 14:02:29 | DEBUG   | automl_libs.base_layer_utils.BaseLayerResultsRepo.__init__             | #235 | load StackNet saves from file\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.stacknet.layer1               | #67  | GBVc already processed in StackNet, so removed it from chosen_gs_results\n",
      "2018-07-17 14:02:29 | INFO    | automl_libs.stacknet.layer1               | #67  | 6XfZ already processed in StackNet, so removed it from chosen_gs_results\n",
      "2018-07-17 14:02:29 | INFO    | automl_app.app.AlphaBoosting.__init__             | #132 | save run record\n",
      "2018-07-17 14:02:29 | INFO    | automl_app.app.AlphaBoosting._save_run_record     | #164 | val index is saved at ./temp_data/val_index.pkl\n",
      "2018-07-17 14:02:29 | INFO    | automl_app.app.AlphaBoosting._save_run_record     | #166 | run record is saved at ./output/last_run_record.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<automl_app.app.AlphaBoosting at 0x7f185b5f24a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from automl_app.app import AlphaBoosting\n",
    "\n",
    "automl_config_file = project_path + 'automl_config.json'\n",
    "run_record_file_name = project_path + 'last_run_record.json' # don't created this file\n",
    "AlphaBoosting(automl_config_file, features_to_gen, params_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
