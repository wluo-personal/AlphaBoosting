{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:21.834677Z",
     "start_time": "2018-07-10T17:58:21.818107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kai/data/shiyi/AlphaBoosting/automl/automl_app\n",
      "['', '/home/kai/anaconda3/envs/tf_gpu/lib/python35.zip', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/plat-linux', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/lib-dynload', '/home/kai/.local/lib/python3.5/site-packages', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages', '/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/extensions', '/home/kai/.ipython', '/home/kai/data/shiyi/AlphaBoosting/automl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "print(nb_dir)\n",
    "#if nb_dir not in sys.path:\n",
    "#    sys.path.append(nb_dir)\n",
    "    \n",
    "# autolib_dir = '/home/kai/data/shiyi/AlphaBoosting/automl'\n",
    "autolib_dir = '/'.join(nb_dir.split('/')[:-1])\n",
    "if autolib_dir not in sys.path:\n",
    "    sys.path.append(autolib_dir)\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.254971Z",
     "start_time": "2018-07-10T17:58:21.837064Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from automl_libs import base_layer_utils, stacknet\n",
    "from automl_libs import feature_engineering as fe\n",
    "from automl_libs import encoding, kernels, nn_libs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.276558Z",
     "start_time": "2018-07-10T17:58:23.256403Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features = ['Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'UniqueCarrier', 'Origin', 'Dest', 'Distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.308681Z",
     "start_time": "2018-07-10T17:58:23.278510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_cols': ['Month', 'DayofMonth'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'DayOfWeek'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'DepTime'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'UniqueCarrier'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Month', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'DayOfWeek'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'DepTime'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'UniqueCarrier'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayofMonth', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'DepTime'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'UniqueCarrier'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DayOfWeek', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DepTime', 'UniqueCarrier'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DepTime', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DepTime', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['DepTime', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['UniqueCarrier', 'Origin'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['UniqueCarrier', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['UniqueCarrier', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Origin', 'Dest'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Origin', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}},\n",
       " {'feature_cols': ['Dest', 'Distance'],\n",
       "  'function': <function automl_libs.feature_engineering.count(df, cols, dummy_col, generated_feature_name, params=None)>,\n",
       "  'params': {}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "#params = {'split_col': 't', 'coefficient': 10, 'n': 2, 'fillna': 22}\n",
    "def get_features_to_gen(function_list, low, high):\n",
    "    features_to_gen = []\n",
    "    for function in function_list:\n",
    "        for i in range(low, high+1):\n",
    "            for combine in itertools.combinations(categorical_features, i):\n",
    "                if function.__name__ == 'count_std_over_mean':\n",
    "                    features_to_gen.append({'params': {'coefficient': 10}, 'function': function, 'feature_cols': list(combine)})\n",
    "                else:\n",
    "                    features_to_gen.append({'params': {}, 'function': function, 'feature_cols': list(combine)})\n",
    "                \n",
    "    return features_to_gen\n",
    "\n",
    "# features_to_gen = get_features_to_gen([fe.count, fe.unique_count, \n",
    "#                                        fe.cumulative_count, \n",
    "#                                        fe.reverse_cumulative_count, \n",
    "#                                        fe.variance, fe.count_std_over_mean], \n",
    "#                                       2, 2)# len(categorical_features))\n",
    "# features_to_gen = get_features_to_gen([fe.count, fe.unique_count, fe.cumulative_count])\n",
    "features_to_gen = get_features_to_gen([fe.count], 2, 2)#len(categorical_features))\n",
    "\n",
    "features_to_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.342363Z",
     "start_time": "2018-07-10T17:58:23.310790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_to_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.372501Z",
     "start_time": "2018-07-10T17:58:23.344552Z"
    }
   },
   "outputs": [],
   "source": [
    "project_path = './' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.407500Z",
     "start_time": "2018-07-10T17:58:23.374892Z"
    }
   },
   "outputs": [],
   "source": [
    "from automl_app import logger_config\n",
    "import logging\n",
    "logger_config.config(project_path+'log_project2.log', file_loglevel=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.428459Z",
     "start_time": "2018-07-10T17:58:23.409094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1527222588767888\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.random.rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.474943Z",
     "start_time": "2018-07-10T17:58:23.429930Z"
    }
   },
   "outputs": [],
   "source": [
    "def gs_params_gen(model='lgb'):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    seed = int(time.time()* 1000000) % 45234634\n",
    "    np.random.seed(seed)\n",
    "    if model == 'svc':\n",
    "        params = {\n",
    "            'C': 0.911#np.random.rand(),\n",
    "#             'metric': 'roc_auc'\n",
    "        }\n",
    "    elif model == 'logreg':\n",
    "        params = {\n",
    "            'penalty': np.random.choice(['l2']),\n",
    "            'dual': np.random.choice([True, False]),\n",
    "            'C': 1,#np.random.rand(),\n",
    "            'metric': 'roc_auc'\n",
    "        }\n",
    "    elif model == 'lgb':\n",
    "        params = {    \n",
    "            'objective': 'binary',\n",
    "            'boosting': 'gbdt',\n",
    "            'num_boost_round': 30, # ignored in params. extract it and put it in input arguments in train or cv explicitly\n",
    "                                   # seems to work fine as the upper limit when combined with early_stopping_round\n",
    "            'learning_rate': np.random.choice([0.1,0.03]),#0.001]),\n",
    "            'num_leaves': np.random.choice([15,31]),#,61,127]),\n",
    "            'num_threads': 8, # best speed: set to number of real cpu cores, which is vCPU/2\n",
    "            'max_depth': -1, # no limit. This is used to deal with over-fitting when #data is small.\n",
    "            'min_data_in_leaf': np.random.randint(20,50),  #minimal number of data in one leaf. \n",
    "            'feature_fraction': np.random.randint(9,11)/10,\n",
    "            'feature_fraction_seed': seed,\n",
    "            'early_stopping_round':10,\n",
    "            'bagging_freq': 1, #0 means disable bagging. k: perform bagging at every k iteration\n",
    "            'bagging_fraction': np.random.randint(4,11)/10, #Randomly select part of data \n",
    "            'bagging_seed': seed,\n",
    "            'scale_pos_weight': 1,\n",
    "            'metric': 'auc' \n",
    "        }\n",
    "    elif model == 'nn':\n",
    "        params = {\n",
    "            'nn_seed': int(time.time() * 1000000) % 45234634,\n",
    "            'ep_for_lr': 1,\n",
    "            'lr_init': 0.01,\n",
    "            'lr_fin': 0.005, # if == lr_init, then no lr decay\n",
    "            'batch_size': np.random.choice([32, 64, 128, 256, 512, 1024, 2048]),\n",
    "            \"pred_batch_size\": 50000,\n",
    "            'max_ep': 1,\n",
    "            'patience': 1,\n",
    "            'cat_emb_outdim': 50, # could be a constant or a dict (col name:embed out dim). e.g.:\n",
    "                                  # embed_outdim = [3, 3, 8, 8, 3]\n",
    "                                  # embed_outdim_dict = dict(zip(X_train.columns.values, embed_outdim))\n",
    "            'dense_units': 50,\n",
    "            'num_dense_n_layers': 1,\n",
    "            'drop_rate': 0.2,\n",
    "            'combined_dense_n_layers': 1,\n",
    "            'monitor': 'val_auc',  # or val_loss (MUST HAVE)\n",
    "            'mode': 'max'  # MUST HAVE\n",
    "        }\n",
    "    elif model == 'nn_layer2':\n",
    "        params = {\n",
    "            'nn_seed': int(time.time() * 1000000) % 45234634,\n",
    "            'ep_for_lr': 1,\n",
    "            'lr_init': 0.01,\n",
    "            'lr_fin': 0.01, # if == lr_init, then no lr decay\n",
    "            'batch_size': 128,\n",
    "            \"pred_batch_size\": 50000,\n",
    "            'max_ep': 1,\n",
    "            'patience': 1,\n",
    "            'cat_emb_outdim': 50, # could be a constant or a dict (col name:embed out dim). e.g.:\n",
    "                                  # embed_outdim = [3, 3, 8, 8, 3]\n",
    "                                  # embed_outdim_dict = dict(zip(X_train.columns.values, embed_outdim))\n",
    "            'dense_units': 50,\n",
    "            'num_dense_n_layers': 1,\n",
    "            'drop_rate': 0.2,\n",
    "            'combined_dense_n_layers': 1,\n",
    "            'monitor': 'val_auc',  # or val_loss (MUST HAVE)\n",
    "            'mode': 'max',  # MUST HAVE\n",
    "            'categorical_feature': []\n",
    "        }\n",
    "    return params, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T17:58:23.503248Z",
     "start_time": "2018-07-10T17:58:23.476869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'batch_size': 128,\n",
       "  'cat_emb_outdim': 50,\n",
       "  'categorical_feature': [],\n",
       "  'combined_dense_n_layers': 1,\n",
       "  'dense_units': 50,\n",
       "  'drop_rate': 0.2,\n",
       "  'ep_for_lr': 1,\n",
       "  'lr_fin': 0.01,\n",
       "  'lr_init': 0.01,\n",
       "  'max_ep': 1,\n",
       "  'mode': 'max',\n",
       "  'monitor': 'val_auc',\n",
       "  'nn_seed': 37139752,\n",
       "  'num_dense_n_layers': 1,\n",
       "  'patience': 1,\n",
       "  'pred_batch_size': 50000},\n",
       " 37139739)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_params_gen('nn_layer2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:02:36.107233Z",
     "start_time": "2018-07-10T17:58:23.505071Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 13:58:23 | INFO    | automl_app.app.AlphaBoosting.__init__             | #22  | ==========NEW RUN==========\n",
      "/home/kai/data/shiyi/AlphaBoosting/automl/automl_app/app.py:139: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  self.df = pd.concat([self.train, self.test], ignore_index=True)\n",
      "2018-07-10 13:58:23 | INFO    | automl_app.app.AlphaBoosting.__init__             | #65  | Run record file [./output/last_run_record.json] not found. Begin the first time run...\n",
      "2018-07-10 13:58:23 | INFO    | automl_app.app.AlphaBoosting.__init__             | #96  | generate todo list\n",
      "2018-07-10 13:58:23 | INFO    | automl_app.app.AlphaBoosting.__init__             | #112 | STAGE: FEATURE_ENGINEERING\n",
      "2018-07-10 13:58:24 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Month_DayofMonth\n",
      "2018-07-10 13:58:25 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Month_DayOfWeek\n",
      "2018-07-10 13:58:27 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Month_DepTime\n",
      "2018-07-10 13:58:28 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Month_UniqueCarrier\n",
      "2018-07-10 13:58:28 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Month_Origin\n",
      "2018-07-10 13:58:29 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Month_Dest\n",
      "2018-07-10 13:58:29 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Month_Distance\n",
      "2018-07-10 13:58:30 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayofMonth_DayOfWeek\n",
      "2018-07-10 13:58:30 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayofMonth_DepTime\n",
      "2018-07-10 13:58:31 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayofMonth_UniqueCarrier\n",
      "2018-07-10 13:58:32 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayofMonth_Origin\n",
      "2018-07-10 13:58:34 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayofMonth_Dest\n",
      "2018-07-10 13:58:35 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayofMonth_Distance\n",
      "2018-07-10 13:58:36 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayOfWeek_DepTime\n",
      "2018-07-10 13:58:37 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayOfWeek_UniqueCarrier\n",
      "2018-07-10 13:58:38 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayOfWeek_Origin\n",
      "2018-07-10 13:58:40 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayOfWeek_Dest\n",
      "2018-07-10 13:58:40 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DayOfWeek_Distance\n",
      "2018-07-10 13:58:41 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DepTime_UniqueCarrier\n",
      "2018-07-10 13:58:42 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DepTime_Origin\n",
      "2018-07-10 13:58:42 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DepTime_Dest\n",
      "2018-07-10 13:58:43 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__DepTime_Distance\n",
      "2018-07-10 13:58:43 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__UniqueCarrier_Origin\n",
      "2018-07-10 13:58:44 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__UniqueCarrier_Dest\n",
      "2018-07-10 13:58:44 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__UniqueCarrier_Distance\n",
      "2018-07-10 13:58:45 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Origin_Dest\n",
      "2018-07-10 13:58:45 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Origin_Distance\n",
      "2018-07-10 13:58:47 | DEBUG   | automl_libs.feature_engineering.count                | #65  | feature generated: count__Dest_Distance\n",
      "2018-07-10 13:58:47 | INFO    | automl_app.app.AlphaBoosting.__init__             | #116 | STAGE: VALIDATION_DOWNSAMPLING_GEN\n",
      "2018-07-10 13:59:07 | INFO    | automl_app.app.AlphaBoosting.__init__             | #120 | STAGE: CONCAT_DATA\n",
      "2018-07-10 13:59:10 | INFO    | automl_app.app.AlphaBoosting.__init__             | #124 | STAGE: GRID_SEARCH\n",
      "2018-07-10 13:59:11 | INFO    | automl_app.app.AlphaBoosting._get_final_data      | #333 | Data retrieved. Shape: train (50000, 37) | val (50000, 37) | test (100000, 36) | 8 cat features | 36 total features | y name: label\n",
      "2018-07-10 13:59:11 | INFO    | automl_libs.grid_search.gs                   | #34  | Grid search lgb. round 1 of 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[20]\ttraining's auc: 0.720742\tvalid_1's auc: 0.703137\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[30]\ttraining's auc: 0.728444\tvalid_1's auc: 0.708745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 13:59:12 | INFO    | automl_libs.grid_search._lgb_gs              | #179 | val_auc: 0.70874 | train_auc: 0.72844 (not cv)\n",
      "2018-07-10 13:59:12 | INFO    | automl_libs.grid_search._lgb_gs              | #187 | [do_preds] is True, generating predictions ...\n",
      "2018-07-10 13:59:12 | INFO    | automl_libs.grid_search._lgb_gs              | #188 | Retrain model using best_round and all data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\ttraining's auc: 0.704734\n",
      "[12]\ttraining's auc: 0.711737\n",
      "[18]\ttraining's auc: 0.716139\n",
      "[24]\ttraining's auc: 0.719617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 13:59:13 | INFO    | automl_libs.grid_search._lgb_gs              | #196 | Training done. Iteration: 30 | train_auc: 0.72217 | 36 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttraining's auc: 0.722169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 13:59:13 | INFO    | automl_libs.grid_search._lgb_gs              | #201 | (_nn_gs) roc of test: 0.7135557355438436\n",
      "2018-07-10 13:59:13 | INFO    | automl_libs.grid_search._lgb_gs              | #206 | LGB predictions(OUTo) saved in ./output/gs_saved_preds/.\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.grid_search.gs                   | #59  | ./output/lgb_grid_search.csv created\n",
      "2018-07-10 13:59:13 | INFO    | automl_libs.grid_search.gs                   | #34  | Grid search nn. round 1 of 1\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Month]: embed dim: input 13, output 13\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Distance]: embed dim: input 10, output 10\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Origin]: embed dim: input 292, output 50\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayofMonth]: embed dim: input 32, output 32\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayOfWeek]: embed dim: input 8, output 8\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Dest]: embed dim: input 293, output 50\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [UniqueCarrier]: embed dim: input 23, output 23\n",
      "2018-07-10 13:59:13 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DepTime]: embed dim: input 27, output 27\n",
      "2018-07-10 13:59:14 | DEBUG   | automl_libs.nn_libs.get_model            | #111 | steps in on epoch: 781\n",
      "2018-07-10 13:59:14 | DEBUG   | automl_libs.nn_libs.get_model            | #112 | steps for lr decay: 781\n",
      "2018-07-10 13:59:14 | DEBUG   | automl_libs.nn_libs.get_model            | #113 | lr decay: 0.000889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 50000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 13:59:29 | DEBUG   | automl_libs.nn_libs.LearningRateTracker._show_lr             | #170 | At epoch end: init lr 0.01000, lr_decay 0.00089, iterations 782, current lr 0.00590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: roc_auc_val improved from -inf to 0.71678, saving model to ./output/gs_saved_preds/nn_saved_models/nn_Xjgb.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 13:59:29 | INFO    | automl_libs.grid_search._nn_gs               | #255 | val_auc: 0.71678\n",
      "2018-07-10 13:59:29 | INFO    | automl_libs.grid_search._nn_gs               | #266 | val_loss: 0.44585 | train_loss: 0.45461 (not cv)\n",
      "2018-07-10 13:59:29 | INFO    | automl_libs.grid_search._nn_gs               | #274 | [do_preds] is True, generating predictions ...\n",
      "2018-07-10 13:59:30 | INFO    | automl_libs.grid_search._nn_gs               | #279 | (_nn_gs) roc of test: 0.7194668690459505\n",
      "2018-07-10 13:59:30 | INFO    | automl_libs.grid_search._nn_gs               | #284 | NN predictions(Xjgb) saved in ./output/gs_saved_preds/.\n",
      "2018-07-10 13:59:30 | DEBUG   | automl_libs.grid_search.gs                   | #59  | ./output/nn_grid_search.csv created\n",
      "2018-07-10 13:59:30 | INFO    | automl_app.app.AlphaBoosting.__init__             | #128 | STAGE: STACKNET\n",
      "2018-07-10 13:59:31 | INFO    | automl_app.app.AlphaBoosting._get_final_data      | #333 | Data retrieved. Shape: train (50000, 37) | val (50000, 37) | test (100000, 36) | 8 cat features | 36 total features | y name: label\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.stacknet.layer1               | #37  | data_id: flight_data_ordinal  \n",
      "\tx_train: (100000, 36)\tx_test: (100000, 36)\n",
      "\ty_train type: <class 'dict'>\n",
      "\tcompatible_models: {'NN', 'LGB'}\n",
      " \n",
      "2018-07-10 13:59:31 | INFO    | automl_libs.stacknet.layer1               | #67  | using nn params: Xjgb to do oof\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.stacknet.layer1               | #68  | {'nn_seed': 42200901, 'num_dense_n_layers': 1, 'max_ep': 1, 'val_acc': 0.8128, 'ep_for_lr': 1, 'cat_emb_outdim': 50, 'trn_loss': 0.4546077640628815, 'trn_acc': 0.80892, 'patience': 1, 'monitor': 'val_auc', 'pred_batch_size': 50000, 'dense_units': 50, 'combined_dense_n_layers': 1, 'val_loss': 0.4458516232299805, 'timestamp': '2018-07-10 13:59:13', 'lr_init': 0.01, 'mode': 'max', 'val_auc': 0.7167842142394093, 'lr_fin': 0.005, 'pred_timespent': '0:00:00', 'best_epoch': 1, 'drop_rate': 0.2, 'batch_size': 64, 'gs_timespent': '0:00:15'}\n",
      "2018-07-10 13:59:31 | INFO    | automl_libs.base_layer_utils.compute_layer1_oof   | #488 | StackNet layer1: label: label    model_data_id: Xjgb__NN_flight_data_ordinal_layer1\n",
      "2018-07-10 13:59:31 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 1 of 5...\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Month]: embed dim: input 13, output 13\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Distance]: embed dim: input 10, output 10\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Origin]: embed dim: input 292, output 50\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayofMonth]: embed dim: input 32, output 32\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayOfWeek]: embed dim: input 8, output 8\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Dest]: embed dim: input 293, output 50\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [UniqueCarrier]: embed dim: input 23, output 23\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DepTime]: embed dim: input 27, output 27\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #111 | steps in on epoch: 1249\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #112 | steps for lr decay: 1249\n",
      "2018-07-10 13:59:31 | DEBUG   | automl_libs.nn_libs.get_model            | #113 | lr decay: 0.000556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79999 samples, validate on 20001 samples\n",
      "Epoch 1/1\n",
      "79999/79999 [==============================] - 17s 214us/step - loss: 0.4530 - acc: 0.8093 - val_loss: 0.4425 - val_acc: 0.8140\n",
      "20001/20001 [==============================] - 0s 20us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 13:59:49 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 1: 0.712497232434501\n",
      "2018-07-10 13:59:49 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 2 of 5...\n",
      "2018-07-10 13:59:49 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Month]: embed dim: input 13, output 13\n",
      "2018-07-10 13:59:49 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Distance]: embed dim: input 10, output 10\n",
      "2018-07-10 13:59:49 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Origin]: embed dim: input 292, output 50\n",
      "2018-07-10 13:59:49 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayofMonth]: embed dim: input 32, output 32\n",
      "2018-07-10 13:59:49 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayOfWeek]: embed dim: input 8, output 8\n",
      "2018-07-10 13:59:49 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Dest]: embed dim: input 293, output 50\n",
      "2018-07-10 13:59:49 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [UniqueCarrier]: embed dim: input 23, output 23\n",
      "2018-07-10 13:59:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DepTime]: embed dim: input 27, output 27\n",
      "2018-07-10 13:59:50 | DEBUG   | automl_libs.nn_libs.get_model            | #111 | steps in on epoch: 1249\n",
      "2018-07-10 13:59:50 | DEBUG   | automl_libs.nn_libs.get_model            | #112 | steps for lr decay: 1249\n",
      "2018-07-10 13:59:50 | DEBUG   | automl_libs.nn_libs.get_model            | #113 | lr decay: 0.000556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79999 samples, validate on 20001 samples\n",
      "Epoch 1/1\n",
      "79999/79999 [==============================] - 18s 231us/step - loss: 0.4516 - acc: 0.8100 - val_loss: 0.4402 - val_acc: 0.8121\n",
      "20001/20001 [==============================] - 0s 13us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:00:10 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 2: 0.7201721799572786\n",
      "2018-07-10 14:00:10 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 3 of 5...\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Month]: embed dim: input 13, output 13\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Distance]: embed dim: input 10, output 10\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Origin]: embed dim: input 292, output 50\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayofMonth]: embed dim: input 32, output 32\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayOfWeek]: embed dim: input 8, output 8\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Dest]: embed dim: input 293, output 50\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [UniqueCarrier]: embed dim: input 23, output 23\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DepTime]: embed dim: input 27, output 27\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #111 | steps in on epoch: 1250\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #112 | steps for lr decay: 1250\n",
      "2018-07-10 14:00:10 | DEBUG   | automl_libs.nn_libs.get_model            | #113 | lr decay: 0.000555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "80000/80000 [==============================] - 19s 233us/step - loss: 0.4509 - acc: 0.8095 - val_loss: 0.4442 - val_acc: 0.8126\n",
      "20000/20000 [==============================] - 0s 19us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:00:30 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 3: 0.7095033894897672\n",
      "2018-07-10 14:00:30 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 4 of 5...\n",
      "2018-07-10 14:00:30 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Month]: embed dim: input 13, output 13\n",
      "2018-07-10 14:00:30 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Distance]: embed dim: input 10, output 10\n",
      "2018-07-10 14:00:30 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Origin]: embed dim: input 292, output 50\n",
      "2018-07-10 14:00:30 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayofMonth]: embed dim: input 32, output 32\n",
      "2018-07-10 14:00:30 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayOfWeek]: embed dim: input 8, output 8\n",
      "2018-07-10 14:00:30 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Dest]: embed dim: input 293, output 50\n",
      "2018-07-10 14:00:30 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [UniqueCarrier]: embed dim: input 23, output 23\n",
      "2018-07-10 14:00:30 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DepTime]: embed dim: input 27, output 27\n",
      "2018-07-10 14:00:31 | DEBUG   | automl_libs.nn_libs.get_model            | #111 | steps in on epoch: 1250\n",
      "2018-07-10 14:00:31 | DEBUG   | automl_libs.nn_libs.get_model            | #112 | steps for lr decay: 1250\n",
      "2018-07-10 14:00:31 | DEBUG   | automl_libs.nn_libs.get_model            | #113 | lr decay: 0.000555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80001 samples, validate on 19999 samples\n",
      "Epoch 1/1\n",
      "80001/80001 [==============================] - 19s 231us/step - loss: 0.4511 - acc: 0.8099 - val_loss: 0.4434 - val_acc: 0.8144\n",
      "19999/19999 [==============================] - 0s 15us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:00:50 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 4: 0.720777523918895\n",
      "2018-07-10 14:00:50 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 5 of 5...\n",
      "2018-07-10 14:00:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Month]: embed dim: input 13, output 13\n",
      "2018-07-10 14:00:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Distance]: embed dim: input 10, output 10\n",
      "2018-07-10 14:00:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Origin]: embed dim: input 292, output 50\n",
      "2018-07-10 14:00:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayofMonth]: embed dim: input 32, output 32\n",
      "2018-07-10 14:00:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayOfWeek]: embed dim: input 8, output 8\n",
      "2018-07-10 14:00:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Dest]: embed dim: input 293, output 50\n",
      "2018-07-10 14:00:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [UniqueCarrier]: embed dim: input 23, output 23\n",
      "2018-07-10 14:00:50 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DepTime]: embed dim: input 27, output 27\n",
      "2018-07-10 14:00:51 | DEBUG   | automl_libs.nn_libs.get_model            | #111 | steps in on epoch: 1250\n",
      "2018-07-10 14:00:51 | DEBUG   | automl_libs.nn_libs.get_model            | #112 | steps for lr decay: 1250\n",
      "2018-07-10 14:00:51 | DEBUG   | automl_libs.nn_libs.get_model            | #113 | lr decay: 0.000555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80001 samples, validate on 19999 samples\n",
      "Epoch 1/1\n",
      "80001/80001 [==============================] - 19s 241us/step - loss: 0.4525 - acc: 0.8099 - val_loss: 0.4431 - val_acc: 0.8113\n",
      "19999/19999 [==============================] - 1s 42us/step\n",
      "100000/100000 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:12 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 5: 0.7215340582384983\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Month]: embed dim: input 13, output 13\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Distance]: embed dim: input 10, output 10\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Origin]: embed dim: input 292, output 50\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayofMonth]: embed dim: input 32, output 32\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DayOfWeek]: embed dim: input 8, output 8\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [Dest]: embed dim: input 293, output 50\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [UniqueCarrier]: embed dim: input 23, output 23\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #65  | Col [DepTime]: embed dim: input 27, output 27\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #111 | steps in on epoch: 1562\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #112 | steps for lr decay: 1562\n",
      "2018-07-10 14:01:12 | DEBUG   | automl_libs.nn_libs.get_model            | #113 | lr decay: 0.000444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100000/100000 [==============================] - 22s 216us/step - loss: 0.4502 - acc: 0.8104\n",
      "100000/100000 [==============================] - 0s 3us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:35 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.add_score            | #294 | Xjgb__NN_flight_data_ordinal_layer1 found in repo. Update score from 0 to 0.71678\n",
      "2018-07-10 14:01:35 | DEBUG   | automl_libs.base_layer_utils.BaseLayerResultsRepo.__init__             | #235 | load StackNet saves from file\n",
      "2018-07-10 14:01:35 | INFO    | automl_libs.stacknet.layer1               | #67  | using lgb params: OUTo to do oof\n",
      "2018-07-10 14:01:35 | DEBUG   | automl_libs.stacknet.layer1               | #68  | {'learning_rate': 0.03, 'train_auc': 0.7284444640256228, 'scale_pos_weight': 1, 'best_round': 30, 'pred_timespent': '0:00:01', 'max_depth': -1, 'val_auc': 0.7087448046068241, 'boosting': 'gbdt', 'feature_fraction_seed': 39463042, 'metric': 'auc', 'objective': 'binary', 'feature_fraction': 1.0, 'num_leaves': 15, 'timestamp': '2018-07-10 13:59:11', 'bagging_fraction': 0.9, 'bagging_seed': 39463042, 'min_data_in_leaf': 40, 'num_threads': 8, 'bagging_freq': 1, 'gs_timespent': '0:00:01'}\n",
      "2018-07-10 14:01:35 | INFO    | automl_libs.base_layer_utils.compute_layer1_oof   | #488 | StackNet layer1: label: label    model_data_id: OUTo__LGB_flight_data_ordinal_layer1\n",
      "2018-07-10 14:01:35 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 1 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[6]\ttraining's auc: 0.701957\n",
      "[12]\ttraining's auc: 0.709465\n",
      "[18]\ttraining's auc: 0.714959\n",
      "[24]\ttraining's auc: 0.719525\n",
      "[30]\ttraining's auc: 0.722817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:35 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 1: 0.7095278858854561\n",
      "2018-07-10 14:01:35 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 2 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[6]\ttraining's auc: 0.704189\n",
      "[12]\ttraining's auc: 0.711272\n",
      "[18]\ttraining's auc: 0.714253\n",
      "[24]\ttraining's auc: 0.718977\n",
      "[30]\ttraining's auc: 0.721886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:36 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 2: 0.7139731065792086\n",
      "2018-07-10 14:01:36 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 3 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[6]\ttraining's auc: 0.706195\n",
      "[12]\ttraining's auc: 0.712689\n",
      "[18]\ttraining's auc: 0.716507\n",
      "[24]\ttraining's auc: 0.720991\n",
      "[30]\ttraining's auc: 0.72451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:36 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 3: 0.7058527039523943\n",
      "2018-07-10 14:01:36 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 4 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[6]\ttraining's auc: 0.700442\n",
      "[12]\ttraining's auc: 0.7088\n",
      "[18]\ttraining's auc: 0.715022\n",
      "[24]\ttraining's auc: 0.719178\n",
      "[30]\ttraining's auc: 0.721923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:37 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 4: 0.7148161801663566\n",
      "2018-07-10 14:01:37 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 5 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[6]\ttraining's auc: 0.707505\n",
      "[12]\ttraining's auc: 0.712395\n",
      "[18]\ttraining's auc: 0.715954\n",
      "[24]\ttraining's auc: 0.720009\n",
      "[30]\ttraining's auc: 0.723319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:37 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 5: 0.7148191717874051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[6]\ttraining's auc: 0.704734\n",
      "[12]\ttraining's auc: 0.711737\n",
      "[18]\ttraining's auc: 0.716139\n",
      "[24]\ttraining's auc: 0.719617\n",
      "[30]\ttraining's auc: 0.722169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:38 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.add_score            | #294 | OUTo__LGB_flight_data_ordinal_layer1 found in repo. Update score from 0 to 0.70874\n",
      "2018-07-10 14:01:38 | DEBUG   | automl_libs.base_layer_utils.BaseLayerResultsRepo.__init__             | #235 | load StackNet saves from file\n",
      "2018-07-10 14:01:38 | INFO    | automl_libs.stacknet.layer2               | #112 | All available layer1 model_data:\n",
      "2018-07-10 14:01:38 | INFO    | automl_libs.stacknet.layer2               | #113 | [('Xjgb__NN_flight_data_ordinal_layer1', 0.7167842142394093), ('OUTo__LGB_flight_data_ordinal_layer1', 0.7087448046068241)]\n",
      "2018-07-10 14:01:38 | INFO    | automl_libs.base_layer_utils.compute_layer2_oof   | #587 | Generating Layer2 model uOQl__LOGREG OOF\n",
      "2018-07-10 14:01:38 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using LogisticRegression)\n",
      "2018-07-10 14:01:38 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 1 of 5...\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 1: 0.7205917967509545\n",
      "2018-07-10 14:01:39 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using LogisticRegression)\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 2 of 5...\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 2: 0.7191602036542316\n",
      "2018-07-10 14:01:39 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using LogisticRegression)\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 3 of 5...\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 3: 0.7157302400385991\n",
      "2018-07-10 14:01:39 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using LogisticRegression)\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 4 of 5...\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 4: 0.7156470868285841\n",
      "2018-07-10 14:01:39 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using LogisticRegression)\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 5 of 5...\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 5: 0.7194924698807292\n",
      "2018-07-10 14:01:39 | INFO    | automl_libs.base_layer_utils.compute_layer2_oof   | #587 | Generating Layer2 model m7KO__NN OOF\n",
      "2018-07-10 14:01:39 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using NNBLE)\n",
      "2018-07-10 14:01:40 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 1 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79999 samples, validate on 20001 samples\n",
      "Epoch 1/1\n",
      "79999/79999 [==============================] - 7s 83us/step - loss: 0.4474 - acc: 0.8114 - val_loss: 0.4489 - val_acc: 0.8156\n",
      "20001/20001 [==============================] - 0s 17us/step\n",
      "100000/100000 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:48 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 1: 0.720746482960881\n",
      "2018-07-10 14:01:48 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using NNBLE)\n",
      "2018-07-10 14:01:48 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 2 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79999 samples, validate on 20001 samples\n",
      "Epoch 1/1\n",
      "79999/79999 [==============================] - 7s 84us/step - loss: 0.4465 - acc: 0.8128 - val_loss: 0.4557 - val_acc: 0.8034\n",
      "20001/20001 [==============================] - 0s 21us/step\n",
      "100000/100000 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:01:55 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 2: 0.7191706146849398\n",
      "2018-07-10 14:01:55 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using NNBLE)\n",
      "2018-07-10 14:01:55 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 3 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/1\n",
      "80000/80000 [==============================] - 8s 106us/step - loss: 0.4477 - acc: 0.8124 - val_loss: 0.4523 - val_acc: 0.8130\n",
      "20000/20000 [==============================] - 1s 36us/step\n",
      "100000/100000 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:02:05 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 3: 0.7155168589924008\n",
      "2018-07-10 14:02:05 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using NNBLE)\n",
      "2018-07-10 14:02:05 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 4 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80001 samples, validate on 19999 samples\n",
      "Epoch 1/1\n",
      "80001/80001 [==============================] - 8s 100us/step - loss: 0.4480 - acc: 0.8110 - val_loss: 0.4449 - val_acc: 0.8167\n",
      "19999/19999 [==============================] - 0s 21us/step\n",
      "100000/100000 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:02:14 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 4: 0.7154005836877841\n",
      "2018-07-10 14:02:14 | WARNING | automl_libs.base_layer_utils.get_oof              | #419 | warning: x_train is not dataframe, you should NOT use models like LGB and NN where categorical_feature is needed (you are using NNBLE)\n",
      "2018-07-10 14:02:14 | INFO    | automl_libs.base_layer_utils.get_oof              | #424 | processing fold 5 of 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80001 samples, validate on 19999 samples\n",
      "Epoch 1/1\n",
      "80001/80001 [==============================] - 9s 115us/step - loss: 0.4470 - acc: 0.8122 - val_loss: 0.4469 - val_acc: 0.8100\n",
      "19999/19999 [==============================] - 0s 20us/step\n",
      "100000/100000 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:02:24 | INFO    | automl_libs.base_layer_utils.get_oof              | #438 | metric of fold 5: 0.7190443620408323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100000/100000 [==============================] - 8s 81us/step - loss: 0.4461 - acc: 0.8131\n",
      "100000/100000 [==============================] - 1s 15us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-10 14:02:34 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.add_score            | #294 | uOQl__LOGREG_layer2 found in repo. Update score from 0 to 0.71812\n",
      "2018-07-10 14:02:34 | INFO    | automl_libs.base_layer_utils.BaseLayerResultsRepo.add_score            | #294 | m7KO__NN_layer2 found in repo. Update score from 0 to 0.71798\n",
      "2018-07-10 14:02:34 | INFO    | automl_libs.stacknet.layer2               | #183 | StackNet Report saved at ./output/oof/stacknet_report.csv\n",
      "2018-07-10 14:02:34 | INFO    | automl_app.app.AlphaBoosting.__init__             | #132 | save run record\n",
      "2018-07-10 14:02:34 | INFO    | automl_app.app.AlphaBoosting._save_run_record     | #164 | val index is saved at ./temp_data/val_index.pkl\n",
      "2018-07-10 14:02:34 | INFO    | automl_app.app.AlphaBoosting._save_run_record     | #166 | run record is saved at ./output/last_run_record.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<automl_app.app.AlphaBoosting at 0x7f4c9bec8828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from automl_app.app import AlphaBoosting\n",
    "\n",
    "automl_config_file = project_path + 'automl_config.json'\n",
    "run_record_file_name = project_path + 'last_run_record.json' # don't created this file\n",
    "AlphaBoosting(automl_config_file, features_to_gen, gs_params_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:03:07.976432Z",
     "start_time": "2018-07-10T18:03:07.945339Z"
    }
   },
   "outputs": [],
   "source": [
    "temp  = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:03:24.687251Z",
     "start_time": "2018-07-10T18:03:24.610497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False if temp is None else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
