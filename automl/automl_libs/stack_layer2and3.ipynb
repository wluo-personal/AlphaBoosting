{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:43:09.985361Z",
     "start_time": "2018-06-28T15:43:09.971162Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:43:12.229135Z",
     "start_time": "2018-06-28T15:43:10.485207Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from base_layer_utils import BaseLayerDataRepo, BaseLayerResultsRepo, ModelName\n",
    "from base_layer_utils import SklearnBLE\n",
    "from base_layer_utils import compute_layer2_oof\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time, re, gc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:47:55.123633Z",
     "start_time": "2018-06-28T15:47:54.827060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 9) (100000, 8) (100000,)\n"
     ]
    }
   ],
   "source": [
    "# PATH = '~/data/toxic/data/'\n",
    "\n",
    "# train = pd.read_csv(PATH + 'train.csv')\n",
    "# test = pd.read_csv(PATH + 'test.csv')\n",
    "train = pd.read_pickle('/home/kai/data/shiyi/data/flight_data/train_1M.pkl').head(500000)\n",
    "testX = pd.read_pickle('/home/kai/data/shiyi/data/flight_data/testX_100k.pkl')\n",
    "testY = np.load('/home/kai/data/shiyi/data/flight_data/testY_100k.npy')\n",
    "\n",
    "print(train.shape, testX.shape, testY.shape)\n",
    "\n",
    "label_cols = ['label']#['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:46:10.783088Z",
     "start_time": "2018-06-28T15:46:10.753513Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_layer_oof_per_label(layer1_oof_dict, label):\n",
    "    \"\"\"\n",
    "    Util method for stacking\n",
    "    \"\"\"\n",
    "    x = None\n",
    "    data_list = layer1_oof_dict[label]\n",
    "    for i in range(len(data_list)):\n",
    "        if i == 0:\n",
    "            x = data_list[0]\n",
    "        else:\n",
    "            x = np.concatenate((x, data_list[i]), axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:48:24.657594Z",
     "start_time": "2018-06-28T15:48:24.616130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from file\n"
     ]
    }
   ],
   "source": [
    "# load the saved repo. IMPORTANT: set load_from_file to True! or you will overwrite the saved repo\n",
    "base_layer_results_repo = BaseLayerResultsRepo(label_cols=label_cols, filepath='oof/', load_from_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:48:26.481425Z",
     "start_time": "2018-06-28T15:48:26.412006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7383\tModelName.LGB_flight_data_ordinal\n",
      "0.7232\tModelName.LOGREG_flight_data_one_hot\n",
      "0.7152\tModelName.XGB_flight_data_one_hot\n"
     ]
    }
   ],
   "source": [
    "scores = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we will construct a logreg model and a lightgbm model using different layer1 model_data at layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:49:07.153558Z",
     "start_time": "2018-06-28T15:49:07.129024Z"
    }
   },
   "outputs": [],
   "source": [
    "model_pool = {}\n",
    "layer2_inputs = {}\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_pool[ModelName.LOGREG] = SklearnBLE(LogisticRegression)\n",
    "layer2_inputs[ModelName.LOGREG] = base_layer_results_repo.get_results(threshold=0.7)\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "# model_pool[ModelName.LGB] = SklearnBLE(LGBMClassifier)\n",
    "# selected = ['ModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0',\n",
    "#             'ModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0']\n",
    "# layer2_inputs[ModelName.LGB] = base_layer_results_repo.get_results(chosen_ones=selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:52:25.060408Z",
     "start_time": "2018-06-28T15:52:25.024338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([<ModelName.LOGREG: 9>])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:54:24.489785Z",
     "start_time": "2018-06-28T15:54:24.454177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer2_inputs[ModelName.LOGREG]) # number of data_models chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:54:44.414262Z",
     "start_time": "2018-06-28T15:54:44.339209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<ModelName.LOGREG: 9>: <base_layer_utils.SklearnBLE at 0x7ff7a105c7b8>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:49:12.085909Z",
     "start_time": "2018-06-28T15:49:11.948770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:55:39.278822Z",
     "start_time": "2018-06-28T15:55:31.450680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Layer2 model ModelName.LOGREG OOF\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 0...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 1...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 2...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 3...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 4...\n"
     ]
    }
   ],
   "source": [
    "layer2_est_preds, layer2_oof_train, layer2_oof_test, layer2_model_data_list = compute_layer2_oof(model_pool, layer2_inputs, train, label_cols, 5, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check layer 2 model_data before add it to a repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:55:55.073319Z",
     "start_time": "2018-06-28T15:55:55.050177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer2_oof_train[label_cols[0]]) # number of model_data just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:56:02.672229Z",
     "start_time": "2018-06-28T15:56:02.641761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_oof_train[label_cols[0]][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:56:14.236879Z",
     "start_time": "2018-06-28T15:56:14.212702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelName.LOGREG_layer2']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer2_est_preds) # list of layer2 model_data just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:56:16.647959Z",
     "start_time": "2018-06-28T15:56:16.578203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2_est_preds[list(layer2_est_preds.keys())[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:57:17.163740Z",
     "start_time": "2018-06-28T15:57:17.044650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7394619506713762"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(testY, layer2_est_preds['ModelName.LOGREG_layer2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: you can add layer2 model_data to the base repo, or create another data repo and save them. \n",
    "### Here we will save them to the base repo, because at layer 3, you might want to build a model using model_data from both layer1 and layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_layer_results_repo.add(layer2_oof_train, layer2_oof_test, layer2_est_preds, layer2_model_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888\tModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9777\tModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9666\tModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0\tModelName.LGB_layer2\n",
      "0\tModelName.LOGREG_layer2\n"
     ]
    }
   ],
   "source": [
    "_ = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelName.LGB_layer2 already existed in the repo. score: 0 update to 0.09911\n",
      "ModelName.LOGREG_layer2 already existed in the repo. score: 0 update to 0.09922\n"
     ]
    }
   ],
   "source": [
    "# give it some fake score\n",
    "base_layer_results_repo.add_score('ModelName.LGB_layer2', 0.09911)\n",
    "base_layer_results_repo.add_score('ModelName.LOGREG_layer2', 0.09922)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9888\tModelName.NBLOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9777\tModelName.LOGREG_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.9666\tModelName.LOGREG_PERLABEL_tfidf_word_(1, 1)_30000_1_1.0\n",
      "0.09922\tModelName.LOGREG_layer2\n",
      "0.09911\tModelName.LGB_layer2\n"
     ]
    }
   ],
   "source": [
    "_ = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save it\n",
    "base_layer_results_repo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_predictions_to_file(base_layer_est_preds):\n",
    "    for key in base_layer_est_preds:\n",
    "        submission = pd.read_csv(PATH + 'sample_submission.csv')#.head(1000)\n",
    "        submission[label_cols] = base_layer_est_preds[key]\n",
    "        sub_id = int(time.time())\n",
    "        print(sub_id)\n",
    "        submission.to_csv('./BaseEstPreds/' + key + '_' + str(sub_id) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522100333\n",
      "1522100334\n"
     ]
    }
   ],
   "source": [
    "write_predictions_to_file(layer2_est_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now build a logreg at stacknet layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_for_layer3 = ['ModelName.LOGREG_layer2',\n",
    "                       'ModelName.LGB_layer2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer3_model_pool = {}\n",
    "layer3_inputs = {}\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "layer3_model_pool[ModelName.LOGREG] = SklearnBLE(LogisticRegression)\n",
    "# because you saved layer2 to base_layer_results_repo, we retrieve data from it\n",
    "layer3_inputs[ModelName.LOGREG] = base_layer_results_repo.get_results(chosen_ones=selected_for_layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Layer2 model ModelName.LOGREG OOF\n"
     ]
    }
   ],
   "source": [
    "layer3_est_preds, layer3_oof_train, layer3_oof_test, layer3_model_data_list = compute_layer2_oof(layer3_model_pool, layer3_inputs, train, label_cols, 4, 1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if layer3 is the last layer, then just use write_predictions_to_file to convert the layer3_est_preds to a prediction file and submit it, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522101283\n"
     ]
    }
   ],
   "source": [
    "write_predictions_to_file(layer3_est_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otherwise, you have layer3_oof_train and layer3_oof_test for even higher layer stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOOD LUCK!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good luck\n"
     ]
    }
   ],
   "source": [
    "print('good luck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
