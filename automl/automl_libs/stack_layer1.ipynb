{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:54:17.308073Z",
     "start_time": "2018-06-28T14:54:17.288722Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:54:18.545668Z",
     "start_time": "2018-06-28T14:54:17.547981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from base_layer_utils import BaseLayerDataRepo, BaseLayerResultsRepo, ModelName\n",
    "from base_layer_utils import compute_layer1_oof\n",
    "from base_layer_utils import SklearnBLE\n",
    "\n",
    "#from fast_text_data import FastTextDataGenerator# fasttext_data_process \n",
    "#from tfidf_data import tfidf_data_process\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:37:04.864447Z",
     "start_time": "2018-06-28T14:37:04.643324Z"
    }
   },
   "source": [
    "train_ori = pd.read_pickle('/home/kai/data/shiyi/data/flight_data/train_ori_1M.pkl').head(500000)\n",
    "testX_ori = pd.read_pickle('/home/kai/data/shiyi/data/flight_data/testX_ori_100k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:54:19.427930Z",
     "start_time": "2018-06-28T14:54:19.281402Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle('/home/kai/data/shiyi/data/flight_data/train_1M.pkl').head(500000)\n",
    "testX = pd.read_pickle('/home/kai/data/shiyi/data/flight_data/testX_100k.pkl')\n",
    "testY = np.load('/home/kai/data/shiyi/data/flight_data/testY_100k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:54:20.166994Z",
     "start_time": "2018-06-28T14:54:20.132348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 9), (100000, 8), (100000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T18:22:26.537749Z",
     "start_time": "2018-06-26T18:22:26.455491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RARE_VALUE</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>157</td>\n",
       "      <td>133</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>79</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>129</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month  DayofMonth  DayOfWeek  DepTime  UniqueCarrier  Origin  Dest  \\\n",
       "0  RARE_VALUE          19          2       18             21     157   133   \n",
       "1           4           3          1       12             18      79   172   \n",
       "2           2           1          6        9             15     129    72   \n",
       "\n",
       "   Distance  label  \n",
       "0         6      0  \n",
       "1         4      0  \n",
       "2         2      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_rare = train.copy()\n",
    "# train_rare.loc[train_rare['Month'].value_counts()[train_rare['Month']].values < 800, 'Month'] = 'RARE_VALUE'\n",
    "# train_rare.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:54:24.147638Z",
     "start_time": "2018-06-28T14:54:24.115620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month            int64\n",
       "DayofMonth       int64\n",
       "DayOfWeek        int64\n",
       "DepTime          int64\n",
       "UniqueCarrier    int64\n",
       "Origin           int64\n",
       "Dest             int64\n",
       "Distance         uint8\n",
       "label            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfidf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:47:52.559847Z",
     "start_time": "2018-06-28T14:47:52.530645Z"
    }
   },
   "outputs": [],
   "source": [
    "# compatible_models = [ModelName.XGB]#[ModelName.LGB, ModelName.LOGREG]\n",
    "# ModelName.LGB_PERLABEL, ModelName.NBLGB, ModelName.NBLGB_PERLABEL,\n",
    "# ModelName.XGB, ModelName.XGB_PERLABEL, ModelName.NBXGB, ModelName.NBXGB_PERLABEL,\n",
    "# ModelName.LOGREG, ModelName.LOGREG_PERLABEL, ModelName.NBLOGREG, \n",
    "# ModelName.NBLOGREG_PERLABEL,\n",
    "# ModelName.LSVC, ModelName.LSVC_PERLABEL, ModelName.NBLSVC, ModelName.NBLSVC_PERLABEL]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bldr.add_tfidf_data(train_sentence=train['comment_text'], test_sentence=test['comment_text'], \n",
    "                    y_train=train[label_cols], label_cols=label_cols, \n",
    "                    compatible_models=tfidfdata_compatible_models, word_ngram=(1,1), word_max=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T14:54:26.812688Z",
     "start_time": "2018-06-28T14:54:26.414694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "(500000, 8) (500000, 1)\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\"Month\", \"DayofMonth\", \"DayOfWeek\", \"DepTime\", \"UniqueCarrier\", \"Origin\", \"Dest\", \"Distance\"]\n",
    "label_cols = ['label']\n",
    "feature_cols = list(set(train.columns) - set(label_cols))\n",
    "\n",
    "X_train_ordinal = train[feature_cols]\n",
    "y_train = train[label_cols]#.to_dict('list')\n",
    "X_test_ordinal = testX[feature_cols]\n",
    "print(type(X_train_ordinal), type(y_train))\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train_ordinal)\n",
    "X_train_one_hot = enc.transform(X_train_ordinal)\n",
    "X_test_one_hot = enc.transform(X_test_ordinal)\n",
    "\n",
    "print(X_train_ordinal.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:25:18.208277Z",
     "start_time": "2018-06-28T15:25:18.176847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_id: flight_data_one_hot  \n",
      "\tx_train: (500000, 692)\tx_test: (100000, 692)\n",
      "\ty_train type: <class 'dict'>\n",
      "\tcompatible_models: {<ModelName.XGB: 1>, <ModelName.LOGREG: 9>}\n",
      " data_id: flight_data_ordinal  \n",
      "\tx_train: (500000, 8)\tx_test: (100000, 8)\n",
      "\ty_train type: <class 'dict'>\n",
      "\tcompatible_models: {<ModelName.LGB: 5>}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "bldr = BaseLayerDataRepo()\n",
    "\n",
    "bldr.add_data('flight_data_ordinal', X_train_ordinal, X_test_ordinal, y_train, label_cols, [ModelName.LGB])\n",
    "bldr.add_data('flight_data_one_hot', X_train_one_hot, X_test_one_hot, y_train, label_cols, [ModelName.LOGREG, ModelName.XGB])\n",
    "\n",
    "print(bldr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start generating oof_train, oof_test,  layer1 estimater prediction and model data id list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:25:19.899600Z",
     "start_time": "2018-06-28T15:25:19.865041Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment any model to add to the model pool\n",
    "\n",
    "model_pool = {}\n",
    "\n",
    "SEED = 2018 \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# ###################################  Logreg normal   ####################################\n",
    "logreg_ble = SklearnBLE(LogisticRegression, nb=False, seed=SEED)\n",
    "model_pool[ModelName.LOGREG] = logreg_ble\n",
    "# ###################################  Logreg nb       ####################################\n",
    "# nblogreg_params = {'C':0.25}\n",
    "# nblogreg_ble = SklearnBLE(LogisticRegression, nb=True, seed=SEED, params=nblogreg_params)\n",
    "# model_pool[ModelName.NBLOGREG] = nblogreg_ble\n",
    "# ###################################  Logreg per label  ##################################\n",
    "# logreg_params_per_label = {\n",
    "#     'identity_hate': {'C': 0.25, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "#     'insult': {'C': 0.25, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "#     'obscene': {'C': 0.7, 'class_weight': 'balanced', 'fit_intercept': True},\n",
    "#     'severe_toxic': {'C': 0.3,'class_weight': None, 'fit_intercept': True},\n",
    "#     'threat': {'C': 0.05, 'class_weight': 'balanced', 'fit_intercept': True}, \n",
    "#     'toxic': {'C': 0.8, 'class_weight': 'balanced', 'fit_intercept': True}\n",
    "# }\n",
    "# logreg_per_label_ble = SklearnBLE(LogisticRegression, nb=False, seed=SEED, per_label_params=logreg_params_per_label)\n",
    "# model_pool[ModelName.LOGREG_PERLABEL] = logreg_per_label_ble\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# ###################################  Logreg normal   ####################################\n",
    "# lsvc_ble = SklearnBLE(LinearSVC, need_calibrated_classifier_cv=True)\n",
    "# model_pool[ModelName.LSVC] = lsvc_ble\n",
    "# ###################################  Logreg nb   ####################################\n",
    "# nblsvc_params = {'C':0.02}\n",
    "# nblsvc_ble = SklearnBLE(LinearSVC, nb=True, seed=SEED, params=nblogreg_params, need_calibrated_classifier_cv=True)\n",
    "# model_pool[ModelName.NBLSVC] = nblsvc_ble\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# ###################################  XGB normal   ####################################\n",
    "xgb_params = {'n_jobs': 5}\n",
    "xgb_ble = SklearnBLE(XGBClassifier, seed=SEED, params=xgb_params)# XGBoostBLE(params=xgb_params, nb=False, seed=SEED)\n",
    "model_pool[ModelName.XGB] = xgb_ble\n",
    "# ###################################  XGB nb   ####################################\n",
    "# nbxgb_ble = SklearnBLE(XGBClassifier, nb=True, seed=SEED, params=xgb_params)\n",
    "# model_pool[ModelName.NBXGB] = nbxgb_ble\n",
    "\n",
    "\n",
    "\n",
    "from base_layer_utils import LightgbmBLE\n",
    "lgb_params = {\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_seed': SEED,\n",
    "    'boosting': 'gbdt',\n",
    "    'best_round': 100, # this will be extract from grid search result\n",
    "    'feature_fraction': 1,\n",
    "    'feature_fraction_seed': SEED,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,\n",
    "    'metric': 'auc',\n",
    "    'min_data_in_leaf': 20,\n",
    "    'num_leaves': 31,\n",
    "    'num_threads': 8,\n",
    "    'objective': 'binary',\n",
    "    'scale_pos_weight': 1,\n",
    "    'categorical_feature': categorical_cols,\n",
    "    'verbose_eval': 20\n",
    "}\n",
    "lgb_ble = LightgbmBLE(params=lgb_params)\n",
    "model_pool[ModelName.LGB] = lgb_ble\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "###################################  LGB normal   ####################################\n",
    "# lgb_params = {'n_jobs': 3,'n_estimators': 50}\n",
    "# lgb_ble = SklearnBLE(LGBMClassifier, seed=SEED, params=lgb_params)\n",
    "# model_pool[ModelName.LGB] = lgb_ble\n",
    "# ###################################  LGB nb   ####################################\n",
    "# nblgb_ble = SklearnBLE(LGBMClassifier, nb=True, seed=SEED, params=lgb_params)\n",
    "# model_pool[ModelName.NBLGB] = nblgb_ble\n",
    "# ###################################  LGB per label   ####################################\n",
    "# lgb_params_per_label = {}\n",
    "# lgb_params_per_label['toxic'] = {'n_jobs': 8, 'num_leaves': 61}\n",
    "# lgb_params_per_label['severe_toxic'] = {'n_jobs': 8, 'num_leaves': 11}\n",
    "# lgb_params_per_label['obscene'] = {'n_jobs': 8, 'num_leaves': 61}\n",
    "# lgb_params_per_label['threat'] = {'n_jobs': 8, 'num_leaves': 11}\n",
    "# lgb_params_per_label['insult'] = {'n_jobs': 8,'num_leaves': 11}\n",
    "# lgb_params_per_label['identity_hate'] = {'n_jobs': 8, 'num_leaves': 61}\n",
    "# nblgb_per_label_ble = SklearnBLE(LGBMClassifier, seed=SEED, per_label_params=lgb_params_per_label)\n",
    "# model_pool[ModelName.NBLGB_PERLABEL] = nblgb_per_label_ble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:25:00.103459Z",
     "start_time": "2018-06-28T15:25:00.080904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelName.XGB: 1>, <ModelName.LGB: 5>, <ModelName.LOGREG: 9>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:27:27.312774Z",
     "start_time": "2018-06-28T15:25:49.130859Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing... label: label        model_data_id: ModelName.XGB_flight_data_one_hot\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 0...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 1...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 2...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 3...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 4...\n",
      "Computing... label: label        model_data_id: ModelName.LGB_flight_data_ordinal\n",
      "processing fold 0...\n",
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's auc: 0.739713\n",
      "[40]\ttraining's auc: 0.757236\n",
      "[60]\ttraining's auc: 0.768935\n",
      "[80]\ttraining's auc: 0.776477\n",
      "[100]\ttraining's auc: 0.7824\n",
      "processing fold 1...\n",
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's auc: 0.73986\n",
      "[40]\ttraining's auc: 0.757638\n",
      "[60]\ttraining's auc: 0.769366\n",
      "[80]\ttraining's auc: 0.777548\n",
      "[100]\ttraining's auc: 0.783509\n",
      "processing fold 2...\n",
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[20]\ttraining's auc: 0.739337\n",
      "[40]\ttraining's auc: 0.75793\n",
      "[60]\ttraining's auc: 0.770115\n",
      "[80]\ttraining's auc: 0.777818\n",
      "[100]\ttraining's auc: 0.783956\n",
      "processing fold 3...\n",
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[20]\ttraining's auc: 0.739948\n",
      "[40]\ttraining's auc: 0.757353\n",
      "[60]\ttraining's auc: 0.768232\n",
      "[80]\ttraining's auc: 0.775743\n",
      "[100]\ttraining's auc: 0.781806\n",
      "processing fold 4...\n",
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[20]\ttraining's auc: 0.738562\n",
      "[40]\ttraining's auc: 0.757525\n",
      "[60]\ttraining's auc: 0.768925\n",
      "[80]\ttraining's auc: 0.776744\n",
      "[100]\ttraining's auc: 0.782466\n",
      "No evaluation set, thus not possible to use early stopping. Please train with your best params.\n",
      "[20]\ttraining's auc: 0.739005\n",
      "[40]\ttraining's auc: 0.756209\n",
      "[60]\ttraining's auc: 0.766565\n",
      "[80]\ttraining's auc: 0.774288\n",
      "[100]\ttraining's auc: 0.779646\n",
      "Computing... label: label        model_data_id: ModelName.LOGREG_flight_data_one_hot\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 0...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 1...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 2...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 3...\n",
      "warning: x_train is not dataframe, be careful if categorical_feature is needed when fitting models like LGB\n",
      "processing fold 4...\n"
     ]
    }
   ],
   "source": [
    "layer1_est_preds, layer1_oof_train, layer1_oof_mean_test, model_data_id_list = compute_layer1_oof(bldr, model_pool, label_cols, nfolds=5, sfm_threshold=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit the layer 1 estimator predictions. If they look fine, save them to BaseLayerResultsRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:27:31.561751Z",
     "start_time": "2018-06-28T15:27:31.539044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelName.XGB_flight_data_one_hot',\n",
       " 'ModelName.LOGREG_flight_data_one_hot',\n",
       " 'ModelName.LGB_flight_data_ordinal']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer1_est_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:27:32.732351Z",
     "start_time": "2018-06-28T15:27:32.650674Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB 0.7383601269295124\n",
      "XGB 0.7152229827376881\n",
      "LOGREG 0.7232898472070477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('LGB', roc_auc_score(testY, layer1_est_preds['ModelName.LGB_flight_data_ordinal']))\n",
    "print('XGB', roc_auc_score(testY, layer1_est_preds['ModelName.XGB_flight_data_one_hot']))\n",
    "print('LOGREG', roc_auc_score(testY, layer1_est_preds['ModelName.LOGREG_flight_data_one_hot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:59:49.860557Z",
     "start_time": "2018-06-28T15:59:49.832540Z"
    }
   },
   "outputs": [],
   "source": [
    "avg = (layer1_est_preds['ModelName.LGB_flight_data_ordinal'] + \n",
    "layer1_est_preds['ModelName.LOGREG_flight_data_one_hot'] + \n",
    "layer1_est_preds['ModelName.XGB_flight_data_one_hot']) / 3\n",
    "\n",
    "roc_auc_score(testY, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T16:00:56.867496Z",
     "start_time": "2018-06-28T16:00:56.811198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.737480398808783"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_avg = (0.7*layer1_est_preds['ModelName.LGB_flight_data_ordinal'] + \n",
    "0.2*layer1_est_preds['ModelName.LOGREG_flight_data_one_hot'] + \n",
    "0.1*layer1_est_preds['ModelName.XGB_flight_data_one_hot']) / 3\n",
    "\n",
    "roc_auc_score(testY, weighted_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate files to submit from layer 1 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_predictions_to_file(base_layer_est_preds):\n",
    "    for key in base_layer_est_preds:\n",
    "        submission = pd.read_csv(PATH + 'sample_submission.csv')#.head(1000)\n",
    "        submission[label_cols] = base_layer_est_preds[key]\n",
    "        sub_id = int(time.time())\n",
    "        print(sub_id)\n",
    "        submission.to_csv('./BaseEstPreds/' + key + '_' + str(sub_id) + '.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522094161\n",
      "1522094166\n",
      "1522094171\n"
     ]
    }
   ],
   "source": [
    "write_predictions_to_file(layer1_est_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sanity check before save to BaseLayerResultsRepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:27:42.525694Z",
     "start_time": "2018-06-28T15:27:42.497677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelName.XGB_flight_data_one_hot',\n",
       " 'ModelName.LGB_flight_data_ordinal',\n",
       " 'ModelName.LOGREG_flight_data_one_hot']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_id_list # model_data we just computed in the layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:29:07.310283Z",
     "start_time": "2018-06-28T15:29:07.284165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:27:43.721690Z",
     "start_time": "2018-06-28T15:27:43.693491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer1_oof_train) # list keys (which are labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:29:13.844835Z",
     "start_time": "2018-06-28T15:29:13.816765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer1_oof_train[label_cols[0]]) # number of models to stack (each model will predict one set of labels like: toxic, servere_toxic, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:29:40.249610Z",
     "start_time": "2018-06-28T15:29:40.220886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer1_oof_train[label_cols[0]][0]) # examples in oof_train (meta features, x_train) (meta labels are in train[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:30:07.206170Z",
     "start_time": "2018-06-28T15:30:07.177290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer1_oof_mean_test) # all labels like toxic, servere_toxic, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:29:33.959864Z",
     "start_time": "2018-06-28T15:29:33.931834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layer1_oof_mean_test[label_cols[0]][0]) # examples in oof_test (will be used by meta model (after validation) to predict the final prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:38:23.858688Z",
     "start_time": "2018-06-28T15:38:23.789404Z"
    }
   },
   "outputs": [],
   "source": [
    "# read the doc string to BaseLayerResultsRepo to set params\n",
    "base_layer_results_repo = BaseLayerResultsRepo(label_cols=label_cols, filepath='oof/', load_from_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:38:25.142789Z",
     "start_time": "2018-06-28T15:38:25.111992Z"
    }
   },
   "outputs": [],
   "source": [
    "base_layer_results_repo.add(layer1_oof_train, layer1_oof_mean_test, layer1_est_preds, model_data_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T21:31:57.980760Z",
     "start_time": "2018-06-28T21:31:57.893734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ModelName.XGB_flight_data_one_hot',\n",
       " 'ModelName.LGB_flight_data_ordinal',\n",
       " 'ModelName.LOGREG_flight_data_one_hot']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_layer_results_repo.get_model_data_id_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:38:26.329980Z",
     "start_time": "2018-06-28T15:38:26.298268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tModelName.XGB_flight_data_one_hot\n",
      "0\tModelName.LOGREG_flight_data_one_hot\n",
      "0\tModelName.LGB_flight_data_ordinal\n"
     ]
    }
   ],
   "source": [
    "scores = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:38:32.503407Z",
     "start_time": "2018-06-28T15:38:32.473541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelName.XGB_flight_data_one_hot already existed in the repo. score: 0 update to 0.7152\n",
      "ModelName.LOGREG_flight_data_one_hot already existed in the repo. score: 0 update to 0.7232\n",
      "ModelName.LGB_flight_data_ordinal already existed in the repo. score: 0 update to 0.7383\n"
     ]
    }
   ],
   "source": [
    " # let's give some fake scores\n",
    "base_layer_results_repo.add_score('ModelName.XGB_flight_data_one_hot', 0.7152)\n",
    "base_layer_results_repo.add_score('ModelName.LOGREG_flight_data_one_hot', 0.7232)\n",
    "base_layer_results_repo.add_score('ModelName.LGB_flight_data_ordinal', 0.7383)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:38:33.695038Z",
     "start_time": "2018-06-28T15:38:33.666584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7383\tModelName.LGB_flight_data_ordinal\n",
      "0.7232\tModelName.LOGREG_flight_data_one_hot\n",
      "0.7152\tModelName.XGB_flight_data_one_hot\n"
     ]
    }
   ],
   "source": [
    "scores = base_layer_results_repo.show_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:38:35.218512Z",
     "start_time": "2018-06-28T15:38:35.170470Z"
    }
   },
   "outputs": [],
   "source": [
    "base_layer_results_repo.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T15:38:38.285754Z",
     "start_time": "2018-06-28T15:38:38.256476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack 1\n"
     ]
    }
   ],
   "source": [
    "print('stack 1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
