{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index' 'ip' 'app' 'device' 'os' 'channel' 'click_time' 'is_attributed'\n",
      " 'is_train']\n",
      "   index      ip  app  device  os  channel           click_time  \\\n",
      "0      0   83230    3       1  13      379  2017-11-06 14:32:21   \n",
      "1      1   17357    3       1  19      379  2017-11-06 14:33:34   \n",
      "2      2   35810    3       1  13      379  2017-11-06 14:34:12   \n",
      "3      3   45745   14       1  13      478  2017-11-06 14:34:52   \n",
      "4      4  161007    3       1  13      379  2017-11-06 14:35:08   \n",
      "\n",
      "   is_attributed  is_train  \n",
      "0              0         1  \n",
      "1              0         1  \n",
      "2              0         1  \n",
      "3              0         1  \n",
      "4              0         1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = \"/home/kai/data/kaggle/talkingdata/data/\"\n",
    "test_nrows = 5\n",
    "nrows = None\n",
    "dtypes = {\n",
    "    'ip':            'uint32',\n",
    "    'app':           'uint16',\n",
    "    'device':        'uint16',\n",
    "    'os':            'uint16',\n",
    "    'channel':       'uint16',\n",
    "    'is_attributed': 'uint8',\n",
    "    'click_id':      'uint32'\n",
    "}\n",
    "train = pd.read_csv(PATH + 'train.csv', nrows=test_nrows, dtype=dtypes,\n",
    "                    usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']).reset_index()\n",
    "test = pd.read_csv(PATH + 'test_supplement.csv', nrows=test_nrows, dtype=dtypes,\n",
    "                    usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id']).reset_index()\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test['is_attributed'] = 2\n",
    "print(train.columns.values)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine = device + os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app  channel  click_id                click_time  day  device  hour  \\\n",
      "0    3      379       NaN 2017-11-06 22:32:21+08:00    6       1    22   \n",
      "1    3      379       NaN 2017-11-06 22:33:34+08:00    6       1    22   \n",
      "2    3      379       NaN 2017-11-06 22:34:12+08:00    6       1    22   \n",
      "3   14      478       NaN 2017-11-06 22:34:52+08:00    6       1    22   \n",
      "4    3      379       NaN 2017-11-06 22:35:08+08:00    6       1    22   \n",
      "0    3      379       0.0 2017-11-09 22:23:39+08:00    9       1    22   \n",
      "1    3      379       1.0 2017-11-09 22:23:51+08:00    9       1    22   \n",
      "2    3      379       2.0 2017-11-09 22:25:57+08:00    9       1    22   \n",
      "3    3      379       3.0 2017-11-09 22:26:03+08:00    9       1    22   \n",
      "4   58      120       4.0 2017-11-09 22:26:41+08:00    9       1    22   \n",
      "\n",
      "   hourminute  hourminute10  index      ip  is_attributed  is_train  machine  \\\n",
      "0        1352          1350      0   83230              0         1     1013   \n",
      "1        1353          1350      1   17357              0         1     1019   \n",
      "2        1354          1350      2   35810              0         1     1013   \n",
      "3        1354          1350      3   45745              0         1     1013   \n",
      "4        1355          1350      4  161007              0         1     1013   \n",
      "0        1343          1340      0   43570              2         0     1018   \n",
      "1        1343          1340      1   80528              2         0     1013   \n",
      "2        1345          1340      2   32323              2         0     1013   \n",
      "3        1346          1340      3   42887              2         0     1017   \n",
      "4        1346          1340      4  119289              2         0     1030   \n",
      "\n",
      "   minute  minute10  os  \n",
      "0      32        30  13  \n",
      "1      33        30  19  \n",
      "2      34        30  13  \n",
      "3      34        30  13  \n",
      "4      35        30  13  \n",
      "0      23        20  18  \n",
      "1      23        20  13  \n",
      "2      25        20  13  \n",
      "3      26        20  17  \n",
      "4      26        20  30  \n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "\n",
    "# set time zone to be Shanghai time and split click_time into day, hour and minute\n",
    "def data_clean(df):\n",
    "    tz = pytz.timezone('Asia/Shanghai')\n",
    "    df['click_time'] = pd.to_datetime(df['click_time']).dt.tz_localize(pytz.utc).dt.tz_convert(tz)\n",
    "    df['day'] = df['click_time'].dt.day.astype('uint8')\n",
    "    df['hour'] = df['click_time'].dt.hour.astype('uint8')\n",
    "    df['minute'] = df['click_time'].dt.minute.astype('uint8')\n",
    "    df['minute10'] = (df['minute'] / 10).astype('uint8') * 10 # set to 10 minute\n",
    "    df['hourminute'] = (df['minute'].astype('uint16') + df['hour'].astype('uint16') * 60)\n",
    "    df['hourminute10'] = (df['minute10'].astype('uint16') + df['hour'].astype('uint16') * 60)\n",
    "    df['machine'] = 1000 * df['device'] + df['os']\n",
    "    \n",
    "data_clean(train)\n",
    "data_clean(test)\n",
    "df = train.append(test) # concat train and test\n",
    "\n",
    "data_type = df.dtypes.to_dict()\n",
    "\n",
    "label = 'is_attributed'\n",
    "train_len = train.shape[0]\n",
    "fdir = './data/'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count the click number for each feature combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app  channel  click_id                click_time  day  device  hour  \\\n",
      "0    3      379       NaN 2017-11-06 22:32:21+08:00    6       1    22   \n",
      "1    3      379       NaN 2017-11-06 22:33:34+08:00    6       1    22   \n",
      "2    3      379       NaN 2017-11-06 22:34:12+08:00    6       1    22   \n",
      "3   14      478       NaN 2017-11-06 22:34:52+08:00    6       1    22   \n",
      "4    3      379       NaN 2017-11-06 22:35:08+08:00    6       1    22   \n",
      "5    3      379       0.0 2017-11-09 22:23:39+08:00    9       1    22   \n",
      "6    3      379       1.0 2017-11-09 22:23:51+08:00    9       1    22   \n",
      "7    3      379       2.0 2017-11-09 22:25:57+08:00    9       1    22   \n",
      "8    3      379       3.0 2017-11-09 22:26:03+08:00    9       1    22   \n",
      "9   58      120       4.0 2017-11-09 22:26:41+08:00    9       1    22   \n",
      "\n",
      "   hourminute  hourminute10  index      ip  is_attributed  is_train  machine  \\\n",
      "0        1352          1350      0   83230              0         1     1013   \n",
      "1        1353          1350      1   17357              0         1     1019   \n",
      "2        1354          1350      2   35810              0         1     1013   \n",
      "3        1354          1350      3   45745              0         1     1013   \n",
      "4        1355          1350      4  161007              0         1     1013   \n",
      "5        1343          1340      0   43570              2         0     1018   \n",
      "6        1343          1340      1   80528              2         0     1013   \n",
      "7        1345          1340      2   32323              2         0     1013   \n",
      "8        1346          1340      3   42887              2         0     1017   \n",
      "9        1346          1340      4  119289              2         0     1030   \n",
      "\n",
      "   minute  minute10  os  count_app_channel  \n",
      "0      32        30  13                  8  \n",
      "1      33        30  19                  8  \n",
      "2      34        30  13                  8  \n",
      "3      34        30  13                  1  \n",
      "4      35        30  13                  8  \n",
      "5      23        20  18                  8  \n",
      "6      23        20  13                  8  \n",
      "7      25        20  13                  8  \n",
      "8      26        20  17                  8  \n",
      "9      26        20  30                  1  \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Here df is [train test_supp]\n",
    "def count(df, cols, label, train_len):\n",
    "    col_name = 'count_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    _df[[col_name]][ : train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    _df[[col_name]][train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "\n",
    "patterns = [\n",
    "    ['app','channel'],\n",
    "    ['app','device','channel','day','hour'],\n",
    "    ['app','device','day','hour'],\n",
    "    ['app','os','channel','day','hour'],\n",
    "    ['ip','day'],\n",
    "    ['ip'],\n",
    "    ['ip','app','device','channel','day'],\n",
    "    ['ip','app','device','day'],\n",
    "    ['ip','app','device','os','day','hour'],\n",
    "    ['ip','app','os','channel'],\n",
    "    ['ip','app','os','channel','day'],\n",
    "    ['ip','os'],\n",
    "    ['app','day','hourminute'],\n",
    "    ['device','os','day','hourminute10'],\n",
    "    ['ip','device','os','day','hourminute10']\n",
    "]\n",
    "\n",
    "count(df, patterns[0], 'is_attributed', train_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unique count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group data by certain feature combination and count the number of different values of another feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app  channel  click_id                click_time  day  device  hour  \\\n",
      "0    3      379       NaN 2017-11-06 22:32:21+08:00    6       1    22   \n",
      "1    3      379       NaN 2017-11-06 22:33:34+08:00    6       1    22   \n",
      "2    3      379       NaN 2017-11-06 22:34:12+08:00    6       1    22   \n",
      "3   14      478       NaN 2017-11-06 22:34:52+08:00    6       1    22   \n",
      "4    3      379       NaN 2017-11-06 22:35:08+08:00    6       1    22   \n",
      "5    3      379       0.0 2017-11-09 22:23:39+08:00    9       1    22   \n",
      "6    3      379       1.0 2017-11-09 22:23:51+08:00    9       1    22   \n",
      "7    3      379       2.0 2017-11-09 22:25:57+08:00    9       1    22   \n",
      "8    3      379       3.0 2017-11-09 22:26:03+08:00    9       1    22   \n",
      "9   58      120       4.0 2017-11-09 22:26:41+08:00    9       1    22   \n",
      "\n",
      "   hourminute  hourminute10  index      ip  is_attributed  is_train  machine  \\\n",
      "0        1352          1350      0   83230              0         1     1013   \n",
      "1        1353          1350      1   17357              0         1     1019   \n",
      "2        1354          1350      2   35810              0         1     1013   \n",
      "3        1354          1350      3   45745              0         1     1013   \n",
      "4        1355          1350      4  161007              0         1     1013   \n",
      "5        1343          1340      0   43570              2         0     1018   \n",
      "6        1343          1340      1   80528              2         0     1013   \n",
      "7        1345          1340      2   32323              2         0     1013   \n",
      "8        1346          1340      3   42887              2         0     1017   \n",
      "9        1346          1340      4  119289              2         0     1030   \n",
      "\n",
      "   minute  minute10  os  nunique_app_channel_ip  \n",
      "0      32        30  13                       8  \n",
      "1      33        30  19                       8  \n",
      "2      34        30  13                       8  \n",
      "3      34        30  13                       1  \n",
      "4      35        30  13                       8  \n",
      "5      23        20  18                       8  \n",
      "6      23        20  13                       8  \n",
      "7      25        20  13                       8  \n",
      "8      26        20  17                       8  \n",
      "9      26        20  30                       1  \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def unique_count(df, cols, train_len):\n",
    "    col_name = 'nunique_' + '_'.join(cols)\n",
    "    count_result = df[cols].groupby(by=cols[:-1])[[cols[-1]]].nunique().rename(index=str,\\\n",
    "                                                                               columns={cols[-1]: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols[:-1], how='left')\n",
    "    _df[[col_name]][ : train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    _df[[col_name]][train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['day','ip','machine'],\n",
    "    ['day','ip','os'],\n",
    "    ['day','ip','device'],\n",
    "    ['day','ip','app'],\n",
    "    ['day','ip','channel'],\n",
    "    ['machine','app'],\n",
    "    ['machine','ip'],\n",
    "    ['machine','channel'],\n",
    "]\n",
    "\n",
    "unique_count(df, ['app','channel','ip'], train_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cumulative count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## give an order number in each feature combination by each feature combination, sorted by [click_time, index, is_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cumcount_app_channel\n",
      "0                     0\n",
      "1                     1\n",
      "2                     2\n",
      "3                     0\n",
      "4                     3\n",
      "0                     4\n",
      "1                     5\n",
      "2                     6\n",
      "3                     7\n",
      "4                     0\n",
      "\n",
      "   app  channel  click_id                click_time  day  device  hour  \\\n",
      "0    3      379       NaN 2017-11-06 22:32:21+08:00    6       1    22   \n",
      "1    3      379       NaN 2017-11-06 22:33:34+08:00    6       1    22   \n",
      "2    3      379       NaN 2017-11-06 22:34:12+08:00    6       1    22   \n",
      "3   14      478       NaN 2017-11-06 22:34:52+08:00    6       1    22   \n",
      "4    3      379       NaN 2017-11-06 22:35:08+08:00    6       1    22   \n",
      "0    3      379       0.0 2017-11-09 22:23:39+08:00    9       1    22   \n",
      "1    3      379       1.0 2017-11-09 22:23:51+08:00    9       1    22   \n",
      "2    3      379       2.0 2017-11-09 22:25:57+08:00    9       1    22   \n",
      "3    3      379       3.0 2017-11-09 22:26:03+08:00    9       1    22   \n",
      "4   58      120       4.0 2017-11-09 22:26:41+08:00    9       1    22   \n",
      "\n",
      "   hourminute  hourminute10  index      ip  is_attributed  is_train  machine  \\\n",
      "0        1352          1350      0   83230              0         1     1013   \n",
      "1        1353          1350      1   17357              0         1     1019   \n",
      "2        1354          1350      2   35810              0         1     1013   \n",
      "3        1354          1350      3   45745              0         1     1013   \n",
      "4        1355          1350      4  161007              0         1     1013   \n",
      "0        1343          1340      0   43570              2         0     1018   \n",
      "1        1343          1340      1   80528              2         0     1013   \n",
      "2        1345          1340      2   32323              2         0     1013   \n",
      "3        1346          1340      3   42887              2         0     1017   \n",
      "4        1346          1340      4  119289              2         0     1030   \n",
      "\n",
      "   minute  minute10  os  \n",
      "0      32        30  13  \n",
      "1      33        30  19  \n",
      "2      34        30  13  \n",
      "3      34        30  13  \n",
      "4      35        30  13  \n",
      "0      23        20  18  \n",
      "1      23        20  13  \n",
      "2      25        20  13  \n",
      "3      26        20  17  \n",
      "4      26        20  30  \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def cum_count(df, cols, train_len):\n",
    "    col_name = 'cumcount_' + '_'.join(cols)\n",
    "    result = df[cols].groupby(cols).cumcount().rename(col_name).to_frame()\n",
    "    result[:train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    result[train_len:].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del result\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['ip','app','device','os','day','hour'],\n",
    "    ['ip','day'],\n",
    "    ['app','device','os','day']\n",
    "]\n",
    "\n",
    "cum_count(df, ['app', 'channel'], train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cumcount_app_channel\n",
      "0                     0\n",
      "1                     1\n",
      "2                     2\n",
      "3                     0\n",
      "4                     3\n"
     ]
    }
   ],
   "source": [
    "xxx = pd.read_csv(fdir + 'train_cumcount_app_channel.csv')\n",
    "print(xxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cols1 count / cols2 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count_ratio_app_machine\n",
      "0                 1.333333\n",
      "1                 8.000000\n",
      "2                 1.333333\n",
      "3                 0.166667\n",
      "4                 1.333333\n",
      "5                 8.000000\n",
      "6                 1.333333\n",
      "7                 1.333333\n",
      "8                 8.000000\n",
      "9                 1.000000\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def _count(df, cols, label):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    result = _df[[col_name]].copy()\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    return result\n",
    "\n",
    "def count_ratio(df, cols1, cols2, label, train_len):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols1) + '_' + '_'.join(cols2)\n",
    "    x1 = _count(df, cols1, label)\n",
    "    x2 = _count(df, cols2, label)\n",
    "    x1[col_name] = x1[x1.columns.values[0]] / x2[x2.columns.values[0]] # or = round(x1 / x2, 4)\n",
    "    result = x1[[col_name]]\n",
    "    result[:train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    result[train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del x1, x2\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    {'cols1':['ip'], 'cols2':['machine']},\n",
    "    {'cols1':['ip'], 'cols2':['channel']},\n",
    "    {'cols1':['machine'], 'cols2':['ip']},\n",
    "    {'cols1':['app'], 'cols2':['channel']},\n",
    "    {'cols1':['channel'], 'cols2':['app']}\n",
    "]\n",
    "\n",
    "count_ratio(df, ['app'], patterns[0]['cols2'], label, train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['count_ratio_app_machine']\n"
     ]
    }
   ],
   "source": [
    "xxx = pd.read_csv('./data/train_count_ratio_app_machine.csv')\n",
    "print(xxx.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cumulative count ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cols cumcount / (cols count-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cumcount_ratio_app_channel\n",
      "0                           0\n",
      "1                           1\n",
      "2                           2\n",
      "3                           0\n",
      "4                           3\n",
      "5                           4\n",
      "6                           5\n",
      "7                           6\n",
      "8                           7\n",
      "9                           0    count_ratio_app_channel\n",
      "0                        8\n",
      "1                        8\n",
      "2                        8\n",
      "3                        1\n",
      "4                        8\n",
      "5                        8\n",
      "6                        8\n",
      "7                        8\n",
      "8                        8\n",
      "9                        1\n",
      "   cumcount_ratio_app_channel\n",
      "0                      0.0000\n",
      "1                      0.1429\n",
      "2                      0.2857\n",
      "3                      1.1000\n",
      "4                      0.4286\n",
      "5                      0.5714\n",
      "6                      0.7143\n",
      "7                      0.8571\n",
      "8                      1.0000\n",
      "9                      1.1000\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def _count(df, cols, label):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    result = _df[[col_name]].copy()\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    return result\n",
    "\n",
    "def _cum_count(df, cols):\n",
    "    col_name = 'cumcount_ratio_' + '_'.join(cols)\n",
    "    result = df[cols].groupby(cols).cumcount().rename(col_name).to_frame()\n",
    "    return result.reset_index()[[col_name]]\n",
    "    \n",
    "def cum_count_ratio(df, cols, label, train_len):\n",
    "    col_name = 'cumcount_ratio_' + '_'.join(cols)\n",
    "    x1 = _cum_count(df, cols)\n",
    "    x2 = _count(df, cols, label)\n",
    "    print(x1, x2)\n",
    "    x1[col_name] = round(x1[x1.columns.values[0]] / (x2[x2.columns.values[0]] - 1), 4).fillna(1.1)\n",
    "    result = x1[[col_name]]\n",
    "    result[:train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    result[train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    print(result)\n",
    "    del x1, x2\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['ip','day']\n",
    "]\n",
    "\n",
    "cum_count_ratio(df, ['app','channel'], label, train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cumcount_ratio_app_channel\n",
      "0                      0.0000\n",
      "1                      0.1429\n",
      "2                      0.2857\n",
      "3                      1.1000\n",
      "4                      0.4286\n"
     ]
    }
   ],
   "source": [
    "xxx = pd.read_csv(fdir + 'train_cumcount_ratio_app_channel.csv')\n",
    "print(xxx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
