{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index' 'ip' 'app' 'device' 'os' 'channel' 'click_time' 'is_attributed'\n",
      " 'click_id' 'is_test']\n",
      "   index      ip  app  device  os  channel           click_time  \\\n",
      "0      0   83230    3       1  13      379  2017-11-06 14:32:21   \n",
      "1      1   17357    3       1  19      379  2017-11-06 14:33:34   \n",
      "2      2   35810    3       1  13      379  2017-11-06 14:34:12   \n",
      "3      3   45745   14       1  13      478  2017-11-06 14:34:52   \n",
      "4      4  161007    3       1  13      379  2017-11-06 14:35:08   \n",
      "\n",
      "   is_attributed  click_id  is_test  \n",
      "0              0         0        0  \n",
      "1              0         0        0  \n",
      "2              0         0        0  \n",
      "3              0         0        0  \n",
      "4              0         0        0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = \"/home/kai/data/kaggle/talkingdata/data/\"\n",
    "test_nrows = 5\n",
    "nrows = None\n",
    "dtypes = {\n",
    "    'ip':            'uint32',\n",
    "    'app':           'uint16',\n",
    "    'device':        'uint16',\n",
    "    'os':            'uint16',\n",
    "    'channel':       'uint16',\n",
    "    'is_attributed': 'uint8',\n",
    "    'click_id':      'uint32'\n",
    "}\n",
    "train = pd.read_csv(PATH + 'train.csv', nrows=test_nrows, dtype=dtypes,\n",
    "                    usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']).reset_index()\n",
    "test = pd.read_csv(PATH + 'test_supplement.csv', nrows=test_nrows, dtype=dtypes,\n",
    "                    usecols=['ip', 'app', 'device', 'os', 'channel', 'click_time', 'click_id']).reset_index()\n",
    "train['click_id'] = 0\n",
    "train['is_test'] = 0\n",
    "test['is_test'] = 1\n",
    "test['is_attributed'] = 2\n",
    "print(train.columns.values)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine = device + os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app  channel  click_id                click_time  click_timestamp  day  \\\n",
      "0    3      379         0 2017-11-06 22:32:21+08:00       1509978741    6   \n",
      "1    3      379         0 2017-11-06 22:33:34+08:00       1509978814    6   \n",
      "2    3      379         0 2017-11-06 22:34:12+08:00       1509978852    6   \n",
      "3   14      478         0 2017-11-06 22:34:52+08:00       1509978892    6   \n",
      "4    3      379         0 2017-11-06 22:35:08+08:00       1509978908    6   \n",
      "5    3      379         0 2017-11-09 22:23:39+08:00       1510237419    9   \n",
      "6    3      379         1 2017-11-09 22:23:51+08:00       1510237431    9   \n",
      "7    3      379         2 2017-11-09 22:25:57+08:00       1510237557    9   \n",
      "8    3      379         3 2017-11-09 22:26:03+08:00       1510237563    9   \n",
      "9   58      120         4 2017-11-09 22:26:41+08:00       1510237601    9   \n",
      "\n",
      "   device  hour  hourminute  hourminute10  index      ip  is_attributed  \\\n",
      "0       1    22        1352          1350      0   83230              0   \n",
      "1       1    22        1353          1350      1   17357              0   \n",
      "2       1    22        1354          1350      2   35810              0   \n",
      "3       1    22        1354          1350      3   45745              0   \n",
      "4       1    22        1355          1350      4  161007              0   \n",
      "5       1    22        1343          1340      0   43570              2   \n",
      "6       1    22        1343          1340      1   80528              2   \n",
      "7       1    22        1345          1340      2   32323              2   \n",
      "8       1    22        1346          1340      3   42887              2   \n",
      "9       1    22        1346          1340      4  119289              2   \n",
      "\n",
      "   is_test  machine  minute  minute10  os  \n",
      "0        0     1013      32        30  13  \n",
      "1        0     1019      33        30  19  \n",
      "2        0     1013      34        30  13  \n",
      "3        0     1013      34        30  13  \n",
      "4        0     1013      35        30  13  \n",
      "5        1     1018      23        20  18  \n",
      "6        1     1013      23        20  13  \n",
      "7        1     1013      25        20  13  \n",
      "8        1     1017      26        20  17  \n",
      "9        1     1030      26        20  30  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pytz\n",
    "\n",
    "# set time zone to be Shanghai time and split click_time into day, hour and minute\n",
    "def data_clean(df):\n",
    "    tz = pytz.timezone('Asia/Shanghai')\n",
    "    df['click_time'] = pd.to_datetime(df['click_time']).dt.tz_localize(pytz.utc).dt.tz_convert(tz)\n",
    "    df['day'] = df['click_time'].dt.day.astype('uint8')\n",
    "    df['hour'] = df['click_time'].dt.hour.astype('uint8')\n",
    "    df['minute'] = df['click_time'].dt.minute.astype('uint8')\n",
    "    df['minute10'] = (df['minute'] / 10).astype('uint8') * 10 # set to 10 minute\n",
    "    df['hourminute'] = (df['minute'].astype('uint16') + df['hour'].astype('uint16') * 60)\n",
    "    df['hourminute10'] = (df['minute10'].astype('uint16') + df['hour'].astype('uint16') * 60)\n",
    "    df['dayhourminute'] = (df['hourminute'].astype('uint32') + df['day'].astype('uinte32') * 60 * 24)\n",
    "    df['dayhourminute10'] = (df['hourminute10'].astype('uint32') + df['day'].astype('uinte32') * 60 * 24)\n",
    "    df['machine'] = 1000 * df['device'] + df['os']\n",
    "    df['click_timestamp'] = (df['click_time'].astype(np.int64) // 10 ** 9).astype(np.int32)\n",
    "\n",
    "    \n",
    "    \n",
    "data_clean(train)\n",
    "data_clean(test)\n",
    "df = pd.concat([train, test], ignore_index=True) # concat train and test\n",
    "\n",
    "data_type = df.dtypes.to_dict()\n",
    "\n",
    "label = 'is_attributed'\n",
    "train_len = train.shape[0]\n",
    "fdir = './data/'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count the click number for each feature combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app  channel  click_id                click_time  day  device  hour  \\\n",
      "0    3      379       NaN 2017-11-06 22:32:21+08:00    6       1    22   \n",
      "1    3      379       NaN 2017-11-06 22:33:34+08:00    6       1    22   \n",
      "2    3      379       NaN 2017-11-06 22:34:12+08:00    6       1    22   \n",
      "3   14      478       NaN 2017-11-06 22:34:52+08:00    6       1    22   \n",
      "4    3      379       NaN 2017-11-06 22:35:08+08:00    6       1    22   \n",
      "5    3      379       0.0 2017-11-09 22:23:39+08:00    9       1    22   \n",
      "6    3      379       1.0 2017-11-09 22:23:51+08:00    9       1    22   \n",
      "7    3      379       2.0 2017-11-09 22:25:57+08:00    9       1    22   \n",
      "8    3      379       3.0 2017-11-09 22:26:03+08:00    9       1    22   \n",
      "9   58      120       4.0 2017-11-09 22:26:41+08:00    9       1    22   \n",
      "\n",
      "   hourminute  hourminute10  index      ip  is_attributed  is_train  machine  \\\n",
      "0        1352          1350      0   83230              0         1     1013   \n",
      "1        1353          1350      1   17357              0         1     1019   \n",
      "2        1354          1350      2   35810              0         1     1013   \n",
      "3        1354          1350      3   45745              0         1     1013   \n",
      "4        1355          1350      4  161007              0         1     1013   \n",
      "5        1343          1340      0   43570              2         0     1018   \n",
      "6        1343          1340      1   80528              2         0     1013   \n",
      "7        1345          1340      2   32323              2         0     1013   \n",
      "8        1346          1340      3   42887              2         0     1017   \n",
      "9        1346          1340      4  119289              2         0     1030   \n",
      "\n",
      "   minute  minute10  os  count_app_channel  \n",
      "0      32        30  13                  8  \n",
      "1      33        30  19                  8  \n",
      "2      34        30  13                  8  \n",
      "3      34        30  13                  1  \n",
      "4      35        30  13                  8  \n",
      "5      23        20  18                  8  \n",
      "6      23        20  13                  8  \n",
      "7      25        20  13                  8  \n",
      "8      26        20  17                  8  \n",
      "9      26        20  30                  1  \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Here df is [train test_supp]\n",
    "def count(df, cols, label, train_len):\n",
    "    col_name = 'count_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    _df[[col_name]][ : train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    _df[[col_name]][train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "\n",
    "patterns = [\n",
    "    ['app','channel'],\n",
    "    ['app','device','channel','day','hour'],\n",
    "    ['app','device','day','hour'],\n",
    "    ['app','os','channel','day','hour'],\n",
    "    ['ip','day'],\n",
    "    ['ip'],\n",
    "    ['ip','app','device','channel','day'],\n",
    "    ['ip','app','device','day'],\n",
    "    ['ip','app','device','os','day','hour'],\n",
    "    ['ip','app','os','channel'],\n",
    "    ['ip','app','os','channel','day'],\n",
    "    ['ip','os'],\n",
    "    ['app','day','hourminute'],\n",
    "    ['device','os','day','hourminute10'],\n",
    "    ['ip','device','os','day','hourminute10']\n",
    "]\n",
    "\n",
    "count(df, patterns[0], 'is_attributed', train_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unique count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group data by certain feature combination and count the number of different values of another feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app  channel  click_id                click_time  day  device  hour  \\\n",
      "0    3      379       NaN 2017-11-06 22:32:21+08:00    6       1    22   \n",
      "1    3      379       NaN 2017-11-06 22:33:34+08:00    6       1    22   \n",
      "2    3      379       NaN 2017-11-06 22:34:12+08:00    6       1    22   \n",
      "3   14      478       NaN 2017-11-06 22:34:52+08:00    6       1    22   \n",
      "4    3      379       NaN 2017-11-06 22:35:08+08:00    6       1    22   \n",
      "5    3      379       0.0 2017-11-09 22:23:39+08:00    9       1    22   \n",
      "6    3      379       1.0 2017-11-09 22:23:51+08:00    9       1    22   \n",
      "7    3      379       2.0 2017-11-09 22:25:57+08:00    9       1    22   \n",
      "8    3      379       3.0 2017-11-09 22:26:03+08:00    9       1    22   \n",
      "9   58      120       4.0 2017-11-09 22:26:41+08:00    9       1    22   \n",
      "\n",
      "   hourminute  hourminute10  index      ip  is_attributed  is_train  machine  \\\n",
      "0        1352          1350      0   83230              0         1     1013   \n",
      "1        1353          1350      1   17357              0         1     1019   \n",
      "2        1354          1350      2   35810              0         1     1013   \n",
      "3        1354          1350      3   45745              0         1     1013   \n",
      "4        1355          1350      4  161007              0         1     1013   \n",
      "5        1343          1340      0   43570              2         0     1018   \n",
      "6        1343          1340      1   80528              2         0     1013   \n",
      "7        1345          1340      2   32323              2         0     1013   \n",
      "8        1346          1340      3   42887              2         0     1017   \n",
      "9        1346          1340      4  119289              2         0     1030   \n",
      "\n",
      "   minute  minute10  os  nunique_app_channel_ip  \n",
      "0      32        30  13                       8  \n",
      "1      33        30  19                       8  \n",
      "2      34        30  13                       8  \n",
      "3      34        30  13                       1  \n",
      "4      35        30  13                       8  \n",
      "5      23        20  18                       8  \n",
      "6      23        20  13                       8  \n",
      "7      25        20  13                       8  \n",
      "8      26        20  17                       8  \n",
      "9      26        20  30                       1  \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def unique_count(df, cols, train_len):\n",
    "    col_name = 'nunique_' + '_'.join(cols)\n",
    "    count_result = df[cols].groupby(by=cols[:-1])[[cols[-1]]].nunique().rename(index=str,\\\n",
    "                                                                               columns={cols[-1]: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols[:-1], how='left')\n",
    "    _df[[col_name]][ : train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    _df[[col_name]][train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['day','ip','machine'],\n",
    "    ['day','ip','os'],\n",
    "    ['day','ip','device'],\n",
    "    ['day','ip','app'],\n",
    "    ['day','ip','channel'],\n",
    "    ['machine','app'],\n",
    "    ['machine','ip'],\n",
    "    ['machine','channel'],\n",
    "]\n",
    "\n",
    "unique_count(df, ['app','channel','ip'], train_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cumulative count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## give an order number in each feature combination by each feature combination, sorted by [click_time, index, is_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cumcount_app_channel\n",
      "0                     0\n",
      "1                     1\n",
      "2                     2\n",
      "3                     0\n",
      "4                     3\n",
      "0                     4\n",
      "1                     5\n",
      "2                     6\n",
      "3                     7\n",
      "4                     0\n",
      "\n",
      "   app  channel  click_id                click_time  day  device  hour  \\\n",
      "0    3      379       NaN 2017-11-06 22:32:21+08:00    6       1    22   \n",
      "1    3      379       NaN 2017-11-06 22:33:34+08:00    6       1    22   \n",
      "2    3      379       NaN 2017-11-06 22:34:12+08:00    6       1    22   \n",
      "3   14      478       NaN 2017-11-06 22:34:52+08:00    6       1    22   \n",
      "4    3      379       NaN 2017-11-06 22:35:08+08:00    6       1    22   \n",
      "0    3      379       0.0 2017-11-09 22:23:39+08:00    9       1    22   \n",
      "1    3      379       1.0 2017-11-09 22:23:51+08:00    9       1    22   \n",
      "2    3      379       2.0 2017-11-09 22:25:57+08:00    9       1    22   \n",
      "3    3      379       3.0 2017-11-09 22:26:03+08:00    9       1    22   \n",
      "4   58      120       4.0 2017-11-09 22:26:41+08:00    9       1    22   \n",
      "\n",
      "   hourminute  hourminute10  index      ip  is_attributed  is_train  machine  \\\n",
      "0        1352          1350      0   83230              0         1     1013   \n",
      "1        1353          1350      1   17357              0         1     1019   \n",
      "2        1354          1350      2   35810              0         1     1013   \n",
      "3        1354          1350      3   45745              0         1     1013   \n",
      "4        1355          1350      4  161007              0         1     1013   \n",
      "0        1343          1340      0   43570              2         0     1018   \n",
      "1        1343          1340      1   80528              2         0     1013   \n",
      "2        1345          1340      2   32323              2         0     1013   \n",
      "3        1346          1340      3   42887              2         0     1017   \n",
      "4        1346          1340      4  119289              2         0     1030   \n",
      "\n",
      "   minute  minute10  os  \n",
      "0      32        30  13  \n",
      "1      33        30  19  \n",
      "2      34        30  13  \n",
      "3      34        30  13  \n",
      "4      35        30  13  \n",
      "0      23        20  18  \n",
      "1      23        20  13  \n",
      "2      25        20  13  \n",
      "3      26        20  17  \n",
      "4      26        20  30  \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def cum_count(df, cols, train_len):\n",
    "    col_name = 'cumcount_' + '_'.join(cols)\n",
    "    result = df[cols].groupby(cols).cumcount().rename(col_name).to_frame()\n",
    "    result[:train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    result[train_len:].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del result\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['ip','app','device','os','day','hour'],\n",
    "    ['ip','day'],\n",
    "    ['app','device','os','day']\n",
    "]\n",
    "\n",
    "df.sort_values(['click_time','index','is_test'], inplace=True)\n",
    "cum_count(df, ['app', 'channel'], train_len)\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cumcount_app_channel\n",
      "0                     0\n",
      "1                     1\n",
      "2                     2\n",
      "3                     0\n",
      "4                     3\n"
     ]
    }
   ],
   "source": [
    "xxx = pd.read_csv(fdir + 'train_cumcount_app_channel.csv')\n",
    "print(xxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cols1 count / cols2 count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count_ratio_app_machine\n",
      "0                 1.333333\n",
      "1                 8.000000\n",
      "2                 1.333333\n",
      "3                 0.166667\n",
      "4                 1.333333\n",
      "5                 8.000000\n",
      "6                 1.333333\n",
      "7                 1.333333\n",
      "8                 8.000000\n",
      "9                 1.000000\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def _count(df, cols, label):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    result = _df[[col_name]].copy()\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    return result\n",
    "\n",
    "def count_ratio(df, cols1, cols2, label, train_len):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols1) + '_' + '_'.join(cols2)\n",
    "    x1 = _count(df, cols1, label)\n",
    "    x2 = _count(df, cols2, label)\n",
    "    x1[col_name] = x1[x1.columns.values[0]] / x2[x2.columns.values[0]] # or = round(x1 / x2, 4)\n",
    "    result = x1[[col_name]]\n",
    "    result[:train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    result[train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del x1, x2\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    {'cols1':['ip'], 'cols2':['machine']},\n",
    "    {'cols1':['ip'], 'cols2':['channel']},\n",
    "    {'cols1':['machine'], 'cols2':['ip']},\n",
    "    {'cols1':['app'], 'cols2':['channel']},\n",
    "    {'cols1':['channel'], 'cols2':['app']}\n",
    "]\n",
    "\n",
    "count_ratio(df, ['app'], patterns[0]['cols2'], label, train_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cumulative count ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cols cumcount / (cols count-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cumcount_ratio_app_channel\n",
      "0                           0\n",
      "1                           1\n",
      "2                           2\n",
      "3                           0\n",
      "4                           3\n",
      "5                           4\n",
      "6                           5\n",
      "7                           6\n",
      "8                           7\n",
      "9                           0    count_ratio_app_channel\n",
      "0                        8\n",
      "1                        8\n",
      "2                        8\n",
      "3                        1\n",
      "4                        8\n",
      "5                        8\n",
      "6                        8\n",
      "7                        8\n",
      "8                        8\n",
      "9                        1\n",
      "   cumcount_ratio_app_channel\n",
      "0                      0.0000\n",
      "1                      0.1429\n",
      "2                      0.2857\n",
      "3                      1.1000\n",
      "4                      0.4286\n",
      "5                      0.5714\n",
      "6                      0.7143\n",
      "7                      0.8571\n",
      "8                      1.0000\n",
      "9                      1.1000\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def _count(df, cols, label):\n",
    "    col_name = 'count_ratio_' + '_'.join(cols)\n",
    "    d_cols = list(cols)\n",
    "    d_cols.append(label)\n",
    "    count_result = df[d_cols].groupby(by=cols)[[label]].count().rename(index=str, columns={label: col_name}).reset_index()\n",
    "    type_map = {i: data_type[i] for i in count_result.columns.values if i in data_type.keys()}\n",
    "    _df = df.merge(count_result.astype(type_map), on=cols, how='left')\n",
    "    result = _df[[col_name]].copy()\n",
    "    del _df, count_result\n",
    "    gc.collect()\n",
    "    return result\n",
    "\n",
    "def _cum_count(df, cols):\n",
    "    col_name = 'cumcount_ratio_' + '_'.join(cols)\n",
    "    result = df[cols].groupby(cols).cumcount().rename(col_name).to_frame()\n",
    "    return result.reset_index()[[col_name]]\n",
    "    \n",
    "def cum_count_ratio(df, cols, label, train_len):\n",
    "    col_name = 'cumcount_ratio_' + '_'.join(cols)\n",
    "    x1 = _cum_count(df, cols)\n",
    "    x2 = _count(df, cols, label)\n",
    "    print(x1, x2)\n",
    "    x1[col_name] = round(x1[x1.columns.values[0]] / (x2[x2.columns.values[0]] - 1), 4).fillna(1.1)\n",
    "    result = x1[[col_name]]\n",
    "    result[ : train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    result[train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    print(result)\n",
    "    del x1, x2\n",
    "    gc.collect()\n",
    "    \n",
    "patterns = [\n",
    "    ['ip','day']\n",
    "]\n",
    "\n",
    "cum_count_ratio(df, ['app','channel'], label, train_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to n next click and its filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0b3a1635e261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;34m'day'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'app'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'os'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m ]\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtime_to_n_next_click_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_to_n_next_click\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'click_timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0b3a1635e261>\u001b[0m in \u001b[0;36mtime_to_n_next_click\u001b[0;34m(df, n, cols, time_col, train_len)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcol_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'time_to_n_next_click_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtime_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m999999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtrain_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def time_to_n_next_click(df, n, cols, time_col, train_len):\n",
    "    col_name = 'time_to_n_next_click_' + str(n) + '_' + '_'.join(cols)\n",
    "    _df = df[cols].copy()\n",
    "    _df[col_name] = (_df.groupby(cols)[time_col].shift(-n) - _df[time_col] + 1).fillna(999999).astype(int)\n",
    "    out = _df[[col_name]].sort_index()\n",
    "    out[ : train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    out[train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del _df, out\n",
    "    gc.collect()\n",
    "    return col_name\n",
    "    \n",
    "def time_to_n_next_click_filter(name, train_len):\n",
    "    col_name = 'filter_' + name\n",
    "    in_func_train = pd.read_csv(fdir + 'train_' + name + '.csv')\n",
    "    in_func_test = pd.read_csv(fdir + 'test_supplement_' + name + '.csv')\n",
    "    in_func_df = pd.concat([in_func_train, in_func_test], ignore_index=True)\n",
    "    in_func_df[col_name] = 2\n",
    "    in_func_df[col_name] -= (in_func_df[col_name] < 1800) & (in_func_df[col_name] > 30)\n",
    "    in_func_df[col_name] -= (in_func_df[col_name] < 30) * 2\n",
    "    in_func_df[[col_name]][ : train_len].to_csv(fdir + 'train_' + col_name + '.csv', index=False)\n",
    "    in_func_df[[col_name]][train_len : ].to_csv(fdir + 'test_supplement_' + col_name + '.csv', index=False)\n",
    "    del in_func_df, in_func_train, in_func_test\n",
    "    gc.collect()\n",
    "    \n",
    "df.sort_values(['click_time','is_attributed','click_id'], inplace=True)\n",
    "# time_col = 'click_timestamp'\n",
    "patterns = [\n",
    "    ['day','ip','app','device','os']\n",
    "]\n",
    "time_to_n_next_click_filter(time_to_n_next_click(df, 1, patterns[0], 'click_timestamp', train_len), train_len)\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# range count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
