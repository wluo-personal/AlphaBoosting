{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T14:30:59.884750Z",
     "start_time": "2018-05-31T14:30:58.975745Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "\n",
    "class Feature:\n",
    "    \n",
    "    class Utils:\n",
    "        def _set_type(series, dtype):\n",
    "            _max, _min = max(series), min(series)\n",
    "            if dtype == 'uint':\n",
    "                if _max <= 255: return np.uint8\n",
    "                elif _max <= 65535: return np.uint16\n",
    "                elif _max <= 4294967295: return np.uint32\n",
    "                else: return np.uint64\n",
    "            elif dtype == 'int':\n",
    "                if _min >= -128 and _max <= 127: return np.int8\n",
    "                elif _min >=-32768 and _max <= 32767: return np.int16\n",
    "                elif _min >= -2147483648 and _max <= 2147483647: return np.int32\n",
    "                else: return np.int64\n",
    "            elif dtype == 'float':\n",
    "                if max(abs(_min), _max) <= 3.4028235e+38: return np.float32\n",
    "                else: return np.float64\n",
    "\n",
    "        def save(df=None, flg='both', train_len=0, url='./', name='default'):\n",
    "            if flg == 'train':\n",
    "                df.reset_index(drop=True).to_feather(url + 'train__' + name + '.ftr')\n",
    "            elif flg == 'test':\n",
    "                df.reset_index(drop=True).to_feather(url + 'test__' + name + '.ftr')\n",
    "            else:\n",
    "                df[:train_len].reset_index(drop=True).to_feather(url + 'train__' + name + '.ftr')\n",
    "                df[train_len:].reset_index(drop=True).to_feather(url + 'test__' + name + '.ftr')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # calc_col: additional col to help count\n",
    "    def count(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "        d_cols = list(group_cols)\n",
    "        d_cols.append(calc_col)\n",
    "        count_result = df[d_cols].groupby(by=group_cols)[[calc_col]].count().rename(index=str, columns={calc_col: col_name}).reset_index()\n",
    "        dtype[col_name] = Feature.Utils._set_type(count_result[col_name], 'uint')\n",
    "        _df = df.merge(count_result.astype(dtype), on=group_cols, how='left')\n",
    "        result = _df[[col_name]].copy()\n",
    "        del _df, count_result, d_cols, dtype\n",
    "        gc.collect()\n",
    "        return result\n",
    "    \n",
    "    def unique_count(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "        d_cols = list(group_cols)\n",
    "        d_cols.append(calc_col)\n",
    "        count_result = df[d_cols].groupby(by=group_cols)[[calc_col]].nunique().rename(index=str, columns={calc_col: col_name}).reset_index()\n",
    "        dtype[col_name] = Feature.Utils._set_type(count_result[col_name], 'uint')\n",
    "        _df = df.merge(count_result.astype(dtype), on=group_cols, how='left')\n",
    "        result = _df[[col_name]].copy()\n",
    "        del _df, count_result, d_cols, dtype\n",
    "        gc.collect()\n",
    "        return result\n",
    "    \n",
    "    def cummulative_count(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        result = df[group_cols].groupby(group_cols).cumcount().rename(col_name)\n",
    "        r = result.astype(Feature.Utils._set_type(result, 'uint'))\n",
    "        r = r.to_frame()\n",
    "        del result\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    def reverse_cummulative_count(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        result = df.sort_index(inplace=True, ascending=False).[group_cols].groupby(group_cols).cumcount().rename(col_name).sort_index(inplace=True)\n",
    "        r = result.astype(Feature.Utils._set_type(result, 'uint'))\n",
    "        r = r.to_frame()\n",
    "        del result\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    def variance(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        d_cols = list(group_cols)\n",
    "        d_cols.append(calc_col)\n",
    "        group = df[d_cols].groupby(by=group_cols)[[calc_col]].var().reset_index().rename(index=str, columns={calc_col: col_name}).fillna(0)\n",
    "        dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "        dtype[col_name] = Feature.Utils._set_type(group[col_name], 'float')\n",
    "        _df = df.merge(group.astype(dtype), on=group_cols, how='left')\n",
    "        r = _df[[col_name]].copy()\n",
    "        del d_cols, dtype, _df, group\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    # params['col']: additional col to help count\n",
    "    # params['coefficient']: \n",
    "    def count_std_over_mean(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        d_cols = list(group_cols)\n",
    "        d_cols.append(calc_col)\n",
    "        d_cols1 = list(d_cols)\n",
    "        d_cols1.append(params['col'])\n",
    "        group = df[d_cols1].groupby(by=d_cols)[[params['col']]].count().reset_index().rename(index=str, columns={params['col']: 'count'})\n",
    "        result = group.groupby(by=group_cols)[['count']].agg(['mean','std'])['count'].reset_index()\n",
    "        result[col_name] = ((params['coefficient'] * result['std']) / result['mean']).fillna(-1)\n",
    "        dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "        dtype[col_name] = Feature.Utils._set_type(result[col_name], 'float')\n",
    "        _df = df.merge(result.astype(dtype), on=group_cols, how='left')\n",
    "        r = _df[[col_name]].copy()\n",
    "        del d_cols, d_cols1, group, result, _df\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # params['n']: n, params['fillna']: fillna\n",
    "    def time_to_n_next(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        n = params['n']\n",
    "        m = params['fillna']\n",
    "        d_cols = list(group_cols)\n",
    "        d_cols.append(calc_col)\n",
    "        result = (df[d_cols].groupby(by=group_cols)[calc_col].shift(-n) - df[calc_col]).fillna(m)\n",
    "        result = result.astype(Feature.Utils._set_type(result, 'uint')).to_frame()\n",
    "        del n, m, d_cols\n",
    "        gc.collect()\n",
    "        return result\n",
    "    \n",
    "    # params['n']: n\n",
    "    def count_in_previous_n_time_unit(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        n = params['n']\n",
    "        encodings = df[group_cols[0]].copy()\n",
    "        if len(group_cols) > 1:\n",
    "            for c in group_cols[1 : ]:\n",
    "                encodings = encodings * (10 ** (int(np.log(df[c].max() + 1) / np.log(10)) + 1)) + df[c]\n",
    "        encodings = encodings.values\n",
    "        times = df[calc_col].values\n",
    "        dict_count = defaultdict(int)\n",
    "        result = []\n",
    "        bound = 0\n",
    "        for cur in range(len(encodings)):\n",
    "            while times[cur] - times[bound] > n:\n",
    "                dict_count[encodings[bound]] -= 1\n",
    "                bound += 1\n",
    "            result.append(dict_count[encodings[cur]])\n",
    "            dict_count[encodings[cur]] += 1\n",
    "        r = pd.DataFrame(result, columns=[col_name], dtype=Feature.Utils._set_type(result, 'uint'))\n",
    "        del encodings, times, dict_count, result, bound, n\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    def count_in_next_n_time_unit(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "        r = Feature.click_count_in_previous_n_time_unit(df.sort_index(ascending=False), group_cols, calc_col, col_name, params)\n",
    "        r = r.reindex(index=r.index[::-1]).reset_index(drop=True)\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    \n",
    "    \n",
    "    class Encoding:\n",
    "        def woe(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "            Feature.Encoding._wrapper(df, group_cols, calc_col, col_name,\\\n",
    "                                      {'train_len': params['train_len'], 'function': Feature.Encoding._woe})\n",
    "            \n",
    "        def chi_square(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "            Feature.Encoding._wrapper(df, group_cols, calc_col, col_name,\\\n",
    "                                      {'train_len': params['train_len'], 'function': Feature.Encoding._chi_square})\n",
    "        \n",
    "        def mean(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "            Feature.Encoding._wrapper(df, group_cols, calc_col, col_name,\\\n",
    "                                      {'train_len': params['train_len'], 'function': Feature.Encoding._mean})\n",
    "        \n",
    "        def _wrapper(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "            train = df[ : params['train_len']]\n",
    "            test = df[params['train_len']:]\n",
    "            return pd.concat([Feature.Encoding._train_wrapper(df[:params['train_len']],\\\n",
    "                                                              group_cols, calc_col,\\\n",
    "                                                              col_name, params['function'],\\\n",
    "                                                              params['split_col']),\\\n",
    "                              Feature.Encoding._test_wrapper(df[:params['train_len']],\\\n",
    "                                                             df[params['train_len']:],\\\n",
    "                                                             group_cols, label,\\\n",
    "                                                             col_name, params['function'])],\\\n",
    "                             ignore_index=True)\n",
    "        \n",
    "        def _train_wrapper(df, group_cols, label, col_name, func, split_col):\n",
    "            r_list = []\n",
    "            for i in range(df[split_col].min(), df[split_col].max() + 1):\n",
    "                dictionary = func(df=df[df[split_col]==i], group_cols=group_cols, calc_col=label, col_name=col_name)\n",
    "                r_list.append(df[df[split_col]==i].merge(dictionary, on=group_cols, how='left')[[col_name]])\n",
    "            r = pd.concat(r_list).fillna(-1).reset_index(drop=True)\n",
    "            del r_list, dictionary\n",
    "            gc.collect()\n",
    "            return r\n",
    "        \n",
    "        def _testset_wrapper(train, test, group_cols, label, col_name, func):\n",
    "            dictionary = func(df=train, group_cols=group_cols, calc_col=label, col_name=col_name)\n",
    "            _df[col_name] = test.merge(dictionary, on=group_cols, how='left')\n",
    "            r = _df[[col_name]].copy().fillna(-1)\n",
    "            del _df, dictionary\n",
    "            gc.collect()\n",
    "            return r\n",
    "        \n",
    "        # label = calc_col\n",
    "        def _woe(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "            d_cols = list(group_cols)\n",
    "            d_cols.append(calc_col)\n",
    "            group = df[d_cols].groupby(by=group_cols)[[calc_col]].agg(['count','sum'])[calc_col].reset_index()\n",
    "            positive = df[calc_col].sum()\n",
    "            negative = df.shape[0] - positive\n",
    "            group[col_name] = np.log((group['sum']+0.5) / positive) / ((group['count']-group['sum']+0.5) / negative)\n",
    "            dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "            dtype[col_name] = Feature.Utils._set_type(group[col_name], 'float')\n",
    "            r = group[[col_name]].astype(dtype)\n",
    "            del d_cols, group, positive, negative, dtype\n",
    "            gc.collect()\n",
    "            return r\n",
    "        \n",
    "        # label = calc_col\n",
    "        def _chi_square(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "            total_count = df.shape[0]\n",
    "            total_sum = df[calc_col].sum()\n",
    "            group = df.groupby(by=group_cols)[[calc_col]].agg(['count','sum'])[calc_col].reset_index().rename(index=str, columns={'sum': 'n11'})\n",
    "            group['n12'] = group['count'] - group['n11']\n",
    "            group['n21'] = total_sum - group['n11']\n",
    "            group['n22'] = total_count - group['n11'] - group['n12'] - group['n21']\n",
    "            group['e11'] = (group['n11'] + group['n12']) * (group['n11'] + group['n21']) / total_count\n",
    "            group['e12'] = (group['n11'] + group['n12']) * (group['n12'] + group['n22']) / total_count\n",
    "            group['e21'] = (group['n21'] + group['n22']) * (group['n11'] + group['n21']) / total_count\n",
    "            group['e22'] = (group['n21'] + group['n22']) * (group['n12'] + group['n22']) / total_count\n",
    "            group[col_name] = (group['n11'] - group['e11']) ** 2 / group['e11'] + \\\n",
    "                                  (group['n12'] - group['e12']) ** 2 / group['e12'] + \\\n",
    "                                  (group['n21'] - group['e21']) ** 2 / group['e21'] + \\\n",
    "                                  (group['n22'] - group['e22']) ** 2 / group['e22']\n",
    "            total_cols = list(group_cols)\n",
    "            total_cols.append(col_name)\n",
    "            dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "            dtype[col_name] = Feature.Utils._set_type(group[col_name], 'float')\n",
    "            r = group[[total_cols]].copy().astype(dtype)\n",
    "            del total_count, total_sum, group, total_cols\n",
    "            gc.collect()\n",
    "            return r\n",
    "        \n",
    "        def _mean(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "            r = df.groupby(by=group_cols)[[calc_col]].mean().reset_index().rename(index=str, columns={calc_col:col_name})\n",
    "            r = r.astype(Feature.Utils._set_type(r, 'float')).to_frame()\n",
    "            gc.collect()\n",
    "            return r\n",
    "            \n",
    "        \n",
    "        \n",
    "    class Kernels:\n",
    "        def square(df=None, group_cols=None, calc_col=None, col_name=None, params=None):\n",
    "            r = df[[calc_col]].apply(lambda x: x ** 2)\n",
    "            r = r.astype(Feature.Utils._set_type(r, 'float'))\n",
    "            gc.collect()\n",
    "            return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T14:35:07.894304Z",
     "start_time": "2018-05-31T14:35:07.823212Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ip' 'app' 'device' 'os' 'channel' 'click_time' 'attributed_time'\n",
      " 'is_attributed' 'second']\n",
      "[0.0016697274, 0.0033400115, 0.0050108526, 0.0066822511, 0.0083542075, 0.010026721, 0.011699793, 0.013373424, 0.015047614, 0.016722361, 0.018397668, 0.020073537, 0.021749962, 0.02342695, 0.025104497, 0.026782606, 0.028461274, 0.030140504, 0.031820297, 0.033500649, 0.035181567, 0.036863044, 0.038545083, 0.040227689, 0.041910857, 0.043594588, 0.045278881, 0.04696374, 0.048649162, 0.050335146, 0.055396501, 0.05708475, 0.058773562, 0.063843407, 0.065534487, 0.067226134, 0.070611142, 0.072304495, 0.079083592, 0.084173903, 0.089269347, 0.092669167, 0.097773187, 0.10288236, 0.11311622, 0.11824092, 0.11995029, 0.1233708, 0.12508191, 0.12850587, 0.13021871, 0.13536073, 0.14737907, 0.16804826, 0.16977449, 0.2148627, 0.21834756, 0.22009088, 0.2288164, 0.27266812, 0.30447447, 0.30624726, 0.3115693, 0.32756832, 0.34183136, 0.58672237, 0.74622941, 2.6732893, 41.044495, 298.60037, 599.09985, 797.73273, 1797.8989]\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "\n",
    "x = pd.read_csv(PATH + 'train.csv', nrows=6000)\n",
    "\n",
    "x['click_time'] = (pd.to_datetime(x['click_time']).astype(np.int64) // 10 ** 9).astype(np.int32)\n",
    "\n",
    "x['second'] = pd.to_datetime(x['click_time']).dt.second.astype('int8')\n",
    "print(x.columns.values)\n",
    "y = Feature.Encoding._chi_square(x, ['app', 'channel'], 'is_attributed', 'a', [2])\n",
    "\n",
    "# print(y.dtypes,type(y))\n",
    "print(sorted(list(set(y['a']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-30T20:09:20.506188Z",
     "start_time": "2018-05-30T20:09:20.494895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ip  app  device  os  channel  click_time attributed_time  \\\n",
      "999  27849    6       1  13      459  1509984001             NaN   \n",
      "998  77065    6       1  10      459  1509984001             NaN   \n",
      "997  47456    3       1  13      137  1509984001             NaN   \n",
      "\n",
      "     is_attributed  second  \n",
      "999              0       1  \n",
      "998              0       1  \n",
      "997              0       1  \n",
      "        ip  app  device  os  channel  click_time attributed_time  \\\n",
      "997  47456    3       1  13      137  1509984001             NaN   \n",
      "998  77065    6       1  10      459  1509984001             NaN   \n",
      "999  27849    6       1  13      459  1509984001             NaN   \n",
      "\n",
      "     is_attributed  second  \n",
      "997              0       1  \n",
      "998              0       1  \n",
      "999              0       1  \n"
     ]
    }
   ],
   "source": [
    "y = x.reindex(index=x.index[::-1])\n",
    "print(y.head(3))\n",
    "print(x.tail(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T14:27:53.624125Z",
     "start_time": "2018-05-31T14:27:53.604908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a  b  c\n",
      "0  1  2  3\n",
      "1  3  4  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.DataFrame([[1,2,3],[3,4,5]], columns=['a','b','c'])\n",
    "y = x.drop('a', axis=1)\n",
    "\n",
    "\n",
    "print(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# group = x.groupby(by=['a','b'])[['c']].agg(['count'])['c'].reset_index().rename(index=str, columns={'count': 'n11'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
