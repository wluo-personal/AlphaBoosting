{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T21:25:08.384950Z",
     "start_time": "2018-06-18T21:25:04.800225Z"
    }
   },
   "source": [
    "##### import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'application_train.csv')\n",
    "test = pd.read_csv(PATH + 'application_test.csv')\n",
    "'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T14:03:30.338187Z",
     "start_time": "2018-06-18T14:03:30.302191Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SK_ID_CURR', \n",
      "'TARGET', \n",
      "'NAME_CONTRACT_TYPE', \n",
      "'CODE_GENDER', \n",
      "'FLAG_OWN_CAR', \n",
      "'FLAG_OWN_REALTY', \n",
      "'CNT_CHILDREN', \n",
      "'AMT_INCOME_TOTAL', \n",
      "'AMT_CREDIT', \n",
      "'AMT_ANNUITY', \n",
      "'AMT_GOODS_PRICE', \n",
      "'NAME_TYPE_SUITE', \n",
      "'NAME_INCOME_TYPE', \n",
      "'NAME_EDUCATION_TYPE', \n",
      "'NAME_FAMILY_STATUS', \n",
      "'NAME_HOUSING_TYPE', \n",
      "'REGION_POPULATION_RELATIVE', \n",
      "'DAYS_BIRTH', \n",
      "'DAYS_EMPLOYED', \n",
      "'DAYS_REGISTRATION', \n",
      "'DAYS_ID_PUBLISH', \n",
      "'OWN_CAR_AGE', \n",
      "'FLAG_MOBIL', \n",
      "'FLAG_EMP_PHONE', \n",
      "'FLAG_WORK_PHONE', \n",
      "'FLAG_CONT_MOBILE', \n",
      "'FLAG_PHONE', \n",
      "'FLAG_EMAIL', \n",
      "'OCCUPATION_TYPE', \n",
      "'CNT_FAM_MEMBERS', \n",
      "'REGION_RATING_CLIENT', \n",
      "'REGION_RATING_CLIENT_W_CITY', \n",
      "'WEEKDAY_APPR_PROCESS_START', \n",
      "'HOUR_APPR_PROCESS_START', \n",
      "'REG_REGION_NOT_LIVE_REGION', \n",
      "'REG_REGION_NOT_WORK_REGION', \n",
      "'LIVE_REGION_NOT_WORK_REGION', \n",
      "'REG_CITY_NOT_LIVE_CITY', \n",
      "'REG_CITY_NOT_WORK_CITY', \n",
      "'LIVE_CITY_NOT_WORK_CITY', \n",
      "'ORGANIZATION_TYPE', \n",
      "'EXT_SOURCE_1', \n",
      "'EXT_SOURCE_2', \n",
      "'EXT_SOURCE_3', \n",
      "'APARTMENTS_AVG', \n",
      "'BASEMENTAREA_AVG', \n",
      "'YEARS_BEGINEXPLUATATION_AVG', \n",
      "'YEARS_BUILD_AVG', \n",
      "'COMMONAREA_AVG', \n",
      "'ELEVATORS_AVG', \n",
      "'ENTRANCES_AVG', \n",
      "'FLOORSMAX_AVG', \n",
      "'FLOORSMIN_AVG', \n",
      "'LANDAREA_AVG', \n",
      "'LIVINGAPARTMENTS_AVG', \n",
      "'LIVINGAREA_AVG', \n",
      "'NONLIVINGAPARTMENTS_AVG', \n",
      "'NONLIVINGAREA_AVG', \n",
      "'APARTMENTS_MODE', \n",
      "'BASEMENTAREA_MODE', \n",
      "'YEARS_BEGINEXPLUATATION_MODE', \n",
      "'YEARS_BUILD_MODE', \n",
      "'COMMONAREA_MODE', \n",
      "'ELEVATORS_MODE', \n",
      "'ENTRANCES_MODE', \n",
      "'FLOORSMAX_MODE', \n",
      "'FLOORSMIN_MODE', \n",
      "'LANDAREA_MODE', \n",
      "'LIVINGAPARTMENTS_MODE', \n",
      "'LIVINGAREA_MODE', \n",
      "'NONLIVINGAPARTMENTS_MODE', \n",
      "'NONLIVINGAREA_MODE', \n",
      "'APARTMENTS_MEDI', \n",
      "'BASEMENTAREA_MEDI', \n",
      "'YEARS_BEGINEXPLUATATION_MEDI', \n",
      "'YEARS_BUILD_MEDI', \n",
      "'COMMONAREA_MEDI', \n",
      "'ELEVATORS_MEDI', \n",
      "'ENTRANCES_MEDI', \n",
      "'FLOORSMAX_MEDI', \n",
      "'FLOORSMIN_MEDI', \n",
      "'LANDAREA_MEDI', \n",
      "'LIVINGAPARTMENTS_MEDI', \n",
      "'LIVINGAREA_MEDI', \n",
      "'NONLIVINGAPARTMENTS_MEDI', \n",
      "'NONLIVINGAREA_MEDI', \n",
      "'FONDKAPREMONT_MODE', \n",
      "'HOUSETYPE_MODE', \n",
      "'TOTALAREA_MODE', \n",
      "'WALLSMATERIAL_MODE', \n",
      "'EMERGENCYSTATE_MODE', \n",
      "'OBS_30_CNT_SOCIAL_CIRCLE', \n",
      "'DEF_30_CNT_SOCIAL_CIRCLE', \n",
      "'OBS_60_CNT_SOCIAL_CIRCLE', \n",
      "'DEF_60_CNT_SOCIAL_CIRCLE', \n",
      "'DAYS_LAST_PHONE_CHANGE', \n",
      "'FLAG_DOCUMENT_2', \n",
      "'FLAG_DOCUMENT_3', \n",
      "'FLAG_DOCUMENT_4', \n",
      "'FLAG_DOCUMENT_5', \n",
      "'FLAG_DOCUMENT_6', \n",
      "'FLAG_DOCUMENT_7', \n",
      "'FLAG_DOCUMENT_8', \n",
      "'FLAG_DOCUMENT_9', \n",
      "'FLAG_DOCUMENT_10', \n",
      "'FLAG_DOCUMENT_11', \n",
      "'FLAG_DOCUMENT_12', \n",
      "'FLAG_DOCUMENT_13', \n",
      "'FLAG_DOCUMENT_14', \n",
      "'FLAG_DOCUMENT_15', \n",
      "'FLAG_DOCUMENT_16', \n",
      "'FLAG_DOCUMENT_17', \n",
      "'FLAG_DOCUMENT_18', \n",
      "'FLAG_DOCUMENT_19', \n",
      "'FLAG_DOCUMENT_20', \n",
      "'FLAG_DOCUMENT_21', \n",
      "'AMT_REQ_CREDIT_BUREAU_HOUR', \n",
      "'AMT_REQ_CREDIT_BUREAU_DAY', \n",
      "'AMT_REQ_CREDIT_BUREAU_WEEK', \n",
      "'AMT_REQ_CREDIT_BUREAU_MON', \n",
      "'AMT_REQ_CREDIT_BUREAU_QRT', \n",
      "'AMT_REQ_CREDIT_BUREAU_YEAR', \n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(train.columns):\n",
    "    print('\\'' + x + '\\', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T14:05:46.024622Z",
     "start_time": "2018-06-18T14:05:46.000323Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "house_info = [\n",
    "    'APARTMENTS_AVG', \n",
    "    'BASEMENTAREA_AVG', \n",
    "    'YEARS_BEGINEXPLUATATION_AVG', \n",
    "    'YEARS_BUILD_AVG', \n",
    "    'COMMONAREA_AVG', \n",
    "    'ELEVATORS_AVG', \n",
    "    'ENTRANCES_AVG', \n",
    "    'FLOORSMAX_AVG', \n",
    "    'FLOORSMIN_AVG', \n",
    "    'LANDAREA_AVG', \n",
    "    'LIVINGAPARTMENTS_AVG', \n",
    "    'LIVINGAREA_AVG', \n",
    "    'NONLIVINGAPARTMENTS_AVG', \n",
    "    'NONLIVINGAREA_AVG', \n",
    "    'APARTMENTS_MODE', \n",
    "    'BASEMENTAREA_MODE', \n",
    "    'YEARS_BEGINEXPLUATATION_MODE', \n",
    "    'YEARS_BUILD_MODE', \n",
    "    'COMMONAREA_MODE', \n",
    "    'ELEVATORS_MODE', \n",
    "    'ENTRANCES_MODE', \n",
    "    'FLOORSMAX_MODE', \n",
    "    'FLOORSMIN_MODE', \n",
    "    'LANDAREA_MODE', \n",
    "    'LIVINGAPARTMENTS_MODE', \n",
    "    'LIVINGAREA_MODE', \n",
    "    'NONLIVINGAPARTMENTS_MODE', \n",
    "    'NONLIVINGAREA_MODE', \n",
    "    'APARTMENTS_MEDI', \n",
    "    'BASEMENTAREA_MEDI', \n",
    "    'YEARS_BEGINEXPLUATATION_MEDI', \n",
    "    'YEARS_BUILD_MEDI', \n",
    "    'COMMONAREA_MEDI', \n",
    "    'ELEVATORS_MEDI', \n",
    "    'ENTRANCES_MEDI', \n",
    "    'FLOORSMAX_MEDI', \n",
    "    'FLOORSMIN_MEDI', \n",
    "    'LANDAREA_MEDI', \n",
    "    'LIVINGAPARTMENTS_MEDI', \n",
    "    'LIVINGAREA_MEDI', \n",
    "    'NONLIVINGAPARTMENTS_MEDI', \n",
    "    'NONLIVINGAREA_MEDI', \n",
    "    'FONDKAPREMONT_MODE', \n",
    "    'HOUSETYPE_MODE', \n",
    "    'TOTALAREA_MODE', \n",
    "    'WALLSMATERIAL_MODE', \n",
    "    'EMERGENCYSTATE_MODE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T14:05:46.246780Z",
     "start_time": "2018-06-18T14:05:46.242588Z"
    },
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flag_doc = [\n",
    "    'FLAG_DOCUMENT_2', \n",
    "    'FLAG_DOCUMENT_3', \n",
    "    'FLAG_DOCUMENT_4', \n",
    "    'FLAG_DOCUMENT_5', \n",
    "    'FLAG_DOCUMENT_6', \n",
    "    'FLAG_DOCUMENT_7', \n",
    "    'FLAG_DOCUMENT_8', \n",
    "    'FLAG_DOCUMENT_9', \n",
    "    'FLAG_DOCUMENT_10', \n",
    "    'FLAG_DOCUMENT_11', \n",
    "    'FLAG_DOCUMENT_12', \n",
    "    'FLAG_DOCUMENT_13', \n",
    "    'FLAG_DOCUMENT_14', \n",
    "    'FLAG_DOCUMENT_15', \n",
    "    'FLAG_DOCUMENT_16', \n",
    "    'FLAG_DOCUMENT_17', \n",
    "    'FLAG_DOCUMENT_18', \n",
    "    'FLAG_DOCUMENT_19', \n",
    "    'FLAG_DOCUMENT_20', \n",
    "    'FLAG_DOCUMENT_21'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phone = [\n",
    "    'FLAG_MOBIL', \n",
    "    'FLAG_EMP_PHONE', \n",
    "    'FLAG_WORK_PHONE', \n",
    "    'FLAG_CONT_MOBILE', \n",
    "    'FLAG_PHONE', \n",
    "    'FLAG_EMAIL'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T14:06:56.494791Z",
     "start_time": "2018-06-18T14:06:56.471292Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SK_ID_CURR', \n",
      "'TARGET', \n",
      "'NAME_CONTRACT_TYPE', \n",
      "'CODE_GENDER', \n",
      "'FLAG_OWN_CAR', \n",
      "'FLAG_OWN_REALTY', \n",
      "'CNT_CHILDREN', \n",
      "'AMT_INCOME_TOTAL', \n",
      "'AMT_CREDIT', \n",
      "'AMT_ANNUITY', \n",
      "'AMT_GOODS_PRICE', \n",
      "'NAME_TYPE_SUITE', \n",
      "'NAME_INCOME_TYPE', \n",
      "'NAME_EDUCATION_TYPE', \n",
      "'NAME_FAMILY_STATUS', \n",
      "'NAME_HOUSING_TYPE', \n",
      "'REGION_POPULATION_RELATIVE', \n",
      "'DAYS_BIRTH', \n",
      "'DAYS_EMPLOYED', \n",
      "'DAYS_REGISTRATION', \n",
      "'DAYS_ID_PUBLISH', \n",
      "'OWN_CAR_AGE', \n",
      "'FLAG_MOBIL', \n",
      "'FLAG_EMP_PHONE', \n",
      "'FLAG_WORK_PHONE', \n",
      "'FLAG_CONT_MOBILE', \n",
      "'FLAG_PHONE', \n",
      "'FLAG_EMAIL', \n",
      "'OCCUPATION_TYPE', \n",
      "'CNT_FAM_MEMBERS', \n",
      "'REGION_RATING_CLIENT', \n",
      "'REGION_RATING_CLIENT_W_CITY', \n",
      "'WEEKDAY_APPR_PROCESS_START', \n",
      "'HOUR_APPR_PROCESS_START', \n",
      "'REG_REGION_NOT_LIVE_REGION', \n",
      "'REG_REGION_NOT_WORK_REGION', \n",
      "'LIVE_REGION_NOT_WORK_REGION', \n",
      "'REG_CITY_NOT_LIVE_CITY', \n",
      "'REG_CITY_NOT_WORK_CITY', \n",
      "'LIVE_CITY_NOT_WORK_CITY', \n",
      "'ORGANIZATION_TYPE', \n",
      "'EXT_SOURCE_1', \n",
      "'EXT_SOURCE_2', \n",
      "'EXT_SOURCE_3', \n",
      "'OBS_30_CNT_SOCIAL_CIRCLE', \n",
      "'DEF_30_CNT_SOCIAL_CIRCLE', \n",
      "'OBS_60_CNT_SOCIAL_CIRCLE', \n",
      "'DEF_60_CNT_SOCIAL_CIRCLE', \n",
      "'DAYS_LAST_PHONE_CHANGE', \n",
      "'AMT_REQ_CREDIT_BUREAU_HOUR', \n",
      "'AMT_REQ_CREDIT_BUREAU_DAY', \n",
      "'AMT_REQ_CREDIT_BUREAU_WEEK', \n",
      "'AMT_REQ_CREDIT_BUREAU_MON', \n",
      "'AMT_REQ_CREDIT_BUREAU_QRT', \n",
      "'AMT_REQ_CREDIT_BUREAU_YEAR', \n"
     ]
    }
   ],
   "source": [
    "tl = house_info + flag_doc\n",
    "for x in train.columns:\n",
    "    if x not in tl:\n",
    "        print('\\'' + x + '\\', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T14:37:06.328575Z",
     "start_time": "2018-06-18T14:37:06.322880Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = [_f for _f in train.columns if 'FLAG_DOC' in _f]\n",
    "live = [_f for _f in train.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T14:37:12.882720Z",
     "start_time": "2018-06-18T14:37:12.877009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FLAG_OWN_CAR',\n",
       " 'FLAG_OWN_REALTY',\n",
       " 'FLAG_MOBIL',\n",
       " 'FLAG_EMP_PHONE',\n",
       " 'FLAG_WORK_PHONE',\n",
       " 'FLAG_CONT_MOBILE',\n",
       " 'FLAG_PHONE',\n",
       " 'FLAG_EMAIL']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T21:25:11.354462Z",
     "start_time": "2018-06-18T21:25:11.333807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'OWN_CAR_AGE', 'DAYS_LAST_PHONE_CHANGE']\n",
      "['CNT_CHILDREN', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'CNT_FAM_MEMBERS', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR', 'OWN_CAR_AGE', 'DAYS_LAST_PHONE_CHANGE']\n"
     ]
    }
   ],
   "source": [
    "can_be_numerator = [x for x in train.columns if 'AMT' in x] + ['OWN_CAR_AGE', 'DAYS_LAST_PHONE_CHANGE']\n",
    "can_be_denominator = [x for x in train.columns if 'CNT' in x or 'DAYS' in x] + can_be_numerator\n",
    "print(can_be_numerator)\n",
    "print(can_be_denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T21:25:13.102009Z",
     "start_time": "2018-06-18T21:25:11.675000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ratio_name(numerator, denominator): return numerator + '_divide_' + denominator\n",
    "\n",
    "def ratio(df, numerator, denominator):\n",
    "    return df[numerator] / df[denominator]\n",
    "\n",
    "r = pd.DataFrame()\n",
    "rt = pd.DataFrame()\n",
    "for x in can_be_numerator:\n",
    "    for y in can_be_denominator:\n",
    "        r[ratio_name(x, y)] = ratio(train, x, y)\n",
    "        rt[ratio_name(x, y)] = ratio(test, x, y)\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T21:25:15.825027Z",
     "start_time": "2018-06-18T21:25:14.748812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122)\n"
     ]
    }
   ],
   "source": [
    "r.to_pickle(PATH + 'train_ratio.pkl')\n",
    "rt.to_pickle(PATH + 'test_ratio.pkl')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finish calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T15:05:49.586900Z",
     "start_time": "2018-06-18T15:05:40.000573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "train.to_csv(PATH + 'train_test.csv', index=False)\n",
    "print('train')\n",
    "test.to_csv(PATH + 'test_test.csv', index=False)\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T15:51:01.031966Z",
     "start_time": "2018-06-18T15:51:01.026176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 386)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:08:47.068011Z",
     "start_time": "2018-06-18T16:08:46.847573Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "n = 10\n",
    "idx = [i % n for i in range(train.shape[0])]\n",
    "shuffle(idx)\n",
    "train['tmp_idx'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:08:47.442952Z",
     "start_time": "2018-06-18T16:08:47.439689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 387)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:08:50.280877Z",
     "start_time": "2018-06-18T16:08:48.387221Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "\n",
    "class Feature:\n",
    "    \n",
    "    class Utils:\n",
    "        def _set_type(series, dtype):\n",
    "            _max, _min = max(series), min(series)\n",
    "            if dtype == 'uint':\n",
    "                if _max <= 255: return np.uint8\n",
    "                elif _max <= 65535: return np.uint16\n",
    "                elif _max <= 4294967295: return np.uint32\n",
    "                else: return np.uint64\n",
    "            elif dtype == 'int':\n",
    "                if _min >= -128 and _max <= 127: return np.int8\n",
    "                elif _min >=-32768 and _max <= 32767: return np.int16\n",
    "                elif _min >= -2147483648 and _max <= 2147483647: return np.int32\n",
    "                else: return np.int64\n",
    "            elif dtype == 'float':\n",
    "                if max(abs(_min), _max) <= 3.4028235e+38: return np.float32\n",
    "                else: return np.float64\n",
    "\n",
    "        def save(df=None, flg='both', train_len=0, url='./', name='default'):\n",
    "            if flg == 'train':\n",
    "                df.reset_index(drop=True).to_feather(url + 'train__' + name + '.ftr')\n",
    "            elif flg == 'test':\n",
    "                df.reset_index(drop=True).to_feather(url + 'test__' + name + '.ftr')\n",
    "            else:\n",
    "                df[:train_len].reset_index(drop=True).to_feather(url + 'train__' + name + '.ftr')\n",
    "                df[train_len:].reset_index(drop=True).to_feather(url + 'test__' + name + '.ftr')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # params['col']\n",
    "    def count(df=None, cols=None, col_name=None, params=None):\n",
    "        r_col = params['col']\n",
    "        dtype = {x: df[x].dtype for x in cols if x in df.columns.values}\n",
    "        d_cols = list(cols)\n",
    "        d_cols.append(r_col)\n",
    "        result = df[d_cols].groupby(by=cols)[[r_col]].count().rename(index=str, columns={r_col: col_name}).reset_index()\n",
    "        dtype[col_name] = Feature.Utils._set_type(result[col_name], 'uint')\n",
    "        _df = df.merge(result.astype(dtype), on=cols, how='left')\n",
    "        r = _df[[col_name]].copy()\n",
    "        del _df, result, d_cols, dtype\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    # params['col']\n",
    "    def unique_count(df=None, cols=None, col_name=None, params=None):\n",
    "        r_col = params['col']\n",
    "        dtype = {x: df[x].dtype for x in cols if x in df.columns.values}\n",
    "        d_cols = list(cols)\n",
    "        d_cols.append(r_col)\n",
    "        result = df[d_cols].groupby(by=cols)[[r_col]].nunique().rename(index=str, columns={r_col: col_name}).reset_index()\n",
    "        dtype[col_name] = Feature.Utils._set_type(result[col_name], 'uint')\n",
    "        _df = df.merge(result.astype(dtype), on=cols, how='left')\n",
    "        r = _df[[col_name]].copy()\n",
    "        del _df, result, d_cols, dtype\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    def cummulative_count(df=None, cols=None, col_name=None, params=None):\n",
    "        result = df[cols].groupby(by=cols).cumcount().rename(col_name)\n",
    "        r = result.astype(Feature.Utils._set_type(result, 'uint'))\n",
    "        r = r.to_frame()\n",
    "        del result\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    def reverse_cummulative_count(df=None, cols=None, col_name=None, params=None):\n",
    "        result = df.sort_index(ascending=False)[cols].groupby(cols).cumcount().rename(col_name)\n",
    "        r = result.astype(Feature.Utils._set_type(result, 'uint')).to_frame()\n",
    "        r.sort_index(inplace=True)\n",
    "        del result\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    def variance(df=None, cols=None, col_name=None, params=None):\n",
    "        group_cols = cols[:-1]\n",
    "        calc_col = cols[-1]\n",
    "        group = df[cols].groupby(by=group_cols)[[calc_col]].var().reset_index().rename(index=str, columns={calc_col: col_name}).fillna(0)\n",
    "        dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "        dtype[col_name] = Feature.Utils._set_type(group[col_name], 'float')\n",
    "        _df = df.merge(group.astype(dtype), on=group_cols, how='left')\n",
    "        r = _df[[col_name]].copy()\n",
    "        del dtype, _df, group\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    # params['col']: additional col to help count\n",
    "    # params['coefficient']: \n",
    "    def count_std_over_mean(df=None, cols=None, col_name=None, params=None):\n",
    "        group_cols = cols[:-1]\n",
    "        calc_col = cols[-1]\n",
    "        d_cols = list(cols)\n",
    "        d_cols.append(params['col'])\n",
    "        group = df[d_cols].groupby(by=cols)[[params['col']]].count().reset_index().rename(index=str, columns={params['col']: 'count'})\n",
    "        result = group.groupby(by=group_cols)[['count']].agg(['mean','std'])['count'].reset_index()\n",
    "        result[col_name] = ((int(params['coefficient']) * result['std']) / result['mean']).fillna(-1)\n",
    "        dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "        dtype[col_name] = Feature.Utils._set_type(result[col_name], 'float')\n",
    "        _df = df.merge(result.astype(dtype), on=group_cols, how='left')\n",
    "        r = _df[[col_name]].copy()\n",
    "        del d_cols, group, result, _df\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # params['n']: n, params['fillna']: fillna, cols[-1]: time\n",
    "    def time_to_n_next(df=None, cols=None, col_name=None, params=None):\n",
    "        group_cols = cols[:-1]\n",
    "        calc_col = cols[-1]\n",
    "        n = int(params['n'])\n",
    "        m = int(params['fillna'])\n",
    "        result = (df[cols].groupby(by=group_cols)[calc_col].shift(-n) - df[calc_col]).fillna(m)\n",
    "        result = result.astype(Feature.Utils._set_type(result, 'uint')).to_frame()\n",
    "        del n, m\n",
    "        gc.collect()\n",
    "        return result\n",
    "    \n",
    "    # params['n']: n, cols[-1]: time\n",
    "    def count_in_previous_n_time_unit(df=None, cols=None, col_name=None, params=None):\n",
    "        group_cols = cols[:-1]\n",
    "        calc_col = cols[-1]\n",
    "        n = int(params['n'])\n",
    "        encodings = df[group_cols[0]].copy()\n",
    "        if len(group_cols) > 1:\n",
    "            for c in group_cols[1 : ]:\n",
    "                encodings = encodings * (10 ** (int(np.log(df[c].max() + 1) / np.log(10)) + 1)) + df[c]\n",
    "        encodings = encodings.values\n",
    "        times = df[calc_col].values\n",
    "        dict_count = defaultdict(int)\n",
    "        result = []\n",
    "        bound = 0\n",
    "        for cur in range(len(encodings)):\n",
    "            while times[cur] - times[bound] > n:\n",
    "                dict_count[encodings[bound]] -= 1\n",
    "                bound += 1\n",
    "            result.append(dict_count[encodings[cur]])\n",
    "            dict_count[encodings[cur]] += 1\n",
    "        r = pd.DataFrame(result, columns=[col_name], dtype=Feature.Utils._set_type(result, 'uint'))\n",
    "        del encodings, times, dict_count, result, bound, n\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    # cols[-1]: time\n",
    "    def count_in_next_n_time_unit(df=None, cols=None, col_name=None, params=None):\n",
    "        r = Feature.count_in_previous_n_time_unit(df.sort_index(ascending=False), cols, col_name, params)\n",
    "        r = r.reindex(index=r.index[::-1]).reset_index(drop=True)\n",
    "        gc.collect()\n",
    "        return r\n",
    "    \n",
    "    \n",
    "    \n",
    "    class Encoding:\n",
    "        # params['train_len'], params['split_col'], params['col']\n",
    "        def woe(df=None, cols=None, col_name=None, params=None):\n",
    "            return Feature.Encoding._wrapper(df, cols, col_name,\\\n",
    "                                      {'train_len': params['train_len'],\\\n",
    "                                       'function': Feature.Encoding._woe,\\\n",
    "                                       'split_col': params['split_col'],\\\n",
    "                                       'col': params['col']})\n",
    "            \n",
    "        def chi_square(df=None, cols=None, col_name=None, params=None):\n",
    "            return Feature.Encoding._wrapper(df, cols, col_name,\\\n",
    "                                      {'train_len': params['train_len'],\\\n",
    "                                       'function': Feature.Encoding._chi_square,\\\n",
    "                                       'split_col':params['split_col'],\\\n",
    "                                       'col': params['col']})\n",
    "        \n",
    "        def mean(df=None, cols=None, col_name=None, params=None):\n",
    "            return Feature.Encoding._wrapper(df, cols, col_name,\\\n",
    "                                      {'train_len': params['train_len'],\\\n",
    "                                       'function': Feature.Encoding._mean,\\\n",
    "                                       'split_col':params['split_col'],\\\n",
    "                                       'col': params['col']})\n",
    "        \n",
    "        def _wrapper(df=None, cols=None, col_name=None, params=None):\n",
    "            train_len = int(params['train_len'])\n",
    "            train = df[ : train_len]\n",
    "            test = df[train_len:]\n",
    "            return pd.concat([Feature.Encoding._train_wrapper(df[:train_len],\\\n",
    "                                                              cols, params['col'],\\\n",
    "                                                              col_name, params['function'],\\\n",
    "                                                              params['split_col']),\\\n",
    "                              Feature.Encoding._testset_wrapper(df[:train_len],\\\n",
    "                                                             df[params['train_len']:],\\\n",
    "                                                             cols, params['col'],\\\n",
    "                                                             col_name, params['function'])],\\\n",
    "                             ignore_index=True)\n",
    "        \n",
    "        def _train_wrapper(df, group_cols, label, col_name, func, split_col):\n",
    "            r_list = []\n",
    "            for i in range(df[split_col].min(), df[split_col].max() + 1):\n",
    "                dictionary = func(df=df[df[split_col]!=i], group_cols=group_cols, label=label, col_name=col_name)\n",
    "                r_list.append(df[df[split_col]==i].merge(dictionary, on=group_cols, how='left')[[col_name]])\n",
    "            r = pd.concat(r_list).fillna(-1).reset_index(drop=True)\n",
    "            del r_list, dictionary\n",
    "            gc.collect()\n",
    "            return r\n",
    "        \n",
    "        def _testset_wrapper(train, test, group_cols, label, col_name, func):\n",
    "            dictionary = func(df=train, group_cols=group_cols, label=label, col_name=col_name)\n",
    "            _df = test.merge(dictionary, on=group_cols, how='left')\n",
    "            r = _df[[col_name]].copy().fillna(-1)\n",
    "            del _df, dictionary\n",
    "            gc.collect()\n",
    "            return r\n",
    "        \n",
    "        def _woe(df=None, group_cols=None, label=None, col_name=None, params=None):\n",
    "            d_cols = list(group_cols)\n",
    "            d_cols.append(label)\n",
    "            group = df[d_cols].groupby(by=group_cols)[[label]].agg(['count','sum'])[label].reset_index()\n",
    "            positive = df[label].sum()\n",
    "            negative = df.shape[0] - positive\n",
    "            group[col_name] = np.log((group['sum']+0.5) / positive / ((group['count']-group['sum']+0.5) / negative))\n",
    "            dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "            dtype[col_name] = Feature.Utils._set_type(group[col_name], 'float')\n",
    "            group.astype(dtype)\n",
    "            return_cols = list(group_cols)\n",
    "            return_cols.append(col_name)\n",
    "            r = group[return_cols]\n",
    "            del d_cols, group, positive, negative, dtype, return_cols\n",
    "            gc.collect()\n",
    "            return r\n",
    "        \n",
    "        def _chi_square(df=None, group_cols=None, label=None, col_name=None, params=None):\n",
    "            total_count = df.shape[0]\n",
    "            total_sum = df[label].sum()\n",
    "            group = df.groupby(by=group_cols)[[label]].agg(['count','sum'])[label].reset_index().rename(index=str, columns={'sum': 'n11'})\n",
    "            group['n12'] = group['count'] - group['n11']\n",
    "            group['n21'] = total_sum - group['n11']\n",
    "            group['n22'] = total_count - group['n11'] - group['n12'] - group['n21']\n",
    "            group['e11'] = (group['n11'] + group['n12']) * (group['n11'] + group['n21']) / total_count\n",
    "            group['e12'] = (group['n11'] + group['n12']) * (group['n12'] + group['n22']) / total_count\n",
    "            group['e21'] = (group['n21'] + group['n22']) * (group['n11'] + group['n21']) / total_count\n",
    "            group['e22'] = (group['n21'] + group['n22']) * (group['n12'] + group['n22']) / total_count\n",
    "            group[col_name] = (group['n11'] - group['e11']) ** 2 / group['e11'] + \\\n",
    "                                  (group['n12'] - group['e12']) ** 2 / group['e12'] + \\\n",
    "                                  (group['n21'] - group['e21']) ** 2 / group['e21'] + \\\n",
    "                                  (group['n22'] - group['e22']) ** 2 / group['e22']\n",
    "            dtype = {x: df[x].dtype for x in group_cols if x in df.columns.values}\n",
    "            dtype[col_name] = Feature.Utils._set_type(group[col_name], 'float')\n",
    "            group.astype(dtype)\n",
    "            return_cols = list(group_cols)\n",
    "            return_cols.append(col_name)\n",
    "            r = group[return_cols]\n",
    "            del group, total_count, total_sum, dtype, return_cols\n",
    "            gc.collect()\n",
    "            return r\n",
    "        \n",
    "        def _mean(df=None, group_cols=None, label=None, col_name=None, params=None):\n",
    "            r = df.groupby(by=group_cols)[[label]].mean().reset_index().rename(index=str, columns={label:col_name})\n",
    "            r.astype(Feature.Utils._set_type(r[col_name], 'float'))\n",
    "            gc.collect()\n",
    "            return r\n",
    "            \n",
    "        \n",
    "        \n",
    "    class Kernels:\n",
    "        def square(df=None, cols=None, col_name=None, params=None):\n",
    "            r = df[[cols]].apply(lambda x: x ** 2)\n",
    "            r = r.astype(Feature.Utils._set_type(r, 'float'))\n",
    "            gc.collect()\n",
    "            return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:09:17.144530Z",
     "start_time": "2018-06-18T16:09:14.704655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER\n",
      "FLAG_OWN_CAR\n",
      "FLAG_OWN_REALTY\n",
      "NAME_TYPE_SUITE\n",
      "NAME_INCOME_TYPE\n",
      "NAME_EDUCATION_TYPE\n",
      "NAME_FAMILY_STATUS\n",
      "NAME_HOUSING_TYPE\n",
      "OCCUPATION_TYPE\n",
      "WEEKDAY_APPR_PROCESS_START\n",
      "FONDKAPREMONT_MODE\n",
      "HOUSETYPE_MODE\n",
      "WALLSMATERIAL_MODE\n",
      "EMERGENCYSTATE_MODE\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_feats = [\n",
    "    'NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_TYPE_SUITE',\n",
    "    'NAME_INCOME_TYPE','NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE',\n",
    "    'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE',\n",
    "    'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n",
    "    'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "    'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "    'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n",
    "    'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19',\n",
    "    'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21','WEEKDAY_APPR_PROCESS_START', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', \n",
    "    'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'\n",
    "]\n",
    "\n",
    "for x in categorical_feats:\n",
    "    if train[x].dtype == 'object':\n",
    "        print(x)\n",
    "        train[x].fillna('na', inplace=True)\n",
    "        test[x].fillna('na', inplace=True)\n",
    "        train[x] = LabelEncoder().fit_transform(train[x])\n",
    "        test[x] = LabelEncoder().fit_transform(test[x])\n",
    "    else:\n",
    "        train[x].fillna('na', inplace=True)\n",
    "        test[x].fillna('na', inplace=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:09:25.554116Z",
     "start_time": "2018-06-18T16:09:25.543881Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_feat = [\n",
    "    'NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_TYPE_SUITE',\n",
    "    'NAME_INCOME_TYPE','NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE',\n",
    "    'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE',\n",
    "    'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n",
    "    'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "    'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "    'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n",
    "    'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19',\n",
    "    'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21','WEEKDAY_APPR_PROCESS_START', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', \n",
    "    'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:09:29.709091Z",
     "start_time": "2018-06-18T16:09:27.751880Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:09:30.228269Z",
     "start_time": "2018-06-18T16:09:30.225111Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 387)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:11:48.660869Z",
     "start_time": "2018-06-18T16:11:48.652075Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tmp_idx'] = df['tmp_idx'].fillna(-1).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:14:19.551248Z",
     "start_time": "2018-06-18T16:14:19.521798Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_ANNUITY</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_GOODS_PRICE</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>tmp_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24700.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>0.070372</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35698.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>0.132217</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_ANNUITY  AMT_ANNUITY_divide_AMT_ANNUITY  AMT_ANNUITY_divide_AMT_CREDIT  \\\n",
       "0      24700.5                             1.0                       0.060749   \n",
       "1      35698.5                             1.0                       0.027598   \n",
       "\n",
       "   AMT_ANNUITY_divide_AMT_GOODS_PRICE  AMT_ANNUITY_divide_AMT_INCOME_TOTAL  \\\n",
       "0                            0.070372                             0.121978   \n",
       "1                            0.031606                             0.132217   \n",
       "\n",
       "   AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                                           inf   \n",
       "1                                           inf   \n",
       "\n",
       "   AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                                            inf   \n",
       "1                                            inf   \n",
       "\n",
       "   AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                                           inf   \n",
       "1                                           inf   \n",
       "\n",
       "   AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                                           inf   \n",
       "1                                           inf   \n",
       "\n",
       "   AMT_ANNUITY_divide_AMT_REQ_CREDIT_BUREAU_WEEK   ...     TOTALAREA_MODE  \\\n",
       "0                                            inf   ...             0.0149   \n",
       "1                                            inf   ...             0.0714   \n",
       "\n",
       "   WALLSMATERIAL_MODE  WEEKDAY_APPR_PROCESS_START  \\\n",
       "0                   5                           6   \n",
       "1                   0                           1   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_AVG  YEARS_BEGINEXPLUATATION_MEDI  \\\n",
       "0                       0.9722                        0.9722   \n",
       "1                       0.9851                        0.9851   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_MODE  YEARS_BUILD_AVG  YEARS_BUILD_MEDI  \\\n",
       "0                        0.9722           0.6192            0.6243   \n",
       "1                        0.9851           0.7960            0.7987   \n",
       "\n",
       "   YEARS_BUILD_MODE  tmp_idx  \n",
       "0            0.6341        3  \n",
       "1            0.8040        9  \n",
       "\n",
       "[2 rows x 387 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:31:04.946769Z",
     "start_time": "2018-06-18T16:18:27.619492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME_CONTRACT_TYPE\n",
      "CODE_GENDER\n",
      "FLAG_OWN_CAR\n",
      "FLAG_OWN_REALTY\n",
      "NAME_TYPE_SUITE\n",
      "NAME_INCOME_TYPE\n",
      "NAME_EDUCATION_TYPE\n",
      "NAME_FAMILY_STATUS\n",
      "NAME_HOUSING_TYPE\n",
      "FLAG_MOBIL\n",
      "FLAG_EMP_PHONE\n",
      "FLAG_WORK_PHONE\n",
      "FLAG_CONT_MOBILE\n",
      "FLAG_PHONE\n",
      "FLAG_EMAIL\n",
      "OCCUPATION_TYPE\n",
      "REG_REGION_NOT_LIVE_REGION\n",
      "REG_REGION_NOT_WORK_REGION\n",
      "LIVE_REGION_NOT_WORK_REGION\n",
      "REG_CITY_NOT_LIVE_CITY\n",
      "REG_CITY_NOT_WORK_CITY\n",
      "LIVE_CITY_NOT_WORK_CITY\n",
      "FLAG_DOCUMENT_2\n",
      "FLAG_DOCUMENT_3\n",
      "FLAG_DOCUMENT_4\n",
      "FLAG_DOCUMENT_5\n",
      "FLAG_DOCUMENT_6\n",
      "FLAG_DOCUMENT_7\n",
      "FLAG_DOCUMENT_8\n",
      "FLAG_DOCUMENT_9\n",
      "FLAG_DOCUMENT_10\n",
      "FLAG_DOCUMENT_11\n",
      "FLAG_DOCUMENT_12\n",
      "FLAG_DOCUMENT_13\n",
      "FLAG_DOCUMENT_14\n",
      "FLAG_DOCUMENT_15\n",
      "FLAG_DOCUMENT_16\n",
      "FLAG_DOCUMENT_17\n",
      "FLAG_DOCUMENT_18\n",
      "FLAG_DOCUMENT_19\n",
      "FLAG_DOCUMENT_20\n",
      "FLAG_DOCUMENT_21\n",
      "WEEKDAY_APPR_PROCESS_START\n",
      "FONDKAPREMONT_MODE\n",
      "HOUSETYPE_MODE\n",
      "WALLSMATERIAL_MODE\n",
      "EMERGENCYSTATE_MODE\n"
     ]
    }
   ],
   "source": [
    "params = {'train_len':train.shape[0], 'split_col':'tmp_idx', 'col':'TARGET'}\n",
    "for x in cat_feat:\n",
    "    df['woe_'+x] = Feature.Encoding.woe(df, [x], 'woe_'+x, params)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:57:35.891715Z",
     "start_time": "2018-06-18T16:57:32.834877Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "df[:train.shape[0]].to_pickle(PATH + 'train_test.pkl')\n",
    "print('train')\n",
    "df[train.shape[0]:].to_pickle(PATH + 'test_test.pkl')\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:59:53.458878Z",
     "start_time": "2018-06-18T16:59:53.449972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woe_NAME_CONTRACT_TYPE',\n",
       " 'woe_CODE_GENDER',\n",
       " 'woe_FLAG_OWN_CAR',\n",
       " 'woe_FLAG_OWN_REALTY',\n",
       " 'woe_NAME_TYPE_SUITE',\n",
       " 'woe_NAME_INCOME_TYPE',\n",
       " 'woe_NAME_EDUCATION_TYPE',\n",
       " 'woe_NAME_FAMILY_STATUS',\n",
       " 'woe_NAME_HOUSING_TYPE',\n",
       " 'woe_FLAG_MOBIL',\n",
       " 'woe_FLAG_EMP_PHONE',\n",
       " 'woe_FLAG_WORK_PHONE',\n",
       " 'woe_FLAG_CONT_MOBILE',\n",
       " 'woe_FLAG_PHONE',\n",
       " 'woe_FLAG_EMAIL',\n",
       " 'woe_OCCUPATION_TYPE',\n",
       " 'woe_REG_REGION_NOT_LIVE_REGION',\n",
       " 'woe_REG_REGION_NOT_WORK_REGION',\n",
       " 'woe_LIVE_REGION_NOT_WORK_REGION',\n",
       " 'woe_REG_CITY_NOT_LIVE_CITY',\n",
       " 'woe_REG_CITY_NOT_WORK_CITY',\n",
       " 'woe_LIVE_CITY_NOT_WORK_CITY',\n",
       " 'woe_FLAG_DOCUMENT_2',\n",
       " 'woe_FLAG_DOCUMENT_3',\n",
       " 'woe_FLAG_DOCUMENT_4',\n",
       " 'woe_FLAG_DOCUMENT_5',\n",
       " 'woe_FLAG_DOCUMENT_6',\n",
       " 'woe_FLAG_DOCUMENT_7',\n",
       " 'woe_FLAG_DOCUMENT_8',\n",
       " 'woe_FLAG_DOCUMENT_9',\n",
       " 'woe_FLAG_DOCUMENT_10',\n",
       " 'woe_FLAG_DOCUMENT_11',\n",
       " 'woe_FLAG_DOCUMENT_12',\n",
       " 'woe_FLAG_DOCUMENT_13',\n",
       " 'woe_FLAG_DOCUMENT_14',\n",
       " 'woe_FLAG_DOCUMENT_15',\n",
       " 'woe_FLAG_DOCUMENT_16',\n",
       " 'woe_FLAG_DOCUMENT_17',\n",
       " 'woe_FLAG_DOCUMENT_18',\n",
       " 'woe_FLAG_DOCUMENT_19',\n",
       " 'woe_FLAG_DOCUMENT_20',\n",
       " 'woe_FLAG_DOCUMENT_21',\n",
       " 'woe_WEEKDAY_APPR_PROCESS_START',\n",
       " 'woe_FONDKAPREMONT_MODE',\n",
       " 'woe_HOUSETYPE_MODE',\n",
       " 'woe_WALLSMATERIAL_MODE',\n",
       " 'woe_EMERGENCYSTATE_MODE']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = [x for x in df if 'woe' in x]\n",
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:00:46.464939Z",
     "start_time": "2018-06-18T17:00:44.963806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "df[:train.shape[0]][new_cols].to_pickle(PATH + 'train_woe.pkl')\n",
    "print('train')\n",
    "df[train.shape[0]:][new_cols].to_pickle(PATH + 'test_woe.pkl')\n",
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T20:20:50.971906Z",
     "start_time": "2018-06-18T20:20:40.572863Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woe\n",
      "ratio\n",
      "merged\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainw = pd.read_pickle(PATH + 'train_woe.pkl')\n",
    "testw = pd.read_pickle(PATH + 'test_woe.pkl')\n",
    "print('woe')\n",
    "\n",
    "trainr = pd.read_pickle(PATH + 'train_ratio.pkl')\n",
    "testr = pd.read_pickle(PATH + 'test_ratio.pkl')\n",
    "print('ratio')\n",
    "\n",
    "train = pd.read_pickle(PATH + 'train_merged.pkl')\n",
    "test = pd.read_pickle(PATH + 'test_merged.pkl')\n",
    "print('merged')\n",
    "\n",
    "train = pd.concat([train, trainr], axis=1)\n",
    "test = pd.concat([test, testr], axis=1)\n",
    "train.to_pickle(PATH + 'train_ratio_merged.pkl')\n",
    "test.to_pickle(PATH + 'test_ratio_merged.pkl')\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T20:08:29.591181Z",
     "start_time": "2018-06-19T20:08:23.517184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 557) (48744, 556)\n",
      "ratio\n",
      "(307511, 821) (48744, 820)\n",
      "b\n",
      "(307511, 899) (48744, 898)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "PATH = '/home/kai/data/kaggle/homecredit/inter/'\n",
    "train = pd.read_pickle(PATH + 'train_total.pkl')\n",
    "test = pd.read_pickle(PATH + 'test_total.pkl')\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "trainr = pd.read_pickle(PATH + 'train_ratio.pkl')\n",
    "testr = pd.read_pickle(PATH + 'test_ratio.pkl')\n",
    "print('ratio')\n",
    "\n",
    "train = pd.concat([train, trainr], axis=1)\n",
    "test = pd.concat([test, testr], axis=1)\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "trainb = pd.read_pickle(PATH + 'train_cleaned_bureau_final.pkl')\n",
    "testb = pd.read_pickle(PATH + 'test_cleaned_bureau_final.pkl')\n",
    "print('b')\n",
    "\n",
    "trainb.drop('TARGET', inplace=True, axis=1)\n",
    "\n",
    "train = train.merge(trainb, on='SK_ID_CURR', how='left')\n",
    "test = test.merge(testb, on='SK_ID_CURR', how='left')\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# train.to_pickle(PATH + 'train_merge0.pkl')\n",
    "# test.to_pickle(PATH + 'test_merge0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
