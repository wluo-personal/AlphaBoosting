{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T17:05:46.891216Z",
     "start_time": "2018-06-22T17:05:46.471432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "if not os.path.exists(PATH + 'inter/linear/'): os.mkdir(PATH + 'inter/linear/')\n",
    "    \n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T17:05:46.902303Z",
     "start_time": "2018-06-22T17:05:46.893427Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def numerical(df, gp_col, col, agg_fun):\n",
    "    _df = df.groupby(gp_col)[[col]].agg(agg_fun)\n",
    "    \n",
    "    columns = []\n",
    "    for x in _df.columns.levels[0]:\n",
    "        for y in _df.columns.levels[1]:\n",
    "            columns.append('_'.join([x, y]))\n",
    "    _df.columns = columns\n",
    "    return _df.reset_index().astype({gp_col: df[gp_col].dtype})\n",
    "\n",
    "def minus_name(col1, col2): return col1 + '_minus_' + col2\n",
    "def minus(df, col1, col2): return df[col1] - df[col2]\n",
    "\n",
    "def ratio_name(col1, col2): return col1 + '_divide_' + col2\n",
    "def ratio(df, col1, col2): return df[col1] / (df[col2] + 1)\n",
    "\n",
    "\n",
    "def _apply_group(args):\n",
    "    func, group_id, x, y = args\n",
    "    return [group_id] + func(x, y)\n",
    "\n",
    "def apply_by_multiprocessing(func, **kwargs):\n",
    "    workers = kwargs.pop('workers')\n",
    "    group_list = kwargs.pop('group_list')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    print(len(group_list), len(group_list[0]))\n",
    "    a = [(func, group_id, x, y) for group_id, x, y in group_list]\n",
    "    result = pool.map(_apply_group, a)\n",
    "    pool.close()\n",
    "    return result\n",
    "\n",
    "def liner_reg(x, y, **kwargs):\n",
    "    lg = LinearRegression()\n",
    "    lg.fit(x, y)\n",
    "    \n",
    "    lg1 = LinearRegression()\n",
    "    x_max = max(x.iloc[:,0])\n",
    "    x_min = min(x.iloc[:,0])\n",
    "    lg1.fit((x-x_max)/(x_max-x_min+1), y)\n",
    "    return [lg.coef_[0][0], lg1.coef_[0][0]]\n",
    "\n",
    "def linear0(df_, gp_col, x_col_name, y_col_name, x_map=None, n_job=8):\n",
    "    df = df_.copy()\n",
    "    if x_map != None: df[x_col_name] = df[x_col_name].map(x_map)\n",
    "    group = [(i, x[[x_col_name]], x[[y_col_name]]) for i, x in df.groupby(gp_col)]\n",
    "    r = apply_by_multiprocessing(liner_reg, workers=n_job, group_list=group)\n",
    "    tmpdf = pd.DataFrame(r, columns=[gp_col, x_col_name+'_lg_'+y_col_name, x_col_name+'_normallg_'+y_col_name])\n",
    "    return tmpdf.astype({gp_col: df_[gp_col].dtype})\n",
    "\n",
    "def linear(df, gp_col, x_col_name, y_col_name):\n",
    "    r = []\n",
    "    for i, x in df.groupby(gp_col):\n",
    "        lg = LinearRegression()\n",
    "        lg1 = LinearRegression()\n",
    "        \n",
    "        lg.fit(x[[x_col_name]], x[[y_col_name]])\n",
    "        x_max = max(x[x_col_name])\n",
    "        x_min = min(x[x_col_name])\n",
    "        lg1.fit((x[[x_col_name]]-x_max)/(x_max-x_min+1), x[[y_col_name]])\n",
    "        r.append([i, lg.coef_[0][0], lg1.coef_[0][0]])\n",
    "    tmpdf = pd.DataFrame(r, columns=[gp_col, x_col_name+'_lg_'+y_col_name, x_col_name+'_normallg_'+y_col_name])\n",
    "    return tmpdf.astype({gp_col: df[gp_col].dtype})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# installments payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T17:05:55.469565Z",
     "start_time": "2018-06-22T17:05:46.903901Z"
    }
   },
   "outputs": [],
   "source": [
    "inst = pd.read_csv(PATH + 'installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:09:24.402214Z",
     "start_time": "2018-06-22T17:05:55.471184Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13605401, 11)\n",
      "DAYS_ENTRY_PAYMENT_minus_DAYS_INSTALMENT\n",
      "(339587, 3)\n",
      "AMT_INSTALMENT_minus_AMT_PAYMENT\n",
      "(339587, 5)\n",
      "AMT_INSTALMENT_minus_AMT_PAYMENT_divide_DAYS_ENTRY_PAYMENT_minus_DAYS_INSTALMENT\n",
      "(339587, 7)\n",
      "CPU times: user 17h 14min 54s, sys: 56min 2s, total: 18h 10min 56s\n",
      "Wall time: 1h 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "name1 = minus_name('DAYS_ENTRY_PAYMENT', 'DAYS_INSTALMENT')\n",
    "inst[name1] = minus(inst, 'DAYS_ENTRY_PAYMENT', 'DAYS_INSTALMENT')\n",
    "inst.at[inst[name1] < 0, name1] = 0\n",
    "name2 = minus_name('AMT_INSTALMENT', 'AMT_PAYMENT')\n",
    "inst[name2] = minus(inst, 'AMT_INSTALMENT', 'AMT_PAYMENT')\n",
    "inst.at[inst[name2] < 0, name2] = 0\n",
    "name3 = ratio_name(name2, name1)\n",
    "inst[name3] = ratio(inst, name2, name1)\n",
    "print(inst.shape)\n",
    "\n",
    "r = None\n",
    "for x in [name1, name2, name3]:\n",
    "    print(x)\n",
    "    if r is None: r = linear(inst.fillna(0), 'SK_ID_CURR', 'DAYS_INSTALMENT', x)\n",
    "    else: r = r.merge(linear(inst.fillna(0), 'SK_ID_CURR', 'DAYS_INSTALMENT', x), on='SK_ID_CURR', how='left')\n",
    "    print(r.shape)\n",
    "\n",
    "columns = []\n",
    "for x in r.columns:\n",
    "    tmp = 'install_' + x if x != 'SK_ID_CURR' else x\n",
    "    columns.append(tmp)\n",
    "r.columns = columns\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:09:24.472841Z",
     "start_time": "2018-06-22T18:09:24.408551Z"
    }
   },
   "outputs": [],
   "source": [
    "r.to_pickle(PATH + 'inter/linear/linearinstal2curr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T18:09:36.412688Z",
     "start_time": "2018-06-22T18:09:24.474768Z"
    }
   },
   "outputs": [],
   "source": [
    "bureau = pd.read_csv(PATH + 'bureau.csv')\n",
    "bb = pd.read_csv(PATH + 'bureau_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-22T20:28:01.078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map done\n"
     ]
    }
   ],
   "source": [
    "tmp_df = pd.DataFrame(bureau[['SK_ID_CURR', 'SK_ID_BUREAU']])\n",
    "tmp_df1 = bb[(bb['STATUS']!='C') & (bb['STATUS']!='X')]\n",
    "tmp_df2 = bb[bb['STATUS'] != 'X']\n",
    "x_map = {'C':0, '0':0, '1':1, '2':2, '3':3, '4':4, '5':5}\n",
    "\n",
    "tmp_df1['STATUS'] = tmp_df1['STATUS'].map(x_map)\n",
    "tmp_df2['STATUS'] = tmp_df2['STATUS'].map(x_map)\n",
    "print('map done')\n",
    "\n",
    "tmp_df = tmp_df.merge(linear(tmp_df1, 'SK_ID_BUREAU', 'MONTHS_BALANCE', 'STATUS'), on='SK_ID_BUREAU', how='left')\n",
    "tmp_df = tmp_df.merge(linear(tmp_df2, 'SK_ID_BUREAU', 'MONTHS_BALANCE', 'STATUS'), on='SK_ID_BUREAU', how='left')\n",
    "\n",
    "r = None\n",
    "agg_list = ['mean', 'median', 'max', 'min']\n",
    "for x in tmp_df.columns:\n",
    "    if x not in ['SK_ID_BUREAU', 'SK_ID_CURR']:\n",
    "        if r is None: r = numerical(tmp_df, 'SK_ID_CURR', x, agg_list)\n",
    "        else: r = r.merge(numerical(tmp_df, 'SK_ID_CURR', x, agg_list), on='SK_ID_CURR', how='left')\n",
    "\n",
    "columns = []\n",
    "for x in r.columns:\n",
    "    tmp = 'bureau_' + x if x != 'SK_ID_CURR' else x\n",
    "    columns.append(tmp)\n",
    "r.columns = columns\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T19:53:48.276125Z",
     "start_time": "2018-06-22T18:22:38.177Z"
    }
   },
   "outputs": [],
   "source": [
    "r.to_pickle(PATH + 'inter/linearbureau2curr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pos cash balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T19:53:48.279064Z",
     "start_time": "2018-06-22T18:22:38.682Z"
    }
   },
   "outputs": [],
   "source": [
    "pos = pd.read_csv(PATH + 'POS_CASH_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T19:53:48.282176Z",
     "start_time": "2018-06-22T18:22:38.881Z"
    }
   },
   "outputs": [],
   "source": [
    "r = None\n",
    "for x in ['SK_DPD']:\n",
    "    print(x)\n",
    "    if r is None: r = linear(pos.fillna(0), 'SK_ID_CURR', 'MONTHS_BALANCE', x)\n",
    "    else: r = r.merge(linear(pos.fillna(0), 'SK_ID_CURR', 'MONTHS_BALANCE', x), on='SK_ID_CURR', how='left')\n",
    "    print(r.shape)\n",
    "\n",
    "columns = []\n",
    "for x in r.columns:\n",
    "    tmp = 'poscash_' + x if x != 'SK_ID_CURR' else x\n",
    "    columns.append(tmp)\n",
    "r.columns = columns\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T19:53:48.295457Z",
     "start_time": "2018-06-22T18:22:40.106Z"
    }
   },
   "outputs": [],
   "source": [
    "r.to_pickle(PATH + 'inter/linearposcash2curr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# credit card balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T19:53:48.288918Z",
     "start_time": "2018-06-22T18:22:39.553Z"
    }
   },
   "outputs": [],
   "source": [
    "credit = pd.read_csv(PATH + 'credit_card_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T19:53:48.292157Z",
     "start_time": "2018-06-22T18:22:39.825Z"
    }
   },
   "outputs": [],
   "source": [
    "r = None\n",
    "name1 = minus_name('AMT_BALANCE', 'AMT_CREDIT_LIMIT_ACTUAL')\n",
    "name2 = minus_name('AMT_BALANCE', 'AMT_PAYMENT_TOTAL_CURRENT')\n",
    "credit[name1] = minus(credit, 'AMT_BALANCE', 'AMT_CREDIT_LIMIT_ACTUAL')\n",
    "credit[name2] = minus(credit, 'AMT_BALANCE', 'AMT_PAYMENT_TOTAL_CURRENT')\n",
    "\n",
    "credit.at[credit[name1]<0, name1] = 0\n",
    "credit.at[credit[name2]<0, name2] = 0\n",
    "\n",
    "for x in ['SK_DPD', 'AMT_BALANCE', 'AMT_DROWINGS_CURRENT', 'AMT_TOTAL_REVEIVABLE', 'SK_DPD', name1, name2]:\n",
    "    print(x)\n",
    "    if r is None: r = linear(credit.fillna(0), 'SK_ID_CURR', 'MONTHS_BALANCE', x)\n",
    "    else: r = r.merge(linear(credit.fillna(0), 'SK_ID_CURR', 'MONTHS_BALANCE', x), on='SK_ID_CURR', how='left')\n",
    "    print(r.shape)\n",
    "\n",
    "columns = []\n",
    "for x in r.columns:\n",
    "    tmp = 'poscash_' + x if x != 'SK_ID_CURR' else x\n",
    "    columns.append(tmp)\n",
    "r.columns = columns\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-22T19:53:48.295457Z",
     "start_time": "2018-06-22T18:22:40.106Z"
    }
   },
   "outputs": [],
   "source": [
    "r.to_pickle(PATH + 'inter/linearcredit2curr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
