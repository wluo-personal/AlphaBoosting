{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T19:52:08.897167Z",
     "start_time": "2018-06-29T19:52:08.888213Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, logtofile=True, logfilename='log'):\n",
    "        self.terminal = sys.stdout\n",
    "        self.logfile = \"{}_{}.log\".format(logfilename, int(time.time()))\n",
    "        self.logtofile = logtofile\n",
    "    def write(self, message):\n",
    "        if self.logtofile:\n",
    "            self.log = open(self.logfile, \"a\")\n",
    "            self.log.write(message)  \n",
    "            self.log.close()\n",
    "sys.stdout = Logger(logfilename='logfile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T20:05:18.654083Z",
     "start_time": "2018-06-29T20:05:15.979644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 329), (48744, 328))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "\n",
    "train = pd.read_pickle(PATH + 'inter/train_only_0.pkl')\n",
    "test = pd.read_pickle(PATH + 'inter/test_only_0.pkl')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T20:06:52.384418Z",
     "start_time": "2018-06-29T20:05:21.274692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poscash2curr.pkl\n",
      "(356255, 116)\n",
      "(307511, 429) (48744, 428)\n",
      "bureau2curr.pkl\n",
      "(356255, 554)\n",
      "(307511, 888) (48744, 887)\n",
      "prev2curr.pkl\n",
      "(356255, 610)\n",
      "(307511, 1423) (48744, 1422)\n",
      "credit2curr.pkl\n",
      "(356255, 502)\n",
      "(307511, 1804) (48744, 1803)\n",
      "install2curr.pkl\n",
      "(356255, 60)\n",
      "(307511, 1854) (48744, 1853)\n",
      "linearposcash2curr.pkl\n",
      "(307511, 1858) (48744, 1857)\n",
      "linearbureau2curr.pkl\n",
      "(307511, 1874) (48744, 1873)\n",
      "newlinearinst2curr.pkl\n",
      "(307511, 1902) (48744, 1901)\n",
      "linearcredit2curr.pkl\n",
      "(307511, 1916) (48744, 1915)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "do_deleting = True\n",
    "ptn = 'std'\n",
    "for x in os.listdir(PATH + 'inter/'):\n",
    "    if 'curr.pkl' in x:\n",
    "        print(x)\n",
    "        tmp = pd.read_pickle(PATH + 'inter/' + x)\n",
    "        print(tmp.shape)\n",
    "        if do_deleting:\n",
    "            col = [i for i in tmp.columns if not re.findall(ptn, i)]\n",
    "        else:\n",
    "            col = [i for i in tmp.columns]\n",
    "        train = train.merge(tmp[col], on='SK_ID_CURR', how='left')\n",
    "        test = test.merge(tmp[col], on='SK_ID_CURR', how='left')\n",
    "        print(train.shape, test.shape)\n",
    "        del tmp\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "for x in os.listdir(PATH + 'inter/linear/'):\n",
    "    if x.split('.')[-1] == 'pkl':\n",
    "        if x != 'linearinstal2curr.pkl':\n",
    "            print(x)\n",
    "            tmp = pd.read_pickle(PATH + 'inter/linear/' + x)\n",
    "            if do_deleting:\n",
    "                col = [i for i in tmp.columns if not re.findall(ptn, i)]\n",
    "            else:\n",
    "                col = [i for i in tmp.columns]\n",
    "            train = train.merge(tmp[col], on='SK_ID_CURR', how='left')\n",
    "            test = test.merge(tmp[col], on='SK_ID_CURR', how='left')\n",
    "            del tmp\n",
    "            gc.collect()\n",
    "            print(train.shape, test.shape)'\n",
    "             \n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T20:07:18.196591Z",
     "start_time": "2018-06-29T20:06:54.081539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 1916)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.to_pickle(PATH + 'haoyan_train.pkl')\n",
    "test.to_pickle(PATH + 'haoyan_test.pkl')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T16:31:14.009356Z",
     "start_time": "2018-07-06T16:31:12.949572Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T16:31:29.811428Z",
     "start_time": "2018-07-06T16:31:14.254268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 2374), (48744, 2373))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read train and test\n",
    "train_df = pd.read_pickle(PATH + 'inter/train_base.pkl')\n",
    "test_df = pd.read_pickle(PATH + 'inter/test_base.pkl')\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T16:35:01.344841Z",
     "start_time": "2018-07-06T16:35:01.328185Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_feat = [\n",
    "    'NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_TYPE_SUITE',\n",
    "    'NAME_INCOME_TYPE','NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE',\n",
    "    'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE',\n",
    "    'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n",
    "    'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "    'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "    'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n",
    "    'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19',\n",
    "    'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21','WEEKDAY_APPR_PROCESS_START', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', \n",
    "    'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE'\n",
    "]\n",
    "cat_feat = [x for x in train_df.columns if x in cat_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-06T16:35:04.356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin cv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:390: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's auc: 0.779911 + 0.00411083\n",
      "[200]\tcv_agg's auc: 0.789804 + 0.00344758\n",
      "[300]\tcv_agg's auc: 0.792555 + 0.00336656\n",
      "[400]\tcv_agg's auc: 0.79362 + 0.00334096\n",
      "[500]\tcv_agg's auc: 0.793922 + 0.00331341\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "print('begin cv')\n",
    "target = train_df['TARGET']\n",
    "ignore_cols = ['ORGANIZATION_TYPE', 'TARGET', 'SK_ID_CURR']\n",
    "features = [x for x in train_df.columns if x not in ignore_cols]\n",
    "train = train_df[features]\n",
    "test = test_df[features]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgbm\n",
    "\n",
    "lgbm_train = lgbm.Dataset(data=train,\n",
    "                          label=target,\n",
    "                          categorical_feature=[],\n",
    "                          free_raw_data=False)\n",
    "\n",
    "lgbm_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_iteration': 4000,\n",
    "    'num_threads': 8,\n",
    "\n",
    "    'num_leaves': int(round(44.368535336628419)),\n",
    "    'feature_fraction': 0.28231763168020257,\n",
    "    'bagging_fraction': 0.94901525271474951,\n",
    "    'max_depth': int(round(8.0430115561596267)),\n",
    "    'lambda_l1': 0.30680079516647751,\n",
    "    'lambda_l2': 0.079128660903201031,\n",
    "    'min_split_gain': 0.054005067457890979,\n",
    "    'min_child_weight': 98.172643147364937\n",
    "}\n",
    "\n",
    "cv_results = lgbm.cv(train_set=lgbm_train,\n",
    "                     params=lgbm_params,\n",
    "                     nfold=n_splits,\n",
    "                     seed=2018,\n",
    "                     early_stopping_rounds=150,\n",
    "                     verbose_eval=100,\n",
    "                     metrics=['auc'])\n",
    "\n",
    "optimum_boost_rounds = np.argmax(cv_results['auc-mean'])\n",
    "print('Optimum boost rounds = {}'.format(optimum_boost_rounds))\n",
    "print('Best CV result = {}'.format(np.max(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T20:05:07.623634Z",
     "start_time": "2018-06-29T19:52:25.099Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = lgbm.train(train_set=lgbm_train,\n",
    "                 params=lgbm_params,\n",
    "                 num_boost_round=optimum_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T20:05:07.647868Z",
     "start_time": "2018-06-29T19:52:25.878Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test)\n",
    "out_df = pd.DataFrame({'SK_ID_CURR': test_df['SK_ID_CURR'], 'TARGET': y_pred})\n",
    "out_df.to_csv(PATH+'/submission/haoyan_pred1_0629.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new install linear\n",
    "[100]\tcv_agg's auc: 0.779285 + 0.00427557\n",
    "[200]\tcv_agg's auc: 0.789532 + 0.00380641\n",
    "[300]\tcv_agg's auc: 0.792621 + 0.00363398\n",
    "[400]\tcv_agg's auc: 0.793798 + 0.00379608\n",
    "[500]\tcv_agg's auc: 0.794238 + 0.0039459\n",
    "[600]\tcv_agg's auc: 0.794262 + 0.00387596\n",
    "[700]\tcv_agg's auc: 0.794274 + 0.00381348\n",
    "Optimum boost rounds = 636\n",
    "Best CV result = 0.7943991998600779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with linear with outliers\n",
    "[100]\tcv_agg's auc: 0.779877 + 0.00414474\n",
    "[200]\tcv_agg's auc: 0.789619 + 0.00362956\n",
    "[300]\tcv_agg's auc: 0.792776 + 0.00336169\n",
    "[400]\tcv_agg's auc: 0.793822 + 0.00331481\n",
    "[500]\tcv_agg's auc: 0.794346 + 0.00335585\n",
    "[600]\tcv_agg's auc: 0.794679 + 0.00340904\n",
    "[700]\tcv_agg's auc: 0.794795 + 0.00338389\n",
    "[800]\tcv_agg's auc: 0.794702 + 0.00342039\n",
    "Optimum boost rounds = 725\n",
    "Best CV result = 0.7948496327582341 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without linear with outliers\n",
    "[100]\tcv_agg's auc: 0.778547 + 0.00412467\n",
    "[200]\tcv_agg's auc: 0.789063 + 0.00344099\n",
    "[300]\tcv_agg's auc: 0.792374 + 0.00341128\n",
    "[400]\tcv_agg's auc: 0.793485 + 0.00322214\n",
    "[500]\tcv_agg's auc: 0.793913 + 0.00320875\n",
    "[600]\tcv_agg's auc: 0.793994 + 0.00324946\n",
    "[700]\tcv_agg's auc: 0.794062 + 0.0033091\n",
    "[800]\tcv_agg's auc: 0.793972 + 0.00308594\n",
    "Optimum boost rounds = 701\n",
    "Best CV result = 0.7940757965150353 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL\n",
    "[100]\tcv_agg's auc: 0.7795 + 0.00411813\n",
    "[200]\tcv_agg's auc: 0.789489 + 0.0034798\n",
    "[300]\tcv_agg's auc: 0.792526 + 0.00351702\n",
    "[400]\tcv_agg's auc: 0.7936 + 0.00338604\n",
    "[500]\tcv_agg's auc: 0.794217 + 0.00323238\n",
    "[600]\tcv_agg's auc: 0.794211 + 0.00315142\n",
    "[700]\tcv_agg's auc: 0.794229 + 0.00328479\n",
    "Optimum boost rounds = 550\n",
    "Best CV result = 0.7943004497519002\n",
    "\n",
    "\n",
    "with std\n",
    "[100]\tcv_agg's auc: 0.779445 + 0.00383935\n",
    "[200]\tcv_agg's auc: 0.789236 + 0.00355325\n",
    "\n",
    "\n",
    "No idea\n",
    "[100]\tcv_agg's auc: 0.779646 + 0.00419223\n",
    "[200]\tcv_agg's auc: 0.789602 + 0.00344841\n",
    "[300]\tcv_agg's auc: 0.792667 + 0.00343178\n",
    "[400]\tcv_agg's auc: 0.793703 + 0.00339853\n",
    "[500]\tcv_agg's auc: 0.794175 + 0.00342015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sth2prev2curr no sum\n",
    "[100]\tcv_agg's auc: 0.777611 + 0.00437966\n",
    "[200]\tcv_agg's auc: 0.784903 + 0.00415943\n",
    "[300]\tcv_agg's auc: 0.786765 + 0.00370779\n",
    "[400]\tcv_agg's auc: 0.787215 + 0.00346352\n",
    "[500]\tcv_agg's auc: 0.787577 + 0.00352841 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
