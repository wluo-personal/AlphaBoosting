{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:46:47.877636Z",
     "start_time": "2018-07-10T18:46:46.791692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13605229, 7)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "\n",
    "inst0 = pd.read_pickle(PATH + '/inter/tmp/inst.pkl')\n",
    "inst0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:46:47.882350Z",
     "start_time": "2018-07-10T18:46:47.879198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_PREV', 'SK_ID_CURR', 'NUM_INSTALMENT_NUMBER', 'DAYS_INSTALMENT',\n",
       "       'DAYS_ENTRY_PAYMENT', 'AMT_PAYMENT', 'AMT_INSTALMENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:46:48.079806Z",
     "start_time": "2018-07-10T18:46:47.883785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def minus_name(col1, col2): return col1 + '_minus_' + col2\n",
    "def minus(df, col1, col2): return df[col1] - df[col2]\n",
    "\n",
    "def ratio_name(col1, col2): return col1 + '_divide_' + col2\n",
    "def ratio(df, col1, col2): return df[col1] / (df[col2] + 1e-3)\n",
    "\n",
    "def positive_count(df, gp_col, col):\n",
    "    group = (df[col] > 0).astype('int8')\n",
    "    group = pd.concat([df[gp_col], group], axis=1).groupby(gp_col)[[col]].sum().reset_index().rename(columns={col: 'positivecount_'+col})\n",
    "    return group\n",
    "\n",
    "def negative_count(df, gp_col, col):\n",
    "    group = (df[col] < 0).astype('int8')\n",
    "    group = pd.concat([df[gp_col], group], axis=1).groupby(gp_col)[[col]].sum().reset_index().rename(columns={col: 'negativecount_'+col})\n",
    "    return group\n",
    "\n",
    "def count(df, gp_col, col):\n",
    "    group = df.groupby(gp_col)[[col]].count().reset_index().rename(index=str, columns={col:'count_' + '_'.join(gp_col)})\n",
    "    return group\n",
    "\n",
    "def numerical(df, gp_col, col, agg_fun):\n",
    "    _df = df.groupby(gp_col)[[col]].agg(agg_fun)\n",
    "    \n",
    "    columns = []\n",
    "    for x in _df.columns.levels[0]:\n",
    "        for y in _df.columns.levels[1]:\n",
    "            columns.append('_'.join([x, y]))\n",
    "    _df.columns = columns\n",
    "    return _df.reset_index()\n",
    "\n",
    "def feature_in_time_window(df, gp_col, col, func, agg_fun=None, n=None, time_col=None):\n",
    "    tmp = None\n",
    "    _df = df.copy()\n",
    "    if n is not None:\n",
    "        _df = _df[_df[time_col] >= n]\n",
    "    if agg_fun is None:\n",
    "        tmp = func(_df, gp_col, col)\n",
    "    else:\n",
    "        tmp = func(_df, gp_col, col, agg_fun)\n",
    "    columns = [str(abs(n))+'_'+x for x in set(tmp.columns) - set(gp_col)]\n",
    "    tmp.columns = columns\n",
    "    del _df\n",
    "    gc.collect()\n",
    "    return tmp\n",
    "\n",
    "# def slope_agg(df, gp_col, x, y):\n",
    "#     gp = df.copy()\n",
    "#     gp['slope_'+y] = gp.groupby(gp_col)[y].shift(-1) - gp[y]\n",
    "#     r = gp.groupby(gp_col).size().reset_index()[gp_col]\n",
    "#     l = ['max', 'min', 'mean', 'std']\n",
    "#     r = r.merge(numerical(gp, gp_col, 'slope_'+y, l), on=gp_col, how='left')\n",
    "#     r = r.merge(positive_count(gp, gp_col, 'slope_'+y), on=gp_col, how='left')\n",
    "#     r = r.merge(negative_count(gp, gp_col, 'slope_'+y), on=gp_col, how='left')\n",
    "#     return r\n",
    "\n",
    "def slope_agg(df, gp_col, x, y):\n",
    "    gp = df.copy()\n",
    "    gp_max = gp.groupby(gp_col)[[x]].max().reset_index().rename(columns={x:'max'})\n",
    "    gp_min = gp.groupby(gp_col)[[x]].min().reset_index().rename(columns={x:'min'})\n",
    "    gp = gp.merge(gp_max)\n",
    "    gp = gp.merge(gp_min)\n",
    "    gp['normal_x'] = (gp[x]-gp['max']) / (gp['max']-gp['min']+1)\n",
    "    gp['value'] = gp.groupby(gp_col)[y].shift(-1) - gp[y]\n",
    "    gp['x_diff'] = gp.groupby(gp_col)[x].shift(-1) - gp[x]\n",
    "    gp['normal_x_diff'] = gp.groupby(gp_col)['normal_x'].shift(-1) - gp['normal_x']\n",
    "    gp['slope_'+y] = gp['value'] / gp['x_diff']\n",
    "    gp['normalslope_'+y] = gp['value'] / gp['normal_x_diff']\n",
    "    r = gp.groupby(gp_col).size().reset_index()[gp_col]\n",
    "    l = ['max', 'min', 'mean', 'std']\n",
    "    r = r.merge(numerical(gp, gp_col, 'slope_'+y, l), on=gp_col, how='left')\n",
    "    r = r.merge(positive_count(gp, gp_col, 'slope_'+y), on=gp_col, how='left')\n",
    "    r = r.merge(negative_count(gp, gp_col, 'slope_'+y), on=gp_col, how='left')\n",
    "    r = r.merge(numerical(gp, gp_col, 'normalslope_'+y, l), on=gp_col, how='left')\n",
    "    r = r.merge(positive_count(gp, gp_col, 'normalslope_'+y), on=gp_col, how='left')\n",
    "    r = r.merge(negative_count(gp, gp_col, 'normalslope_'+y), on=gp_col, how='left')\n",
    "    return r\n",
    "    \n",
    "def area_under_curve(df, gp_col, x, y):\n",
    "    gp = df.copy()\n",
    "    gp_max = gp.groupby(gp_col)[[x]].max().reset_index().rename(columns={x:'max'})\n",
    "    gp_min = gp.groupby(gp_col)[[x]].min().reset_index().rename(columns={x:'min'})\n",
    "    gp = gp.merge(gp_max)\n",
    "    gp = gp.merge(gp_min)\n",
    "    gp['normal_x'] = (gp[x]-gp['max']) / (gp['max']-gp['min']+1)\n",
    "    \n",
    "    group = gp.groupby(gp_col)\n",
    "    gp['tmp'] = (group[y].shift(-1)+gp[y]) * (group[x].shift(-1)-gp[x]) / 2\n",
    "    gp['tmp_normal'] = (group[y].shift(-1)+gp[y]) * (group['normal_x'].shift(-1)-gp['normal_x']) / 2\n",
    "    return gp.groupby(gp_col).agg({'tmp':'sum', 'tmp_normal':'sum'}).reset_index().rename(columns={'tmp':x+'_area_'+y, 'tmp_normal':x+'_normalarea_'+y})\n",
    "\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:47:29.294835Z",
     "start_time": "2018-07-10T18:46:48.081578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14011460, 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_col = ['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER', 'DAYS_INSTALMENT', 'SK_ID_CURR']\n",
    "new = inst0.groupby(gp_col)[['AMT_INSTALMENT']].max().reset_index()\n",
    "new['AMT_PAYMENT'] = 0\n",
    "new['DAYS_ENTRY_PAYMENT'] = new['DAYS_INSTALMENT']\n",
    "inst = pd.concat([inst0, new])\n",
    "\n",
    "inst['EARLY_DAYS'] = inst['DAYS_INSTALMENT'] - inst['DAYS_ENTRY_PAYMENT']\n",
    "inst['LATE_DAYS'] = -inst['EARLY_DAYS']\n",
    "inst['LATE_DAYS_SIGN'] = (np.sign(inst['LATE_DAYS']) > 0) * inst['LATE_DAYS']\n",
    "inst['EARLY_DAYS_SIGN'] = (np.sign(inst['EARLY_DAYS']) > 0) * inst['EARLY_DAYS']\n",
    "\n",
    "p = inst.groupby(gp_col+['LATE_DAYS_SIGN']).agg({'AMT_PAYMENT': 'sum', 'DAYS_ENTRY_PAYMENT': 'max', 'AMT_INSTALMENT': 'max', 'EARLY_DAYS_SIGN': 'max'}).reset_index()\n",
    "p['AMT_CUM_PAYMENT'] = p.groupby(gp_col)[['AMT_PAYMENT']].cumsum()\n",
    "p['AMT_LATE_PAYMENT'] = p['AMT_INSTALMENT'] - p['AMT_CUM_PAYMENT']\n",
    "p['AMT_LATE_PAYMENT'] = p['AMT_LATE_PAYMENT'] * (abs(p['AMT_LATE_PAYMENT'])>1e-4)\n",
    "p['RATE_LATE_PAYMENT'] = p['AMT_LATE_PAYMENT'] / p['AMT_INSTALMENT']\n",
    "\n",
    "p['RATE_AMT_CUM_PAYMENT'] = p['AMT_CUM_PAYMENT'] / p['DAYS_INSTALMENT']\n",
    "p['RATE_AMT_LATE_PAYMENT'] = p['AMT_LATE_PAYMENT'] / p['DAYS_INSTALMENT']\n",
    "p['RATE_RATE_LATE_PAYMENT'] = p['RATE_LATE_PAYMENT'] / p['DAYS_INSTALMENT']\n",
    "inst['RATE_LATE_DAYS_SIGN'] = inst['LATE_DAYS_SIGN'] / inst['DAYS_INSTALMENT']\n",
    "inst['RATE_EARLY_DAYS_SIGN'] = inst['EARLY_DAYS_SIGN'] / inst['DAYS_INSTALMENT']\n",
    "\n",
    "p_new_cols = ['AMT_CUM_PAYMENT', 'AMT_LATE_PAYMENT', 'RATE_LATE_PAYMENT', 'RATE_AMT_CUM_PAYMENT', 'RATE_AMT_LATE_PAYMENT', 'RATE_RATE_LATE_PAYMENT']\n",
    "\n",
    "inst_new_cols = ['RATE_LATE_DAYS_SIGN', 'LATE_DAYS_SIGN', 'RATE_EARLY_DAYS_SIGN', 'EARLY_DAYS_SIGN']\n",
    "\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T18:59:59.138562Z",
     "start_time": "2018-07-10T18:47:29.299519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12862309, 5) count_SK_ID_PREV_NUM_INSTALMENT_NUMBER_DAYS_INSTALMENT_SK_ID_CURR\n",
      "slope (12862309, 29)\n",
      "DURATION (12862309, 30)\n",
      "EARLY_DURATION (12862309, 31)\n",
      "TOTAL_DURATION (12862309, 32)\n",
      "AREA (12862309, 36)\n",
      "AMT_TOTAL_LATE (12862309, 39)\n",
      "AMT_ONTIME_PAYMENT (12862309, 41)\n",
      "positivecount (12862309, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER', 'DAYS_INSTALMENT', 'SK_ID_CURR',\n",
       "       'count_SK_ID_PREV_NUM_INSTALMENT_NUMBER_DAYS_INSTALMENT_SK_ID_CURR',\n",
       "       'slope_AMT_LATE_PAYMENT_max', 'slope_AMT_LATE_PAYMENT_min',\n",
       "       'slope_AMT_LATE_PAYMENT_mean', 'slope_AMT_LATE_PAYMENT_std',\n",
       "       'positivecount_slope_AMT_LATE_PAYMENT',\n",
       "       'negativecount_slope_AMT_LATE_PAYMENT',\n",
       "       'normalslope_AMT_LATE_PAYMENT_max', 'normalslope_AMT_LATE_PAYMENT_min',\n",
       "       'normalslope_AMT_LATE_PAYMENT_mean', 'normalslope_AMT_LATE_PAYMENT_std',\n",
       "       'positivecount_normalslope_AMT_LATE_PAYMENT',\n",
       "       'negativecount_normalslope_AMT_LATE_PAYMENT',\n",
       "       'slope_RATE_LATE_PAYMENT_max', 'slope_RATE_LATE_PAYMENT_min',\n",
       "       'slope_RATE_LATE_PAYMENT_mean', 'slope_RATE_LATE_PAYMENT_std',\n",
       "       'positivecount_slope_RATE_LATE_PAYMENT',\n",
       "       'negativecount_slope_RATE_LATE_PAYMENT',\n",
       "       'normalslope_RATE_LATE_PAYMENT_max',\n",
       "       'normalslope_RATE_LATE_PAYMENT_min',\n",
       "       'normalslope_RATE_LATE_PAYMENT_mean',\n",
       "       'normalslope_RATE_LATE_PAYMENT_std',\n",
       "       'positivecount_normalslope_RATE_LATE_PAYMENT',\n",
       "       'negativecount_normalslope_RATE_LATE_PAYMENT', 'DURATION',\n",
       "       'EARLY_DURATION', 'TOTAL_DURATION',\n",
       "       'LATE_DAYS_SIGN_area_AMT_LATE_PAYMENT',\n",
       "       'LATE_DAYS_SIGN_normalarea_AMT_LATE_PAYMENT',\n",
       "       'LATE_DAYS_SIGN_area_RATE_LATE_PAYMENT',\n",
       "       'LATE_DAYS_SIGN_normalarea_RATE_LATE_PAYMENT', 'AMT_INSTALMENT',\n",
       "       'AMT_TOTAL_LATE', 'AMT_TOTAL_LATE_divide_AMT_INSTALMENT',\n",
       "       'AMT_ONTIME_PAYMENT', 'AMT_ONTIME_PAYMENT_divide_AMT_INSTALMENT',\n",
       "       'positivecount_LATE_DAYS_SIGN', 'positivecount_EARLY_DAYS_SIGN',\n",
       "       'positivecount_LATE_DAYS_SIGN_divide_count_SK_ID_PREV_NUM_INSTALMENT_NUMBER_DAYS_INSTALMENT_SK_ID_CURR',\n",
       "       'positivecount_EARLY_DAYS_SIGN_divide_count_SK_ID_PREV_NUM_INSTALMENT_NUMBER_DAYS_INSTALMENT_SK_ID_CURR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = p.groupby(gp_col).size().reset_index()[gp_col]\n",
    "\n",
    "df = df.merge(count(inst, gp_col, 'AMT_INSTALMENT'), on=gp_col, how='left')\n",
    "count_col = [x for x in df.columns if 'count_' in x][0]\n",
    "print(df.shape, count_col)\n",
    "\n",
    "\n",
    "df = df.merge(slope_agg(p, gp_col, 'LATE_DAYS_SIGN', 'AMT_LATE_PAYMENT'))\n",
    "df = df.merge(slope_agg(p, gp_col, 'LATE_DAYS_SIGN', 'RATE_LATE_PAYMENT'))\n",
    "print('slope', df.shape)\n",
    "\n",
    "p['DURATION'] = p['DAYS_ENTRY_PAYMENT'] - p['DAYS_INSTALMENT']\n",
    "df = df.merge(p.groupby(gp_col)[['DURATION']].max().reset_index(), on=gp_col, how='left')\n",
    "p.drop('DURATION', axis=1, inplace=True)\n",
    "print('DURATION', df.shape)\n",
    "\n",
    "\n",
    "p['EARLY_DURATION'] = p['DAYS_INSTALMENT'] - p['DAYS_ENTRY_PAYMENT']\n",
    "df = df.merge(p.groupby(gp_col)[['EARLY_DURATION']].max().reset_index(), on=gp_col, how='left')\n",
    "p.drop('EARLY_DURATION', axis=1, inplace=True)\n",
    "print('EARLY_DURATION', df.shape)\n",
    "\n",
    "\n",
    "df['TOTAL_DURATION'] = df['DURATION'] + df['EARLY_DURATION']\n",
    "print('TOTAL_DURATION', df.shape)\n",
    "\n",
    "\n",
    "df = df.merge(area_under_curve(p, gp_col, 'LATE_DAYS_SIGN', 'AMT_LATE_PAYMENT'))\n",
    "df = df.merge(area_under_curve(p, gp_col, 'LATE_DAYS_SIGN', 'RATE_LATE_PAYMENT'))\n",
    "print('AREA', df.shape)\n",
    "\n",
    "\n",
    "df = df.merge(p.groupby(gp_col)[['AMT_INSTALMENT']].max().reset_index(), on=gp_col, how='left')\n",
    "\n",
    "df = df.merge(p.groupby(gp_col)[['AMT_LATE_PAYMENT']].max().reset_index().rename(columns={'AMT_LATE_PAYMENT':'AMT_TOTAL_LATE'}), on=gp_col, how='left')\n",
    "name = ratio_name('AMT_TOTAL_LATE', 'AMT_INSTALMENT')\n",
    "df[name] = ratio(df, 'AMT_TOTAL_LATE', 'AMT_INSTALMENT')\n",
    "print('AMT_TOTAL_LATE', df.shape)\n",
    "\n",
    "df['AMT_ONTIME_PAYMENT'] = df['AMT_INSTALMENT'] - df['AMT_TOTAL_LATE']\n",
    "name = ratio_name('AMT_ONTIME_PAYMENT', 'AMT_INSTALMENT')\n",
    "df[name] = ratio(df, 'AMT_ONTIME_PAYMENT', 'AMT_INSTALMENT')\n",
    "print('AMT_ONTIME_PAYMENT', df.shape)\n",
    "\n",
    "\n",
    "df = df.merge(positive_count(inst, gp_col, 'LATE_DAYS_SIGN'), on=gp_col, how='left')\n",
    "df = df.merge(positive_count(inst, gp_col, 'EARLY_DAYS_SIGN'), on=gp_col, how='left')\n",
    "name1 = ratio_name('positivecount_LATE_DAYS_SIGN', count_col)\n",
    "df[name1] = ratio(df, 'positivecount_LATE_DAYS_SIGN', count_col)\n",
    "name2 = ratio_name('positivecount_EARLY_DAYS_SIGN', count_col)\n",
    "df[name2] = ratio(df, 'positivecount_EARLY_DAYS_SIGN', count_col)\n",
    "print('positivecount', df.shape)\n",
    "    \n",
    "    \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T19:02:04.313493Z",
     "start_time": "2018-07-10T18:59:59.140149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df (339587, 211)\n",
      "p (339587, 241)\n",
      "inst (339587, 261)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_CURR', 'slope_RATE_LATE_PAYMENT_max_mean',\n",
       "       'slope_RATE_LATE_PAYMENT_max_max', 'slope_RATE_LATE_PAYMENT_max_min',\n",
       "       'slope_RATE_LATE_PAYMENT_max_sum', 'slope_RATE_LATE_PAYMENT_max_std',\n",
       "       'LATE_DAYS_SIGN_normalarea_AMT_LATE_PAYMENT_mean',\n",
       "       'LATE_DAYS_SIGN_normalarea_AMT_LATE_PAYMENT_max',\n",
       "       'LATE_DAYS_SIGN_normalarea_AMT_LATE_PAYMENT_min',\n",
       "       'LATE_DAYS_SIGN_normalarea_AMT_LATE_PAYMENT_sum',\n",
       "       ...\n",
       "       'RATE_EARLY_DAYS_SIGN_mean', 'RATE_EARLY_DAYS_SIGN_max',\n",
       "       'RATE_EARLY_DAYS_SIGN_min', 'RATE_EARLY_DAYS_SIGN_sum',\n",
       "       'RATE_EARLY_DAYS_SIGN_std', 'EARLY_DAYS_SIGN_mean',\n",
       "       'EARLY_DAYS_SIGN_max', 'EARLY_DAYS_SIGN_min', 'EARLY_DAYS_SIGN_sum',\n",
       "       'EARLY_DAYS_SIGN_std'],\n",
       "      dtype='object', length=261)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(PATH + 'application_train.csv')\n",
    "test = pd.read_csv(PATH + 'application_test.csv')\n",
    "\n",
    "merge_col = ['SK_ID_CURR']\n",
    "m = pd.concat([train[merge_col], test[merge_col]])\n",
    "\n",
    "for x in set(df.columns) - set(['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER', 'SK_ID_CURR']):\n",
    "    m = m.merge(numerical(df, merge_col, x, ['mean', 'max', 'min', 'sum', 'std']))\n",
    "print('df', m.shape)\n",
    "    \n",
    "for x in p_new_cols:\n",
    "    m = m.merge(numerical(p, merge_col, x, ['mean', 'max', 'min', 'sum', 'std']))\n",
    "print('p', m.shape)\n",
    "    \n",
    "for x in inst_new_cols:\n",
    "    m = m.merge(numerical(inst, merge_col, x, ['mean', 'max', 'min', 'sum', 'std']))\n",
    "print('inst', m.shape)\n",
    "m.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T19:02:05.966809Z",
     "start_time": "2018-07-10T19:02:04.315053Z"
    }
   },
   "outputs": [],
   "source": [
    "col = []\n",
    "for x in m.columns:\n",
    "    tmp = 'inst_' + x if x != 'SK_ID_CURR' else x\n",
    "    col.append(tmp)\n",
    "m.columns = col\n",
    "m.to_pickle(PATH + 'inter/brandnew_inst2curr_with_days.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
