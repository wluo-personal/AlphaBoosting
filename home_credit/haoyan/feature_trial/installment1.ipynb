{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:31:40.363159Z",
     "start_time": "2018-07-06T19:31:36.426466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13605229, 7)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "\n",
    "inst = pd.read_pickle(PATH + '/inter/tmp/inst.pkl')\n",
    "inst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:39:23.419523Z",
     "start_time": "2018-07-06T19:39:23.388997Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def minus_name(col1, col2): return col1 + '_minus_' + col2\n",
    "def minus(df, col1, col2): return df[col1] - df[col2]\n",
    "\n",
    "def ratio_name(col1, col2): return col1 + '_divide_' + col2\n",
    "def ratio(df, col1, col2): return df[col1] / (df[col2] + 1)\n",
    "\n",
    "def positive_count(df, gp_col, col):\n",
    "    group = (df[col] > 0).astype('int8')\n",
    "    group = pd.concat([df[gp_col], group], axis=1).groupby(gp_col)[[col]].sum().reset_index().rename(columns={col: 'positivecount_'+col})\n",
    "    return group\n",
    "\n",
    "def negative_count(df, gp_col, col):\n",
    "    group = (df[col] < 0).astype('int8')\n",
    "    group = pd.concat([df[gp_col], group], axis=1).groupby(gp_col)[[col]].sum().reset_index().rename(columns={col: 'negativecount_'+col})\n",
    "    return group\n",
    "\n",
    "def count(df, gp_col, col):\n",
    "    group = df.groupby(gp_col)[[col]].count().reset_index().rename(index=str, columns={col:'count_' + '_'.join(gp_col)})\n",
    "    return group\n",
    "\n",
    "def numerical(df, gp_col, col, agg_fun):\n",
    "    _df = df.groupby(gp_col)[[col]].agg(agg_fun)\n",
    "    \n",
    "    columns = []\n",
    "    for x in _df.columns.levels[0]:\n",
    "        for y in _df.columns.levels[1]:\n",
    "            columns.append('_'.join([x, y]))\n",
    "    _df.columns = columns\n",
    "    return _df.reset_index()\n",
    "\n",
    "def feature_in_time_window(df, gp_col, col, func, agg_fun=None, n=None, time_col=None):\n",
    "    tmp = None\n",
    "    _df = df.copy()\n",
    "    if n is not None:\n",
    "        _df = _df[_df[time_col] >= n]\n",
    "    if agg_fun is None:\n",
    "        tmp = func(_df, gp_col, col)\n",
    "    else:\n",
    "        tmp = func(_df, gp_col, col, agg_fun)\n",
    "    columns = [str(abs(n))+'_'+x for x in set(tmp.columns) - set(gp_col)]\n",
    "    tmp.columns = columns\n",
    "    del _df\n",
    "    gc.collect()\n",
    "    return tmp\n",
    "\n",
    "def slope_agg(df, gp_col, x, y):\n",
    "    gp = df.copy()\n",
    "    gp_max = gp.groupby(gp_col)[[x]].max().reset_index().rename(columns={x:'max'})\n",
    "    gp_min = gp.groupby(gp_col)[[x]].min().reset_index().rename(columns={x:'min'})\n",
    "    gp = gp.merge(gp_max)\n",
    "    gp = gp.merge(gp_min)\n",
    "    gp['normal_x'] = (gp[x]-gp['max']) / (gp['max']-gp['min']+1)\n",
    "    gp['value'] = gp.groupby(gp_col)[y].shift(-1) - gp[y]\n",
    "    gp['x_diff'] = gp.groupby(gp_col)[x].shift(-1) - gp[x]\n",
    "    gp['normal_x_diff'] = gp.groupby(gp_col)['normal_x'].shift(-1) - gp['normal_x']\n",
    "    gp['slope_'+y] = gp['value'] / gp['x_diff']\n",
    "    gp['normalslope_'+y] = gp['value'] / gp['normal_x_diff']\n",
    "    r = gp.groupby(gp_col).size().reset_index()[gp_col]\n",
    "    l = ['max', 'min', 'mean', 'std']\n",
    "    r = r.merge(numerical(gp, gp_col, 'slope_'+y, l), on=gp_col, how='left')\n",
    "    r = r.merge(positive_count(gp, gp_col, 'slope_'+y), on=gp_col, how='left')\n",
    "    r = r.merge(negative_count(gp, gp_col, 'slope_'+y), on=gp_col, how='left')\n",
    "    r = r.merge(numerical(gp, gp_col, 'normalslope_'+y, l), on=gp_col, how='left')\n",
    "    r = r.merge(positive_count(gp, gp_col, 'normalslope_'+y), on=gp_col, how='left')\n",
    "    r = r.merge(negative_count(gp, gp_col, 'normalslope_'+y), on=gp_col, how='left')\n",
    "    return r\n",
    "    \n",
    "def area_under_curve(df, gp_col, x, y):\n",
    "    gp = df.copy()\n",
    "    gp_max = gp.groupby(gp_col)[[x]].max().reset_index().rename(columns={x:'max'})\n",
    "    gp_min = gp.groupby(gp_col)[[x]].min().reset_index().rename(columns={x:'min'})\n",
    "    gp = gp.merge(gp_max)\n",
    "    gp = gp.merge(gp_min)\n",
    "    gp['normal_x'] = (gp[x]-gp['max']) / (gp['max']-gp['min']+1)\n",
    "    \n",
    "    group = gp.groupby(gp_col)\n",
    "    gp['tmp'] = (group[y].shift(-1)+gp[y]) * (group[x].shift(-1)-gp[x]) / 2\n",
    "    gp['tmp_normal'] = (group[y].shift(-1)+gp[y]) * (group['normal_x'].shift(-1)-gp['normal_x']) / 2\n",
    "    return gp.groupby(gp_col).agg({'tmp':'sum', 'tmp_normal':'sum'}).reset_index().rename(columns={'tmp':x+'_area_'+y, 'tmp_normal':x+'_normalarea_'+y})\n",
    "\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:34:10.588083Z",
     "start_time": "2018-07-06T19:31:42.508318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14011460, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst0 = pd.read_pickle(PATH + '/inter/tmp/inst.pkl')\n",
    "\n",
    "gp_col = ['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER', 'DAYS_INSTALMENT', 'SK_ID_CURR']\n",
    "new = inst0.groupby(gp_col)[['AMT_INSTALMENT']].max().reset_index()\n",
    "new['AMT_PAYMENT'] = 0\n",
    "new['DAYS_ENTRY_PAYMENT'] = new['DAYS_INSTALMENT']\n",
    "inst = pd.concat([inst0, new])\n",
    "\n",
    "inst['EARLY_DAYS'] = inst['DAYS_INSTALMENT'] - inst['DAYS_ENTRY_PAYMENT']\n",
    "inst['LATE_DAYS'] = -inst['EARLY_DAYS']\n",
    "inst['LATE_DAYS_SIGN'] = (np.sign(inst['LATE_DAYS']) > 0) * inst['LATE_DAYS']\n",
    "\n",
    "p = inst.groupby(gp_col+['LATE_DAYS_SIGN']).agg({'AMT_PAYMENT': 'sum', 'DAYS_ENTRY_PAYMENT': 'max', 'AMT_INSTALMENT': 'max'}).reset_index()\n",
    "p['AMT_CUM_PAYMENT'] = p.groupby(gp_col)[['AMT_PAYMENT']].cumsum()\n",
    "p['AMT_LATE_PAYMENT'] = p['AMT_INSTALMENT'] - p['AMT_CUM_PAYMENT']\n",
    "p['AMT_LATE_PAYMENT'] = p['AMT_LATE_PAYMENT'] * (abs(p['AMT_LATE_PAYMENT'])>1e-4)\n",
    "p['RATE_LATE_PAYMENT'] = p['AMT_LATE_PAYMENT'] / p['AMT_INSTALMENT']\n",
    "p.sort_values('DAYS_ENTRY_PAYMENT', ascending=False)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T20:41:30.422877Z",
     "start_time": "2018-07-06T20:41:30.414581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121597"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "527828 - 14011460 + 13605229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T20:04:52.804340Z",
     "start_time": "2018-07-06T20:04:52.799340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER', 'DAYS_INSTALMENT', 'SK_ID_CURR',\n",
       "       'LATE_DAYS_SIGN', 'AMT_PAYMENT', 'DAYS_ENTRY_PAYMENT', 'AMT_INSTALMENT',\n",
       "       'AMT_CUM_PAYMENT', 'AMT_LATE_PAYMENT', 'RATE_LATE_PAYMENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:55:54.271120Z",
     "start_time": "2018-07-06T19:39:26.041080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12862309, 28)\n",
      "(12862309, 29)\n",
      "(12862309, 30)\n",
      "(12862309, 32)\n",
      "(12862309, 34)\n",
      "(12862309, 38)\n",
      "(12862309, 39)\n",
      "(12862309, 41)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER', 'DAYS_INSTALMENT', 'SK_ID_CURR',\n",
       "       'slope_AMT_LATE_PAYMENT_max', 'slope_AMT_LATE_PAYMENT_min',\n",
       "       'slope_AMT_LATE_PAYMENT_mean', 'slope_AMT_LATE_PAYMENT_std',\n",
       "       'positivecount_slope_AMT_LATE_PAYMENT_x',\n",
       "       'positivecount_slope_AMT_LATE_PAYMENT_y',\n",
       "       'normalslope_AMT_LATE_PAYMENT_max', 'normalslope_AMT_LATE_PAYMENT_min',\n",
       "       'normalslope_AMT_LATE_PAYMENT_mean', 'normalslope_AMT_LATE_PAYMENT_std',\n",
       "       'positivecount_normalslope_AMT_LATE_PAYMENT_x',\n",
       "       'positivecount_normalslope_AMT_LATE_PAYMENT_y',\n",
       "       'slope_RATE_LATE_PAYMENT_max', 'slope_RATE_LATE_PAYMENT_min',\n",
       "       'slope_RATE_LATE_PAYMENT_mean', 'slope_RATE_LATE_PAYMENT_std',\n",
       "       'positivecount_slope_RATE_LATE_PAYMENT_x',\n",
       "       'positivecount_slope_RATE_LATE_PAYMENT_y',\n",
       "       'normalslope_RATE_LATE_PAYMENT_max',\n",
       "       'normalslope_RATE_LATE_PAYMENT_min',\n",
       "       'normalslope_RATE_LATE_PAYMENT_mean',\n",
       "       'normalslope_RATE_LATE_PAYMENT_std',\n",
       "       'positivecount_normalslope_RATE_LATE_PAYMENT_x',\n",
       "       'positivecount_normalslope_RATE_LATE_PAYMENT_y', 'DURATION',\n",
       "       'HAS_EARLY_DAYS', 'AMT_INSTALMENT',\n",
       "       'count_SK_ID_PREV_NUM_INSTALMENT_NUMBER_DAYS_INSTALMENT_SK_ID_CURR',\n",
       "       'AMT_TOTAL_LATE', 'AMT_TOTAL_LATE_divide_AMT_INSTALMENT',\n",
       "       'LATE_DAYS_SIGN_area_AMT_LATE_PAYMENT',\n",
       "       'LATE_DAYS_SIGN_normalarea_AMT_LATE_PAYMENT',\n",
       "       'LATE_DAYS_SIGN_area_RATE_LATE_PAYMENT',\n",
       "       'LATE_DAYS_SIGN_normalarea_RATE_LATE_PAYMENT', 'SCORE',\n",
       "       'positivecount_LATE_DAYS_SIGN',\n",
       "       'positivecount_LATE_DAYS_SIGN_divide_positivecount_slope_AMT_LATE_PAYMENT_x'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = p.groupby(gp_col).size().reset_index()[gp_col]\n",
    "\n",
    "df = df.merge(slope_agg(p, gp_col, 'LATE_DAYS_SIGN', 'AMT_LATE_PAYMENT'))\n",
    "df = df.merge(slope_agg(p, gp_col, 'LATE_DAYS_SIGN', 'RATE_LATE_PAYMENT'))\n",
    "print(df.shape)\n",
    "\n",
    "p['DURATION'] = p['DAYS_ENTRY_PAYMENT'] - p['DAYS_INSTALMENT']\n",
    "df = df.merge(p.groupby(gp_col)[['DURATION']].max().reset_index(), on=gp_col, how='left')\n",
    "p.drop('DURATION', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "inst['HAS_EARLY_DAYS'] = inst['EARLY_DAYS'] > 0\n",
    "df = df.merge(inst.groupby(gp_col)[['HAS_EARLY_DAYS']].max().reset_index(), on=gp_col, how='left')\n",
    "inst.drop('HAS_EARLY_DAYS', axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "\n",
    "df = df.merge(p.groupby(gp_col)[['AMT_INSTALMENT']].max().reset_index(), on=gp_col, how='left')\n",
    "\n",
    "df = df.merge(count(inst, gp_col, 'AMT_INSTALMENT'), on=gp_col, how='left')\n",
    "count_col = [x for x in df.columns if 'count_' in x][0]\n",
    "print(df.shape)\n",
    "\n",
    "df = df.merge(p.groupby(gp_col)[['AMT_LATE_PAYMENT']].max().reset_index().rename(columns={'AMT_LATE_PAYMENT':'AMT_TOTAL_LATE'}), on=gp_col, how='left')\n",
    "name = ratio_name('AMT_TOTAL_LATE', 'AMT_INSTALMENT')\n",
    "df[name] = ratio(df, 'AMT_TOTAL_LATE', 'AMT_INSTALMENT')\n",
    "print(df.shape)\n",
    "\n",
    "df = df.merge(area_under_curve(p, gp_col, 'LATE_DAYS_SIGN', 'AMT_LATE_PAYMENT'))\n",
    "df = df.merge(area_under_curve(p, gp_col, 'LATE_DAYS_SIGN', 'RATE_LATE_PAYMENT'))\n",
    "print(df.shape)\n",
    "\n",
    "df['SCORE'] = (df['DURATION'] / df['AMT_INSTALMENT'] + df[name]) / df['AMT_INSTALMENT']\n",
    "print(df.shape)\n",
    "\n",
    "df = df.merge(positive_count(p, gp_col, 'LATE_DAYS_SIGN'), on=gp_col, how='left')\n",
    "name1 = ratio_name('positivecount_LATE_DAYS_SIGN', count_col)\n",
    "df[name1] = ratio(df, 'positivecount_LATE_DAYS_SIGN', count_col)\n",
    "print(df.shape)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH + 'application_train.csv')\n",
    "test = pd.read_csv(PATH + 'application_test.csv')\n",
    "\n",
    "merge_col = ['SK_ID_CURR']\n",
    "m = pd.concat([train[merge_col], test[merge_col]])\n",
    "m = m.merge(count(p, merge_col, 'DAYS_ENTRY_PAYMENT'), on=merge_col, how='left')\n",
    "m = m.merge(count(df, merge_col, 'SCORE'), on=merge_col, how='left')\n",
    "print(m.shape)\n",
    "\n",
    "\n",
    "\n",
    "for x in ['AMT_INSTALMENT', 'DURATION', 'AMT_TOTAL_LATE', 'LATE_DAYS_SIGN'] + [x for x in df.columns if '_area_' in x]:\n",
    "    m = m.merge(numerical(df, merge_col, x, ['mean', 'max', 'min', 'sum', 'std']))\n",
    "print(m.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
