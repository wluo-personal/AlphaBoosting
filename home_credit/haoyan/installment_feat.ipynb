{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T08:19:53.974627Z",
     "start_time": "2018-06-16T08:19:53.642026Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def _set_type(series, dtype):\n",
    "    _max, _min = max(series), min(series)\n",
    "    if dtype == 'uint':\n",
    "        if _max <= 255: return np.uint8\n",
    "        elif _max <= 65535: return np.uint16\n",
    "        elif _max <= 4294967295: return np.uint32\n",
    "        else: return np.uint64\n",
    "    elif dtype == 'int':\n",
    "        if _min >= -128 and _max <= 127: return np.int8\n",
    "        elif _min >=-32768 and _max <= 32767: return np.int16\n",
    "        elif _min >= -2147483648 and _max <= 2147483647: return np.int32\n",
    "        else: return np.int64\n",
    "    elif dtype == 'float':\n",
    "        if max(abs(_min), _max) <= 3.4028235e+38: return np.float32\n",
    "        else: return np.float64\n",
    "\n",
    "def split_categorical_feature(df, group_col, calc_col):\n",
    "    tmp_df = pd.concat([df[group_col], pd.get_dummies(df[calc_col], prefix=calc_col)], axis=1).groupby(by=group_col).sum().reset_index()\n",
    "    dtype = {x: _set_type(tmp_df[x], 'uint') for x in tmp_df.columns if x != group_col}\n",
    "    for x in tmp_df:\n",
    "        if x in df.columns:\n",
    "            dtype[x] = df[x].dtype\n",
    "    return tmp_df.astype(dtype)\n",
    "\n",
    "def score(df, group_col, calc_col, time_col, score_map, table_name):\n",
    "    total = list(group_col)\n",
    "    total.extend([calc_col, time_col])\n",
    "    _df = df.sort_values('MONTHS_BALANCE').reset_index()\n",
    "    _df[calc_col] = _df[calc_col].map(score_map)\n",
    "    group = _df.groupby(by=group_col)\n",
    "    _df[calc_col] = (group[calc_col].shift(1).fillna(0) + group[calc_col].shift(-1).fillna(0) + _df[calc_col]) ** 2 / np.exp(-(_df[time_col])**2/144/2)\n",
    "    dtype = {x: df[x].dtype for x in group_col if x in df.columns}\n",
    "    dtype[calc_col] = _set_type(_df[calc_col], 'float')\n",
    "    __df = _df[[group_col, calc_col]].astype(dtype).rename(index=str, columns={calc_col: table_name + '_score'})\n",
    "    del _df\n",
    "    gc.collect()\n",
    "    return __df\n",
    "\n",
    "def count(df, group_col, calc_col, table_name):\n",
    "    group = df[[group_col, calc_col]].groupby(by=group_col)[[calc_col]].count().reset_index()\n",
    "    dtype = {x: df[x].dtype for x in group_col if x in df.columns}\n",
    "    dtype[calc_col] = _set_type(group[calc_col], 'uint')\n",
    "    _df = group.astype(dtype).rename(index=str, columns={calc_col: table_name + '_' + calc_col + '_count'})\n",
    "    return _df\n",
    "\n",
    "def linear(df_, group_col, value_col, time_col, table_name):\n",
    "    l = []\n",
    "    df = df_.sort_values(time_col).reset_index()\n",
    "    gp = df[[group_col, time_col, value_col]].groupby(by=group_col)\n",
    "    for i, group in gp:\n",
    "        lg = LinearRegression()\n",
    "        lg.fit(group[[time_col]], group[[value_col]])\n",
    "        \n",
    "        group1 = group.copy()\n",
    "        group1[time_col] = (group1[time_col] - group1[time_col].max()) / (group1[time_col].max() - group1[time_col].min() + 1)\n",
    "        lg1 = LinearRegression()\n",
    "        lg1.fit(group[[time_col]], group[[value_col]])\n",
    "        l.append([i, lg.coef_[0][0], lg1.coef_[0][0]])\n",
    "        \n",
    "    tmp_df = pd.DataFrame(l, columns=[group_col, table_name + '_' + 'lg_coef', table_name + '_' + 'lg_normalized_coef'])\n",
    "    dtype = {x: df[x].dtype for x in group_col if x in df.columns}\n",
    "    dtype[table_name + '_' + 'lg_coef'] = _set_type(tmp_df[table_name + '_' + 'lg_coef'], 'float')\n",
    "    dtype[table_name + '_' + 'lg_normalized_coef'] = _set_type(tmp_df[table_name + '_' + 'lg_normalized_coef'], 'float')\n",
    "    return tmp_df.astype(dtype)\n",
    "\n",
    "def last_before_C(df_, group_col, value_col, time_col, score_map, table_name):\n",
    "    l = []\n",
    "    df = df_.sort_values('MONTHS_BALANCE', ascending=False).reset_index()\n",
    "    df[value_col] = df[value_col].map(score_map)\n",
    "    d = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        idx = df.loc[i, group_col]\n",
    "        val = df.loc[i, value_col]\n",
    "        if d.get(idx) == None:\n",
    "            d[idx] = 'on C'\n",
    "        elif d.get(idx) == 'on C':\n",
    "            if val != 7:\n",
    "                d[idx] = 'not on C'\n",
    "                l.append([idx, val])\n",
    "    tmp = pd.DataFrame(l, columns=[group_col, table_name+'_last_on_C_'+value_col])\n",
    "    return tmp.astype({group_col: df[group_col].dtype, table_name+'_last_on_C_'+value_col: _set_type(tmp[table_name+'_last_on_C_'+value_col], 'uint')})\n",
    "\n",
    "def ratio_name(numerator, denominator): return numerator + '_divide_' + denominator\n",
    "\n",
    "def ratio(df, numerator, denominator):\n",
    "    return df[numerator] / df[denominator]\n",
    "\n",
    "def substraction_name(col1, col2): return col1 + '_minus_' + col2\n",
    "\n",
    "def substraction(df, col1, col2):\n",
    "    return df[col1] - df[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T08:19:54.436965Z",
     "start_time": "2018-06-16T08:19:54.348985Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_agg( df, gp_col, agg_col, extrafunc_list = None):\n",
    "    \n",
    "    agg_list = ['max', 'min', 'std','mean']\n",
    "    '''\n",
    "    Possible extrafunc_list: ['sum','median','two_minus_one_third','positive_count', 'negative_count','standard_error', 'trimmed_mean_10_pct', 'trimmed_mean_25_pct','normed_std', 'max_minus_min','one_third','two_third']\n",
    "    '''\n",
    "    if extrafunc_list:\n",
    "        if 'one_third' in extrafunc_list:\n",
    "            def one_third(series):\n",
    "                return series.quantile(1/3)\n",
    "            \n",
    "        if 'two_third' in extrafunc_list:\n",
    "            def two_third(series):\n",
    "                return series.quantile(2/3)\n",
    "            \n",
    "        if 'max_minus_min' in extrafunc_list:\n",
    "            def max_minus_min(series):\n",
    "                return (series.max() - series.min())\n",
    "        \n",
    "        if 'two_minus_one_third' in extrafunc_list:\n",
    "            def two_minus_one_third(series):\n",
    "                return(series.quantile(0.66666) - series.quantile(0.33333))\n",
    "       \n",
    "        if 'positive_count' in extrafunc_list:\n",
    "            def positive_count(series):\n",
    "                return pd.Series(series > 0).sum()\n",
    "\n",
    "        if 'negative_count' in extrafunc_list:\n",
    "            def negative_count(series):\n",
    "                return pd.Series(series < 0).sum()\n",
    "\n",
    "        if 'standard_error' in extrafunc_list:\n",
    "            def standard_error(series):\n",
    "                return series.std()/np.sqrt(len(series))\n",
    "\n",
    "        if 'normed_std' in extrafunc_list:\n",
    "            def normed_std(series):\n",
    "                return series.std()/series.mean()\n",
    "\n",
    "        if 'trimmed_mean_10_pct' in extrafunc_list:\n",
    "            def trimmed_mean_10_pct(series):\n",
    "                return stats.trim_mean(series.dropna(), 0.1)\n",
    "\n",
    "        if 'trimmed_mean_25_pct' in extrafunc_list:\n",
    "            def trimmed_mean_25_pct(series):\n",
    "                return stats.trim_mean(series.dropna(), 0.25)\n",
    "        \n",
    "        list_tocall = []\n",
    "        for i in extrafunc_list:\n",
    "            if i not in set(['sum', 'median']):\n",
    "                list_tocall.append(eval(i))\n",
    "            \n",
    "    if extrafunc_list != None:   \n",
    "        agg_list.extend(list_tocall)\n",
    "    \n",
    "    _df = df.groupby(gp_col).agg({agg_col:agg_list})\n",
    "    columns = []\n",
    "    for pre in _df.columns.levels[0]:\n",
    "        for middle in _df.columns.levels[1]:\n",
    "            columns.append('bureau_%s_%s' %(pre,middle))\n",
    "    _df.columns = columns\n",
    "    \n",
    "    return _df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T08:20:05.309261Z",
     "start_time": "2018-06-16T08:19:56.295694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installments_payments done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "inst = pd.read_csv(PATH + 'installments_payments.csv')\n",
    "print('installments_payments done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T08:20:10.559421Z",
     "start_time": "2018-06-16T08:20:05.398713Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sv_path = PATH + 'data/'\n",
    "inst[substraction_name('DAYS_INSTALMENT', 'DAYS_ENTRY_PAYMENT')] = substraction(inst, 'DAYS_INSTALMENT' ,'DAYS_ENTRY_PAYMENT')\n",
    "\n",
    "inst[substraction_name('AMT_PAYMENT', 'AMT_INSTALMENT')] = substraction(inst, 'AMT_PAYMENT' ,'AMT_INSTALMENT')\n",
    "\n",
    "inst['late_days'] = 0\n",
    "x = inst['DAYS_INSTALMENT_minus_DAYS_ENTRY_PAYMENT'] < 0\n",
    "inst['late_days'][x] = inst['DAYS_INSTALMENT_minus_DAYS_ENTRY_PAYMENT'][x]\n",
    "\n",
    "inst['AMT_PAYMENT_minus_AMT_INSTALMENT_divide_DAYS_INSTALMENT_minus_DAYS_ENTRY_PAYMENT'] = inst['AMT_PAYMENT_minus_AMT_INSTALMENT'] / abs(inst['late_days'] - 1)\n",
    "inst = inst.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T08:35:19.877506Z",
     "start_time": "2018-06-16T08:20:10.651998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "x = linear(inst, 'SK_ID_CURR', 'AMT_PAYMENT_minus_AMT_INSTALMENT', 'DAYS_ENTRY_PAYMENT', 'installment')\n",
    "x.to_pickle(sv_path + '1.pkl')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T08:51:10.397664Z",
     "start_time": "2018-06-16T08:35:19.976334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "y = linear(inst, 'SK_ID_CURR', 'DAYS_INSTALMENT_minus_DAYS_ENTRY_PAYMENT', 'DAYS_ENTRY_PAYMENT', 'installment')\n",
    "y.to_pickle(sv_path + '2.pkl')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T09:06:26.745039Z",
     "start_time": "2018-06-16T08:51:10.511777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "z = linear(inst, 'SK_ID_CURR', 'AMT_PAYMENT_minus_AMT_INSTALMENT_divide_DAYS_INSTALMENT_minus_DAYS_ENTRY_PAYMENT', 'DAYS_ENTRY_PAYMENT', 'installment')\n",
    "z.to_pickle(sv_path + '3.pkl')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T08:14:12.874659Z",
     "start_time": "2018-06-16T08:09:48.598Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x.SK_ID_CURR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:33:42.688117Z",
     "start_time": "2018-06-16T10:33:40.775729Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "train = pd.read_pickle(PATH + 'train_merged.pkl')\n",
    "test = pd.read_pickle(PATH + 'test_merged.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:34:05.351791Z",
     "start_time": "2018-06-16T10:33:50.811295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.pkl\n",
      "2.pkl\n",
      "1.pkl\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for x in os.listdir(PATH + 'data/'):\n",
    "    if x.split('.')[-1] == 'pkl':\n",
    "        print(x)\n",
    "        tmp = pd.read_pickle(PATH + 'data/' + x)\n",
    "        train = train.merge(tmp, on='SK_ID_CURR', how='left')\n",
    "        test = test.merge(tmp, on='SK_ID_CURR', how='left')\n",
    "train.to_pickle(PATH + 'train_merged.pkl')\n",
    "test.to_pickle(PATH + 'test_merged.pkl')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
