{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:29:57.718125Z",
     "start_time": "2018-08-27T15:29:55.456285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: (307511, 764)\n",
      "test shape is: (48744, 763)\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../LIB/')\n",
    "from env import ENV\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "print_to_file = False \n",
    "test_run = False \n",
    "\n",
    "train = pd.read_pickle(ENV.lightgbm_train_764.value)\n",
    "print('train shape is: {}'.format(train.shape))\n",
    "test = pd.read_pickle(ENV.lightgbm_test_764.value)\n",
    "print('test shape is: {}'.format(test.shape))\n",
    "fe_id = 'comb_764'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:29:58.417092Z",
     "start_time": "2018-08-27T15:29:58.369519Z"
    }
   },
   "outputs": [],
   "source": [
    "train['SK_ID_CURR'] = train['SK_ID_CURR'].astype(int)\n",
    "test['SK_ID_CURR'] = test['SK_ID_CURR'].astype(int)\n",
    "targets = train.TARGET.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:29:58.888979Z",
     "start_time": "2018-08-27T15:29:58.885158Z"
    }
   },
   "outputs": [],
   "source": [
    "train_id = train['SK_ID_CURR']\n",
    "test_id = test['SK_ID_CURR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:29:59.967348Z",
     "start_time": "2018-08-27T15:29:59.900971Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_time(timezone='America/New_York', time_format='%Y-%m-%d %H:%M:%S'):\n",
    "    from datetime import datetime\n",
    "    from dateutil import tz\n",
    "\n",
    "    # METHOD 1: Hardcode zones:\n",
    "    from_zone = tz.gettz('UTC')\n",
    "    to_zone = tz.gettz(timezone)\n",
    "\n",
    "    utc = datetime.utcnow()\n",
    "\n",
    "    # Tell the datetime object that it's in UTC time zone since \n",
    "    # datetime objects are 'naive' by default\n",
    "    utc = utc.replace(tzinfo=from_zone)\n",
    "\n",
    "    # Convert time zone\n",
    "    est = utc.astimezone(to_zone)\n",
    "\n",
    "    return est.strftime(time_format)\n",
    "\n",
    "import sys, time\n",
    "class Logger(object):\n",
    "    def __init__(self, logtofile=True, logfilename='log'):\n",
    "        self.terminal = sys.stdout\n",
    "        self.logfile = \"{}_{}.log\".format(logfilename, int(time.time()))\n",
    "        self.logtofile = logtofile\n",
    "\n",
    "    def write(self, message):\n",
    "        #         self.terminal.write(message)\n",
    "        if self.logtofile:\n",
    "            self.log = open(self.logfile, \"a\")\n",
    "            self.log.write('[' + get_time() + '] ' + message)\n",
    "            self.log.close()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass\n",
    "\n",
    "\n",
    "def divert_printout_to_file():\n",
    "    sys.stdout = Logger(logfilename='logfile')\n",
    "\n",
    "if print_to_file:\n",
    "    divert_printout_to_file()  # note: comment this to use pdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, train_df, test_df, holdout, num_folds, submission_file_name, fe_img_name, stratified = False, debug= False, colsample=0.67, max_depth=8, num_leaves=31, min_child_samples=20, subsample=0.7, reg_lambda=0.3, lr=0.04, seed=1001, verbose=100, rounds=None):\n",
    "    print(train_df.shape, test_df.shape, holdout.shape)\n",
    "    print('MEAN: train({}) vs holdout({}): '.format(len(train_df), len(holdout)), train_df['TARGET'].mean(), holdout['TARGET'].mean())\n",
    "    # Divide in training/validation and test data\n",
    "    if df is not None:\n",
    "        train_df = df[df['TARGET'].notnull()]\n",
    "        test_df = df[df['TARGET'].isnull()]\n",
    "        print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "        del df\n",
    "        gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "        \n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    holdout_final_preds = np.zeros(holdout.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feature_importance_gain_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    train_scores = []\n",
    "    holdout_scores = []\n",
    "    scores = []\n",
    "    actual_y = []\n",
    "    pred_y = []\n",
    "    diff_val_holdout = []\n",
    "    SK_ID_CURR = []\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "#         print('valid index : ',list(valid_idx)[:5])\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "#         print('MEAN: train({}) vs valid({}): '.format(len(train_y), len(valid_y)), np.mean(train_y), np.mean(valid_y))\n",
    "        SK_ID_CURR.extend(train_df['SK_ID_CURR'].iloc[valid_idx])\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=18,\n",
    "            n_estimators=30000,\n",
    "            learning_rate=lr,\n",
    "            num_leaves=num_leaves,\n",
    "            colsample_bytree=colsample, # 0.67\n",
    "            subsample=subsample,\n",
    "            subsample_freq=0, ## disable subsampling\n",
    "            max_depth=max_depth,\n",
    "            reg_alpha=0.65,\n",
    "            reg_lambda=reg_lambda,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            min_child_samples=min_child_samples,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "        if rounds is not None:\n",
    "            clf.n_estimators = rounds\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric= 'auc', verbose=verbose)\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "            sub_preds += clf.predict_proba(test_df[feats])[:, 1] / folds.n_splits\n",
    "            holdout_preds = clf.predict_proba(holdout[feats])[:, 1] \n",
    "        else:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric= 'auc', verbose=verbose, early_stopping_rounds= 200)\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "            sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "            holdout_preds = clf.predict_proba(holdout[feats], num_iteration=clf.best_iteration_)[:, 1] \n",
    "            \n",
    "        holdout_final_preds += holdout_preds / folds.n_splits\n",
    "        score = roc_auc_score(valid_y, oof_preds[valid_idx])\n",
    "        train_score = clf.best_score_['training']['auc']\n",
    "        holdout_score = roc_auc_score(holdout['TARGET'], holdout_preds)\n",
    "        diff = abs(score - holdout_score)\n",
    "        actual_y.extend(list(valid_y))\n",
    "        pred_y.extend(list(oof_preds[valid_idx]))\n",
    "        best_rounds = rounds if rounds is not None else clf.best_iteration_\n",
    "        print('Fold %2d [%5d] AUC : ho: %.6f / te: %.6f / tr: %.6f (diff: %.6f)' % (n_fold + 1, best_rounds, holdout_score, score,  train_score, diff))\n",
    "        scores.append(score)\n",
    "        train_scores.append(train_score)\n",
    "        holdout_scores.append(holdout_score)\n",
    "        diff_val_holdout.append(diff)\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        fold_importance_gain_df = pd.DataFrame()\n",
    "        fold_importance_gain_df[\"feature\"] = feats\n",
    "        fold_importance_gain_df[\"importance\"] = clf.booster_.feature_importance(importance_type='gain')\n",
    "        fold_importance_gain_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_gain_df = pd.concat([feature_importance_gain_df, fold_importance_gain_df], axis=0)\n",
    "        \n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "    holdout_roc = roc_auc_score(holdout['TARGET'], holdout_final_preds)\n",
    "    holdout_mean = np.mean(holdout_scores)\n",
    "    full_te_mean = np.mean(scores)\n",
    "    full_tr_mean = np.mean(train_scores)\n",
    "    predsAndActual = pd.DataFrame()\n",
    "    predsAndActual['preds'] = pred_y\n",
    "    predsAndActual['label'] = actual_y\n",
    "    predsAndActual['SK_ID_CURR'] = SK_ID_CURR\n",
    "    predsAndActual.to_pickle('{}_oof.pkl'.format(submission_file_name))\n",
    "#     print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    print('Full HO score %.6f' % holdout_roc)\n",
    "    print('FULL HO mean {:.6f}, std {:.6f}'.format(holdout_mean, np.std(holdout_scores)))\n",
    "    print('FULL TE mean {:.6f}, std {:.6f}'.format(full_te_mean, np.std(scores)))\n",
    "    print('FULL TR mean {:.6f}, std {:.6f}'.format(full_tr_mean, np.std(train_scores)))\n",
    "    print('FULL DIFF mean {:.6f}, std {:.6f}'.format(np.mean(diff_val_holdout), np.std(diff_val_holdout)))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        print(submission_file_name)\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "#     if not print_to_file:\n",
    "#         display_importances(feature_importance_df, fe_img_name)\n",
    "    feature_importance_df = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    feature_importance_gain_df = feature_importance_gain_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    return feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds,test_df \n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_, fe_img_name):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fe_img_name+'.png')\n",
    "\n",
    "\n",
    "def convert_and_save_imp_df(fe_imp_df, dumpfilename):\n",
    "    fe_imp_df_mean = fe_imp_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    pickle.dump(fe_imp_df_mean, open(dumpfilename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:30:04.421854Z",
     "start_time": "2018-08-27T15:30:04.411181Z"
    }
   },
   "outputs": [],
   "source": [
    "def runlgb(train, test, holdout):\n",
    "    colsamples = [0.07]#[0.1,0.15,0.2]#[0.03,0.04,0.05,0.06,0.07,0.08]\n",
    "    seeds = [20]#[300,4000,50000,600000,7000000,80000000,523445,31275479] # 20\n",
    "    depth = [5]\n",
    "    leaves = [16]\n",
    "    min_child_sam = [20]#, 800]\n",
    "    subsamples = [1]#0.8, 0.7, 0.6, 0.5, 0.4] # was 1\n",
    "    reg_lambdas = [0.5]\n",
    "    # lrs = lrs.tolist()\n",
    "    lrs2 = [0.05]\n",
    "    nfolds = 5\n",
    "    rounds = [None] #[1000]#, 1300, 1600, 1900, 2200, 2500]\n",
    "    for seed in seeds:\n",
    "        for colsample in colsamples:\n",
    "            for d in depth:\n",
    "                for l in leaves:\n",
    "                    for mcs in min_child_sam:\n",
    "                        for subsample in subsamples:\n",
    "                            for reg_lambda in reg_lambdas:\n",
    "                                for lr in lrs2:\n",
    "                                    for r in rounds:\n",
    "                                        filename = 'fe_936_col{}_lr{}_n{}'.format(len(train.columns), lr, nfolds)\n",
    "                                        print('#############################################')\n",
    "                                        print(colsample, seed, d, l, mcs, subsample, reg_lambda, lr, 'nfolds:', nfolds)\n",
    "                                        print('#############################################')\n",
    "                                        numfeats = len(train.columns)\n",
    "                                        with timer(\"Run LightGBM with kfold\"):\n",
    "                                            return kfold_lightgbm(None, train, test, holdout, nfolds, filename+'.csv', filename, colsample=colsample, verbose=None, max_depth=d, num_leaves=l, min_child_samples=mcs, subsample=subsample, reg_lambda=reg_lambda, lr=lr, seed=seed, stratified=True, rounds=r,debug=False)\n",
    "    #                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add Feature Wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:51:51.043484Z",
     "start_time": "2018-08-26T16:49:29.865090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(339587, 19)\n",
      "Index(['SK_ID_CURR', 'Wei_Normed_CNT_LATE_PAYMENT_MEAN',\n",
      "       'Wei_Normed_CNT_LATE_PAYMENT_MAX', 'Wei_Normed_CNT_LESS_PAYMENT_MEAN',\n",
      "       'Wei_Normed_CNT_LESS_PAYMENT_MAX', 'Wei_Install_Payment_Rate_MEAN',\n",
      "       'Wei_Install_Payment_Rate_MIN', 'Wei_CNT_installment_per_version_STD',\n",
      "       'Wei_Remaining_AMT_Payment_TOTAL', 'Wei_CNT_NOT_TERMINATION',\n",
      "       'Wei_Normed_CNT_LATE_PAYMENT_LAST', 'Wei_Normed_CNT_LESS_PAYMENT_LAST',\n",
      "       'Wei_Install_Payment_Rate_LAST', 'Wei_CNT_installment_per_version_LAST',\n",
      "       'Wei_Remaining_AMT_Payment_LAST', 'Wei_Remaning_CNT_Payment_TOTAL',\n",
      "       'Wei_IF_TERMINATION_LAST', 'Wei_Remaing_Payment_Ratio_CURR',\n",
      "       'Wei_TOTAl_NEEDPAY_INCOME_RATIO'],\n",
      "      dtype='object')\n",
      "(307511, 782)\n",
      "(48744, 781)\n"
     ]
    }
   ],
   "source": [
    "extra_feature_wei = pd.read_pickle('../../data/add_features/install_preapp_hand_fe.pkl')\n",
    "\n",
    "# sure_add_features_wei = ['Wei_Remaning_CNT_Payment_TOTAL',\n",
    "#  'Wei_TOTAl_NEEDPAY_INCOME_RATIO',\n",
    "#  'Wei_Remaining_AMT_Payment_TOTAL',\n",
    "#  'Wei_Normed_CNT_LATE_PAYMENT_LAST','SK_ID_CURR']\n",
    "# extra_feature_wei = extra_feature_wei[sure_add_features_wei]\n",
    "\n",
    "print(extra_feature_wei.shape)\n",
    "print(extra_feature_wei.columns)\n",
    "\n",
    "train = train.merge(extra_feature_wei, how='left', left_on='SK_ID_CURR',right_on='SK_ID_CURR')\n",
    "print(train.shape)\n",
    "\n",
    "test = test.merge(extra_feature_wei, how='left', left_on='SK_ID_CURR',right_on='SK_ID_CURR')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add Feature Shiyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-26T16:51:54.939552Z",
     "start_time": "2018-08-26T16:51:53.588735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 790)\n",
      "(48744, 789)\n"
     ]
    }
   ],
   "source": [
    "extra_feature_shiyi = pd.read_pickle('../../data/add_features/shiyi/shiyifeature1.pkl')\n",
    "\n",
    "\n",
    "\n",
    "train = train.merge(extra_feature_shiyi, how='left', left_on='SK_ID_CURR',right_on='SK_ID_CURR')\n",
    "print(train.shape)\n",
    "\n",
    "test = test.merge(extra_feature_shiyi, how='left', left_on='SK_ID_CURR',right_on='SK_ID_CURR')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:30:51.868310Z",
     "start_time": "2018-08-27T15:30:51.864771Z"
    }
   },
   "outputs": [],
   "source": [
    "# sure_drop = pickle.load(open('../../data/add_features/dropping0824_list','rb'))\n",
    "sure_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:30:53.297255Z",
     "start_time": "2018-08-27T15:30:52.501584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 762)\n",
      "(48744, 761)\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['NAME_EDUCATION_TYPE_CODE_GENDER_AMT_CREDIT_mean_abs_diff',\n",
    "                'inst_DAYS_INSTALMENT_std']\n",
    "\n",
    "drop_columns = list(set(sure_drop + drop_columns))\n",
    "train = train.drop(drop_columns,axis=1)\n",
    "print(train.shape)\n",
    "test = test.drop(drop_columns,axis=1)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:30:53.895337Z",
     "start_time": "2018-08-27T15:30:53.796030Z"
    }
   },
   "outputs": [],
   "source": [
    "train_drop = train.copy()\n",
    "test_drop = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:30:55.799711Z",
     "start_time": "2018-08-27T15:30:54.447322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: train(307480) vs holdout(31):  0.08072720176922077 0.0967741935483871\n",
      "(307480, 762) (48744, 761) (31, 762)\n"
     ]
    }
   ],
   "source": [
    "train_df, holdout = train_test_split(train_drop, test_size=1/10000, random_state=99)\n",
    "print('MEAN: train({}) vs holdout({}): '.format(len(train_df), len(holdout)), train_df['TARGET'].mean(), holdout['TARGET'].mean())\n",
    "print(train_df.shape, test_drop.shape, holdout.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:33:20.523710Z",
     "start_time": "2018-08-27T15:30:56.532876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "0.07 20 5 16 20 1 0.5 0.05 nfolds: 5\n",
      "#############################################\n",
      "(307511, 762) (48744, 761) (31, 762)\n",
      "MEAN: train(307511) vs holdout(31):  0.08072881945686496 0.0967741935483871\n",
      "Fold  1 [ 1145] AUC : ho: 0.773810 / te: 0.793847 / tr: 0.863795 (diff: 0.020038)\n",
      "Fold  2 [ 1115] AUC : ho: 0.738095 / te: 0.795462 / tr: 0.862026 (diff: 0.057366)\n",
      "Fold  3 [ 1117] AUC : ho: 0.750000 / te: 0.797585 / tr: 0.862372 (diff: 0.047585)\n",
      "Fold  4 [ 1283] AUC : ho: 0.773810 / te: 0.795941 / tr: 0.869706 (diff: 0.022131)\n",
      "Fold  5 [ 1084] AUC : ho: 0.714286 / te: 0.798190 / tr: 0.860893 (diff: 0.083904)\n",
      "Full HO score 0.761905\n",
      "FULL HO mean 0.750000, std 0.022588\n",
      "FULL TE mean 0.796205, std 0.001551\n",
      "FULL TR mean 0.863759, std 0.003115\n",
      "FULL DIFF mean 0.046205, std 0.023715\n",
      "fe_936_col762_lr0.05_n5.csv\n",
      "Run LightGBM with kfold - done in 144s\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds,test_preds = runlgb(train_drop, test_drop, holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:33:23.685422Z",
     "start_time": "2018-08-27T15:33:23.678056Z"
    }
   },
   "outputs": [],
   "source": [
    "def large_new(train_ori,test_preds,th=0.5,label='TARGET',random_state=19):\n",
    "    print('original train shape is:{}. Test shape is: {}'.format(train_ori.shape, test_preds.shape))\n",
    "    large_test = test_preds[test_preds[label] > th].copy()\n",
    "    print('In test, the prediction greater than {} is selected. The shape is: {}'.format(th, large_test.shape))\n",
    "    large_test_ori = large_test.copy()\n",
    "    large_test[label] = 1\n",
    "    index_large = large_test.index\n",
    "    \n",
    "    train_new = pd.concat([train_ori,large_test])\n",
    "    train_new = train_new.sample(frac=1,random_state=random_state)\n",
    "    test_new = test_preds.drop(index_large)\n",
    "    print('new train shape is: {}'.format(train_new.shape))\n",
    "    print('new test shape is: {}'.format(test_new.shape))\n",
    "    \n",
    "    return train_new,test_new,large_test_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:33:27.219352Z",
     "start_time": "2018-08-27T15:33:24.353327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original train shape is:(307511, 762). Test shape is: (48744, 762)\n",
      "In test, the prediction greater than 0.6 is selected. The shape is: (62, 762)\n",
      "new train shape is: (307573, 762)\n",
      "new test shape is: (48682, 762)\n"
     ]
    }
   ],
   "source": [
    "train_new,test_new,large_test = large_new(train_drop,test_drop,th=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:35:57.252296Z",
     "start_time": "2018-08-27T15:33:30.514573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "0.07 20 5 16 20 1 0.5 0.05 nfolds: 5\n",
      "#############################################\n",
      "(307573, 762) (48682, 762) (31, 762)\n",
      "MEAN: train(307573) vs holdout(31):  0.08091412445175616 0.0967741935483871\n",
      "Fold  1 [ 1071] AUC : ho: 0.773810 / te: 0.792599 / tr: 0.861578 (diff: 0.018789)\n",
      "Fold  2 [ 1520] AUC : ho: 0.761905 / te: 0.795077 / tr: 0.879233 (diff: 0.033172)\n",
      "Fold  3 [ 1135] AUC : ho: 0.738095 / te: 0.800065 / tr: 0.861707 (diff: 0.061970)\n",
      "Fold  4 [ 1039] AUC : ho: 0.726190 / te: 0.797378 / tr: 0.858906 (diff: 0.071188)\n",
      "Fold  5 [ 1294] AUC : ho: 0.773810 / te: 0.798421 / tr: 0.870835 (diff: 0.024611)\n",
      "Full HO score 0.761905\n",
      "FULL HO mean 0.754762, std 0.019343\n",
      "FULL TE mean 0.796708, std 0.002615\n",
      "FULL TR mean 0.866452, std 0.007560\n",
      "FULL DIFF mean 0.041946, std 0.020831\n",
      "fe_936_col762_lr0.05_n5.csv\n",
      "Run LightGBM with kfold - done in 147s\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds,test_preds = runlgb(train_new, test_new, holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:36:09.783923Z",
     "start_time": "2018-08-27T15:36:09.533743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48744, 2)\n"
     ]
    }
   ],
   "source": [
    "test_sub = test[['SK_ID_CURR']].merge(pd.concat([test_new,large_test])[['SK_ID_CURR','TARGET']],how='left',left_on='SK_ID_CURR',right_on='SK_ID_CURR')\n",
    "print(test_sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:36:17.506974Z",
     "start_time": "2018-08-27T15:36:17.378465Z"
    }
   },
   "outputs": [],
   "source": [
    "test_sub.to_csv('best_psudo_th0.6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T15:28:44.378259Z",
     "start_time": "2018-08-27T15:28:44.370821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_sub['TARGET'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
