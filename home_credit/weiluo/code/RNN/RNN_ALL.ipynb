{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:38:22.185239Z",
     "start_time": "2018-08-20T04:38:21.099808Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../LIB/')\n",
    "from env import ENV\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU,CuDNNGRU,Flatten,BatchNormalization\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from sklearn.utils import shuffle\n",
    "import gc\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:38:28.676340Z",
     "start_time": "2018-08-20T04:38:22.186905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 764)\n",
      "(48744, 763)\n",
      "(356255, 763)\n"
     ]
    }
   ],
   "source": [
    "X_Train = pd.read_pickle(ENV.lightgbm_train_764_nn.value)\n",
    "print(X_Train.shape)\n",
    "X_Test = pd.read_pickle(ENV.lightgbm_test_764_nn.value)\n",
    "print(X_Test.shape)\n",
    "X = pd.concat([X_Train.drop('TARGET',axis=1),X_Test])\n",
    "print(X.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:38:34.054742Z",
     "start_time": "2018-08-20T04:38:28.677749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous app shape: (1670214, 322)\n",
      "bureau shape: (1716428, 124)\n"
     ]
    }
   ],
   "source": [
    "X_pre_combine = pd.read_pickle(ENV.previous_app_combine_rnnALL.value)\n",
    "print('previous app shape: {}'.format(X_pre_combine.shape))\n",
    "\n",
    "\n",
    "X_bu_fe = pd.read_pickle(ENV.bureau_cleaned_rnnALL.value)\n",
    "print('bureau shape: {}'.format(X_bu_fe.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:38:34.066056Z",
     "start_time": "2018-08-20T04:38:34.056285Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_main_doc(X,categorical_col):\n",
    "    #1. create document\n",
    "    X_cal_values = X[categorical_col].values\n",
    "    X_doc = []\n",
    "    for each_line in X_cal_values:\n",
    "        doc = ' '.join(each_line)\n",
    "        X_doc.append(doc)\n",
    "        \n",
    "    #2. get max feature! max unique words\n",
    "    max_features = 0\n",
    "    for each in tqdm(categorical_col):\n",
    "        max_features+=X[each].nunique()\n",
    "    print('number of unique category is : {}'.format(max_features))\n",
    "    \n",
    "    #3. word to sequence\n",
    "    tok=text.Tokenizer(num_words=max_features,lower=True,filters='')\n",
    "    tok.fit_on_texts(X_doc)\n",
    "    maxlen = len(categorical_col)\n",
    "    X_cal=tok.texts_to_sequences(X_doc)\n",
    "    X_cal = sequence.pad_sequences(X_cal,maxlen=maxlen)\n",
    "    \n",
    "    return X_cal,max_features\n",
    "\n",
    "def one_hot_encoding(df,col,pre_fix,drop=True):\n",
    "    df = df.copy()\n",
    "    df[col] = df[col].fillna('NA_NOT_FOUND')\n",
    "    col_name_list = []\n",
    "    print('before encoding, shape is: {}'.format(df.shape))\n",
    "    for each in df[col].unique():\n",
    "        name = str(each)\n",
    "        col_name = pre_fix + '_'+ name.replace(' ','_')\n",
    "        col_name_list.append(col_name)\n",
    "        df[col_name] = 0\n",
    "        df.loc[df[col]==each,col_name] = 1\n",
    "    if drop:\n",
    "        df = df.drop([col],axis=1)\n",
    "    print('after encoding, shape is: {}'.format(df.shape))\n",
    "    return df,col_name_list\n",
    "\n",
    "def get_embeddings_index(sorted_df,nor_ebd):\n",
    "    embeddings_index={}\n",
    "    words_values = sorted_df['words'].values\n",
    "    for index in range(len(words_values)):\n",
    "        embeddings_index  [words_values[index]] = nor_ebd[index,:]\n",
    "    return embeddings_index\n",
    "\n",
    "def create_document(sorted_df):\n",
    "    #Create document\n",
    "    ids = sorted_df.SK_ID_CURR.values\n",
    "    words = sorted_df.words.values\n",
    "    document_dicts = {}\n",
    "\n",
    "    id_list = []\n",
    "    document_list = []\n",
    "\n",
    "    for index in range(len(ids)) :\n",
    "        if document_dicts.get(ids[index]) is None:\n",
    "            document_dicts[ids[index]] = []\n",
    "        document_dicts[ids[index]].append(words[index])\n",
    "\n",
    "    for key in document_dicts :\n",
    "        document_dicts[key] = ' '.join(document_dicts[key])\n",
    "        id_list.append(key)\n",
    "        document_list.append(document_dicts[key])\n",
    "\n",
    "\n",
    "    df_doc = pd.DataFrame({'SK_ID_CURR':id_list, 'text':document_list})  \n",
    "    df_doc_mapping  = df_doc.set_index('SK_ID_CURR').text\n",
    "\n",
    "    train = X_Train[['SK_ID_CURR','TARGET']].copy()\n",
    "    test = X_Test[['SK_ID_CURR']].copy()\n",
    "    train['text'] = train.SK_ID_CURR.map(df_doc_mapping).fillna('notfound')\n",
    "    test['text'] = test.SK_ID_CURR.map(df_doc_mapping).fillna('notfound')\n",
    "    return train,test\n",
    "\n",
    "\n",
    "def get_train_ebdMat(train,test,embeddings_index,max_features,embed_size,maxlen):\n",
    "    X_train = train[\"text\"].str.lower()\n",
    "    X_test = test[\"text\"].str.lower()\n",
    "    y_train = train[\"TARGET\"].values\n",
    "    tok=text.Tokenizer(num_words=max_features,lower=True,filters='')\n",
    "    tok.fit_on_texts(list(X_train)+list(X_test))\n",
    "    X_train=tok.texts_to_sequences(X_train)\n",
    "    X_test=tok.texts_to_sequences(X_test)\n",
    "    x_train=sequence.pad_sequences(X_train,maxlen=maxlen)\n",
    "    x_test=sequence.pad_sequences(X_test,maxlen=maxlen)\n",
    "    print('...get ebd mat')\n",
    "    word_index = tok.word_index\n",
    "    #prepare embedding matrix\n",
    "    num_words = min(max_features, len(word_index) + 1)\n",
    "    print('num of words: {}'.format(num_words))\n",
    "    embedding_matrix = np.zeros((num_words, embed_size))\n",
    "    print(embedding_matrix.shape)\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return x_train,x_test,y_train,embedding_matrix,num_words\n",
    "\n",
    "class_ratio =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:38:34.098388Z",
     "start_time": "2018-08-20T04:38:34.067280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of categorical col is: 37\n"
     ]
    }
   ],
   "source": [
    "categorical_col = []\n",
    "for col in X.columns:\n",
    "    if X[col].dtypes == object:\n",
    "        categorical_col.append(col)\n",
    "print('length of categorical col is: {}'.format(len(categorical_col)))\n",
    "\n",
    "numerical_col = list(set(X.columns) - set(categorical_col))\n",
    "numerical_col.remove('SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:39:32.318197Z",
     "start_time": "2018-08-20T04:38:34.099516Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 725/725 [00:58<00:00, 12.45it/s]\n"
     ]
    }
   ],
   "source": [
    "qt = QuantileTransformer(n_quantiles=10000,output_distribution='normal')\n",
    "for col in tqdm(numerical_col):\n",
    "    X[col] = qt.fit_transform(X[col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:39:34.461588Z",
     "start_time": "2018-08-20T04:39:32.319524Z"
    }
   },
   "outputs": [],
   "source": [
    "X_num = X[numerical_col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:39:52.679490Z",
     "start_time": "2018-08-20T04:39:34.463234Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 51.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique category is : 463\n"
     ]
    }
   ],
   "source": [
    "X_cal,num_words_main = create_main_doc(X,categorical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create one hot columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:41:24.172859Z",
     "start_time": "2018-08-20T04:39:52.680983Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before encoding, shape is: (356255, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/37 [00:02<01:28,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 94)\n",
      "before encoding, shape is: (356255, 94)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/37 [00:03<00:54,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 96)\n",
      "before encoding, shape is: (356255, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/37 [00:05<00:56,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 119)\n",
      "before encoding, shape is: (356255, 119)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 4/37 [00:05<00:48,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 121)\n",
      "before encoding, shape is: (356255, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 5/37 [00:06<00:41,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 122)\n",
      "before encoding, shape is: (356255, 122)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 6/37 [00:09<00:47,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 145)\n",
      "before encoding, shape is: (356255, 145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 7/37 [00:09<00:41,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 146)\n",
      "before encoding, shape is: (356255, 146)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 8/37 [00:12<00:46,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 169)\n",
      "before encoding, shape is: (356255, 169)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 9/37 [00:13<00:43,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 173)\n",
      "before encoding, shape is: (356255, 173)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 10/37 [00:14<00:39,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 174)\n",
      "before encoding, shape is: (356255, 174)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 11/37 [00:18<00:42,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 198)\n",
      "before encoding, shape is: (356255, 198)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 12/37 [00:19<00:40,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 204)\n",
      "before encoding, shape is: (356255, 204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 13/37 [00:22<00:41,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 222)\n",
      "before encoding, shape is: (356255, 222)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 14/37 [00:25<00:41,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 233)\n",
      "before encoding, shape is: (356255, 233)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 15/37 [00:25<00:38,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 234)\n",
      "before encoding, shape is: (356255, 234)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 16/37 [00:26<00:35,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 235)\n",
      "before encoding, shape is: (356255, 235)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 17/37 [00:27<00:32,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 236)\n",
      "before encoding, shape is: (356255, 236)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▊     | 18/37 [00:28<00:30,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 237)\n",
      "before encoding, shape is: (356255, 237)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████▏    | 19/37 [00:29<00:28,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 238)\n",
      "before encoding, shape is: (356255, 238)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 20/37 [00:30<00:25,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 239)\n",
      "before encoding, shape is: (356255, 239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 21/37 [00:31<00:23,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 240)\n",
      "before encoding, shape is: (356255, 240)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 22/37 [00:36<00:25,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 270)\n",
      "before encoding, shape is: (356255, 270)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 23/37 [00:37<00:22,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 271)\n",
      "before encoding, shape is: (356255, 271)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▍   | 24/37 [00:38<00:20,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 272)\n",
      "before encoding, shape is: (356255, 272)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 25/37 [00:43<00:20,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 294)\n",
      "before encoding, shape is: (356255, 294)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 26/37 [00:44<00:18,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 295)\n",
      "before encoding, shape is: (356255, 295)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 27/37 [00:49<00:18,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 319)\n",
      "before encoding, shape is: (356255, 319)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 28/37 [00:56<00:18,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 350)\n",
      "before encoding, shape is: (356255, 350)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 29/37 [01:07<00:18,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 401)\n",
      "before encoding, shape is: (356255, 401)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 30/37 [01:09<00:16,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 402)\n",
      "before encoding, shape is: (356255, 402)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 31/37 [01:18<00:15,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 439)\n",
      "before encoding, shape is: (356255, 439)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▋ | 32/37 [01:20<00:12,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 440)\n",
      "before encoding, shape is: (356255, 440)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 33/37 [01:22<00:10,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 447)\n",
      "before encoding, shape is: (356255, 447)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 34/37 [01:24<00:07,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 448)\n",
      "before encoding, shape is: (356255, 448)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▍| 35/37 [01:26<00:04,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 453)\n",
      "before encoding, shape is: (356255, 453)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 36/37 [01:28<00:02,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 458)\n",
      "before encoding, shape is: (356255, 458)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 37/37 [01:31<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after encoding, shape is: (356255, 463)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_one_hot = X[categorical_col].copy()\n",
    "for col in tqdm(categorical_col):\n",
    "    X_one_hot,new_col = one_hot_encoding(X_one_hot,col,col)\n",
    "X_one_hot = X_one_hot.values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:41:36.887423Z",
     "start_time": "2018-08-20T04:41:24.174568Z"
    }
   },
   "outputs": [],
   "source": [
    "X_one_hot = qt.fit_transform(X_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:41:36.891314Z",
     "start_time": "2018-08-20T04:41:36.888895Z"
    }
   },
   "outputs": [],
   "source": [
    "x_num_train = X_num[:307511]\n",
    "x_num_test = X_num[307511:]\n",
    "x_cal_train = X_cal[:307511]\n",
    "x_cal_test = X_cal[307511:]\n",
    "x_onehot_train = X_one_hot[:307511]\n",
    "x_onehot_test = X_one_hot[307511:]\n",
    "y_train = X_Train.TARGET.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:41:36.911162Z",
     "start_time": "2018-08-20T04:41:36.892469Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dim_main_numeric = x_num_train.shape[1]\n",
    "dim_main_cal = x_cal_train.shape[1]\n",
    "dim_main_onehot = x_onehot_train.shape[1]\n",
    "main_ebd_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Previous Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:41:57.767241Z",
     "start_time": "2018-08-20T04:41:36.912812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_ANNUITY\n",
      "AMT_APPLICATION\n",
      "AMT_CREDIT\n",
      "AMT_DOWN_PAYMENT\n",
      "AMT_GOODS_PRICE\n",
      "RATE_DOWN_PAYMENT\n",
      "RATE_INTEREST_PRIMARY\n",
      "RATE_INTEREST_PRIVILEGED\n",
      "SELLERPLACE_AREA\n",
      "CNT_PAYMENT\n",
      "DAYS_FIRST_DRAWING\n",
      "DAYS_FIRST_DUE\n",
      "DAYS_LAST_DUE_1ST_VERSION\n",
      "DAYS_LAST_DUE\n",
      "DAYS_TERMINATION\n",
      "MONTHS_BALANCE_MAX\n",
      "MONTHS_BALANCE_MIN\n",
      "MONTHS_BALANCE_SPAN\n",
      "CNT_INSTALMENT_MAX\n",
      "CNT_INSTALMENT_MIN\n",
      "CNT_INSTALMENT_SPAN\n",
      "SK_DPD_MAX\n",
      "SK_DPD_MIN\n",
      "SK_DPD_MEAN\n",
      "SK_DPD_COUNT\n",
      "SK_DPD_SUM\n",
      "SK_DPD_DEF_MAX\n",
      "SK_DPD_DEF_MIN\n",
      "SK_DPD_DEF_MEAN\n",
      "SK_DPD_DEF_COUNT\n",
      "SK_DPD_DEF_SUM\n",
      "count_VERSION\n",
      "count_INSTALLMENT\n",
      "DAY_INS_SPAN\n",
      "DAY_ENTRY_SPAN\n",
      "CNT_LATE_PAYMENT\n",
      "CNT_LESS_PAYMENT\n",
      "TOTAL_AMT_INSTALMENT\n",
      "TOTAL_AMT_PAYMENT\n",
      "INSTAL_START_DAY\n",
      "OWE_PORTION\n",
      "CNT_DRAWINGS_CURRENT_MAX\n",
      "CNT_DRAWINGS_CURRENT_MIN\n",
      "CNT_DRAWINGS_CURRENT_MEAN\n",
      "AMT_TOTAL_RECEIVABLE_MAX\n",
      "AMT_TOTAL_RECEIVABLE_MIN\n",
      "AMT_TOTAL_RECEIVABLE_MEAN\n",
      "AMT_RECIVABLE_MAX\n",
      "AMT_RECIVABLE_MIN\n",
      "AMT_RECIVABLE_MEAN\n",
      "AMT_RECEIVABLE_PRINCIPAL_MAX\n",
      "AMT_RECEIVABLE_PRINCIPAL_MIN\n",
      "AMT_RECEIVABLE_PRINCIPAL_MEAN\n",
      "CC_SK_DPD_MAX\n",
      "CC_SK_DPD_MIN\n",
      "CC_SK_DPD_MEAN\n",
      "AMT_PAYMENT_TOTAL_CURRENT_MAX\n",
      "AMT_PAYMENT_TOTAL_CURRENT_MIN\n",
      "AMT_PAYMENT_TOTAL_CURRENT_MEAN\n",
      "AMT_DRAWINGS_CURRENT_MAX\n",
      "AMT_DRAWINGS_CURRENT_MIN\n",
      "AMT_DRAWINGS_CURRENT_MEAN\n",
      "AMT_CREDIT_LIMIT_ACTUAL_MAX\n",
      "AMT_CREDIT_LIMIT_ACTUAL_MIN\n",
      "AMT_CREDIT_LIMIT_ACTUAL_MEAN\n",
      "AMT_BALANCE_MAX\n",
      "AMT_BALANCE_MIN\n",
      "AMT_BALANCE_MEAN\n",
      "CC_MONTHS_BALANCE_MAX\n",
      "CC_MONTHS_BALANCE_MIN\n",
      "MONTHS_BALANCE_MEAN\n",
      "CC_SK_DPD_DEF_MAX\n",
      "CC_SK_DPD_DEF_MIN\n",
      "CC_SK_DPD_DEF_MEAN\n",
      "AMT_INST_MIN_REGULARITY_MAX\n",
      "AMT_INST_MIN_REGULARITY_MIN\n",
      "AMT_INST_MIN_REGULARITY_MEAN\n",
      "CNT_INSTALMENT_MATURE_CUM_MAX\n",
      "CNT_INSTALMENT_MATURE_CUM_MIN\n",
      "CNT_INSTALMENT_MATURE_CUM_MEAN\n",
      "AMT_DRAWINGS_POS_CURRENT_MAX\n",
      "AMT_DRAWINGS_POS_CURRENT_MIN\n",
      "AMT_DRAWINGS_POS_CURRENT_MEAN\n",
      "AMT_DRAWINGS_ATM_CURRENT_MAX\n",
      "AMT_DRAWINGS_ATM_CURRENT_MIN\n",
      "AMT_DRAWINGS_ATM_CURRENT_MEAN\n",
      "CNT_DRAWINGS_ATM_CURRENT_MAX\n",
      "CNT_DRAWINGS_ATM_CURRENT_MIN\n",
      "CNT_DRAWINGS_ATM_CURRENT_MEAN\n",
      "CNT_DRAWINGS_OTHER_CURRENT_MAX\n",
      "CNT_DRAWINGS_OTHER_CURRENT_MIN\n",
      "CNT_DRAWINGS_OTHER_CURRENT_MEAN\n",
      "CNT_DRAWINGS_POS_CURRENT_MAX\n",
      "CNT_DRAWINGS_POS_CURRENT_MIN\n",
      "CNT_DRAWINGS_POS_CURRENT_MEAN\n",
      "AMT_DRAWINGS_OTHER_CURRENT_MAX\n",
      "AMT_DRAWINGS_OTHER_CURRENT_MIN\n",
      "AMT_DRAWINGS_OTHER_CURRENT_MEAN\n",
      "AMT_PAYMENT_CURRENT_MAX\n",
      "AMT_PAYMENT_CURRENT_MIN\n",
      "AMT_PAYMENT_CURRENT_MEAN\n",
      "Records_CNT\n",
      "NAME_CONTRACT_STATUS_Active\n",
      "NAME_CONTRACT_STATUS_Completed\n",
      "NAME_CONTRACT_STATUS_Demand\n",
      "NAME_CONTRACT_STATUS_Signed\n",
      "NAME_CONTRACT_STATUS_Sent_proposal\n",
      "NAME_CONTRACT_STATUS_Refused\n",
      "NAME_CONTRACT_STATUS_Approved\n"
     ]
    }
   ],
   "source": [
    "qt = QuantileTransformer(n_quantiles=10000,output_distribution='normal')\n",
    "trans_col_pre  = ['AMT_ANNUITY',\n",
    "             'AMT_APPLICATION',\n",
    "             'AMT_CREDIT',\n",
    "             'AMT_DOWN_PAYMENT',\n",
    "             'AMT_GOODS_PRICE',\n",
    "             'RATE_DOWN_PAYMENT',\n",
    "             'RATE_INTEREST_PRIMARY',\n",
    "             'RATE_INTEREST_PRIVILEGED',\n",
    "             'SELLERPLACE_AREA',\n",
    "             'CNT_PAYMENT',\n",
    "             'DAYS_FIRST_DRAWING',\n",
    "             'DAYS_FIRST_DUE',\n",
    "             'DAYS_LAST_DUE_1ST_VERSION',\n",
    "             'DAYS_LAST_DUE',\n",
    "             'DAYS_TERMINATION']\n",
    "\n",
    "trans_col_pos = ['MONTHS_BALANCE_MAX',\n",
    "             'MONTHS_BALANCE_MIN',\n",
    "             'MONTHS_BALANCE_SPAN',\n",
    "             'CNT_INSTALMENT_MAX',\n",
    "             'CNT_INSTALMENT_MIN',\n",
    "             'CNT_INSTALMENT_SPAN',\n",
    "             'SK_DPD_MAX',\n",
    "             'SK_DPD_MIN',\n",
    "             'SK_DPD_MEAN',\n",
    "             'SK_DPD_COUNT',\n",
    "             'SK_DPD_SUM',\n",
    "             'SK_DPD_DEF_MAX',\n",
    "             'SK_DPD_DEF_MIN',\n",
    "             'SK_DPD_DEF_MEAN',\n",
    "             'SK_DPD_DEF_COUNT',\n",
    "             'SK_DPD_DEF_SUM']\n",
    "\n",
    "trans_col_ins = ['count_VERSION',\n",
    "             'count_INSTALLMENT',\n",
    "             'DAY_INS_SPAN',\n",
    "             'DAY_ENTRY_SPAN',\n",
    "             'CNT_LATE_PAYMENT',\n",
    "             'CNT_LESS_PAYMENT',\n",
    "             'TOTAL_AMT_INSTALMENT',\n",
    "             'TOTAL_AMT_PAYMENT',\n",
    "             'INSTAL_START_DAY',\n",
    "             'OWE_PORTION']\n",
    "\n",
    "trans_col_cc = [ 'CNT_DRAWINGS_CURRENT_MAX',\n",
    "       'CNT_DRAWINGS_CURRENT_MIN', 'CNT_DRAWINGS_CURRENT_MEAN',\n",
    "       'AMT_TOTAL_RECEIVABLE_MAX', 'AMT_TOTAL_RECEIVABLE_MIN',\n",
    "       'AMT_TOTAL_RECEIVABLE_MEAN', 'AMT_RECIVABLE_MAX', 'AMT_RECIVABLE_MIN',\n",
    "       'AMT_RECIVABLE_MEAN', 'AMT_RECEIVABLE_PRINCIPAL_MAX',\n",
    "       'AMT_RECEIVABLE_PRINCIPAL_MIN', 'AMT_RECEIVABLE_PRINCIPAL_MEAN',\n",
    "       'CC_SK_DPD_MAX', 'CC_SK_DPD_MIN', 'CC_SK_DPD_MEAN',\n",
    "       'AMT_PAYMENT_TOTAL_CURRENT_MAX', 'AMT_PAYMENT_TOTAL_CURRENT_MIN',\n",
    "       'AMT_PAYMENT_TOTAL_CURRENT_MEAN', 'AMT_DRAWINGS_CURRENT_MAX',\n",
    "       'AMT_DRAWINGS_CURRENT_MIN', 'AMT_DRAWINGS_CURRENT_MEAN',\n",
    "       'AMT_CREDIT_LIMIT_ACTUAL_MAX', 'AMT_CREDIT_LIMIT_ACTUAL_MIN',\n",
    "       'AMT_CREDIT_LIMIT_ACTUAL_MEAN', 'AMT_BALANCE_MAX', 'AMT_BALANCE_MIN',\n",
    "       'AMT_BALANCE_MEAN', 'CC_MONTHS_BALANCE_MAX', 'CC_MONTHS_BALANCE_MIN',\n",
    "       'MONTHS_BALANCE_MEAN', 'CC_SK_DPD_DEF_MAX', 'CC_SK_DPD_DEF_MIN',\n",
    "       'CC_SK_DPD_DEF_MEAN', 'AMT_INST_MIN_REGULARITY_MAX',\n",
    "       'AMT_INST_MIN_REGULARITY_MIN', 'AMT_INST_MIN_REGULARITY_MEAN',\n",
    "       'CNT_INSTALMENT_MATURE_CUM_MAX', 'CNT_INSTALMENT_MATURE_CUM_MIN',\n",
    "       'CNT_INSTALMENT_MATURE_CUM_MEAN', 'AMT_DRAWINGS_POS_CURRENT_MAX',\n",
    "       'AMT_DRAWINGS_POS_CURRENT_MIN', 'AMT_DRAWINGS_POS_CURRENT_MEAN',\n",
    "       'AMT_DRAWINGS_ATM_CURRENT_MAX', 'AMT_DRAWINGS_ATM_CURRENT_MIN',\n",
    "       'AMT_DRAWINGS_ATM_CURRENT_MEAN', 'CNT_DRAWINGS_ATM_CURRENT_MAX',\n",
    "       'CNT_DRAWINGS_ATM_CURRENT_MIN', 'CNT_DRAWINGS_ATM_CURRENT_MEAN',\n",
    "       'CNT_DRAWINGS_OTHER_CURRENT_MAX', 'CNT_DRAWINGS_OTHER_CURRENT_MIN',\n",
    "       'CNT_DRAWINGS_OTHER_CURRENT_MEAN', 'CNT_DRAWINGS_POS_CURRENT_MAX',\n",
    "       'CNT_DRAWINGS_POS_CURRENT_MIN', 'CNT_DRAWINGS_POS_CURRENT_MEAN',\n",
    "       'AMT_DRAWINGS_OTHER_CURRENT_MAX', 'AMT_DRAWINGS_OTHER_CURRENT_MIN',\n",
    "       'AMT_DRAWINGS_OTHER_CURRENT_MEAN', 'AMT_PAYMENT_CURRENT_MAX',\n",
    "       'AMT_PAYMENT_CURRENT_MIN', 'AMT_PAYMENT_CURRENT_MEAN', 'Records_CNT',\n",
    "       'NAME_CONTRACT_STATUS_Active', 'NAME_CONTRACT_STATUS_Completed',\n",
    "       'NAME_CONTRACT_STATUS_Demand', 'NAME_CONTRACT_STATUS_Signed',\n",
    "       'NAME_CONTRACT_STATUS_Sent_proposal', 'NAME_CONTRACT_STATUS_Refused',\n",
    "       'NAME_CONTRACT_STATUS_Approved']\n",
    "for col in trans_col_pre + trans_col_pos +trans_col_ins +trans_col_cc:\n",
    "    print(col)\n",
    "    X_pre_combine[col] = qt.fit_transform(X_pre_combine[col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:42:33.202889Z",
     "start_time": "2018-08-20T04:41:57.768815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start normalize\n",
      "get embedding\n",
      "ebd size is 320\n",
      "create document\n",
      "get embedding Mat\n",
      "...get ebd mat\n",
      "num of words: 1670216\n",
      "(1670216, 320)\n"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "#previous application\n",
    "#10001358\n",
    "max_features = 1680000\n",
    "# max 73\n",
    "maxlen_preapp = 12\n",
    "\n",
    "sorted_df = X_pre_combine.sort_values(['SK_ID_CURR','DAYS_DECISION'])\n",
    "sorted_df['words'] = sorted_df.index.astype(str)\n",
    "feature = list(sorted_df.columns)\n",
    "feature.remove('SK_ID_PREV')\n",
    "feature.remove('SK_ID_CURR')\n",
    "feature.remove('words')\n",
    "ebd = sorted_df[feature].values\n",
    "#normalize\n",
    "print('start normalize')\n",
    "# nor_ebd = normalize(ebd, norm='max',axis=0)\n",
    "nor_ebd = ebd\n",
    "print('get embedding')\n",
    "embed_size_preapp = len(feature)\n",
    "print('ebd size is {}'.format(embed_size_preapp))\n",
    "embeddings_index = get_embeddings_index(sorted_df,nor_ebd)\n",
    "print('create document')\n",
    "train,test = create_document(sorted_df)\n",
    "print('get embedding Mat')\n",
    "x_train_preapp,x_test_preapp,y_train_preapp,embedding_matrix_preapp,num_words_preapp = get_train_ebdMat(train,test,embeddings_index,max_features,embed_size_preapp,maxlen_preapp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processs Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:42:52.773017Z",
     "start_time": "2018-08-20T04:42:33.253252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_ANNUITY\n",
      "AMT_CREDIT_MAX_OVERDUE\n",
      "DAYS_ENDDATE_FACT\n",
      "AMT_CREDIT_SUM_LIMIT\n",
      "AMT_CREDIT_SUM_DEBT\n",
      "DAYS_CREDIT_ENDDATE\n",
      "AMT_CREDIT_SUM\n",
      "CREDIT_DAY_OVERDUE\n",
      "CNT_CREDIT_PROLONG\n",
      "BUREAU_LENGTH\n",
      "AMT_CREDIT_SUM_OVERDUE\n",
      "DAYS_CREDIT_UPDATE\n",
      "AMT_ANNUITY_squre\n",
      "AMT_CREDIT_MAX_OVERDUE_squre\n",
      "DAYS_ENDDATE_FACT_squre\n",
      "AMT_CREDIT_SUM_LIMIT_squre\n",
      "AMT_CREDIT_SUM_DEBT_squre\n",
      "DAYS_CREDIT_ENDDATE_squre\n",
      "AMT_CREDIT_SUM_squre\n",
      "CREDIT_DAY_OVERDUE_squre\n",
      "CNT_CREDIT_PROLONG_squre\n",
      "BUREAU_LENGTH_squre\n",
      "AMT_CREDIT_SUM_OVERDUE_squre\n",
      "DAYS_CREDIT_UPDATE_squre\n",
      "AMT_ANNUITY_AMT_CREDIT_MAX_OVERDUE\n",
      "AMT_ANNUITY_DAYS_ENDDATE_FACT\n",
      "AMT_ANNUITY_AMT_CREDIT_SUM_LIMIT\n",
      "AMT_ANNUITY_AMT_CREDIT_SUM_DEBT\n",
      "AMT_ANNUITY_DAYS_CREDIT_ENDDATE\n",
      "AMT_ANNUITY_AMT_CREDIT_SUM\n",
      "AMT_ANNUITY_CREDIT_DAY_OVERDUE\n",
      "AMT_ANNUITY_CNT_CREDIT_PROLONG\n",
      "AMT_ANNUITY_BUREAU_LENGTH\n",
      "AMT_ANNUITY_AMT_CREDIT_SUM_OVERDUE\n",
      "AMT_ANNUITY_DAYS_CREDIT_UPDATE\n",
      "AMT_CREDIT_MAX_OVERDUE_DAYS_ENDDATE_FACT\n",
      "AMT_CREDIT_MAX_OVERDUE_AMT_CREDIT_SUM_LIMIT\n",
      "AMT_CREDIT_MAX_OVERDUE_AMT_CREDIT_SUM_DEBT\n",
      "AMT_CREDIT_MAX_OVERDUE_DAYS_CREDIT_ENDDATE\n",
      "AMT_CREDIT_MAX_OVERDUE_AMT_CREDIT_SUM\n",
      "AMT_CREDIT_MAX_OVERDUE_CREDIT_DAY_OVERDUE\n",
      "AMT_CREDIT_MAX_OVERDUE_CNT_CREDIT_PROLONG\n",
      "AMT_CREDIT_MAX_OVERDUE_BUREAU_LENGTH\n",
      "AMT_CREDIT_MAX_OVERDUE_AMT_CREDIT_SUM_OVERDUE\n",
      "AMT_CREDIT_MAX_OVERDUE_DAYS_CREDIT_UPDATE\n",
      "DAYS_ENDDATE_FACT_AMT_CREDIT_SUM_LIMIT\n",
      "DAYS_ENDDATE_FACT_AMT_CREDIT_SUM_DEBT\n",
      "DAYS_ENDDATE_FACT_DAYS_CREDIT_ENDDATE\n",
      "DAYS_ENDDATE_FACT_AMT_CREDIT_SUM\n",
      "DAYS_ENDDATE_FACT_CREDIT_DAY_OVERDUE\n",
      "DAYS_ENDDATE_FACT_CNT_CREDIT_PROLONG\n",
      "DAYS_ENDDATE_FACT_BUREAU_LENGTH\n",
      "DAYS_ENDDATE_FACT_AMT_CREDIT_SUM_OVERDUE\n",
      "DAYS_ENDDATE_FACT_DAYS_CREDIT_UPDATE\n",
      "AMT_CREDIT_SUM_LIMIT_AMT_CREDIT_SUM_DEBT\n",
      "AMT_CREDIT_SUM_LIMIT_DAYS_CREDIT_ENDDATE\n",
      "AMT_CREDIT_SUM_LIMIT_AMT_CREDIT_SUM\n",
      "AMT_CREDIT_SUM_LIMIT_CREDIT_DAY_OVERDUE\n",
      "AMT_CREDIT_SUM_LIMIT_CNT_CREDIT_PROLONG\n",
      "AMT_CREDIT_SUM_LIMIT_BUREAU_LENGTH\n",
      "AMT_CREDIT_SUM_LIMIT_AMT_CREDIT_SUM_OVERDUE\n",
      "AMT_CREDIT_SUM_LIMIT_DAYS_CREDIT_UPDATE\n",
      "AMT_CREDIT_SUM_DEBT_DAYS_CREDIT_ENDDATE\n",
      "AMT_CREDIT_SUM_DEBT_AMT_CREDIT_SUM\n",
      "AMT_CREDIT_SUM_DEBT_CREDIT_DAY_OVERDUE\n",
      "AMT_CREDIT_SUM_DEBT_CNT_CREDIT_PROLONG\n",
      "AMT_CREDIT_SUM_DEBT_BUREAU_LENGTH\n",
      "AMT_CREDIT_SUM_DEBT_AMT_CREDIT_SUM_OVERDUE\n",
      "AMT_CREDIT_SUM_DEBT_DAYS_CREDIT_UPDATE\n",
      "DAYS_CREDIT_ENDDATE_AMT_CREDIT_SUM\n",
      "DAYS_CREDIT_ENDDATE_CREDIT_DAY_OVERDUE\n",
      "DAYS_CREDIT_ENDDATE_CNT_CREDIT_PROLONG\n",
      "DAYS_CREDIT_ENDDATE_BUREAU_LENGTH\n",
      "DAYS_CREDIT_ENDDATE_AMT_CREDIT_SUM_OVERDUE\n",
      "DAYS_CREDIT_ENDDATE_DAYS_CREDIT_UPDATE\n",
      "AMT_CREDIT_SUM_CREDIT_DAY_OVERDUE\n",
      "AMT_CREDIT_SUM_CNT_CREDIT_PROLONG\n",
      "AMT_CREDIT_SUM_BUREAU_LENGTH\n",
      "AMT_CREDIT_SUM_AMT_CREDIT_SUM_OVERDUE\n",
      "AMT_CREDIT_SUM_DAYS_CREDIT_UPDATE\n",
      "CREDIT_DAY_OVERDUE_CNT_CREDIT_PROLONG\n",
      "CREDIT_DAY_OVERDUE_BUREAU_LENGTH\n",
      "CREDIT_DAY_OVERDUE_AMT_CREDIT_SUM_OVERDUE\n",
      "CREDIT_DAY_OVERDUE_DAYS_CREDIT_UPDATE\n",
      "CNT_CREDIT_PROLONG_BUREAU_LENGTH\n",
      "CNT_CREDIT_PROLONG_AMT_CREDIT_SUM_OVERDUE\n",
      "CNT_CREDIT_PROLONG_DAYS_CREDIT_UPDATE\n",
      "BUREAU_LENGTH_AMT_CREDIT_SUM_OVERDUE\n",
      "BUREAU_LENGTH_DAYS_CREDIT_UPDATE\n",
      "AMT_CREDIT_SUM_OVERDUE_DAYS_CREDIT_UPDATE\n"
     ]
    }
   ],
   "source": [
    "qt = QuantileTransformer(n_quantiles=10000,output_distribution='normal')\n",
    "trans_col = [\n",
    "             'AMT_ANNUITY',\n",
    "             'AMT_CREDIT_MAX_OVERDUE',\n",
    "             'DAYS_ENDDATE_FACT',\n",
    "             'AMT_CREDIT_SUM_LIMIT',\n",
    "             'AMT_CREDIT_SUM_DEBT',\n",
    "             'DAYS_CREDIT_ENDDATE',\n",
    "             'AMT_CREDIT_SUM',\n",
    "             'CREDIT_DAY_OVERDUE',\n",
    "             'CNT_CREDIT_PROLONG',\n",
    "             'BUREAU_LENGTH',\n",
    "             'AMT_CREDIT_SUM_OVERDUE',\n",
    "             'DAYS_CREDIT_UPDATE',\n",
    "    'AMT_ANNUITY_squre',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_squre',\n",
    " 'DAYS_ENDDATE_FACT_squre',\n",
    " 'AMT_CREDIT_SUM_LIMIT_squre',\n",
    " 'AMT_CREDIT_SUM_DEBT_squre',\n",
    " 'DAYS_CREDIT_ENDDATE_squre',\n",
    " 'AMT_CREDIT_SUM_squre',\n",
    " 'CREDIT_DAY_OVERDUE_squre',\n",
    " 'CNT_CREDIT_PROLONG_squre',\n",
    " 'BUREAU_LENGTH_squre',\n",
    " 'AMT_CREDIT_SUM_OVERDUE_squre',\n",
    " 'DAYS_CREDIT_UPDATE_squre',\n",
    "    'AMT_ANNUITY_AMT_CREDIT_MAX_OVERDUE',\n",
    " 'AMT_ANNUITY_DAYS_ENDDATE_FACT',\n",
    " 'AMT_ANNUITY_AMT_CREDIT_SUM_LIMIT',\n",
    " 'AMT_ANNUITY_AMT_CREDIT_SUM_DEBT',\n",
    " 'AMT_ANNUITY_DAYS_CREDIT_ENDDATE',\n",
    " 'AMT_ANNUITY_AMT_CREDIT_SUM',\n",
    " 'AMT_ANNUITY_CREDIT_DAY_OVERDUE',\n",
    " 'AMT_ANNUITY_CNT_CREDIT_PROLONG',\n",
    " 'AMT_ANNUITY_BUREAU_LENGTH',\n",
    " 'AMT_ANNUITY_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'AMT_ANNUITY_DAYS_CREDIT_UPDATE',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_DAYS_ENDDATE_FACT',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_AMT_CREDIT_SUM_LIMIT',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_AMT_CREDIT_SUM_DEBT',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_DAYS_CREDIT_ENDDATE',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_AMT_CREDIT_SUM',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_CREDIT_DAY_OVERDUE',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_CNT_CREDIT_PROLONG',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_BUREAU_LENGTH',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'AMT_CREDIT_MAX_OVERDUE_DAYS_CREDIT_UPDATE',\n",
    " 'DAYS_ENDDATE_FACT_AMT_CREDIT_SUM_LIMIT',\n",
    " 'DAYS_ENDDATE_FACT_AMT_CREDIT_SUM_DEBT',\n",
    " 'DAYS_ENDDATE_FACT_DAYS_CREDIT_ENDDATE',\n",
    " 'DAYS_ENDDATE_FACT_AMT_CREDIT_SUM',\n",
    " 'DAYS_ENDDATE_FACT_CREDIT_DAY_OVERDUE',\n",
    " 'DAYS_ENDDATE_FACT_CNT_CREDIT_PROLONG',\n",
    " 'DAYS_ENDDATE_FACT_BUREAU_LENGTH',\n",
    " 'DAYS_ENDDATE_FACT_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'DAYS_ENDDATE_FACT_DAYS_CREDIT_UPDATE',\n",
    " 'AMT_CREDIT_SUM_LIMIT_AMT_CREDIT_SUM_DEBT',\n",
    " 'AMT_CREDIT_SUM_LIMIT_DAYS_CREDIT_ENDDATE',\n",
    " 'AMT_CREDIT_SUM_LIMIT_AMT_CREDIT_SUM',\n",
    " 'AMT_CREDIT_SUM_LIMIT_CREDIT_DAY_OVERDUE',\n",
    " 'AMT_CREDIT_SUM_LIMIT_CNT_CREDIT_PROLONG',\n",
    " 'AMT_CREDIT_SUM_LIMIT_BUREAU_LENGTH',\n",
    " 'AMT_CREDIT_SUM_LIMIT_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'AMT_CREDIT_SUM_LIMIT_DAYS_CREDIT_UPDATE',\n",
    " 'AMT_CREDIT_SUM_DEBT_DAYS_CREDIT_ENDDATE',\n",
    " 'AMT_CREDIT_SUM_DEBT_AMT_CREDIT_SUM',\n",
    " 'AMT_CREDIT_SUM_DEBT_CREDIT_DAY_OVERDUE',\n",
    " 'AMT_CREDIT_SUM_DEBT_CNT_CREDIT_PROLONG',\n",
    " 'AMT_CREDIT_SUM_DEBT_BUREAU_LENGTH',\n",
    " 'AMT_CREDIT_SUM_DEBT_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'AMT_CREDIT_SUM_DEBT_DAYS_CREDIT_UPDATE',\n",
    " 'DAYS_CREDIT_ENDDATE_AMT_CREDIT_SUM',\n",
    " 'DAYS_CREDIT_ENDDATE_CREDIT_DAY_OVERDUE',\n",
    " 'DAYS_CREDIT_ENDDATE_CNT_CREDIT_PROLONG',\n",
    " 'DAYS_CREDIT_ENDDATE_BUREAU_LENGTH',\n",
    " 'DAYS_CREDIT_ENDDATE_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'DAYS_CREDIT_ENDDATE_DAYS_CREDIT_UPDATE',\n",
    " 'AMT_CREDIT_SUM_CREDIT_DAY_OVERDUE',\n",
    " 'AMT_CREDIT_SUM_CNT_CREDIT_PROLONG',\n",
    " 'AMT_CREDIT_SUM_BUREAU_LENGTH',\n",
    " 'AMT_CREDIT_SUM_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'AMT_CREDIT_SUM_DAYS_CREDIT_UPDATE',\n",
    " 'CREDIT_DAY_OVERDUE_CNT_CREDIT_PROLONG',\n",
    " 'CREDIT_DAY_OVERDUE_BUREAU_LENGTH',\n",
    " 'CREDIT_DAY_OVERDUE_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'CREDIT_DAY_OVERDUE_DAYS_CREDIT_UPDATE',\n",
    " 'CNT_CREDIT_PROLONG_BUREAU_LENGTH',\n",
    " 'CNT_CREDIT_PROLONG_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'CNT_CREDIT_PROLONG_DAYS_CREDIT_UPDATE',\n",
    " 'BUREAU_LENGTH_AMT_CREDIT_SUM_OVERDUE',\n",
    " 'BUREAU_LENGTH_DAYS_CREDIT_UPDATE',\n",
    " 'AMT_CREDIT_SUM_OVERDUE_DAYS_CREDIT_UPDATE']\n",
    "for col in trans_col:\n",
    "    print(col)\n",
    "    X_bu_fe[col] = qt.fit_transform(X_bu_fe[col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:43:18.723534Z",
     "start_time": "2018-08-20T04:42:52.774689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start normalize\n",
      "get embedding\n",
      "ebd size is 122\n",
      "create document\n",
      "get embedding Mat\n",
      "...get ebd mat\n",
      "num of words: 1716430\n",
      "(1716430, 122)\n"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "#previous application\n",
    "#10001358\n",
    "max_features = 1730000\n",
    "# max 73\n",
    "maxlen_bu = 13\n",
    "\n",
    "sorted_df = X_bu_fe.sort_values(['SK_ID_CURR','DAYS_CREDIT'])\n",
    "col = 'DAYS_CREDIT'\n",
    "sorted_df[col] = qt.fit_transform(sorted_df[col].values.reshape(-1,1))\n",
    "sorted_df['words'] = sorted_df.index.astype(str)\n",
    "feature = list(sorted_df.columns)\n",
    "feature.remove('SK_ID_BUREAU')\n",
    "feature.remove('SK_ID_CURR')\n",
    "feature.remove('words')\n",
    "ebd = sorted_df[feature].values\n",
    "#normalize\n",
    "print('start normalize')\n",
    "# nor_ebd = normalize(ebd, norm='max',axis=0)\n",
    "nor_ebd = ebd\n",
    "print('get embedding')\n",
    "embed_size_bu = len(feature)\n",
    "print('ebd size is {}'.format(embed_size_bu))\n",
    "embeddings_index = get_embeddings_index(sorted_df,nor_ebd)\n",
    "print('create document')\n",
    "train,test = create_document(sorted_df)\n",
    "print('get embedding Mat')\n",
    "x_train_bu,x_test_bu,y_train_bu,embedding_matrix_bu,num_words_bu = get_train_ebdMat(train,test,embeddings_index,max_features,embed_size_bu,maxlen_bu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:43:18.779293Z",
     "start_time": "2018-08-20T04:43:18.777055Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = get_NN_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:43:18.802590Z",
     "start_time": "2018-08-20T04:43:18.780861Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_NN_model():\n",
    "    main_numeric_input = Input(shape=(dim_main_numeric, ),name='main_numerical')\n",
    "    main_cal_sequence = Input(shape=(dim_main_cal, ),name = 'main_categorical')\n",
    "    main_onehot_input = Input(shape=(dim_main_onehot, ),name = 'main_onehot')\n",
    "    previousapp_input = Input(shape=(maxlen_preapp, ),name = 'preapp')\n",
    "    bu_input = Input(shape=(maxlen_bu, ),name = 'bu')\n",
    "    \n",
    "    x_preapp = Embedding(num_words_preapp, embed_size_preapp, weights=[embedding_matrix_preapp],trainable = False)(previousapp_input)\n",
    "    x_preapp = BatchNormalization()(x_preapp)\n",
    "    x_preapp = SpatialDropout1D(0.2)(x_preapp)\n",
    "    x_preapp = Bidirectional(CuDNNGRU(8, return_sequences=True))(x_preapp)\n",
    "    x_preapp = Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x_preapp)\n",
    "    x_preapp = BatchNormalization()(x_preapp)\n",
    "    preapp_avg_pool = GlobalAveragePooling1D()(x_preapp)\n",
    "    preapp_max_pool = GlobalMaxPooling1D()(x_preapp)\n",
    "    x_preapp = concatenate([preapp_avg_pool, preapp_max_pool]) \n",
    "    \n",
    "    \n",
    "    x_bu = Embedding(num_words_bu, embed_size_bu, weights=[embedding_matrix_bu],trainable = False)(bu_input)\n",
    "    x_bu = BatchNormalization()(x_bu)\n",
    "    x_bu = SpatialDropout1D(0.2)(x_bu)\n",
    "#     x = Bidirectional(GRU(16, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "    x_bu = Bidirectional(CuDNNGRU(8, return_sequences=True))(x_bu)\n",
    "    x_bu = Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x_bu)\n",
    "    x_bu = BatchNormalization()(x_bu)\n",
    "    bu_avg_pool = GlobalAveragePooling1D()(x_bu)\n",
    "    bu_max_pool = GlobalMaxPooling1D()(x_bu)\n",
    "    x_bu = concatenate([bu_avg_pool, bu_max_pool]) \n",
    "    \n",
    "    \n",
    "    x_main_cat = Embedding(num_words_main, main_ebd_size, trainable = True)(main_cal_sequence)\n",
    "    x_main_cat = SpatialDropout1D(0.5)(x_main_cat)\n",
    "    x_main_cat = Flatten()(x_main_cat)\n",
    "    \n",
    "    x_main_nu = BatchNormalization()(main_numeric_input)\n",
    "    x_main_nu =concatenate([x_main_nu,x_preapp,x_bu])\n",
    "    x_main_nu = Dense(192,activation='relu')(x_main_nu)\n",
    "    x_main_nu = Dropout(0.5)(x_main_nu)\n",
    "    \n",
    "    x_main_oh = Dense(512,activation='relu')(main_onehot_input)\n",
    "    x_main_oh = Dropout(0.5)(x_main_oh)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = concatenate([x_main_nu, x_main_cat,x_main_oh])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    \n",
    "    preds = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model([main_numeric_input,\n",
    "                   main_cal_sequence,\n",
    "                   main_onehot_input,\n",
    "                   previousapp_input,\n",
    "                   bu_input], preds)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "class_ratio = 1\n",
    "def train_each_epoch(model,**args):\n",
    "    #######################################\n",
    "    x_num = args['main_numerical']\n",
    "    x_cat = args['main_categorical']\n",
    "    y = args['y']\n",
    "    batch_size = args['batch_size']\n",
    "    \n",
    "    x_onehot = args['main_onehot']\n",
    "    x_preapp = args['preapp']\n",
    "    x_bu = args['bu']\n",
    "    ########################################\n",
    "    x_num,x_cat,y = shuffle(x_num,x_cat,y)\n",
    "    model.fit({'main_numerical': x_num, \n",
    "               'main_categorical': x_cat,\n",
    "               'main_onehot':x_onehot,\n",
    "               'preapp':x_preapp,\n",
    "               'bu':x_bu}, \n",
    "              y, \n",
    "              batch_size=batch_size, \n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              class_weight={0:1,1:class_ratio})\n",
    "    return model\n",
    "\n",
    "def load_model(model,filepath):\n",
    "    model.load_weights(filepath)\n",
    "    return model\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    model.save_weights(filepath)\n",
    "    \n",
    "def train_each_fold(model,**args):\n",
    "    \n",
    "    x_num = args['main_n_train']\n",
    "    x_num_val = args['main_n_val']\n",
    "    x_cat = args['main_c_train']\n",
    "    x_cat_val = args['main_c_val']\n",
    "    y = args['y']\n",
    "    y_val = args['y_val']\n",
    "    filepath = args['filepath']\n",
    "    reportpath = args['reportpath']\n",
    "    predspath = args['predspath']\n",
    "    batch_size = args.get('batch_size',512)\n",
    "    total_epoch = args.get('total_epoch',400)\n",
    "    patience = args.get('patience',5)\n",
    "    saving = args.get('saving',True)\n",
    "    \n",
    "    x_onehot = args['main_oh_train']\n",
    "    x_onehot_val = args['main_oh_val']\n",
    "    x_preapp = args['preapp_train']\n",
    "    x_preapp_val = args['preapp_val']\n",
    "    x_bu = args['bu_train']\n",
    "    x_bu_val = args['bu_val']\n",
    "    \n",
    "    \n",
    "    ROC_AUC_SCORE = []\n",
    "    for epoch in range(total_epoch):  \n",
    "        model = train_each_epoch(model,\n",
    "                                 main_numerical=x_num,\n",
    "                                 main_categorical=x_cat,\n",
    "                                 y=y,\n",
    "                                 main_onehot = x_onehot,\n",
    "                                 preapp=x_preapp,\n",
    "                                 bu=x_bu,\n",
    "                                 batch_size=batch_size,)\n",
    "        y_pred = model.predict({'main_numerical':x_num_val,\n",
    "                                'main_categorical':x_cat_val,\n",
    "                                'main_onehot':x_onehot_val,\n",
    "                                'preapp':x_preapp_val,\n",
    "                                'bu':x_bu_val},\n",
    "                               batch_size=3000,\n",
    "                               verbose=1)\n",
    "        score = roc_auc_score(y_val,y_pred)\n",
    "        logloss = log_loss(y_val,y_pred)\n",
    "        if len(ROC_AUC_SCORE) == 0:\n",
    "            if saving:\n",
    "                save_model(model,filepath)\n",
    "            best_score = 0 \n",
    "            if saving:\n",
    "                print('saving preds...')\n",
    "                pickle.dump(y_pred,open(predspath,'wb'))\n",
    "        else:\n",
    "            best_score = max(ROC_AUC_SCORE)\n",
    "            if score >= best_score:\n",
    "                if saving:\n",
    "                    print('saving model to... {}'.format(filepath))\n",
    "                    save_model(model,filepath)\n",
    "                    print('saving preds...')\n",
    "                    pickle.dump(y_pred,open(predspath,'wb'))\n",
    "        ROC_AUC_SCORE.append(score)\n",
    "        if saving:\n",
    "            print('saving report to... {}'.format(reportpath))\n",
    "            pickle.dump(ROC_AUC_SCORE,open(reportpath,'wb'))\n",
    "        print('======= current {} / {}'.format(epoch,total_epoch))\n",
    "        print('previous best roc is {}'.format(best_score))\n",
    "        print('current roc is {}'.format(score))\n",
    "        print('current loss is {}'.format(logloss))\n",
    "        try:\n",
    "            best_round = ROC_AUC_SCORE.index(best_score)\n",
    "        except ValueError:\n",
    "            best_round = -1\n",
    "        if len(ROC_AUC_SCORE) > patience + best_round:\n",
    "            print('reach patience! end loop')\n",
    "            break\n",
    "            \n",
    "def train_5_folds(**args):\n",
    "    \n",
    "    filepath = args['filepath']\n",
    "    reportpath = args['reportpath']\n",
    "    predspath = args['predspath']\n",
    "    pred_test_file = args['predspath_test']\n",
    "    batch_size = args.get('batch_size',512)\n",
    "    total_epoch = args.get('total_epoch',400)\n",
    "    patience = args.get('patience',5)\n",
    "    saving = args.get('saving',True)\n",
    "    \n",
    "    train_fold_index = pickle.load(open(ENV.train_fold_index.value,'rb'))\n",
    "    val_fold_index = pickle.load(open(ENV.val_fold_index.value,'rb'))\n",
    "\n",
    "    for fold in range(4,len(train_fold_index)):\n",
    "        print('!!!!!!!! Begin fold: {}'.format(fold))\n",
    "        train_index = train_fold_index[fold]\n",
    "        val_index = val_fold_index[fold]\n",
    "        X_tra_nu = x_num_train[train_index]\n",
    "        X_tra_cat = x_cal_train[train_index]\n",
    "        X_val_nu = x_num_train[val_index]\n",
    "        X_val_cat = x_cal_train[val_index]\n",
    "        y_tra = y_train[train_index]\n",
    "        y_val = y_train[val_index]\n",
    "        \n",
    "        x_tra_oh = x_onehot_train[train_index]\n",
    "        x_val_oh = x_onehot_train[val_index]\n",
    "        x_tra_preapp = x_train_preapp[train_index]\n",
    "        x_val_preapp = x_train_preapp[val_index]\n",
    "        x_tra_bu = x_train_bu[train_index]\n",
    "        x_val_bu = x_train_bu[val_index]\n",
    "        \n",
    "        print('preparing train/val done!')\n",
    "        print('before evaluating: {}'.format(model_file))\n",
    "        model_file_evl = filepath.format(fold)\n",
    "        report_file_evl = reportpath.format(fold)\n",
    "        pred_file_evl = predspath.format(fold)\n",
    "        pred_test_file_evl = pred_test_file.format(fold)\n",
    "        model = get_NN_model()\n",
    "        train_each_fold(model,\n",
    "                main_n_train=X_tra_nu,\n",
    "                main_n_val=X_val_nu,\n",
    "                main_c_train=X_tra_cat,\n",
    "                main_c_val=X_val_cat,\n",
    "                y=y_tra,\n",
    "                y_val=y_val,\n",
    "                filepath=model_file_evl,\n",
    "                reportpath=report_file_evl,\n",
    "                predspath=pred_file_evl,\n",
    "                batch_size=batch_size,\n",
    "                total_epoch=total_epoch,\n",
    "                patience=patience,\n",
    "                saving=saving,\n",
    "                main_oh_train=x_tra_oh,\n",
    "                main_oh_val=x_val_oh,\n",
    "                preapp_train=x_tra_preapp,\n",
    "                preapp_val=x_val_preapp,\n",
    "                bu_train=x_tra_bu,\n",
    "                bu_val=x_val_bu)\n",
    "        gc.collect()\n",
    "        #### predict test\n",
    "        model = load_model(model,model_file_evl)\n",
    "        test_preds = model.predict({'main_numerical':x_num_test,\n",
    "                                    'main_categorical':x_cal_test,\n",
    "                                    'main_onehot':x_onehot_test,\n",
    "                                    'preapp':x_test_preapp,\n",
    "                                    'bu':x_test_bu},\n",
    "                                   batch_size=1500,verbose=1)\n",
    "        pickle.dump(test_preds,open(pred_test_file_evl,'wb'))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:43:24.055865Z",
     "start_time": "2018-08-20T04:43:18.803791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "preapp (InputLayer)             (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bu (InputLayer)                 (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 12, 320)      534469120   preapp[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 13, 122)      209404460   bu[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 12, 320)      1280        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 13, 122)      488         embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 12, 320)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 13, 122)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 12, 16)       15840       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 13, 16)       6336        spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 10, 32)       1568        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 11, 32)       1568        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 32)       128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 11, 32)       128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_numerical (InputLayer)     (None, 725)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 32)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 32)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 32)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 32)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 725)          2900        main_numerical[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64)           0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "main_categorical (InputLayer)   (None, 37)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 853)          0           batch_normalization_5[0][0]      \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 37, 300)      138900      main_categorical[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "main_onehot (InputLayer)        (None, 463)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 192)          163968      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 37, 300)      0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          237568      main_onehot[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 192)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 11100)        0           spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 11804)        0           dropout_1[0][0]                  \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           755520      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 745,199,837\n",
      "Trainable params: 1,323,795\n",
      "Non-trainable params: 743,876,042\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_NN_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:50:24.610636Z",
     "start_time": "2018-08-20T04:43:24.057558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!! Begin fold: 4\n",
      "preparing train/val done!\n",
      "before evaluating: ../LIB/../../data/rnn/main_ALL/fold_{}.hdf5\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 16s 65us/step - loss: 0.2663 - acc: 0.9186\n",
      "61502/61502 [==============================] - 1s 14us/step\n",
      "saving preds...\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 0 / 100\n",
      "previous best roc is 0\n",
      "current roc is 0.7774079420397729\n",
      "current loss is 0.23825845952817382\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2501 - acc: 0.9190\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving model to... ../LIB/../../data/rnn/main_ALL/fold_4.hdf5\n",
      "saving preds...\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 1 / 100\n",
      "previous best roc is 0.7774079420397729\n",
      "current roc is 0.7840268292708329\n",
      "current loss is 0.23652194713965405\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2457 - acc: 0.9190\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving model to... ../LIB/../../data/rnn/main_ALL/fold_4.hdf5\n",
      "saving preds...\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 2 / 100\n",
      "previous best roc is 0.7840268292708329\n",
      "current roc is 0.7860543727118845\n",
      "current loss is 0.23530257590495937\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2426 - acc: 0.9192\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving model to... ../LIB/../../data/rnn/main_ALL/fold_4.hdf5\n",
      "saving preds...\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 3 / 100\n",
      "previous best roc is 0.7860543727118845\n",
      "current roc is 0.786125607469968\n",
      "current loss is 0.2355685917637692\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2413 - acc: 0.9192\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving model to... ../LIB/../../data/rnn/main_ALL/fold_4.hdf5\n",
      "saving preds...\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 4 / 100\n",
      "previous best roc is 0.786125607469968\n",
      "current roc is 0.7874636929840221\n",
      "current loss is 0.2353907275937917\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2394 - acc: 0.9194\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 5 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7873504507657958\n",
      "current loss is 0.23585267694176987\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2382 - acc: 0.9196\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 6 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7865491899257663\n",
      "current loss is 0.2356675365487646\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2363 - acc: 0.9197\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 7 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7868870378893692\n",
      "current loss is 0.23492575599304494\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2349 - acc: 0.9200\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 8 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7870100550873451\n",
      "current loss is 0.2353304965456227\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2333 - acc: 0.9197\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 9 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7859651900350088\n",
      "current loss is 0.23535589061222573\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2310 - acc: 0.9203\n",
      "61502/61502 [==============================] - 1s 9us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 10 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7858419196929034\n",
      "current loss is 0.23530955361932704\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2296 - acc: 0.9200\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 11 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7839968280751247\n",
      "current loss is 0.23797974596367863\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2272 - acc: 0.9203\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 12 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7810213936732888\n",
      "current loss is 0.23698200062757163\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2254 - acc: 0.9207\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 13 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7798195430971228\n",
      "current loss is 0.23904990349955238\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2230 - acc: 0.9206\n",
      "61502/61502 [==============================] - 1s 9us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 14 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7800740451642109\n",
      "current loss is 0.2379651841533492\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2214 - acc: 0.9211\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 15 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7798167567035242\n",
      "current loss is 0.23814583734421294\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2196 - acc: 0.9212\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 16 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7786963335530046\n",
      "current loss is 0.24082975995562922\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2178 - acc: 0.9214\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 17 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7747823817558708\n",
      "current loss is 0.24262694776125196\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2162 - acc: 0.9216\n",
      "61502/61502 [==============================] - 1s 9us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 18 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7753714680354618\n",
      "current loss is 0.24243692278088733\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2135 - acc: 0.9227\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 19 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7721168970263782\n",
      "current loss is 0.24114235279163138\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2113 - acc: 0.9225\n",
      "61502/61502 [==============================] - 1s 9us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 20 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7718076760474939\n",
      "current loss is 0.2449555031997655\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2095 - acc: 0.9226\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 21 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7668543307275688\n",
      "current loss is 0.25051070601049646\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2079 - acc: 0.9232\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 22 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.769435288823999\n",
      "current loss is 0.24788459120096634\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 14s 59us/step - loss: 0.2063 - acc: 0.9234\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 23 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.767768135831296\n",
      "current loss is 0.24823441028731394\n",
      "Epoch 1/1\n",
      "246009/246009 [==============================] - 15s 59us/step - loss: 0.2052 - acc: 0.9239\n",
      "61502/61502 [==============================] - 1s 10us/step\n",
      "saving report to... ../LIB/../../data/rnn/main_ALL/report_fold_4.pkl\n",
      "======= current 24 / 100\n",
      "previous best roc is 0.7874636929840221\n",
      "current roc is 0.7647177382199812\n",
      "current loss is 0.24799826374350195\n",
      "reach patience! end loop\n",
      "48744/48744 [==============================] - 1s 14us/step\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_file = ENV.main_ALL_nn.value\n",
    "report_file = ENV.main_ALL_nn_report.value\n",
    "pred_file = ENV.main_ALL_nn_preds.value\n",
    "pred_test_file = ENV.main_ALL_nn_preds_test.value\n",
    "\n",
    "train_5_folds(filepath=model_file,\n",
    "              reportpath=report_file,\n",
    "              predspath=pred_file,\n",
    "              predspath_test=pred_test_file,\n",
    "              batch_size=512,\n",
    "              total_epoch=100,\n",
    "              patience=20,\n",
    "              saving=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:50:24.800796Z",
     "start_time": "2018-08-20T04:50:24.612450Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aaaaaaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-11be6ffe7b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maaaaaaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aaaaaaa' is not defined"
     ]
    }
   ],
   "source": [
    "aaaaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:50:24.801340Z",
     "start_time": "2018-08-20T04:38:21.521Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_NN_model():\n",
    "#     main_numeric_input = Input(shape=(dim_main_numeric, ),name='main_numerical')\n",
    "#     main_cal_sequence = Input(shape=(dim_main_cal, ),name = 'main_categorical')\n",
    "#     x_main_cat = Embedding(num_words_main, main_ebd_size, trainable = True)(main_cal_sequence)\n",
    "#     x_main_cat = SpatialDropout1D(0.5)(x_main_cat)\n",
    "#     x_main_cat = Flatten()(x_main_cat)\n",
    "#     x_main_nu = Dense(192,activation='relu')(main_numeric_input)\n",
    "#     x_main_nu = Dropout(0.5)(x_main_nu)\n",
    "#     x = concatenate([x_main_nu, x_main_cat])\n",
    "#     x = Dense(64, activation='relu')(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     preds = Dense(1, activation=\"sigmoid\")(x)\n",
    "#     model = Model([main_numeric_input,main_cal_sequence], preds)\n",
    "#     model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:50:24.802112Z",
     "start_time": "2018-08-20T04:38:21.524Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_NN_model():\n",
    "#     main_numeric_input = Input(shape=(dim_main_numeric, ),name='main_numerical')\n",
    "#     main_cal_sequence = Input(shape=(dim_main_cal, ),name = 'main_categorical')\n",
    "#     x_main_cat = Embedding(num_words_main, main_ebd_size, trainable = True)(main_cal_sequence)\n",
    "#     x_main_cat = SpatialDropout1D(0.5)(x_main_cat)\n",
    "#     x_main_cat = Bidirectional(CuDNNGRU(8, return_sequences=True))(x_main_cat)\n",
    "# #     x_main_cat = Flatten()(x_main_cat)\n",
    "#     x_main_cat = Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x_main_cat)\n",
    "#     x_main_cat = BatchNormalization()(x_main_cat)\n",
    "#     avg_pool = GlobalAveragePooling1D()(x_main_cat)\n",
    "#     max_pool = GlobalMaxPooling1D()(x_main_cat)\n",
    "#     x_main_cat = concatenate([avg_pool, max_pool]) \n",
    "\n",
    "#     x_main_nu = Dense(192,activation='relu')(main_numeric_input)\n",
    "#     x_main_nu = Dropout(0.5)(x_main_nu)\n",
    "#     x = concatenate([x_main_nu, x_main_cat])\n",
    "#     x = Dense(64, activation='relu')(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     preds = Dense(1, activation=\"sigmoid\")(x)\n",
    "#     model = Model([main_numeric_input,main_cal_sequence], preds)\n",
    "#     model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T04:50:24.802967Z",
     "start_time": "2018-08-20T04:38:21.527Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_NN_model():\n",
    "#     main_numeric_input = Input(shape=(dim_main_numeric, ),name='main_numerical')\n",
    "#     main_cal_sequence = Input(shape=(dim_main_cal, ),name = 'main_categorical')\n",
    "#     x_main_cat = Embedding(num_words_main, main_ebd_size, trainable = True)(main_cal_sequence)\n",
    "#     x_main_cat = SpatialDropout1D(0.5)(x_main_cat)\n",
    "#     x_main_cat = Flatten()(x_main_cat)\n",
    "#     x_main_nu = BatchNormalization()(main_numeric_input)\n",
    "#     x_main_nu = Dense(192,activation='relu')(x_main_nu)\n",
    "#     x_main_nu = Dropout(0.5)(x_main_nu)\n",
    "#     x = concatenate([x_main_nu, x_main_cat])\n",
    "#     x = Dense(64, activation='relu')(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     preds = Dense(1, activation=\"sigmoid\")(x)\n",
    "#     model = Model([main_numeric_input,main_cal_sequence], preds)\n",
    "#     model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# class_ratio = 1\n",
    "# def train_each_epoch(model,**args):\n",
    "#     #######################################\n",
    "#     x_num = args['main_numerical']\n",
    "#     x_cat = args['main_categorical']\n",
    "#     y = args['y']\n",
    "#     batch_size = args['batch_size']\n",
    "#     ########################################\n",
    "#     x_num,x_cat,y = shuffle(x_num,x_cat,y)\n",
    "#     model.fit({'main_numerical': x_num, 'main_categorical': x_cat}, \n",
    "#               y, \n",
    "#               batch_size=batch_size, \n",
    "#               epochs=1,\n",
    "#               verbose=1,\n",
    "#               class_weight={0:1,1:class_ratio})\n",
    "#     return model\n",
    "\n",
    "# def load_model(model,filepath):\n",
    "#     model.load_weights(filepath)\n",
    "#     return model\n",
    "\n",
    "# def save_model(model, filepath):\n",
    "#     model.save_weights(filepath)\n",
    "    \n",
    "# def train_each_fold(model,**args):\n",
    "    \n",
    "#     x_num = args['main_n_train']\n",
    "#     x_num_val = args['main_n_val']\n",
    "#     x_cat = args['main_c_train']\n",
    "#     x_cat_val = args['main_c_val']\n",
    "#     y = args['y']\n",
    "#     y_val = args['y_val']\n",
    "#     filepath = args['filepath']\n",
    "#     reportpath = args['reportpath']\n",
    "#     predspath = args['predspath']\n",
    "#     batch_size = args.get('batch_size',512)\n",
    "#     total_epoch = args.get('total_epoch',400)\n",
    "#     patience = args.get('patience',5)\n",
    "#     saving = args.get('saving',True)\n",
    "    \n",
    "    \n",
    "#     ROC_AUC_SCORE = []\n",
    "#     for epoch in range(total_epoch):  \n",
    "#         model = train_each_epoch(model,\n",
    "#                                  main_numerical=x_num,\n",
    "#                                  main_categorical=x_cat,\n",
    "#                                  y=y,\n",
    "#                                  batch_size=batch_size)\n",
    "#         y_pred = model.predict({'main_numerical':x_num_val,\n",
    "#                                 'main_categorical':x_cat_val},\n",
    "#                                batch_size=3000,\n",
    "#                                verbose=1)\n",
    "#         score = roc_auc_score(y_val,y_pred)\n",
    "#         logloss = log_loss(y_val,y_pred)\n",
    "#         if len(ROC_AUC_SCORE) == 0:\n",
    "#             if saving:\n",
    "#                 save_model(model,filepath)\n",
    "#             best_score = 0 \n",
    "#             if saving:\n",
    "#                 print('saving preds...')\n",
    "#                 pickle.dump(y_pred,open(predspath,'wb'))\n",
    "#         else:\n",
    "#             best_score = max(ROC_AUC_SCORE)\n",
    "#             if score >= best_score:\n",
    "#                 if saving:\n",
    "#                     print('saving model to... {}'.format(filepath))\n",
    "#                     save_model(model,filepath)\n",
    "#                     print('saving preds...')\n",
    "#                     pickle.dump(y_pred,open(predspath,'wb'))\n",
    "#         ROC_AUC_SCORE.append(score)\n",
    "#         if saving:\n",
    "#             print('saving report to... {}'.format(reportpath))\n",
    "#             pickle.dump(ROC_AUC_SCORE,open(reportpath,'wb'))\n",
    "#         print('======= current {} / {}'.format(epoch,total_epoch))\n",
    "#         print('previous best roc is {}'.format(best_score))\n",
    "#         print('current roc is {}'.format(score))\n",
    "#         print('current loss is {}'.format(logloss))\n",
    "#         try:\n",
    "#             best_round = ROC_AUC_SCORE.index(best_score)\n",
    "#         except ValueError:\n",
    "#             best_round = -1\n",
    "#         if len(ROC_AUC_SCORE) > patience + best_round:\n",
    "#             print('reach patience! end loop')\n",
    "#             break\n",
    "            \n",
    "# def train_5_folds(**args):\n",
    "    \n",
    "#     filepath = args['filepath']\n",
    "#     reportpath = args['reportpath']\n",
    "#     predspath = args['predspath']\n",
    "#     pred_test_file = args['predspath_test']\n",
    "#     batch_size = args.get('batch_size',512)\n",
    "#     total_epoch = args.get('total_epoch',400)\n",
    "#     patience = args.get('patience',5)\n",
    "#     saving = args.get('saving',True)\n",
    "    \n",
    "#     train_fold_index = pickle.load(open(ENV.train_fold_index.value,'rb'))\n",
    "#     val_fold_index = pickle.load(open(ENV.val_fold_index.value,'rb'))\n",
    "\n",
    "#     for fold in range(0,len(train_fold_index)):\n",
    "#         print('!!!!!!!! Begin fold: {}'.format(fold))\n",
    "#         train_index = train_fold_index[fold]\n",
    "#         val_index = val_fold_index[fold]\n",
    "#         X_tra_nu = x_num_train[train_index]\n",
    "#         X_tra_cat = x_cal_train[train_index]\n",
    "#         X_val_nu = x_num_train[val_index]\n",
    "#         X_val_cat = x_cal_train[val_index]\n",
    "#         y_tra = y_train[train_index]\n",
    "#         y_val = y_train[val_index]\n",
    "#         print('preparing train/val done!')\n",
    "#         print('before evaluating: {}'.format(model_file))\n",
    "#         model_file_evl = filepath.format(fold)\n",
    "#         report_file_evl = reportpath.format(fold)\n",
    "#         pred_file_evl = predspath.format(fold)\n",
    "#         pred_test_file_evl = pred_test_file.format(fold)\n",
    "#         model = get_NN_model()\n",
    "#         train_each_fold(model,\n",
    "#                 main_n_train=X_tra_nu,\n",
    "#                 main_n_val=X_val_nu,\n",
    "#                 main_c_train=X_tra_cat,\n",
    "#                 main_c_val=X_val_cat,\n",
    "#                 y=y_tra,\n",
    "#                 y_val=y_val,\n",
    "#                 filepath=model_file_evl,\n",
    "#                 reportpath=report_file_evl,\n",
    "#                 predspath=pred_file_evl,\n",
    "#                 batch_size=batch_size,\n",
    "#                 total_epoch=total_epoch,\n",
    "#                 patience=patience,\n",
    "#                 saving=saving)\n",
    "#         gc.collect()\n",
    "#         #### predict test\n",
    "#         model = load_model(model,model_file_evl)\n",
    "#         test_preds = model.predict({'main_numerical':x_num_test,\n",
    "#                                 'main_categorical':x_cal_test},batch_size=1500,verbose=1)\n",
    "#         pickle.dump(test_preds,open(pred_test_file_evl,'wb'))\n",
    "#         print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
