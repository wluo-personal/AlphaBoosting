{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:18.960941Z",
     "start_time": "2018-08-14T02:14:18.489260Z"
    }
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../LIB/')\n",
    "from env import ENV\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:19.567302Z",
     "start_time": "2018-08-14T02:14:18.962532Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU,CuDNNGRU,Flatten,BatchNormalization\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:19.571668Z",
     "start_time": "2018-08-14T02:14:19.568851Z"
    }
   },
   "outputs": [],
   "source": [
    "def scan_nan_portion(df):\n",
    "    portions = []\n",
    "    columns = []\n",
    "    for col in df.columns:\n",
    "        columns.append(col)\n",
    "        portions.append(np.sum(df[col].isnull())/len(df))\n",
    "    return pd.Series(data=portions, index=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:23.059118Z",
     "start_time": "2018-08-14T02:14:19.573078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (307511, 122)\n",
      "Test shape: (48744, 121)\n",
      "Previous App shape: (1670214, 37)\n",
      "Bureau Balance shape: (27299925, 3)\n",
      "Bureau shape: (1716428, 17)\n",
      "Installment shape: (13605401, 8)\n",
      "POS CASH shape: (10001358, 8)\n",
      "Credit Card shape: (3840312, 23)\n"
     ]
    }
   ],
   "source": [
    "X_Train = pd.read_pickle(ENV.application_train_cleaned.value)\n",
    "print('Train shape: {}'.format(X_Train.shape))\n",
    "\n",
    "X_Test = pd.read_pickle(ENV.application_test_cleaned.value)\n",
    "print('Test shape: {}'.format(X_Test.shape))\n",
    "\n",
    "X_pre = pd.read_pickle(ENV.previous_application_cleaned.value)\n",
    "print('Previous App shape: {}'.format(X_pre.shape))\n",
    "\n",
    "X_bu_b = pd.read_pickle(ENV.bureau_balance_clean.value)\n",
    "print('Bureau Balance shape: {}'.format(X_bu_b.shape))\n",
    "\n",
    "X_bu = pd.read_pickle(ENV.bureau_cleaned.value)\n",
    "print('Bureau shape: {}'.format(X_bu.shape))\n",
    "\n",
    "X_ins = pd.read_pickle(ENV.installments_payments_clean.value)\n",
    "print('Installment shape: {}'.format(X_ins.shape))\n",
    "\n",
    "X_pos = pd.read_pickle(ENV.POS_CASH_balance_clean.value)\n",
    "print('POS CASH shape: {}'.format(X_pos.shape))\n",
    "\n",
    "X_cc = pd.read_pickle(ENV.credit_card_balance_clean.value)\n",
    "print('Credit Card shape: {}'.format(X_cc.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:23.844780Z",
     "start_time": "2018-08-14T02:14:23.060728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installment shape: (13605401, 8)\n"
     ]
    }
   ],
   "source": [
    "X_ins = pd.read_pickle(ENV.installments_payments_clean.value)\n",
    "print('Installment shape: {}'.format(X_ins.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:31.357160Z",
     "start_time": "2018-08-14T02:14:23.846417Z"
    }
   },
   "outputs": [],
   "source": [
    "sort_ins = X_ins.sort_values(['SK_ID_CURR','DAYS_INSTALMENT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process NUM_INSTALMENT_VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:32.941544Z",
     "start_time": "2018-08-14T02:14:31.358872Z"
    }
   },
   "outputs": [],
   "source": [
    "col = 'NUM_INSTALMENT_VERSION'\n",
    "mapping = pd.Series(index=range(0,179),data=range(0,179))\n",
    "mapping[(mapping.index>=3)&(mapping.index<6)] = 3  \n",
    "mapping[(mapping.index>=6)&(mapping.index<15)] = 4  \n",
    "mapping[(mapping.index>=15)] = 5\n",
    "sort_ins[col] = sort_ins[col].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process count install ment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:33.924007Z",
     "start_time": "2018-08-14T02:14:32.943085Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = sort_ins.groupby('SK_ID_CURR')\n",
    "dicts = {}\n",
    "count = 0\n",
    "mapping = sort_ins[['SK_ID_CURR','SK_ID_PREV']].drop_duplicates()\n",
    "mapping = mapping.SK_ID_CURR.value_counts()\n",
    "sort_ins['count_apps'] = sort_ins.SK_ID_CURR.map(mapping)\n",
    "mapping = pd.Series(index=range(0,26),data=range(0,26))\n",
    "mapping[(mapping.index>=7)&(mapping.index<15)] = 7  \n",
    "mapping[(mapping.index>=15)&(mapping.index<29)] = 8\n",
    "sort_ins['count_apps'] = sort_ins.count_apps.map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T23:51:12.988699Z",
     "start_time": "2018-08-13T23:51:12.886217Z"
    }
   },
   "source": [
    "# Process portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:33.945393Z",
     "start_time": "2018-08-14T02:14:33.925498Z"
    }
   },
   "outputs": [],
   "source": [
    "sort_ins['payment_portion'] = sort_ins['AMT_PAYMENT'] / sort_ins['AMT_INSTALMENT'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:34.391868Z",
     "start_time": "2018-08-14T02:14:33.946924Z"
    }
   },
   "outputs": [],
   "source": [
    "sort_ins.loc[sort_ins['payment_portion']>1,'payment_portion'] = 2\n",
    "sort_ins.loc[sort_ins['payment_portion']==1,'payment_portion'] = 1\n",
    "sort_ins.loc[(sort_ins['payment_portion']>0.5)&(sort_ins['payment_portion']<1),'payment_portion'] = -1\n",
    "sort_ins.loc[(sort_ins['payment_portion']>0.0)&(sort_ins['payment_portion']<=0.5),'payment_portion'] = -2\n",
    "sort_ins.loc[sort_ins['payment_portion']==0,'payment_portion'] = -3\n",
    "sort_ins['payment_portion'] = sort_ins['payment_portion'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process total portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:34.796908Z",
     "start_time": "2018-08-14T02:14:34.393357Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = sort_ins.groupby('SK_ID_CURR')\n",
    "ap = groups.AMT_PAYMENT.sum()\n",
    "ai = groups.AMT_INSTALMENT.sum()\n",
    "tportion = ap / ai\n",
    "sort_ins['total_payment_portion'] = sort_ins.SK_ID_CURR.map(tportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:35.245659Z",
     "start_time": "2018-08-14T02:14:34.798464Z"
    }
   },
   "outputs": [],
   "source": [
    "sort_ins.loc[sort_ins['total_payment_portion']>1,'total_payment_portion'] = 2\n",
    "sort_ins.loc[sort_ins['total_payment_portion']==1,'total_payment_portion'] = 1\n",
    "sort_ins.loc[(sort_ins['total_payment_portion']>0.5)&(sort_ins['total_payment_portion']<1),'total_payment_portion'] = -1\n",
    "sort_ins.loc[(sort_ins['total_payment_portion']>0.0)&(sort_ins['total_payment_portion']<=0.5),'total_payment_portion'] = -2\n",
    "sort_ins.loc[sort_ins['total_payment_portion']==0,'total_payment_portion'] = -3\n",
    "sort_ins['total_payment_portion'] = sort_ins['total_payment_portion'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:35.249646Z",
     "start_time": "2018-08-14T02:14:35.247166Z"
    }
   },
   "outputs": [],
   "source": [
    "feature = list(sort_ins.columns)\n",
    "feature.remove('SK_ID_PREV')\n",
    "feature.remove('SK_ID_CURR')\n",
    "feature.remove('DAYS_INSTALMENT')\n",
    "feature.remove('DAYS_ENTRY_PAYMENT')\n",
    "feature.remove('NUM_INSTALMENT_NUMBER')\n",
    "feature.remove('AMT_INSTALMENT')\n",
    "feature.remove('AMT_PAYMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:35.257245Z",
     "start_time": "2018-08-14T02:14:35.250951Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_group(df,cols):\n",
    "    groups = df[cols[0]].astype('str')\n",
    "    for each in cols[1:]:\n",
    "        groups += '_' + df[each].astype('str')\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:16:16.979098Z",
     "start_time": "2018-08-14T02:16:10.411220Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort_ins['words'] = get_group(sort_ins,feature)\n",
    "sort_ins['words'] = sort_ins.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:35.305155Z",
     "start_time": "2018-08-14T02:14:35.272062Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embeddings_index(sorted_df,nor_ebd):\n",
    "    embeddings_index={}\n",
    "    words_values = sorted_df['words'].values\n",
    "    for index in range(len(words_values)):\n",
    "        embeddings_index  [words_values[index]] = nor_ebd[index,:]\n",
    "    return embeddings_index\n",
    "\n",
    "def create_document(sorted_df):\n",
    "    #Create document\n",
    "    ids = sorted_df.SK_ID_CURR.values\n",
    "    words = sorted_df.words.values\n",
    "    document_dicts = {}\n",
    "\n",
    "    id_list = []\n",
    "    document_list = []\n",
    "\n",
    "    for index in range(len(ids)) :\n",
    "        if document_dicts.get(ids[index]) is None:\n",
    "            document_dicts[ids[index]] = []\n",
    "        document_dicts[ids[index]].append(words[index])\n",
    "\n",
    "    for key in document_dicts :\n",
    "        document_dicts[key] = ' '.join(document_dicts[key])\n",
    "        id_list.append(key)\n",
    "        document_list.append(document_dicts[key])\n",
    "\n",
    "\n",
    "    df_doc = pd.DataFrame({'SK_ID_CURR':id_list, 'text':document_list})  \n",
    "    df_doc_mapping  = df_doc.set_index('SK_ID_CURR').text\n",
    "\n",
    "    train = X_Train[['SK_ID_CURR','TARGET']].copy()\n",
    "    test = X_Test[['SK_ID_CURR']].copy()\n",
    "    train['text'] = train.SK_ID_CURR.map(df_doc_mapping).fillna('notfound')\n",
    "    test['text'] = test.SK_ID_CURR.map(df_doc_mapping).fillna('notfound')\n",
    "    return train,test\n",
    "\n",
    "\n",
    "def get_train_ebdMat(train,test,embeddings_index):\n",
    "    X_train = train[\"text\"].str.lower()\n",
    "    X_test = test[\"text\"].str.lower()\n",
    "    y_train = train[\"TARGET\"].values\n",
    "    tok=text.Tokenizer(num_words=max_features,lower=True,filters='')\n",
    "    tok.fit_on_texts(list(X_train)+list(X_test))\n",
    "    X_train=tok.texts_to_sequences(X_train)\n",
    "    X_test=tok.texts_to_sequences(X_test)\n",
    "    x_train=sequence.pad_sequences(X_train,maxlen=maxlen)\n",
    "    x_test=sequence.pad_sequences(X_test,maxlen=maxlen)\n",
    "    print('...get ebd mat')\n",
    "    word_index = tok.word_index\n",
    "    #prepare embedding matrix\n",
    "    num_words = min(max_features, len(word_index) + 1)\n",
    "    print('num of words: {}'.format(num_words))\n",
    "    embedding_matrix = np.zeros((num_words, embed_size))\n",
    "    print(embedding_matrix.shape)\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return x_train,x_test,y_train,embedding_matrix,num_words\n",
    "\n",
    "class_ratio =  sum(X_Train.TARGET ==0)/sum(X_Train.TARGET ==1)\n",
    "class_ratio =  1\n",
    "def get_rnn_model(num_words,embed_size,embedding_matrix):\n",
    "    sequence_input = Input(shape=(maxlen, ))\n",
    "    \n",
    "    x = Embedding(num_words, embed_size, weights=[embedding_matrix],trainable = True)(sequence_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "#     x = Bidirectional(GRU(16, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "    x = Bidirectional(CuDNNGRU(8, return_sequences=True))(x)\n",
    "    x = Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    x = concatenate([avg_pool, max_pool]) \n",
    "   \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    preds = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(sequence_input, preds)\n",
    "#     Adam,RMSprop,Adagrad,Adadelta,Adamax,Nadam\n",
    "#     model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-4),metrics=['accuracy'])\n",
    "    model.compile(loss='binary_crossentropy',optimizer=Adam(),metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_each_epoch(x,y,batch_size,model):\n",
    "    model.fit(x, y, \n",
    "              batch_size=batch_size, \n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              class_weight={0:1,1:class_ratio})\n",
    "    return model\n",
    "\n",
    "def load_model(model,filepath):\n",
    "    model.load_weights(filepath)\n",
    "    return model\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    model.save_weights(filepath)\n",
    "\n",
    "def train_each_fold(x,y,x_val,y_val,model,filepath,reportpath,predspath,\n",
    "                    batch_size=512,total_epoch=40,patience=5,saving=True):\n",
    "    ROC_AUC_SCORE = []\n",
    "    for epoch in range(total_epoch):  \n",
    "        model = train_each_epoch(x,y,batch_size,model)\n",
    "        y_pred = model.predict(x_val,batch_size=3000,verbose=1)\n",
    "        print(y_pred)\n",
    "        score = roc_auc_score(y_val,y_pred)\n",
    "        if len(ROC_AUC_SCORE) == 0:\n",
    "            if saving:\n",
    "                save_model(model,filepath)\n",
    "            best_score = 0 \n",
    "            if saving:\n",
    "                print('saving preds...')\n",
    "                pickle.dump(y_pred,open(predspath,'wb'))\n",
    "        else:\n",
    "            best_score = max(ROC_AUC_SCORE)\n",
    "            if score >= best_score:\n",
    "                if saving:\n",
    "                    print('saving model to... {}'.format(filepath))\n",
    "                    save_model(model,filepath)\n",
    "                    print('saving preds...')\n",
    "                    pickle.dump(y_pred,open(predspath,'wb'))\n",
    "        ROC_AUC_SCORE.append(score)\n",
    "        if saving:\n",
    "            print('saving report to... {}'.format(reportpath))\n",
    "            pickle.dump(ROC_AUC_SCORE,open(reportpath,'wb'))\n",
    "        print('======= current {} / {}'.format(epoch,total_epoch))\n",
    "        print('previous best roc is {}'.format(best_score))\n",
    "        print('current roc is {}'.format(score))\n",
    "        try:\n",
    "            best_round = ROC_AUC_SCORE.index(best_score)\n",
    "        except ValueError:\n",
    "            best_round = -1\n",
    "        if len(ROC_AUC_SCORE) > patience + best_round:\n",
    "            print('reach patience! end loop')\n",
    "            break\n",
    "            \n",
    "def train_5_folds(model_file,report_file,pred_file,pred_test_file,batch_size=512,total_epoch=400,patience=30,saving=False):\n",
    "    train_fold_index = pickle.load(open(ENV.train_fold_index.value,'rb'))\n",
    "    val_fold_index = pickle.load(open(ENV.val_fold_index.value,'rb'))\n",
    "\n",
    "    for fold in range(len(train_fold_index)):\n",
    "        print('!!!!!!!! Begin fold: {}'.format(fold))\n",
    "        train_index = train_fold_index[fold]\n",
    "        val_index = val_fold_index[fold]\n",
    "        X_tra = x_train[train_index]\n",
    "        y_tra = y_train[train_index]\n",
    "        X_val = x_train[val_index]\n",
    "        y_val = y_train[val_index]\n",
    "        print('preparing train/val done!')\n",
    "        print('before evaluating: {}'.format(model_file))\n",
    "        model_file_evl = model_file.format(fold)\n",
    "        report_file_evl = report_file.format(fold)\n",
    "        pred_file_evl = pred_file.format(fold)\n",
    "        pred_test_file_evl = pred_test_file.format(fold)\n",
    "        model = get_rnn_model(num_words,embed_size,embedding_matrix)\n",
    "        train_each_fold(X_tra, y_tra, X_val, y_val,\n",
    "                        model,\n",
    "                        filepath=model_file_evl,reportpath=report_file_evl,predspath=pred_file_evl,\n",
    "                        batch_size=batch_size,total_epoch=total_epoch,patience=patience,saving=saving)\n",
    "        #### predict test\n",
    "        model = load_model(model,model_file_evl)\n",
    "        test_preds = model.predict(x_test,batch_size=1500,verbose=1)\n",
    "        pickle.dump(test_preds,open(pred_test_file_evl,'wb'))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:18:56.058507Z",
     "start_time": "2018-08-14T02:17:12.786113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start normalize\n",
      "get embedding\n",
      "create document\n",
      "get embedding Mat\n",
      "...get ebd mat\n",
      "num of words: 1000\n",
      "(1000, 4)\n",
      "!!!!!!!! Begin fold: 0\n",
      "preparing train/val done!\n",
      "before evaluating: ../LIB/../../data/rnn/installment/fold_{}.hdf5\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2000,60,4]\n\t [[Node: embedding_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n\t [[Node: metrics/acc/Mean_1/_249 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2650_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'embedding_1/Gather', defined at:\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-29d6f18de0b3>\", line 26, in <module>\n    train_5_folds(model_file,report_file,pred_file,pred_test_file,batch_size=2000,total_epoch=500,patience=30,saving=False)\n  File \"<ipython-input-16-218e5a89ea18>\", line 162, in train_5_folds\n    model = get_rnn_model(num_words,embed_size,embedding_matrix)\n  File \"<ipython-input-16-218e5a89ea18>\", line 69, in get_rnn_model\n    x = Embedding(num_words, embed_size, weights=[embedding_matrix],trainable = True)(sequence_input)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 134, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1193, in gather\n    return tf.gather(reference, indices)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2486, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1834, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2000,60,4]\n\t [[Node: embedding_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n\t [[Node: metrics/acc/Mean_1/_249 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2650_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2000,60,4]\n\t [[Node: embedding_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n\t [[Node: metrics/acc/Mean_1/_249 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2650_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-29d6f18de0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mpred_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstallment_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mpred_test_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstallment_preds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrain_5_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreport_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_test_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-218e5a89ea18>\u001b[0m in \u001b[0;36mtrain_5_folds\u001b[0;34m(model_file, report_file, pred_file, pred_test_file, batch_size, total_epoch, patience, saving)\u001b[0m\n\u001b[1;32m    164\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                         \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_file_evl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreportpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_file_evl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredspath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_file_evl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                         batch_size=batch_size,total_epoch=total_epoch,patience=patience,saving=saving)\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;31m#### predict test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_file_evl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-218e5a89ea18>\u001b[0m in \u001b[0;36mtrain_each_fold\u001b[0;34m(x, y, x_val, y_val, model, filepath, reportpath, predspath, batch_size, total_epoch, patience, saving)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mROC_AUC_SCORE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_each_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-218e5a89ea18>\u001b[0m in \u001b[0;36mtrain_each_epoch\u001b[0;34m(x, y, batch_size, model)\u001b[0m\n\u001b[1;32m     94\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m               class_weight={0:1,1:class_ratio})\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2000,60,4]\n\t [[Node: embedding_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n\t [[Node: metrics/acc/Mean_1/_249 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2650_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'embedding_1/Gather', defined at:\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2909, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-29d6f18de0b3>\", line 26, in <module>\n    train_5_folds(model_file,report_file,pred_file,pred_test_file,batch_size=2000,total_epoch=500,patience=30,saving=False)\n  File \"<ipython-input-16-218e5a89ea18>\", line 162, in train_5_folds\n    model = get_rnn_model(num_words,embed_size,embedding_matrix)\n  File \"<ipython-input-16-218e5a89ea18>\", line 69, in get_rnn_model\n    x = Embedding(num_words, embed_size, weights=[embedding_matrix],trainable = True)(sequence_input)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 134, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1193, in gather\n    return tf.gather(reference, indices)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2486, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1834, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/kai/anaconda3/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[2000,60,4]\n\t [[Node: embedding_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_1/embeddings/read, embedding_1/Cast)]]\n\t [[Node: metrics/acc/Mean_1/_249 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2650_metrics/acc/Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "label_mapping = X_Train.set_index('SK_ID_CURR').TARGET\n",
    "test_mapping = pd.Series(index=X_Test.SK_ID_CURR, data=1)\n",
    "sorted_df = sort_ins\n",
    "#previous application\n",
    "#13605401\n",
    "max_features = 1000\n",
    "#372\n",
    "maxlen = 60\n",
    "embed_size = 4\n",
    "\n",
    "ebd = sorted_df[feature].values\n",
    "#normalize\n",
    "print('start normalize')\n",
    "# nor_ebd = normalize(ebd, norm='max',axis=0)\n",
    "nor_ebd = ebd\n",
    "print('get embedding')\n",
    "embeddings_index = get_embeddings_index(sorted_df,nor_ebd)\n",
    "print('create document')\n",
    "train,test = create_document(sorted_df)\n",
    "print('get embedding Mat')\n",
    "x_train,x_test,y_train,embedding_matrix,num_words = get_train_ebdMat(train,test,embeddings_index)\n",
    "model_file = ENV.installment_rnn.value\n",
    "report_file = ENV.installment_report.value\n",
    "pred_file = ENV.installment_preds.value\n",
    "pred_test_file = ENV.installment_preds_test.value\n",
    "train_5_folds(model_file,report_file,pred_file,pred_test_file,batch_size=2000,total_epoch=500,patience=30,saving=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.607623Z",
     "start_time": "2018-08-14T02:14:18.565Z"
    }
   },
   "outputs": [],
   "source": [
    "train_5_folds(model_file,report_file,pred_file,pred_test_file,batch_size=2000,total_epoch=500,patience=30,saving=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.608379Z",
     "start_time": "2018-08-14T02:14:18.569Z"
    }
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.609082Z",
     "start_time": "2018-08-14T02:14:18.573Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train[\"text\"].str.lower()\n",
    "X_test = test[\"text\"].str.lower()\n",
    "y_train = train[\"TARGET\"].values\n",
    "tok=text.Tokenizer(num_words=max_features,lower=True,filters=None)\n",
    "tok.fit_on_texts(list(X_train.values)+list(X_test.values))\n",
    "X_train=tok.texts_to_sequences(X_train)\n",
    "X_test=tok.texts_to_sequences(X_test)\n",
    "x_train=sequence.pad_sequences(X_train,maxlen=maxlen)\n",
    "x_test=sequence.pad_sequences(X_test,maxlen=maxlen)\n",
    "print('...get ebd mat')\n",
    "word_index = tok.word_index\n",
    "#prepare embedding matrix\n",
    "num_words = min(max_features, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "return x_train,x_test,y_train,embedding_matrix,num_words,tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.609718Z",
     "start_time": "2018-08-14T02:14:18.590Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_mapping = X_Train.set_index('SK_ID_CURR').TARGET\n",
    "test_mapping = pd.Series(index=X_Test.SK_ID_CURR, data=1)\n",
    "\n",
    "#previous application\n",
    "#13605401\n",
    "max_features = 13605402\n",
    "#372\n",
    "maxlen = 60\n",
    "embed_size = 6\n",
    "\n",
    "# sorted_df = X_ins.sort_values(['SK_ID_CURR','DAYS_INSTALMENT']).copy()\n",
    "# sorted_df['words'] = sorted_df.index.astype(str)\n",
    "# feature = list(sorted_df.columns)\n",
    "# feature.remove('SK_ID_PREV')\n",
    "# feature.remove('SK_ID_CURR')\n",
    "feature.remove('words')\n",
    "ebd = sorted_df[feature].values\n",
    "#normalize\n",
    "print('start normalize')\n",
    "# nor_ebd = normalize(ebd, norm='max',axis=0)\n",
    "nor_ebd = ebd\n",
    "print('get embedding')\n",
    "embeddings_index = get_embeddings_index(sorted_df,nor_ebd)\n",
    "print('create document')\n",
    "train,test = create_document(sorted_df)\n",
    "print('get embedding Mat')\n",
    "x_train,x_test,y_train,embedding_matrix,num_words = get_train_ebdMat(train,test,embeddings_index)\n",
    "model_file = ENV.installment_rnn.value\n",
    "report_file = ENV.installment_report.value\n",
    "pred_file = ENV.installment_preds.value\n",
    "pred_test_file = ENV.installment_preds_test.value\n",
    "train_5_folds(model_file,report_file,pred_file,pred_test_file,batch_size=2000,total_epoch=500,patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.610397Z",
     "start_time": "2018-08-14T02:14:18.594Z"
    }
   },
   "outputs": [],
   "source": [
    "a = train.text.apply(lambda x: len(x.split(' ')))\n",
    "a.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS_CASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.611098Z",
     "start_time": "2018-08-14T02:14:18.597Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_mapping = X_Train.set_index('SK_ID_CURR').TARGET\n",
    "test_mapping = pd.Series(index=X_Test.SK_ID_CURR, data=1)\n",
    "\n",
    "#previous application\n",
    "#10001358\n",
    "max_features = 10001359\n",
    "#295\n",
    "maxlen = 300\n",
    "embed_size = 6\n",
    "\n",
    "sorted_df = X_pos.sort_values(['SK_ID_CURR','MONTHS_BALANCE'])\n",
    "sorted_df['words'] = sorted_df.index.astype(str)\n",
    "feature = list(sorted_df.columns)\n",
    "feature.remove('SK_ID_PREV')\n",
    "feature.remove('SK_ID_CURR')\n",
    "feature.remove('words')\n",
    "ebd = sorted_df[feature].values\n",
    "#normalize\n",
    "nor_ebd = normalize(ebd, norm='max',axis=0)\n",
    "embeddings_index = get_embeddings_index(sorted_df,nor_ebd)\n",
    "train,test = create_document(sorted_df)\n",
    "x_train,x_test,y_train,embedding_matrix,num_words = get_train_ebdMat(train,test,embeddings_index)\n",
    "model_file = ENV.POS_CASH_rnn.value\n",
    "report_file = ENV.POS_CASH_report.value\n",
    "pred_file = ENV.POS_CASH_preds.value\n",
    "pred_test_file = ENV.POS_CASH_preds_test.value\n",
    "train_5_folds(model_file,report_file,pred_file,pred_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.611807Z",
     "start_time": "2018-08-14T02:14:18.601Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "label_mapping = X_Train.set_index('SK_ID_CURR').TARGET\n",
    "test_mapping = pd.Series(index=X_Test.SK_ID_CURR, data=1)\n",
    "\n",
    "#previous application\n",
    "#10001358\n",
    "max_features = 10001359\n",
    "#192\n",
    "maxlen = 193\n",
    "embed_size = 21\n",
    "\n",
    "sorted_df = X_cc.sort_values(['SK_ID_CURR','MONTHS_BALANCE'])\n",
    "sorted_df['words'] = sorted_df.index.astype(str)\n",
    "feature = list(sorted_df.columns)\n",
    "feature.remove('SK_ID_PREV')\n",
    "feature.remove('SK_ID_CURR')\n",
    "feature.remove('words')\n",
    "ebd = sorted_df[feature].values\n",
    "#normalize\n",
    "nor_ebd = normalize(ebd, norm='max',axis=0)\n",
    "embeddings_index = get_embeddings_index(sorted_df,nor_ebd)\n",
    "train,test = create_document(sorted_df)\n",
    "x_train,x_test,y_train,embedding_matrix,num_words = get_train_ebdMat(train,test,embeddings_index)\n",
    "model_file = ENV.credit_card_rnn.value\n",
    "report_file = ENV.credit_card_report.value\n",
    "pred_file = ENV.credit_card_preds.value\n",
    "pred_test_file = ENV.credit_card_preds_test.value\n",
    "train_5_folds(model_file,report_file,pred_file,pred_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.612460Z",
     "start_time": "2018-08-14T02:14:18.605Z"
    }
   },
   "outputs": [],
   "source": [
    "len(sorted_df['words'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.613145Z",
     "start_time": "2018-08-14T02:14:18.609Z"
    }
   },
   "outputs": [],
   "source": [
    "len(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.613780Z",
     "start_time": "2018-08-14T02:14:18.611Z"
    }
   },
   "outputs": [],
   "source": [
    "max(train.text.apply(lambda x:len(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.614482Z",
     "start_time": "2018-08-14T02:14:18.614Z"
    }
   },
   "outputs": [],
   "source": [
    "max(test.text.apply(lambda x:len(x.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.615101Z",
     "start_time": "2018-08-14T02:14:18.618Z"
    }
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sort by sk curr and decision day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.615748Z",
     "start_time": "2018-08-14T02:14:18.620Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_pre = X_pre.sort_values(['SK_ID_CURR','DAYS_DECISION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use SK_ID_PREV as words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.616401Z",
     "start_time": "2018-08-14T02:14:18.624Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_pre['words'] = sorted_pre.SK_ID_PREV.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T03:45:12.057481Z",
     "start_time": "2018-08-11T03:45:12.049973Z"
    }
   },
   "source": [
    "# Get feature cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.617051Z",
     "start_time": "2018-08-14T02:14:18.627Z"
    }
   },
   "outputs": [],
   "source": [
    "feature = list(sorted_pre.columns)\n",
    "feature.remove('SK_ID_PREV')\n",
    "feature.remove('SK_ID_CURR')\n",
    "feature.remove('words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get EBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.617653Z",
     "start_time": "2018-08-14T02:14:18.632Z"
    }
   },
   "outputs": [],
   "source": [
    "ebd = sorted_pre[feature].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomralize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.618364Z",
     "start_time": "2018-08-14T02:14:18.634Z"
    }
   },
   "outputs": [],
   "source": [
    "nor_ebd = normalize(ebd, norm='max',axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get word EBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.619045Z",
     "start_time": "2018-08-14T02:14:18.638Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_index   = {}\n",
    "words_values = sorted_pre['words'].values\n",
    "for index in range(len(words_values)):\n",
    "    embeddings_index  [words_values[index]] = nor_ebd[index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.619690Z",
     "start_time": "2018-08-14T02:14:18.641Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_5_folds(model_file,report_file,pred_file,pred_test_file):\n",
    "    train_fold_index = pickle.load(open(ENV.train_fold_index.value,'rb'))\n",
    "    val_fold_index = pickle.load(open(ENV.val_fold_index.value,'rb'))\n",
    "\n",
    "    for fold in range(len(train_fold_index)):\n",
    "        print('!!!!!!!! Begin fold: {}'.format(fold))\n",
    "        train_index = train_fold_index[fold]\n",
    "        val_index = val_fold_index[fold]\n",
    "        X_tra = x_train[train_index]\n",
    "        y_tra = y_train[train_index]\n",
    "        X_val = x_train[val_index]\n",
    "        y_val = y_train[val_index]\n",
    "        print('preparing train/val done!')\n",
    "        model = get_rnn_model(num_words,embed_size,embedding_matrix)\n",
    "        train_each_fold(X_tra, y_tra, X_val, y_val,\n",
    "                        model,\n",
    "                        filepath=model_file,reportpath=report_file,predspath=pred_file,\n",
    "                        batch_size=512,total_epoch=40)\n",
    "        #### predict test\n",
    "        model = load_model(model,model_file)\n",
    "        test_preds = model.predict(x_test,batch_size=5120,verbose=1)\n",
    "        pickle.dump(test_preds,open(pred_test_file,'wb'))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.620404Z",
     "start_time": "2018-08-14T02:14:18.645Z"
    }
   },
   "outputs": [],
   "source": [
    "train_fold_index = pickle.load(open(ENV.train_fold_index.value,'rb'))\n",
    "val_fold_index = pickle.load(open(ENV.val_fold_index.value,'rb'))\n",
    "\n",
    "for fold in range(len(train_fold_index)):\n",
    "    print('!!!!!!!! Begin fold: {}'.format(fold))\n",
    "    train_index = train_fold_index[fold]\n",
    "    val_index = val_fold_index[fold]\n",
    "    X_tra = x_train[train_index]\n",
    "    y_tra = y_train[train_index]\n",
    "    X_val = x_train[val_index]\n",
    "    y_val = y_train[val_index]\n",
    "    print('preparing train/val done!')\n",
    "    model_file = ENV.previous_application_rnn.value.format(fold)\n",
    "    report_file = ENV.previous_application_report.value.format(fold)\n",
    "    pred_file = ENV.previous_application_preds.value.format(fold)\n",
    "    pred_test_file = ENV.previous_application_preds_test.value.format(fold)\n",
    "    model = get_rnn_model(num_words,embed_size,embedding_matrix)\n",
    "    train_each_fold(X_tra, y_tra, X_val, y_val,\n",
    "                    model,\n",
    "                    filepath=model_file,reportpath=report_file,predspath=pred_file,\n",
    "                    batch_size=512,total_epoch=40)\n",
    "    #### predict test\n",
    "    model = load_model(model,model_file)\n",
    "    test_preds = model.predict(x_test,batch_size=5120,verbose=1)\n",
    "    pickle.dump(test_preds,open(pred_test_file,'wb'))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.621098Z",
     "start_time": "2018-08-14T02:14:18.647Z"
    }
   },
   "outputs": [],
   "source": [
    "ssss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.621729Z",
     "start_time": "2018-08-14T02:14:18.655Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(maxlen, ))\n",
    "x = Embedding(num_words, embed_size, weights=[embedding_matrix],trainable = False)(sequence_input)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "x = Conv1D(64, kernel_size = 1, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = concatenate([avg_pool, max_pool]) \n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "preds = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.622383Z",
     "start_time": "2018-08-14T02:14:18.659Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 40\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state=233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.622999Z",
     "start_time": "2018-08-14T02:14:18.662Z"
    }
   },
   "outputs": [],
   "source": [
    "# filepath=\"../input/best-model/best.hdf5\"\n",
    "filepath=\"weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"max\", patience=40)\n",
    "ra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval = 1)\n",
    "callbacks_list = [ra_val,checkpoint, early]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.623691Z",
     "start_time": "2018-08-14T02:14:18.664Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"weights_base.best123.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.624576Z",
     "start_time": "2018-08-14T02:14:18.667Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_base.best123.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.625237Z",
     "start_time": "2018-08-14T02:14:18.670Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = model.predict(X_val,batch_size=5120,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-14T02:14:49.625863Z",
     "start_time": "2018-08-14T02:14:18.674Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),callbacks = callbacks_list,verbose=1,class_weight={0:1,1:11.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (tf_gpu)",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
