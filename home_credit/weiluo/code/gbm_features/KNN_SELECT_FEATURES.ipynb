{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:32:44.481280Z",
     "start_time": "2018-08-21T12:32:42.135714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: (307511, 764)\n",
      "test shape is: (48744, 763)\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../LIB/')\n",
    "from env import ENV\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "print_to_file = False \n",
    "test_run = False \n",
    "\n",
    "train = pd.read_pickle(ENV.lightgbm_train_764.value)\n",
    "print('train shape is: {}'.format(train.shape))\n",
    "test = pd.read_pickle(ENV.lightgbm_test_764.value)\n",
    "print('test shape is: {}'.format(test.shape))\n",
    "fe_id = 'comb_764'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:32:46.032016Z",
     "start_time": "2018-08-21T12:32:45.983963Z"
    }
   },
   "outputs": [],
   "source": [
    "train_id = train['SK_ID_CURR']\n",
    "test_id = test['SK_ID_CURR']\n",
    "\n",
    "train['SK_ID_CURR'] = train['SK_ID_CURR'].astype(int)\n",
    "test['SK_ID_CURR'] = test['SK_ID_CURR'].astype(int)\n",
    "targets = train.TARGET.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:32:47.605895Z",
     "start_time": "2018-08-21T12:32:47.552730Z"
    }
   },
   "outputs": [],
   "source": [
    "def scan_nan_portion(df):\n",
    "    portions = []\n",
    "    columns = []\n",
    "    for col in df.columns:\n",
    "        columns.append(col)\n",
    "        portions.append(np.sum(df[col].isnull())/len(df))\n",
    "    return pd.Series(data=portions, index=columns)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_time(timezone='America/New_York', time_format='%Y-%m-%d %H:%M:%S'):\n",
    "    from datetime import datetime\n",
    "    from dateutil import tz\n",
    "\n",
    "    # METHOD 1: Hardcode zones:\n",
    "    from_zone = tz.gettz('UTC')\n",
    "    to_zone = tz.gettz(timezone)\n",
    "\n",
    "    utc = datetime.utcnow()\n",
    "\n",
    "    # Tell the datetime object that it's in UTC time zone since \n",
    "    # datetime objects are 'naive' by default\n",
    "    utc = utc.replace(tzinfo=from_zone)\n",
    "\n",
    "    # Convert time zone\n",
    "    est = utc.astimezone(to_zone)\n",
    "\n",
    "    return est.strftime(time_format)\n",
    "\n",
    "import sys, time\n",
    "class Logger(object):\n",
    "    def __init__(self, logtofile=True, logfilename='log'):\n",
    "        self.terminal = sys.stdout\n",
    "        self.logfile = \"{}_{}.log\".format(logfilename, int(time.time()))\n",
    "        self.logtofile = logtofile\n",
    "\n",
    "    def write(self, message):\n",
    "        #         self.terminal.write(message)\n",
    "        if self.logtofile:\n",
    "            self.log = open(self.logfile, \"a\")\n",
    "            self.log.write('[' + get_time() + '] ' + message)\n",
    "            self.log.close()\n",
    "\n",
    "    def flush(self):\n",
    "        # this flush method is needed for python 3 compatibility.\n",
    "        # this handles the flush command by doing nothing.\n",
    "        # you might want to specify some extra behavior here.\n",
    "        pass\n",
    "\n",
    "\n",
    "def divert_printout_to_file():\n",
    "    sys.stdout = Logger(logfilename='logfile')\n",
    "\n",
    "if print_to_file:\n",
    "    divert_printout_to_file()  # note: comment this to use pdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# LightGBM GBDT with KFold or Stratified KFold\n",
    "# Parameters from Tilii kernel: https://www.kaggle.com/tilii7/olivier-lightgbm-parameters-by-bayesian-opt/code\n",
    "def kfold_lightgbm(df, train_df, test_df, holdout, num_folds, submission_file_name, fe_img_name, stratified = False, debug= False, colsample=0.67, max_depth=8, num_leaves=31, min_child_samples=20, subsample=0.7, reg_lambda=0.3, lr=0.04, seed=1001, verbose=100, rounds=None):\n",
    "    print(train_df.shape, test_df.shape, holdout.shape)\n",
    "    print('MEAN: train({}) vs holdout({}): '.format(len(train_df), len(holdout)), train_df['TARGET'].mean(), holdout['TARGET'].mean())\n",
    "    # Divide in training/validation and test data\n",
    "    if df is not None:\n",
    "        train_df = df[df['TARGET'].notnull()]\n",
    "        test_df = df[df['TARGET'].isnull()]\n",
    "        print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "        del df\n",
    "        gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=seed)\n",
    "        \n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    holdout_final_preds = np.zeros(holdout.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feature_importance_gain_df = pd.DataFrame()\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "    train_scores = []\n",
    "    holdout_scores = []\n",
    "    scores = []\n",
    "    diff_val_holdout = []\n",
    "    \n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "#         print('valid index : ',list(valid_idx)[:5])\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "#         print('MEAN: train({}) vs valid({}): '.format(len(train_y), len(valid_y)), np.mean(train_y), np.mean(valid_y))\n",
    "\n",
    "        clf = LGBMClassifier(\n",
    "            nthread=18,\n",
    "            n_estimators=30000,\n",
    "            learning_rate=lr,\n",
    "            num_leaves=num_leaves,\n",
    "            colsample_bytree=colsample, # 0.67\n",
    "            subsample=subsample,\n",
    "            subsample_freq=0, ## disable subsampling\n",
    "            max_depth=max_depth,\n",
    "            reg_alpha=0.65,\n",
    "            reg_lambda=reg_lambda,\n",
    "            min_split_gain=0.0222415,\n",
    "            min_child_weight=39.3259775,\n",
    "            min_child_samples=min_child_samples,\n",
    "            silent=-1,\n",
    "            verbose=-1, )\n",
    "        if rounds is not None:\n",
    "            clf.n_estimators = rounds\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric= 'auc', verbose=verbose)\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "            sub_preds += clf.predict_proba(test_df[feats])[:, 1] / folds.n_splits\n",
    "            holdout_preds = clf.predict_proba(holdout[feats])[:, 1] \n",
    "        else:\n",
    "            clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric= 'auc', verbose=verbose, early_stopping_rounds= 200)\n",
    "            oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "            sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "            holdout_preds = clf.predict_proba(holdout[feats], num_iteration=clf.best_iteration_)[:, 1] \n",
    "            \n",
    "        holdout_final_preds += holdout_preds / folds.n_splits\n",
    "        score = roc_auc_score(valid_y, oof_preds[valid_idx])\n",
    "        train_score = clf.best_score_['training']['auc']\n",
    "        holdout_score = roc_auc_score(holdout['TARGET'], holdout_preds)\n",
    "        diff = abs(score - holdout_score)\n",
    "        best_rounds = rounds if rounds is not None else clf.best_iteration_\n",
    "        print('Fold %2d [%5d] AUC : ho: %.6f / te: %.6f / tr: %.6f (diff: %.6f)' % (n_fold + 1, best_rounds, holdout_score, score,  train_score, diff))\n",
    "        scores.append(score)\n",
    "        train_scores.append(train_score)\n",
    "        holdout_scores.append(holdout_score)\n",
    "        diff_val_holdout.append(diff)\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        fold_importance_gain_df = pd.DataFrame()\n",
    "        fold_importance_gain_df[\"feature\"] = feats\n",
    "        fold_importance_gain_df[\"importance\"] = clf.booster_.feature_importance(importance_type='gain')\n",
    "        fold_importance_gain_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_gain_df = pd.concat([feature_importance_gain_df, fold_importance_gain_df], axis=0)\n",
    "        \n",
    "        del clf, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()\n",
    "    holdout_roc = roc_auc_score(holdout['TARGET'], holdout_final_preds)\n",
    "    holdout_mean = np.mean(holdout_scores)\n",
    "    full_te_mean = np.mean(scores)\n",
    "    full_tr_mean = np.mean(train_scores)\n",
    "#     print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n",
    "    print('Full HO score %.6f' % holdout_roc)\n",
    "    print('FULL HO mean {:.6f}, std {:.6f}'.format(holdout_mean, np.std(holdout_scores)))\n",
    "    print('FULL TE mean {:.6f}, std {:.6f}'.format(full_te_mean, np.std(scores)))\n",
    "    print('FULL TR mean {:.6f}, std {:.6f}'.format(full_tr_mean, np.std(train_scores)))\n",
    "    print('FULL DIFF mean {:.6f}, std {:.6f}'.format(np.mean(diff_val_holdout), np.std(diff_val_holdout)))\n",
    "    # Write submission file and plot feature importance\n",
    "    if not debug:\n",
    "        test_df['TARGET'] = sub_preds\n",
    "        test_df[['SK_ID_CURR', 'TARGET']].to_csv(submission_file_name, index= False)\n",
    "#     if not print_to_file:\n",
    "#         display_importances(feature_importance_df, fe_img_name)\n",
    "    feature_importance_df = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    feature_importance_gain_df = feature_importance_gain_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    return feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds \n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_, fe_img_name):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fe_img_name+'.png')\n",
    "\n",
    "\n",
    "def convert_and_save_imp_df(fe_imp_df, dumpfilename):\n",
    "    fe_imp_df_mean = fe_imp_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).reset_index()\n",
    "    pickle.dump(fe_imp_df_mean, open(dumpfilename,'wb'))\n",
    "    \n",
    "    \n",
    "def runlgb(train, test, holdout):\n",
    "    colsamples = [0.07]#[0.1,0.15,0.2]#[0.03,0.04,0.05,0.06,0.07,0.08]\n",
    "    seeds = [20]#[300,4000,50000,600000,7000000,80000000,523445,31275479] # 20\n",
    "    depth = [5]\n",
    "    leaves = [16]\n",
    "    min_child_sam = [20]#, 800]\n",
    "    subsamples = [1]#0.8, 0.7, 0.6, 0.5, 0.4] # was 1\n",
    "    reg_lambdas = [0.5]\n",
    "    # lrs = lrs.tolist()\n",
    "    lrs2 = [0.1]\n",
    "    nfolds = 4 \n",
    "    rounds = [None] #[1000]#, 1300, 1600, 1900, 2200, 2500]\n",
    "    for seed in seeds:\n",
    "        for colsample in colsamples:\n",
    "            for d in depth:\n",
    "                for l in leaves:\n",
    "                    for mcs in min_child_sam:\n",
    "                        for subsample in subsamples:\n",
    "                            for reg_lambda in reg_lambdas:\n",
    "                                for lr in lrs2:\n",
    "                                    for r in rounds:\n",
    "                                        filename = 'fe_936_col{}_lr{}_n{}'.format(len(train.columns), lr, nfolds)\n",
    "                                        print('#############################################')\n",
    "                                        print(colsample, seed, d, l, mcs, subsample, reg_lambda, lr, 'nfolds:', nfolds)\n",
    "                                        print('#############################################')\n",
    "                                        numfeats = len(train.columns)\n",
    "                                        with timer(\"Run LightGBM with kfold\"):\n",
    "                                            return kfold_lightgbm(None, train, test, holdout, nfolds, filename+'.csv', filename, colsample=colsample, verbose=None, max_depth=d, num_leaves=l, min_child_samples=mcs, subsample=subsample, reg_lambda=reg_lambda, lr=lr, seed=seed, stratified=True, rounds=r,debug=True)\n",
    "    #                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:32:49.090847Z",
     "start_time": "2018-08-21T12:32:49.088715Z"
    }
   },
   "outputs": [],
   "source": [
    "# X = pd.concat([train.drop('TARGET',axis=1),test])\n",
    "# print(X.shape)\n",
    "\n",
    "# X_coff = X.drop('SK_ID_CURR',axis=1)\n",
    "# coff = X_coff.corr()\n",
    "# coff.to_pickle('../../data/add_features/coff_764.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:33:32.267062Z",
     "start_time": "2018-08-21T12:33:32.250818Z"
    }
   },
   "outputs": [],
   "source": [
    "coff = pd.read_pickle(ENV.coff_764.value)\n",
    "coff_matrix = coff.values\n",
    "columns_index = coff.columns.values\n",
    "report = pd.read_pickle(ENV.drop_column_report.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:36:32.955459Z",
     "start_time": "2018-08-21T12:36:32.949870Z"
    }
   },
   "outputs": [],
   "source": [
    "col_name,thred_hroc,thred_hmean,thred_fulltemean,threa_tr_mean= list(report[report.drop_column=='nodrop'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc get increased number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:39:25.011950Z",
     "start_time": "2018-08-21T12:39:25.005888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(report.holdout_roc > thred_hroc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holdout_mean increased number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:40:19.328357Z",
     "start_time": "2018-08-21T12:40:19.321950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(report.holdout_mean > thred_hmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### full test mean get increased number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:41:14.263894Z",
     "start_time": "2018-08-21T12:41:14.257750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(report.full_te_mean > thred_fulltemean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All get increased number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:42:14.462123Z",
     "start_time": "2018-08-21T12:42:14.453474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((report.full_te_mean > thred_fulltemean) & (report.holdout_mean > thred_hmean) & (report.holdout_roc > thred_hroc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all increased columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:46:49.973987Z",
     "start_time": "2018-08-21T12:46:49.965267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "drop_list = list(report[(report.full_te_mean > thred_fulltemean) & (report.holdout_mean > thred_hmean) & (report.holdout_roc > thred_hroc)]['drop_column'].values)\n",
    "print(len(drop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T04:02:44.952132Z",
     "start_time": "2018-08-21T04:02:39.329395Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=600, random_state=0).fit(coff_matrix)\n",
    "labels = kmeans.labels_.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T04:04:32.459740Z",
     "start_time": "2018-08-21T04:04:30.161879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: train(263580) vs holdout(43931):  0.0807572653463844 0.08055814800482575\n",
      "(263580, 764) (48744, 763) (43931, 764)\n"
     ]
    }
   ],
   "source": [
    "train_df, holdout = train_test_split(train, test_size=1/7, random_state=42)\n",
    "print('MEAN: train({}) vs holdout({}): '.format(len(train_df), len(holdout)), train_df['TARGET'].mean(), holdout['TARGET'].mean())\n",
    "print(train_df.shape, test.shape, holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T04:06:04.854804Z",
     "start_time": "2018-08-21T04:04:36.172340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "0.07 20 5 16 20 1 0.5 0.1 nfolds: 4\n",
      "#############################################\n",
      "(263580, 764) (48744, 763) (43931, 764)\n",
      "MEAN: train(263580) vs holdout(43931):  0.0807572653463844 0.08055814800482575\n",
      "Fold  1 [  528] AUC : ho: 0.792890 / te: 0.793603 / tr: 0.867796 (diff: 0.000713)\n",
      "Fold  2 [  434] AUC : ho: 0.793506 / te: 0.791989 / tr: 0.857608 (diff: 0.001517)\n",
      "Fold  3 [  561] AUC : ho: 0.792675 / te: 0.794414 / tr: 0.870024 (diff: 0.001739)\n",
      "Fold  4 [  415] AUC : ho: 0.793564 / te: 0.788659 / tr: 0.855359 (diff: 0.004905)\n",
      "Full HO score 0.797207\n",
      "FULL HO mean 0.793159, std 0.000385\n",
      "FULL TE mean 0.792166, std 0.002205\n",
      "FULL TR mean 0.862697, std 0.006313\n",
      "FULL DIFF mean 0.002219, std 0.001597\n",
      "Run LightGBM with kfold - done in 89s\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds = runlgb(train_df, test, holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process remove all increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:49:43.614786Z",
     "start_time": "2018-08-21T12:49:42.670198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 746)\n",
      "(48744, 745)\n"
     ]
    }
   ],
   "source": [
    "train_act_columns = list(set(train.columns) - set(drop_list))\n",
    "test_act_columns = list(set(test.columns) - set(drop_list))\n",
    "train_act = train[train_act_columns].copy()\n",
    "test_act = test[test_act_columns].copy()\n",
    "print(train_act.shape)\n",
    "print(test_act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:50:09.137879Z",
     "start_time": "2018-08-21T12:50:07.632876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: train(263580) vs holdout(43931):  0.0807572653463844 0.08055814800482575\n",
      "(263580, 746) (48744, 763) (43931, 746)\n"
     ]
    }
   ],
   "source": [
    "train_df, holdout = train_test_split(train_act, test_size=1/7, random_state=42)\n",
    "print('MEAN: train({}) vs holdout({}): '.format(len(train_df), len(holdout)), train_df['TARGET'].mean(), holdout['TARGET'].mean())\n",
    "print(train_df.shape, test.shape, holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T12:52:35.515849Z",
     "start_time": "2018-08-21T12:51:23.066189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "0.07 20 5 16 20 1 0.5 0.1 nfolds: 4\n",
      "#############################################\n",
      "(263580, 746) (48744, 745) (43931, 746)\n",
      "MEAN: train(263580) vs holdout(43931):  0.0807572653463844 0.08055814800482575\n",
      "Fold  1 [  515] AUC : ho: 0.791892 / te: 0.792562 / tr: 0.865798 (diff: 0.000670)\n",
      "Fold  2 [  555] AUC : ho: 0.792064 / te: 0.791566 / tr: 0.868780 (diff: 0.000499)\n",
      "Fold  3 [  635] AUC : ho: 0.792874 / te: 0.792257 / tr: 0.877403 (diff: 0.000617)\n",
      "Fold  4 [  530] AUC : ho: 0.794579 / te: 0.789682 / tr: 0.867789 (diff: 0.004897)\n",
      "Full HO score 0.797592\n",
      "FULL HO mean 0.792852, std 0.001064\n",
      "FULL TE mean 0.791517, std 0.001119\n",
      "FULL TR mean 0.869943, std 0.004439\n",
      "FULL DIFF mean 0.001671, std 0.001864\n",
      "Run LightGBM with kfold - done in 72s\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds = runlgb(train_df, test_act, holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T04:02:59.069310Z",
     "start_time": "2018-08-21T04:02:59.054645Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/762 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f8aefeb4cfb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiltered_array\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mna_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_nan_portion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mna_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mselected_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "selected_columns = []\n",
    "for index in tqdm(range(len(labels))):\n",
    "    filtered_array = (labels==labels[index])\n",
    "    if filtered_array.sum() == 1:\n",
    "        selected_columns.append(columns_index[index])\n",
    "    else:\n",
    "        columns = columns_index[filtered_array]\n",
    "        na_result = scan_nan_portion(X[columns])\n",
    "        na_result=na_result.sort_values()\n",
    "        selected_columns.append(na_result.index.values[0])\n",
    "selected_columns = list(set(selected_columns))\n",
    "print(len(selected_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T03:52:30.436865Z",
     "start_time": "2018-08-21T03:52:30.434161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T03:52:34.528454Z",
     "start_time": "2018-08-21T03:52:33.761633Z"
    }
   },
   "outputs": [],
   "source": [
    "test_select = test[selected_columns].copy()\n",
    "selected_columns.append('TARGET')\n",
    "train_select = train[selected_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T03:52:40.491263Z",
     "start_time": "2018-08-21T03:52:38.709683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: train(263580) vs holdout(43931):  0.0807572653463844 0.08055814800482575\n",
      "(263580, 601) (48744, 763) (43931, 601)\n"
     ]
    }
   ],
   "source": [
    "train_df, holdout = train_test_split(train_select, test_size=1/7, random_state=42)\n",
    "print('MEAN: train({}) vs holdout({}): '.format(len(train_df), len(holdout)), train_df['TARGET'].mean(), holdout['TARGET'].mean())\n",
    "print(train_df.shape, test.shape, holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T03:54:10.504401Z",
     "start_time": "2018-08-21T03:52:55.858731Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "0.07 20 5 16 20 1 0.5 0.1 nfolds: 4\n",
      "#############################################\n",
      "(263580, 601) (48744, 600) (43931, 601)\n",
      "MEAN: train(263580) vs holdout(43931):  0.0807572653463844 0.08055814800482575\n",
      "Fold  1 [  490] AUC : ho: 0.793089 / te: 0.792989 / tr: 0.860782 (diff: 0.000100)\n",
      "Fold  2 [  480] AUC : ho: 0.792482 / te: 0.791004 / tr: 0.860266 (diff: 0.001478)\n",
      "Fold  3 [  720] AUC : ho: 0.793195 / te: 0.793937 / tr: 0.882264 (diff: 0.000743)\n",
      "Fold  4 [  367] AUC : ho: 0.793329 / te: 0.787599 / tr: 0.848219 (diff: 0.005731)\n",
      "Full HO score 0.797428\n",
      "FULL HO mean 0.793024, std 0.000324\n",
      "FULL TE mean 0.791382, std 0.002427\n",
      "FULL TR mean 0.862883, std 0.012267\n",
      "FULL DIFF mean 0.002013, std 0.002201\n",
      "Run LightGBM with kfold - done in 75s\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds = runlgb(train_df, test_select, holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T03:50:47.998838Z",
     "start_time": "2018-08-21T03:49:21.006338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#############################################\n",
      "0.07 20 5 16 20 1 0.5 0.1 nfolds: 4\n",
      "#############################################\n",
      "(263580, 764) (48744, 763) (43931, 764)\n",
      "MEAN: train(263580) vs holdout(43931):  0.0807572653463844 0.08055814800482575\n",
      "Fold  1 [  528] AUC : ho: 0.792890 / te: 0.793603 / tr: 0.867796 (diff: 0.000713)\n",
      "Fold  2 [  434] AUC : ho: 0.793506 / te: 0.791989 / tr: 0.857608 (diff: 0.001517)\n",
      "Fold  3 [  561] AUC : ho: 0.792675 / te: 0.794414 / tr: 0.870024 (diff: 0.001739)\n",
      "Fold  4 [  415] AUC : ho: 0.793564 / te: 0.788659 / tr: 0.855359 (diff: 0.004905)\n",
      "Full HO score 0.797207\n",
      "FULL HO mean 0.793159, std 0.000385\n",
      "FULL TE mean 0.792166, std 0.002205\n",
      "FULL TR mean 0.862697, std 0.006313\n",
      "FULL DIFF mean 0.002219, std 0.001597\n",
      "Run LightGBM with kfold - done in 87s\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df, feature_importance_gain_df,holdout_roc,holdout_mean,full_te_mean,full_tr_mean,oof_preds = runlgb(train_df, test, holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
