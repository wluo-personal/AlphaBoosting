{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T16:05:42.957264Z",
     "start_time": "2018-06-29T16:05:42.940777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkaggle: kurtois\\n drop some columns\\n add mean of ext 1,2,3\\n add ratio of intersecting cols in (prev, train)\\n drop some columns\\n '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "kaggle: kurtois\n",
    " add mean of ext 1,2,3\n",
    " add ratio of intersecting cols in (prev, train)\n",
    " drop some columns\n",
    " factorize some cols\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T16:12:39.012902Z",
     "start_time": "2018-06-29T16:12:29.375888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'application_train.csv')\n",
    "test = pd.read_csv(PATH + 'application_test.csv')\n",
    "prev = pd.read_csv(PATH + 'previous_application.csv')\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:59:19.019359Z",
     "start_time": "2018-06-29T17:59:09.822397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 818)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "prev = pd.read_pickle(PATH + 'test/prev2curr_0.pkl')\n",
    "print(prev.shape)\n",
    "train = pd.read_pickle(PATH + 'inter/train_only_0.pkl')\n",
    "test = pd.read_pickle(PATH + 'inter/test_only_0.pkl')\n",
    "\n",
    "df = pd.concat([train, test], axis = 0)\n",
    "df = df.merge(prev, how = 'left', on = 'SK_ID_CURR', sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:08:16.791650Z",
     "start_time": "2018-06-29T17:08:16.767190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def minus_name(col1, col2): return col1 + '_minus_' + col2\n",
    "def minus(df, col1, col2): return df[col1] - df[col2]\n",
    "\n",
    "def ratio_name(col1, col2): return col1 + '_divide_' + col2\n",
    "def ratio(df, col1, col2): return df[col1] / df[col2]\n",
    "\n",
    "def multiply_name(col1, col2): return col1 + '_times_' + col2\n",
    "def multiply(df, col1, col2): return df[col1] * df[col2]\n",
    "\n",
    "def positive_count(df, gp_col, col):\n",
    "    group = (df[col] > 0).astype('int8')\n",
    "    group = pd.concat([df[gp_col], group], axis=1).groupby(gp_col)[[col]].sum().reset_index().rename(index=str, columns={col: 'positivecount_'+'_'.join([gp_col, col])})\n",
    "    return group.astype({gp_col: df[gp_col].dtype})\n",
    "\n",
    "def count(df, gp_col, col):\n",
    "    group = df[[gp_col,col]].groupby(gp_col)[[col]].count().reset_index().rename(index=str, columns={col:'count_'+gp_col})\n",
    "    return group.astype({gp_col: df[gp_col].dtype})\n",
    "\n",
    "def numerical(df, gp_col, col, agg_fun):\n",
    "    _df = df.groupby(gp_col)[[col]].agg(agg_fun)\n",
    "    \n",
    "    columns = []\n",
    "    for x in _df.columns.levels[0]:\n",
    "        for y in _df.columns.levels[1]:\n",
    "            columns.append('_'.join([x, y]))\n",
    "    _df.columns = columns\n",
    "    return _df.reset_index().astype({gp_col: df[gp_col].dtype})\n",
    "\n",
    "def one_hot(df, gp_col, col):\n",
    "    return pd.concat([df[gp_col], pd.get_dummies(df[col], prefix='onehot_' + col)], axis=1).groupby(gp_col).sum().reset_index().astype({gp_col: df[gp_col].dtype})\n",
    "\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T16:31:31.232184Z",
     "start_time": "2018-06-29T16:31:31.228494Z"
    }
   },
   "outputs": [],
   "source": [
    "# AMT_ANNUITY AMT_CREDIT AMT_GOODS_PRICE WEEKDAY_APPR_PROCESS_START HOUR_APPR_PROCESS_START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:38:58.258024Z",
     "start_time": "2018-06-29T17:38:58.129853Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_ANNUITY_divide_prev_AMT_ANNUITY_mean\n",
      "AMT_ANNUITY_divide_prev_AMT_ANNUITY_median\n",
      "AMT_ANNUITY_divide_prev_AMT_ANNUITY_max\n",
      "AMT_ANNUITY_divide_prev_AMT_ANNUITY_min\n",
      "AMT_CREDIT_divide_prev_AMT_CREDIT_mean\n",
      "AMT_CREDIT_divide_prev_AMT_CREDIT_median\n",
      "AMT_CREDIT_divide_prev_AMT_CREDIT_max\n",
      "AMT_CREDIT_divide_prev_AMT_CREDIT_min\n",
      "AMT_GOODS_PRICE_divide_prev_AMT_GOODS_PRICE_mean\n",
      "AMT_GOODS_PRICE_divide_prev_AMT_GOODS_PRICE_median\n",
      "AMT_GOODS_PRICE_divide_prev_AMT_GOODS_PRICE_max\n",
      "AMT_GOODS_PRICE_divide_prev_AMT_GOODS_PRICE_min\n",
      "WEEKDAY_APPR_PROCESS_START_divide_prev_WEEKDAY_APPR_PROCESS_START_mean\n",
      "WEEKDAY_APPR_PROCESS_START_divide_prev_WEEKDAY_APPR_PROCESS_START_median\n",
      "WEEKDAY_APPR_PROCESS_START_divide_prev_WEEKDAY_APPR_PROCESS_START_max\n",
      "WEEKDAY_APPR_PROCESS_START_divide_prev_WEEKDAY_APPR_PROCESS_START_min\n"
     ]
    }
   ],
   "source": [
    "amt_annuity = ['prev_AMT_ANNUITY_mean',\n",
    " 'prev_AMT_ANNUITY_median',\n",
    " 'prev_AMT_ANNUITY_max',\n",
    " 'prev_AMT_ANNUITY_min',\n",
    " 'prev_AMT_ANNUITY_sum']\n",
    "amt_credit = ['prev_AMT_CREDIT_mean',\n",
    " 'prev_AMT_CREDIT_median',\n",
    " 'prev_AMT_CREDIT_max',\n",
    " 'prev_AMT_CREDIT_min',\n",
    " 'prev_AMT_CREDIT_sum']\n",
    "amt_goods_price = ['prev_AMT_GOODS_PRICE_mean',\n",
    " 'prev_AMT_GOODS_PRICE_median',\n",
    " 'prev_AMT_GOODS_PRICE_max',\n",
    " 'prev_AMT_GOODS_PRICE_min',\n",
    " 'prev_AMT_GOODS_PRICE_sum']\n",
    "week = ['prev_WEEKDAY_APPR_PROCESS_START_mean',\n",
    " 'prev_WEEKDAY_APPR_PROCESS_START_median',\n",
    " 'prev_WEEKDAY_APPR_PROCESS_START_max',\n",
    " 'prev_WEEKDAY_APPR_PROCESS_START_min',\n",
    " 'prev_WEEKDAY_APPR_PROCESS_START_sum']\n",
    "\n",
    "list_df = ['AMT_ANNUITY','AMT_CREDIT', 'AMT_GOODS_PRICE', 'WEEKDAY_APPR_PROCESS_START']\n",
    "list_prev = [amt_annuity, amt_credit, amt_goods_price, week]\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        print(ratio_name(list_df[i], list_prev[i][j]))\n",
    "        df[ratio_name(list_df[i], list_prev[i][j])] = ratio(df, list_df[i], list_prev[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T18:26:04.590172Z",
     "start_time": "2018-06-29T18:26:04.531442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMT_INCOME_TOTAL_divide_prev_AMT_APPLICATION_mean\n",
      "AMT_INCOME_TOTAL_divide_prev_AMT_APPLICATION_max\n",
      "AMT_INCOME_TOTAL_divide_prev_AMT_APPLICATION_min\n",
      "AMT_INCOME_TOTAL_divide_prev_AMT_ANNUITY_mean\n",
      "AMT_INCOME_TOTAL_divide_prev_AMT_ANNUITY_max\n",
      "AMT_INCOME_TOTAL_divide_prev_AMT_ANNUITY_min\n",
      "AMT_INCOME_TOTAL_divide_prev_AMT_CREDIT_mean\n",
      "AMT_INCOME_TOTAL_divide_prev_AMT_CREDIT_max\n",
      "AMT_INCOME_TOTAL_divide_prev_AMT_CREDIT_min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = ['prev_AMT_APPLICATION_mean','prev_AMT_APPLICATION_max','prev_AMT_APPLICATION_min',\\\n",
    "     'prev_AMT_ANNUITY_mean','prev_AMT_ANNUITY_max','prev_AMT_ANNUITY_min',\\\n",
    "    'prev_AMT_CREDIT_mean','prev_AMT_CREDIT_max','prev_AMT_CREDIT_min']\n",
    "for i in x:\n",
    "    print(ratio_name('AMT_INCOME_TOTAL',i))\n",
    "    df[ratio_name('AMT_INCOME_TOTAL',i)] = ratio(df, 'AMT_INCOME_TOTAL', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:43:44.162418Z",
     "start_time": "2018-06-29T17:43:41.929510Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n",
    "print(docs)\n",
    "df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1) \n",
    "df.drop(docs,axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T17:45:50.246803Z",
     "start_time": "2018-06-29T17:45:45.106645Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorized: in train columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean of exterior sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T18:00:33.163326Z",
     "start_time": "2018-06-29T18:00:33.158738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ext_col = [col for col in df.columns if 'EXT' in col]\n",
    "df['MEAN_EXT'] = df[ext_col].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T18:01:38.364647Z",
     "start_time": "2018-06-29T18:01:37.657239Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
