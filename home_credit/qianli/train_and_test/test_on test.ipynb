{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T20:33:17.470430Z",
     "start_time": "2018-06-21T20:33:12.360145Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "\n",
    "train_ori = pd.read_pickle(PATH+'train_0.pkl')\n",
    "test_ori = pd.read_pickle(PATH+'test_0.pkl')\n",
    "prediction = pd.read_csv(PATH+'inter/06_21_total_1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut for half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T20:33:26.349079Z",
     "start_time": "2018-06-21T20:33:18.347715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "(307511, 1754) (48744, 1753)\n"
     ]
    }
   ],
   "source": [
    "pred = prediction.copy()\n",
    "train_df, test_df = train_ori.copy(), test_ori.copy()\n",
    "print('done')\n",
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T20:33:27.873082Z",
     "start_time": "2018-06-21T20:33:27.868798Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n"
     ]
    }
   ],
   "source": [
    "half = pred[pred['TARGET'] > 0.5]\n",
    "index_half = half.index\n",
    "print(len(half))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T20:33:33.575879Z",
     "start_time": "2018-06-21T20:33:29.302411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48527, 1753) (307728, 1754)\n"
     ]
    }
   ],
   "source": [
    "test_half = test_df.iloc[index_half]\n",
    "test_half['TARGET'] = 1\n",
    "\n",
    "# drop index_half for test_df, add train\n",
    "test_df.drop(index_half, inplace = True)\n",
    "train_df = pd.concat([train_df,test_half])\n",
    "print(test_df.shape,train_df.shape)\n",
    "# test.to_pickle(PATH+ 'inter/621_half_test_0')\n",
    "# train.to_pickle(PATH+ 'inter/621_half_train_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# Cut for small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T20:24:49.183315Z",
     "start_time": "2018-06-21T20:24:49.112928Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-37b5d4502fa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "pred = prediction.copy()\n",
    "train, test = train_ori.copy(), test_ori.copy()\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "small = pred[pred['TARGET']< 0.04]\n",
    "index_small = small.index\n",
    "print(index_small.sum())\n",
    "test_small = test.iloc[index_half]\n",
    "test_small['TARGET'] = 0\n",
    "\n",
    "# drop index_half for test_df, add train\n",
    "test.drop(index_small, inplace = True)\n",
    "train = pd.concat([train,test_small])\n",
    "\n",
    "test.to_pickle(PATH+ 'inter/621_small_test_0')\n",
    "train.to_pickle(PATH+ 'inter/621_small_train_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T20:23:32.554881Z",
     "start_time": "2018-06-21T20:23:16.965Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T20:23:32.558044Z",
     "start_time": "2018-06-21T20:23:17.638Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Forked from excellent kernel : https://www.kaggle.com/jsaguiar/updated-0-792-lb-lightgbm-with-simple-features\n",
    "# From Kaggler : https://www.kaggle.com/jsaguiar\n",
    "# Just added a few features so I thought I had to make release it as well...\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-21T20:33:41.194831Z",
     "start_time": "2018-06-21T20:33:40.694903Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-21T20:33:59.886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.762957\tvalid_1's auc: 0.751565\n",
      "[200]\ttraining's auc: 0.790268\tvalid_1's auc: 0.772249\n",
      "[300]\ttraining's auc: 0.810084\tvalid_1's auc: 0.784228\n",
      "[400]\ttraining's auc: 0.822984\tvalid_1's auc: 0.789521\n",
      "[500]\ttraining's auc: 0.833518\tvalid_1's auc: 0.792822\n",
      "[600]\ttraining's auc: 0.8423\tvalid_1's auc: 0.794643\n",
      "[700]\ttraining's auc: 0.849896\tvalid_1's auc: 0.795923\n",
      "[800]\ttraining's auc: 0.857108\tvalid_1's auc: 0.796716\n",
      "[900]\ttraining's auc: 0.863513\tvalid_1's auc: 0.797245\n",
      "[1000]\ttraining's auc: 0.869462\tvalid_1's auc: 0.797633\n",
      "[1100]\ttraining's auc: 0.87527\tvalid_1's auc: 0.797952\n",
      "[1200]\ttraining's auc: 0.880557\tvalid_1's auc: 0.798356\n",
      "[1300]\ttraining's auc: 0.885666\tvalid_1's auc: 0.798388\n",
      "[1400]\ttraining's auc: 0.890339\tvalid_1's auc: 0.798442\n",
      "[1500]\ttraining's auc: 0.895094\tvalid_1's auc: 0.798525\n",
      "[1600]\ttraining's auc: 0.899653\tvalid_1's auc: 0.798676\n",
      "[1700]\ttraining's auc: 0.90402\tvalid_1's auc: 0.798596\n",
      "Early stopping, best iteration is:\n",
      "[1552]\ttraining's auc: 0.897432\tvalid_1's auc: 0.798735\n",
      "Fold  1 AUC : 0.798718\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.762609\tvalid_1's auc: 0.752281\n",
      "[200]\ttraining's auc: 0.790863\tvalid_1's auc: 0.771831\n",
      "[300]\ttraining's auc: 0.81009\tvalid_1's auc: 0.783265\n",
      "[400]\ttraining's auc: 0.822965\tvalid_1's auc: 0.788814\n",
      "[500]\ttraining's auc: 0.833037\tvalid_1's auc: 0.791627\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "# Cross validation model\n",
    "stratified = False\n",
    "debug = False\n",
    "\n",
    "if stratified:\n",
    "    folds = StratifiedKFold(n_splits= 5, shuffle=True, random_state=1001)\n",
    "else:\n",
    "    folds = KFold(n_splits= 5, shuffle=True, random_state=45)\n",
    "# Create arrays and dataframes to store results\n",
    "oof_preds = np.zeros(train_df.shape[0])\n",
    "sub_preds = np.zeros(test_df.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "    train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "    valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "    # LightGBM parameters found by Bayesian optimization\n",
    "    clf = LGBMClassifier(\n",
    "        nthread=16,\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.02,\n",
    "        num_leaves=34,\n",
    "        colsample_bytree=0.9497036,\n",
    "        subsample=0.8715623,\n",
    "        max_depth=8,\n",
    "        reg_alpha=0.041545473,\n",
    "        reg_lambda=0.0735294,\n",
    "        min_split_gain=0.0222415,\n",
    "        min_child_weight=39.3259775,\n",
    "        silent=-1,\n",
    "        verbose=-1, )\n",
    "\n",
    "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n",
    "        eval_metric= 'auc', verbose= 100, early_stopping_rounds= 200)\n",
    "\n",
    "    oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "#     fold_importance_df = pd.DataFrame()\n",
    "#     fold_importance_df[\"feature\"] = feats\n",
    "# #     fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "#     fold_importance_df[\"fold\"] = n_fold + 1\n",
    "#     feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "    del clf, train_x, train_y, valid_x, valid_y\n",
    "    gc.collect()\n",
    "\n",
    "print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     plt.title('LightGBM Features (avg over folds)')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('lgbm_importances01.png')\n",
    "debug = False    \n",
    "if not debug:\n",
    "    print('a')\n",
    "    test_df['TARGET'] = sub_preds\n",
    "    test_df[['SK_ID_CURR', 'TARGET']].to_csv(PATH+'inter/0621_pred_half_0.csv', index= False)\n",
    "# display_importances(feature_importance_df)\n",
    "\n",
    "df =test_df[['SK_ID_CURR', 'TARGET']] \n",
    "print(len(df[df['TARGET']<0]),len(df[df['TARGET']>1/2]))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_half = pd.concat([test_half,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = test_ori[['SK_ID_CURR']]\n",
    "tmp = tmp.merge(test_half, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
