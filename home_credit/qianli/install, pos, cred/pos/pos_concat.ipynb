{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:02.737194Z",
     "start_time": "2018-07-06T19:08:57.710881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "pos = pd.read_csv(PATH + 'POS_CASH_balance.csv')\n",
    "df  = pd.read_pickle(PATH + 'inter/poscash2curr.pkl')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def minus_name(col1, col2): return col1 + '_minus_' + col2\n",
    "def minus(df, col1, col2): return df[col1] - df[col2]\n",
    "\n",
    "def ratio_name(col1, col2): return col1 + '_divide_' + col2\n",
    "def ratio(df, col1, col2): return df[col1] / (df[col2] + 1)\n",
    "\n",
    "def positive_count(df, gp_col, col):\n",
    "    group = (df[col] > 0).astype('int8')\n",
    "    group = pd.concat([df[gp_col], group], axis=1).groupby(gp_col)[[col]].sum().reset_index().rename(index=str, columns={col: 'positivecount_'+'_'.join(gp_col + [col])})\n",
    "    return group\n",
    "\n",
    "def count(df, gp_col, col):\n",
    "    group = df[[gp_col,col]].groupby(gp_col)[[col]].count().reset_index().rename(index=str, columns={col:'count_'+gp_col})\n",
    "    return group\n",
    "\n",
    "def numerical(df, gp_col, col, agg_fun):\n",
    "    _df = df.groupby(gp_col)[[col]].agg(agg_fun)\n",
    "    \n",
    "    columns = []\n",
    "    for x in _df.columns.levels[0]:\n",
    "        for y in _df.columns.levels[1]:\n",
    "            columns.append('_'.join([x, y]))\n",
    "    _df.columns = columns\n",
    "    return _df.reset_index()\n",
    "\n",
    "def one_hot(df, gp_col, col):\n",
    "    return pd.concat([df[gp_col], pd.get_dummies(df[col], prefix='onehot_' + col)], axis=1).groupby(gp_col).sum().reset_index()\n",
    "\n",
    "def linear(df, gp_col, x_col_name, y_col_name):\n",
    "    r = []\n",
    "    for i, x in df.groupby(gp_col):\n",
    "        lg = LinearRegression()\n",
    "        lg1 = LinearRegression()\n",
    "        \n",
    "        lg.fit(x[[x_col_name]], x[[y_col_name]])\n",
    "        x_max = max(x[x_col_name])\n",
    "        x_min = min(x[x_col_name])\n",
    "        lg1.fit((x[[x_col_name]]-x_max)/(x_max-x_min+1), x[[y_col_name]])\n",
    "        r.append([i, lg.coef_[0][0], lg1.coef_[0][0]])\n",
    "    tmpdf = pd.DataFrame(r, columns=[gp_col, x_col_name+'_lg_'+y_col_name, x_col_name+'_normallg_'+y_col_name])\n",
    "    return tmpdf\n",
    "\n",
    "def feature_in_time_window(df, gp_col, col, func, agg_fun=None, n=None, time_col=None):\n",
    "    tmp = None\n",
    "    _df = df.copy()\n",
    "    if n is not None:\n",
    "        _df = _df[_df[time_col] >= n]\n",
    "    if agg_fun is None:\n",
    "        tmp = func(_df, gp_col, col)\n",
    "    else:\n",
    "        tmp = func(_df, gp_col, col, agg_fun)\n",
    "    columns = [str(abs(n))+'_'+x for x in set(tmp.columns) - set(gp_col)]\n",
    "    tmp.columns = columns\n",
    "    del _df\n",
    "    gc.collect()\n",
    "    return tmp\n",
    "\n",
    "def area_under_curve(df, gp_col, x, y):\n",
    "    gp = df.copy()\n",
    "    gp_max = gp.groupby(gp_col)[[x]].max().reset_index().rename(columns={x:'max'})\n",
    "    gp_min = gp.groupby(gp_col)[[x]].min().reset_index().rename(columns={x:'min'})\n",
    "    gp = gp.merge(gp_max)\n",
    "    gp = gp.merge(gp_min)\n",
    "    gp['normal_x'] = (gp[x]-gp['max']) / (gp['max']-gp['min']+1)\n",
    "    \n",
    "    group = gp.groupby(gp_col)\n",
    "    gp['tmp'] = (group[y].shift(-1)+gp[y]) * (group[x].shift(-1)-gp[x]) / 2\n",
    "    gp['tmp_normal'] = (group[y].shift(-1)+gp[y]) * (group['normal_x'].shift(-1)-gp['normal_x']) / 2\n",
    "    return gp.groupby(gp_col).agg({'tmp':'sum', 'tmp_normal':'sum'}).reset_index().rename(columns={'tmp':x+'_area_'+y, 'tmp_normal':x+'_normalarea_'+y})\n",
    "\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:10.371858Z",
     "start_time": "2018-07-06T19:09:02.739192Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 119)\n"
     ]
    }
   ],
   "source": [
    "#  1. how many records, positive sk_dpd, sk_dpd_def a prev id has---> agg(records, skdpd, sk_dpd_def) of curr id\n",
    "\n",
    "    \n",
    "positive_dpd = positive_count(pos, ['SK_ID_CURR', 'SK_ID_PREV'],'SK_DPD')  \n",
    "positive_def = positive_count(pos, ['SK_ID_CURR', 'SK_ID_PREV'],'SK_DPD_DEF')\n",
    "# How many records a prev id has\n",
    "prev_count = pos[['SK_ID_CURR','SK_ID_PREV','SK_DPD']].groupby(['SK_ID_PREV','SK_ID_CURR'])[['SK_DPD']].count().reset_index().rename(index=str, columns={'SK_DPD':'count_prev'})\n",
    "\n",
    "# group1 = numerical(positive_dpd, 'SK_ID_CURR','positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD', ['sum','max','mean'])\n",
    "# group2 = numerical(positive_def, 'SK_ID_CURR','positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD_DEF', ['sum','max','mean'])\n",
    "group3 = numerical(prev_count, 'SK_ID_CURR','count_prev', ['sum','max','mean'])\n",
    "for group in [group3]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:11.641186Z",
     "start_time": "2018-07-06T19:09:10.373328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 122)\n",
      "(356255, 125)\n"
     ]
    }
   ],
   "source": [
    "# 2. pct of sk_dpd and sk_dpd def in a prev id --> agg into curr\n",
    "pct_count = positive_dpd.merge(prev_count.drop('SK_ID_CURR', axis = 1), on = 'SK_ID_PREV', how = 'left')\n",
    "pct_count = pct_count.merge(positive_def.drop('SK_ID_CURR', axis = 1), on = 'SK_ID_PREV', how = 'left')\n",
    "pct_count = pct_count.rename(index = str, columns = {'positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD': 'dpd','positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD_DEF': 'def'})\n",
    "\n",
    "pct_count[ratio_name('def','count_prev')] = ratio(pct_count,'def','count_prev')\n",
    "pct_count[ratio_name('dpd','count_prev')] = ratio(pct_count,'dpd','count_prev')\n",
    "\n",
    "group1 = numerical(pct_count, 'SK_ID_CURR','dpd_divide_count_prev',['max','sum','mean'])\n",
    "group2 = numerical(pct_count, 'SK_ID_CURR','def_divide_count_prev',['max','sum','mean'])\n",
    "\n",
    "for group in [group1, group2]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:15.787961Z",
     "start_time": "2018-07-06T19:09:11.642782Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count how many UNIQUE prev id per curr id\n",
    "x = pos[['SK_ID_CURR','SK_ID_PREV']].groupby(['SK_ID_CURR'])[['SK_ID_PREV']].nunique().reset_index().\\\n",
    "rename(index = str, columns = {'SK_ID_PREV': 'unique_prev'})\n",
    "df = df.merge(x, how = 'left', on = 'SK_ID_CURR')\n",
    "\n",
    "#  3**.pct of completed/ num of prev id, for each curr id\n",
    "# df[ratio_name('poscash_onehot_NAME_CONTRACT_STATUS_Completed','unique_prev')] = ratio(df, 'poscash_onehot_NAME_CONTRACT_STATUS_Completed','unique_prev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:15.793497Z",
     "start_time": "2018-07-06T19:09:15.789541Z"
    }
   },
   "outputs": [],
   "source": [
    "df[ratio_name('poscash_onehot_NAME_CONTRACT_STATUS_Completed','unique_prev')] = ratio(df, 'poscash_onehot_NAME_CONTRACT_STATUS_Completed','unique_prev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:26.425927Z",
     "start_time": "2018-07-06T19:09:15.795026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift for dpd\n",
      "(356255, 130)\n",
      "(356255, 133)\n",
      "(356255, 134)\n",
      "shift for def\n",
      "(356255, 137)\n",
      "(356255, 140)\n",
      "(356255, 141)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SK_DPD\n",
    "print('shift for dpd')\n",
    "group1 = pos[['SK_ID_CURR','SK_ID_PREV','SK_DPD']].groupby(['SK_ID_CURR','SK_ID_PREV'])[['SK_DPD']].shift(-1)\n",
    "pos['shifted'] = group1\n",
    "# In shift(-1), sk_dpd minus shifted is positive meaning its worsening.\n",
    "pos['diff'] = pos['SK_DPD'] - pos['shifted']\n",
    "tmp = numerical(pos, ['SK_ID_CURR','SK_ID_PREV'],'diff',['max','sum'])\n",
    "# group onto curr\n",
    "group1 = numerical(tmp, 'SK_ID_CURR', 'diff_max',['mean','max','std'])\n",
    "group2 = numerical(tmp, 'SK_ID_CURR', 'diff_sum',['mean','max','std'])\n",
    "\n",
    "for group in [group1, group2]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)\n",
    "    \n",
    "# count how many negative instances\n",
    "dpd_neg = pos.loc[pos['diff'] < 0]\n",
    "\n",
    "x = count(dpd_neg, 'SK_ID_CURR', 'diff')\n",
    "df = df.merge(x, on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "print('shift for def')   \n",
    "# SK_DPD_DEF\n",
    "group1 = pos[['SK_ID_CURR','SK_ID_PREV','SK_DPD_DEF']].groupby(['SK_ID_CURR','SK_ID_PREV'])[['SK_DPD_DEF']].shift(-1)\n",
    "pos['shifted_def'] = group1\n",
    "# In shift(-1), sk_dpd minus shifted is positive meaning its worsening.\n",
    "pos['diff_def'] = pos['SK_DPD'] - pos['shifted_def']\n",
    "tmp = numerical(pos, ['SK_ID_CURR','SK_ID_PREV'],'diff_def',['max','sum'])\n",
    "# group onto curr\n",
    "group1 = numerical(tmp, 'SK_ID_CURR', 'diff_def_max',['mean','max','std'])\n",
    "group2 = numerical(tmp, 'SK_ID_CURR', 'diff_def_sum',['mean','max','std'])\n",
    "for group in [group1, group2]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)\n",
    "\n",
    "    \n",
    "# count how many negative instances\n",
    "def_neg = pos.loc[pos['diff_def'] < 0]\n",
    "x = count(def_neg, 'SK_ID_CURR', 'diff')\n",
    "df = df.merge(x, on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)\n",
    "del x,tmp, group1, group2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:31.827917Z",
     "start_time": "2018-07-06T19:09:26.427363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 146)\n"
     ]
    }
   ],
   "source": [
    "# 6. unique count for count_installment --> agg(sum, mean, min, max, std) for curr id\n",
    "\n",
    "x = pos[['SK_ID_CURR','SK_ID_PREV','CNT_INSTALMENT']].groupby(['SK_ID_CURR','SK_ID_PREV'])[['CNT_INSTALMENT']].nunique().reset_index().\\\n",
    "rename(index = str, columns = {'CNT_INSTALMENT': 'unique_cnt_install'})\n",
    "# agg(unique for curr)\n",
    "df = df.merge(numerical(x, 'SK_ID_CURR','unique_cnt_install',['sum','mean','std','min','max']), on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:35.451296Z",
     "start_time": "2018-07-06T19:09:31.829456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 150)\n"
     ]
    }
   ],
   "source": [
    "# 8. last record for prev id: num of future, and get future installment/count_installment --> curr id\n",
    "x = pos.groupby(['SK_ID_PREV']).first().reset_index()\n",
    "x['possible_future_install'] = x['CNT_INSTALMENT_FUTURE']/x['CNT_INSTALMENT']\n",
    "# Pct of future install/install\n",
    "\n",
    "df = df.merge(numerical(x,'SK_ID_CURR', 'possible_future_install',['max','std','sum']), on = 'SK_ID_CURR', how = 'left')\n",
    "# Last record \n",
    "df = df.merge(numerical(x, 'SK_ID_CURR', 'CNT_INSTALMENT_FUTURE',['max']), on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:35.965965Z",
     "start_time": "2018-07-06T19:09:35.452731Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df.to_pickle(PATH + 'test/pos/concat_pos.pkl')\n",
    "# df.to_pickle(PATH + 'test/pos/poscash2curr_60.pkl')\n",
    "# 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T19:09:35.969303Z",
     "start_time": "2018-07-06T19:09:35.967503Z"
    }
   },
   "outputs": [],
   "source": [
    "# df1 = pd.read_pickle(PATH + 'inter/poscash2curr.pkl')\n",
    "# df2 = pd.read_pickle(PATH + 'test/pos/poscash2curr_24.pkl')\n",
    "# df3 = pd.read_pickle(PATH + 'test/pos/poscash2curr_60.pkl')\n",
    "\n",
    "# df = pd.concat([df1,df2.drop('SK_ID_CURR',axis = 1),df3.drop('SK_ID_CURR', axis = 1)], axis =1)\n",
    "# df.to_pickle(PATH + 'test/pos/ori_36_pos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
