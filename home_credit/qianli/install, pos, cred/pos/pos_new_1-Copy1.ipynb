{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:52.874915Z",
     "start_time": "2018-07-09T14:11:44.540438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos 0.35461494329070115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "\n",
    "train = pd.read_csv(PATH + 'application_train.csv')\n",
    "test = pd.read_csv(PATH + 'application_test.csv')\n",
    "pos = pd.read_csv(PATH + 'POS_CASH_balance.csv')\n",
    "length_pos = pos.shape[0]\n",
    "\n",
    "# intersection\n",
    "month = -18\n",
    "pos = pos[pos['MONTHS_BALANCE']>= month]\n",
    "print('pos', pos.shape[0]/length_pos)\n",
    "\n",
    "\n",
    "df = pd.concat([train[['SK_ID_CURR']], test[['SK_ID_CURR']]], axis = 0)\n",
    "del train, test\n",
    "gc.collect()\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:53.066208Z",
     "start_time": "2018-07-09T14:11:52.876508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def minus_name(col1, col2): return col1 + '_minus_' + col2\n",
    "def minus(df, col1, col2): return df[col1] - df[col2]\n",
    "\n",
    "def ratio_name(col1, col2): return col1 + '_divide_' + col2\n",
    "def ratio(df, col1, col2): return df[col1] / (df[col2])\n",
    "\n",
    "def positive_count(df, gp_col, col):\n",
    "    group = (df[col] > 0).astype('int8')\n",
    "    group = pd.concat([df[gp_col], group], axis=1).groupby(gp_col)[[col]].sum().reset_index().rename(index=str, columns={col: 'positivecount_'+'_'.join(gp_col + [col])})\n",
    "    return group\n",
    "\n",
    "def count(df, gp_col, col):\n",
    "    group = df[[gp_col,col]].groupby(gp_col)[[col]].count().reset_index().rename(index=str, columns={col:'count_'+gp_col})\n",
    "    return group\n",
    "\n",
    "def numerical(df, gp_col, col, agg_fun):\n",
    "    _df = df.groupby(gp_col)[[col]].agg(agg_fun)\n",
    "    \n",
    "    columns = []\n",
    "    for x in _df.columns.levels[0]:\n",
    "        for y in _df.columns.levels[1]:\n",
    "            columns.append('_'.join([x, y]))\n",
    "    _df.columns = columns\n",
    "    return _df.reset_index()\n",
    "\n",
    "def one_hot(df, gp_col, col):\n",
    "    return pd.concat([df[gp_col], pd.get_dummies(df[col], prefix='onehot_' + col)], axis=1).groupby(gp_col).sum().reset_index()\n",
    "\n",
    "def linear(df, gp_col, x_col_name, y_col_name):\n",
    "    r = []\n",
    "    for i, x in df.groupby(gp_col):\n",
    "        lg = LinearRegression()\n",
    "        lg1 = LinearRegression()\n",
    "        \n",
    "        lg.fit(x[[x_col_name]], x[[y_col_name]])\n",
    "        x_max = max(x[x_col_name])\n",
    "        x_min = min(x[x_col_name])\n",
    "        lg1.fit((x[[x_col_name]]-x_max)/(x_max-x_min+1), x[[y_col_name]])\n",
    "        r.append([i, lg.coef_[0][0], lg1.coef_[0][0]])\n",
    "    tmpdf = pd.DataFrame(r, columns=[gp_col, x_col_name+'_lg_'+y_col_name, x_col_name+'_normallg_'+y_col_name])\n",
    "    return tmpdf\n",
    "\n",
    "def feature_in_time_window(df, gp_col, col, func, agg_fun=None, n=None, time_col=None):\n",
    "    tmp = None\n",
    "    _df = df.copy()\n",
    "    if n is not None:\n",
    "        _df = _df[_df[time_col] >= n]\n",
    "    if agg_fun is None:\n",
    "        tmp = func(_df, gp_col, col)\n",
    "    else:\n",
    "        tmp = func(_df, gp_col, col, agg_fun)\n",
    "    columns = [str(abs(n))+'_'+x for x in set(tmp.columns) - set(gp_col)]\n",
    "    tmp.columns = columns\n",
    "    del _df\n",
    "    gc.collect()\n",
    "    return tmp\n",
    "\n",
    "def area_under_curve(df, gp_col, x, y):\n",
    "    gp = df.copy()\n",
    "    gp_max = gp.groupby(gp_col)[[x]].max().reset_index().rename(columns={x:'max'})\n",
    "    gp_min = gp.groupby(gp_col)[[x]].min().reset_index().rename(columns={x:'min'})\n",
    "    gp = gp.merge(gp_max)\n",
    "    gp = gp.merge(gp_min)\n",
    "    gp['normal_x'] = (gp[x]-gp['max']) / (gp['max']-gp['min']+1)\n",
    "    \n",
    "    group = gp.groupby(gp_col)\n",
    "    gp['tmp'] = (group[y].shift(-1)+gp[y]) * (group[x].shift(-1)-gp[x]) / 2\n",
    "    gp['tmp_normal'] = (group[y].shift(-1)+gp[y]) * (group['normal_x'].shift(-1)-gp['normal_x']) / 2\n",
    "    return gp.groupby(gp_col).agg({'tmp':'sum', 'tmp_normal':'sum'}).reset_index().rename(columns={'tmp':x+'_area_'+y, 'tmp_normal':x+'_normalarea_'+y})\n",
    "\n",
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:53.756235Z",
     "start_time": "2018-07-09T14:11:53.067716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Onehot encoding for status & agg onto curr\n",
    "# 1. onehot encoding\n",
    "group = one_hot(pos, 'SK_ID_CURR','NAME_CONTRACT_STATUS')\n",
    "\n",
    "df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "del group\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:55.114404Z",
     "start_time": "2018-07-09T14:11:53.757743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 16)\n",
      "(356255, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. for sk_dpd, and sk_dpd_def, directly do agg of curr:\n",
    "\n",
    "group1 = numerical(pos, 'SK_ID_CURR', 'SK_DPD',['max','mean','std','min','sum']) # ['sum','max']\n",
    "group2 = numerical(pos, 'SK_ID_CURR', 'SK_DPD_DEF',['max','mean','std','min','sum']) # ['sum','max']\n",
    "for group in [group1, group2]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "#2.0 for cnt_install, future_install, do agg of curr:\n",
    "group1 = numerical(pos, 'SK_ID_CURR', 'CNT_INSTALMENT', ['max','mean','std','min','sum']) # ['max','mean','std']\n",
    "group2 = numerical(pos, 'SK_ID_CURR', 'CNT_INSTALMENT_FUTURE',['max','mean','std','min','sum']) # ['max','mean','std']\n",
    "for group in [group1, group2]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)\n",
    "del group1, group2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:55.122845Z",
     "start_time": "2018-07-09T14:11:55.115773Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns\n",
    "df['DPD_SUM'] = df['SK_DPD_sum'] +df['SK_DPD_DEF_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:55.126091Z",
     "start_time": "2018-07-09T14:11:55.124264Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. SK_DPD and SK_DPD_DEF:\n",
    "#     sk_dpd:\n",
    "#         1. how many records, positive sk_dpd, sk_dpd_def a prev id has---> agg(records, skdpd, sk_dpd_def) of curr id\n",
    "#         2. pct of sk_dpd and sk_dpd def in a prev id --> agg into curr\n",
    "#         3**. same for 1: check if prev id is completed in the end ---> (demand & amortized, etc. pct) num of completed, pct of completed into curr id\n",
    "#         4. find the (sum, mean, min, max, std) , agg, for all sk_dpd, sk_dpd_def; --> agg into curr (notice it is different from 1, as 1 is about num of dpd)  some parts curr (CURR AGG)\n",
    "#         5. growth rate: \n",
    "#             1. for sk_dpd increasing, what is the mean, max, min, std for the increase\n",
    "#             2. for sk_dpd decreasing, count how many deceasing are there; what is the mean for the decrease\n",
    "#         6. unique count for count_installment --> agg(sum, mean, min, max, std) for curr id\n",
    "#         7. num of count for count_installment --> agg(mean, min, max, std) for curr id\n",
    "#         8. last record for prev id: num of future, and get future installment/count_installment --> curr id \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:57.577034Z",
     "start_time": "2018-07-09T14:11:55.127280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 23)\n",
      "(356255, 26)\n",
      "(356255, 29)\n"
     ]
    }
   ],
   "source": [
    "#  1. how many records, positive sk_dpd, sk_dpd_def a prev id has---> agg(records, skdpd, sk_dpd_def) of curr id\n",
    "\n",
    "    \n",
    "positive_dpd = positive_count(pos, ['SK_ID_CURR', 'SK_ID_PREV'],'SK_DPD')  \n",
    "positive_def = positive_count(pos, ['SK_ID_CURR', 'SK_ID_PREV'],'SK_DPD_DEF')\n",
    "# How many records a prev id has\n",
    "prev_count = pos[['SK_ID_CURR','SK_ID_PREV','SK_DPD']].groupby(['SK_ID_PREV','SK_ID_CURR'])[['SK_DPD']].count().reset_index().rename(index=str, columns={'SK_DPD':'count_prev'})\n",
    "\n",
    "group1 = numerical(positive_dpd, 'SK_ID_CURR','positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD', ['max','mean','std','min','sum']) #['sum','max','mean']\n",
    "group2 = numerical(positive_def, 'SK_ID_CURR','positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD_DEF', ['max','mean','std','min','sum']) #['sum','max','mean']\n",
    "group3 = numerical(prev_count, 'SK_ID_CURR','count_prev', ['max','mean','std','min','sum']) #['sum','max','mean']\n",
    "for group in [group1, group2, group3]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:57.737513Z",
     "start_time": "2018-07-09T14:11:57.578649Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. pct of sk_dpd and sk_dpd def in a prev id --> agg into curr\n",
    "pct_count = positive_dpd.merge(prev_count.drop('SK_ID_CURR', axis = 1), on = 'SK_ID_PREV', how = 'left')\n",
    "pct_count = pct_count.merge(positive_def.drop('SK_ID_CURR', axis = 1), on = 'SK_ID_PREV', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:57.746464Z",
     "start_time": "2018-07-09T14:11:57.739128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD</th>\n",
       "      <th>count_prev</th>\n",
       "      <th>positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD_DEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1038818</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>1810518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100005</td>\n",
       "      <td>2495675</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>2078043</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100006</td>\n",
       "      <td>2190416</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  SK_ID_PREV  positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD  \\\n",
       "0      100002     1038818                                           0   \n",
       "1      100003     1810518                                           0   \n",
       "2      100005     2495675                                           0   \n",
       "3      100006     2078043                                           0   \n",
       "4      100006     2190416                                           0   \n",
       "\n",
       "   count_prev  positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD_DEF  \n",
       "0          18                                               0  \n",
       "1           1                                               0  \n",
       "2           4                                               0  \n",
       "3           3                                               0  \n",
       "4          10                                               0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:58.168855Z",
     "start_time": "2018-07-09T14:11:57.747874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 32)\n",
      "(356255, 35)\n"
     ]
    }
   ],
   "source": [
    "pct_count = pct_count.rename(index = str, columns = {'positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD': 'dpd','positivecount_SK_ID_CURR_SK_ID_PREV_SK_DPD_DEF': 'def'})\n",
    "\n",
    "pct_count[ratio_name('def','count_prev')] = ratio(pct_count,'def','count_prev')\n",
    "pct_count[ratio_name('dpd','count_prev')] = ratio(pct_count,'dpd','count_prev')\n",
    "\n",
    "group1 = numerical(pct_count, 'SK_ID_CURR','dpd_divide_count_prev',['max','sum','mean','min','std']) # ['max','sum','mean']\n",
    "group2 = numerical(pct_count, 'SK_ID_CURR','def_divide_count_prev',['max','sum','mean','min','std']) # ['max','sum','mean']\n",
    "\n",
    "for group in [group1, group2]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:59.412082Z",
     "start_time": "2018-07-09T14:11:58.170348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count how many UNIQUE prev id per curr id\n",
    "x = pos[['SK_ID_CURR','SK_ID_PREV']].groupby(['SK_ID_CURR'])[['SK_ID_PREV']].nunique().reset_index().\\\n",
    "rename(index = str, columns = {'SK_ID_PREV': 'unique_prev'})\n",
    "df = df.merge(x, how = 'left', on = 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:59.416957Z",
     "start_time": "2018-07-09T14:11:59.413684Z"
    }
   },
   "outputs": [],
   "source": [
    "#  3**.pct of completed/ num of prev id, for each curr id\n",
    "df[ratio_name('onehot_NAME_CONTRACT_STATUS_Completed','unique_prev')] = ratio(df, 'onehot_NAME_CONTRACT_STATUS_Completed','unique_prev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:59.425212Z",
     "start_time": "2018-07-09T14:11:59.418504Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns\n",
    "df[ratio_name('DPD_SUM','count_prev_sum')] = ratio(df, 'DPD_SUM','count_prev_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:11:59.799680Z",
     "start_time": "2018-07-09T14:11:59.426779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 40)\n",
      "(356255, 42)\n",
      "(356255, 44)\n",
      "(356255, 46)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  4. find the (mean,std) , agg, for all sk_dpd, sk_dpd_def; --> agg into curr (notice it is different from 1, as 1 is about num of dpd)  some parts curr (CURR AGG)\n",
    "pos_dpd = pos.loc[pos['SK_DPD']>0]\n",
    "pos_def = pos.loc[pos['SK_DPD_DEF']>0]\n",
    "\n",
    "# pos_dpd onto prev, then onto curr\n",
    "tmp = numerical(pos_dpd, ['SK_ID_CURR','SK_ID_PREV'],'SK_DPD',['mean','std'])\n",
    "group1 = numerical(tmp,'SK_ID_CURR', 'SK_DPD_mean',['mean','std'])\n",
    "group2 = numerical(tmp, 'SK_ID_CURR','SK_DPD_std',['mean','std'])\n",
    "for i in [group1, group2]:\n",
    "    df = df.merge(i, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)\n",
    "    \n",
    "# pos_def onto prev, then onto curr\n",
    "tmp = numerical(pos_def, ['SK_ID_CURR','SK_ID_PREV'],'SK_DPD_DEF',['mean','std'])\n",
    "group1 = numerical(tmp,'SK_ID_CURR', 'SK_DPD_DEF_mean',['mean','std'])\n",
    "group2 = numerical(tmp, 'SK_ID_CURR','SK_DPD_DEF_std',['mean','std'])\n",
    "for i in [group1, group2]:\n",
    "    df = df.merge(i, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)\n",
    "del tmp, group1, group2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:01.963721Z",
     "start_time": "2018-07-09T14:11:59.801095Z"
    }
   },
   "outputs": [],
   "source": [
    "#  5. growth rate: \n",
    "#             1. for sk_dpd increasing, what is the mean, max, min, std for the increase\n",
    "#             2. for sk_dpd decreasing, count how many deceasing are there; what is the mean for the decrease\n",
    "#         6. unique count for count_installment --> agg(sum, mean, min, max, std) for curr id\n",
    "pos = pos.sort_values(['SK_ID_CURR','SK_ID_PREV','MONTHS_BALANCE'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:04.362726Z",
     "start_time": "2018-07-09T14:12:01.965536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift for dpd\n",
      "(356255, 49)\n",
      "(356255, 52)\n",
      "(356255, 53)\n",
      "shift for def\n",
      "(356255, 56)\n",
      "(356255, 59)\n",
      "(356255, 60)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SK_DPD\n",
    "print('shift for dpd')\n",
    "group1 = pos[['SK_ID_CURR','SK_ID_PREV','SK_DPD']].groupby(['SK_ID_CURR','SK_ID_PREV'])[['SK_DPD']].shift(-1)\n",
    "pos['shifted'] = group1\n",
    "# In shift(-1), sk_dpd minus shifted is positive meaning its worsening.\n",
    "pos['diff'] = pos['SK_DPD'] - pos['shifted']\n",
    "tmp = numerical(pos, ['SK_ID_CURR','SK_ID_PREV'],'diff',['max','sum'])\n",
    "# group onto curr\n",
    "group1 = numerical(tmp, 'SK_ID_CURR', 'diff_max',['mean','max','std'])\n",
    "group2 = numerical(tmp, 'SK_ID_CURR', 'diff_sum',['mean','max','std'])\n",
    "\n",
    "for group in [group1, group2]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)\n",
    "    \n",
    "# count how many negative instances\n",
    "dpd_neg = pos.loc[pos['diff'] < 0]\n",
    "\n",
    "x = count(dpd_neg, 'SK_ID_CURR', 'diff')\n",
    "df = df.merge(x, on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "print('shift for def')   \n",
    "# SK_DPD_DEF\n",
    "group1 = pos[['SK_ID_CURR','SK_ID_PREV','SK_DPD_DEF']].groupby(['SK_ID_CURR','SK_ID_PREV'])[['SK_DPD_DEF']].shift(-1)\n",
    "pos['shifted_def'] = group1\n",
    "# In shift(-1), sk_dpd minus shifted is positive meaning its worsening.\n",
    "pos['diff_def'] = pos['SK_DPD'] - pos['shifted_def']\n",
    "tmp = numerical(pos, ['SK_ID_CURR','SK_ID_PREV'],'diff_def',['max','sum'])\n",
    "# group onto curr\n",
    "group1 = numerical(tmp, 'SK_ID_CURR', 'diff_def_max',['mean','max','std'])\n",
    "group2 = numerical(tmp, 'SK_ID_CURR', 'diff_def_sum',['mean','max','std'])\n",
    "for group in [group1, group2]:\n",
    "    df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "    print(df.shape)\n",
    "\n",
    "    \n",
    "# count how many negative instances\n",
    "def_neg = pos.loc[pos['diff_def'] < 0]\n",
    "x = count(def_neg, 'SK_ID_CURR', 'diff')\n",
    "df = df.merge(x, on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)\n",
    "del x,tmp, group1, group2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:05.426372Z",
     "start_time": "2018-07-09T14:12:04.364117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 65)\n"
     ]
    }
   ],
   "source": [
    "# 6. unique count for count_installment --> agg(sum, mean, min, max, std) for curr id\n",
    "\n",
    "x = pos[['SK_ID_CURR','SK_ID_PREV','CNT_INSTALMENT']].groupby(['SK_ID_CURR','SK_ID_PREV'])[['CNT_INSTALMENT']].nunique().reset_index().\\\n",
    "rename(index = str, columns = {'CNT_INSTALMENT': 'unique_cnt_install'})\n",
    "# agg(unique for curr)\n",
    "df = df.merge(numerical(x, 'SK_ID_CURR','unique_cnt_install',['sum','mean','std','min','max']), on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# 7. num of count for count_installment --> agg(mean, min, max, std) for curr id ---> Done through curr agg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:06.454948Z",
     "start_time": "2018-07-09T14:12:05.427970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 69)\n"
     ]
    }
   ],
   "source": [
    "# 8. last record for prev id: num of future, and get future installment/count_installment --> curr id\n",
    "x = pos.groupby(['SK_ID_PREV']).first().reset_index()\n",
    "x['possible_future_install'] = x['CNT_INSTALMENT_FUTURE']/x['CNT_INSTALMENT']\n",
    "# Pct of future install/install\n",
    "\n",
    "df = df.merge(numerical(x,'SK_ID_CURR', 'possible_future_install',['max','std','sum']), on = 'SK_ID_CURR', how = 'left')\n",
    "# Last record \n",
    "df = df.merge(numerical(x, 'SK_ID_CURR', 'CNT_INSTALMENT_FUTURE',['max']), on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:06.986168Z",
     "start_time": "2018-07-09T14:12:06.456477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 72)\n"
     ]
    }
   ],
   "source": [
    "# addition: inspired by Haoyan's version---- revisited _1 07/06\n",
    "# 1. sk_dpd minus sk_dpd_def\n",
    "tmp = minus_name('SK_DPD','SK_DPD_DEF')\n",
    "pos[tmp] = ratio(pos, 'SK_DPD','SK_DPD_DEF')\n",
    "group = numerical(pos,'SK_ID_CURR',tmp,['sum','max'])\n",
    "df = df.merge(group,on='SK_ID_CURR', how = 'left')\n",
    "# 2. positive count for sk dpd, sk def, dpd - def\n",
    "group = positive_count(pos, ['SK_ID_CURR'],tmp)\n",
    "df = df.merge(group, on = 'SK_ID_CURR', how = 'left')\n",
    "print(df.shape)\n",
    "\n",
    "\n",
    "# # some more ratios\n",
    "# numerator = ['SK_DPD', 'SK_DPD_DEF']\n",
    "# denominator = ['MONTHS_BALANCE', 'CNT_INSTALMENT', 'CNT_INSTALMENT_FUTURE']\n",
    "# list_todo = []\n",
    "# for i in numerator:\n",
    "#     for j in denominator:\n",
    "#         list_todo.append(ratio_name(i,j))\n",
    "#         pos[ratio_name(i,j)] = ratio(pos,i,j)\n",
    "\n",
    "# for col in list_todo:\n",
    "#     x = numerical(pos, 'SK_ID_CURR', col, ['max'])\n",
    "#     df = df.merge(x, on = 'SK_ID_CURR', how = 'left')\n",
    "# print(df.shape)\n",
    "\n",
    "# 3. Ratio for onehot encoding\n",
    "one_hot_cols = [col for col in df.columns if 'onehot' in col]\n",
    "for i in one_hot_cols:\n",
    "    df[ratio_name(i, 'count_prev_sum')] = ratio(df, i, 'count_prev_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:07.261949Z",
     "start_time": "2018-07-09T14:12:06.987641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356255, 81)\n"
     ]
    }
   ],
   "source": [
    "# df.to_pickle(PATH +'test/all_pos2curr_3.pkl')\n",
    "# df.to_pickle(PATH +'test/24_pos2curr_3.pkl')\n",
    "# df.to_pickle(PATH +'test/60_pos2curr_3.pkl')\n",
    "# df.to_pickle(PATH +'test/all_pos2curr_4.pkl')\n",
    "# df.to_pickle(PATH +'test/9_pos2curr_4.pkl')\n",
    "df.to_pickle(PATH +'test/18_pos2curr_4.pkl')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:07.265221Z",
     "start_time": "2018-07-09T14:12:07.263386Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_pickle(PATH +'test/new_pos.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:25.948306Z",
     "start_time": "2018-07-09T14:12:25.606055Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle(PATH +'test/all_pos2curr_4.pkl')\n",
    "df2 = pd.read_pickle(PATH +'test/9_pos2curr_4.pkl')\n",
    "df3 = pd.read_pickle(PATH +'test/18_pos2curr_4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T14:12:30.312573Z",
     "start_time": "2018-07-09T14:12:29.091045Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2.drop('SK_ID_CURR',axis = 1),df3.drop('SK_ID_CURR', axis = 1)], axis =1)\n",
    "df.to_pickle(PATH + 'test/new_pos2curr_4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
