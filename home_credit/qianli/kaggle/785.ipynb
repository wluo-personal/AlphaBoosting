{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://www.kaggle.com/shep312/lightgbm-with-weighted-averages-dropout-787/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgbm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\" Load and process inputs \"\"\"\n",
    "input_dir = os.path.join(os.pardir, 'input')\n",
    "print('Input files:\\n{}'.format(os.listdir(input_dir)))\n",
    "print('Loading data sets...')\n",
    "\n",
    "sample_size = None\n",
    "app_train_df = pd.read_csv(os.path.join(input_dir, 'application_train.csv'), nrows=sample_size)\n",
    "app_test_df = pd.read_csv(os.path.join(input_dir, 'application_test.csv'), nrows=sample_size)\n",
    "bureau_df = pd.read_csv(os.path.join(input_dir, 'bureau.csv'), nrows=sample_size)\n",
    "bureau_balance_df = pd.read_csv(os.path.join(input_dir, 'bureau_balance.csv'), nrows=sample_size)\n",
    "credit_card_df = pd.read_csv(os.path.join(input_dir, 'credit_card_balance.csv'), nrows=sample_size)\n",
    "pos_cash_df = pd.read_csv(os.path.join(input_dir, 'POS_CASH_balance.csv'), nrows=sample_size)\n",
    "prev_app_df = pd.read_csv(os.path.join(input_dir, 'previous_application.csv'), nrows=sample_size)\n",
    "install_df = pd.read_csv(os.path.join(input_dir, 'installments_payments.csv'), nrows=sample_size)\n",
    "print('Data loaded.\\nMain application training data set shape = {}'.format(app_train_df.shape))\n",
    "print('Main application test data set shape = {}'.format(app_test_df.shape))\n",
    "print('Positive target proportion = {:.2f}'.format(app_train_df['TARGET'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This kernel provides a simple starter framework for a LightGBM model.\n",
    "\n",
    "There are two supplementary functions designed with room to grow as the kernel develops:\n",
    "    - feature_engineering: Contains the appending of extra features to the main dataset. There are\n",
    "      a lot of datasets to go through in this challenge, so this is very much in progress\n",
    "    - process_dataframe: Takes the engineered dataframe and makes it ready for LightGBM. Currently\n",
    "      is only label encoding thanks to LightGBMs flexbility with nulls and not needing one-hots\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def agg_and_merge(left_df, right_df, agg_method, right_suffix):\n",
    "    \"\"\" Aggregate a df by 'SK_ID_CURR' and merge it onto another.\n",
    "    This method allows feature name \"\"\"\n",
    "    \n",
    "    agg_df = right_df.groupby('SK_ID_CURR').agg(agg_method)\n",
    "    merged_df = left_df.merge(agg_df, left_on='SK_ID_CURR', right_index=True, how='left',\n",
    "                              suffixes=['', '_' + right_suffix + agg_method.upper()])\n",
    "    return merged_df\n",
    "\n",
    "def feature_engineering(app_data, bureau_df, bureau_balance_df, credit_card_df,\n",
    "                        pos_cash_df, prev_app_df, install_df):\n",
    "    \"\"\" \n",
    "    Process the input dataframes into a single one containing all the features. Requires\n",
    "    a lot of aggregating of the supplementary datasets such that they have an entry per\n",
    "    customer.\n",
    "    \n",
    "    Also, add any new features created from the existing ones\n",
    "    \"\"\"\n",
    "    \n",
    "    # # Add new features\n",
    "    \n",
    "    # Amount loaned relative to salary\n",
    "    app_data['LOAN_INCOME_RATIO'] = app_data['AMT_CREDIT'] / app_data['AMT_INCOME_TOTAL']\n",
    "    app_data['ANNUITY_INCOME_RATIO'] = app_data['AMT_ANNUITY'] / app_data['AMT_INCOME_TOTAL']\n",
    "    \n",
    "    # Number of overall payments (I think!)\n",
    "    app_data['ANNUITY LENGTH'] = app_data['AMT_CREDIT'] / app_data['AMT_ANNUITY']\n",
    "    \n",
    "    # Social features\n",
    "    app_data['WORKING_LIFE_RATIO'] = app_data['DAYS_EMPLOYED'] / app_data['DAYS_BIRTH']\n",
    "    app_data['INCOME_PER_FAM'] = app_data['AMT_INCOME_TOTAL'] / app_data['CNT_FAM_MEMBERS']\n",
    "    app_data['CHILDREN_RATIO'] = app_data['CNT_CHILDREN'] / app_data['CNT_FAM_MEMBERS']\n",
    "    \n",
    "    # A lot of the continuous days variables have integers as missing value indicators.\n",
    "    prev_app_df['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev_app_df['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "    prev_app_df['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "    prev_app_df['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev_app_df['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "    \n",
    "    # # Aggregate and merge supplementary datasets\n",
    "\n",
    "    # Previous applications\n",
    "    print('Combined train & test input shape before any merging  = {}'.format(app_data.shape))\n",
    "    agg_funs = {'SK_ID_CURR': 'count', 'AMT_CREDIT': 'sum'}\n",
    "    prev_apps = prev_app_df.groupby('SK_ID_CURR').agg(agg_funs)\n",
    "    prev_apps.columns = ['PREV APP COUNT', 'TOTAL PREV LOAN AMT']\n",
    "    merged_df = app_data.merge(prev_apps, left_on='SK_ID_CURR', right_index=True, how='left')\n",
    "\n",
    "    # Average the rest of the previous app data\n",
    "    for agg_method in ['mean', 'max', 'min']:\n",
    "        merged_df = agg_and_merge(merged_df, prev_app_df, agg_method, 'PRV')\n",
    "    print('Shape after merging with previous apps num data = {}'.format(merged_df.shape))\n",
    "    \n",
    "    # Previous app categorical features\n",
    "    prev_app_df, cat_feats, _ = process_dataframe(prev_app_df)\n",
    "    prev_apps_cat_avg = prev_app_df[cat_feats + ['SK_ID_CURR']].groupby('SK_ID_CURR')\\\n",
    "                             .agg({k: lambda x: str(x.mode().iloc[0]) for k in cat_feats})\n",
    "    merged_df = merged_df.merge(prev_apps_cat_avg, left_on='SK_ID_CURR', right_index=True,\n",
    "                            how='left', suffixes=['', '_BAVG'])\n",
    "    print('Shape after merging with previous apps cat data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Credit card data - numerical features\n",
    "    \n",
    "    wm = lambda x: np.average(x, weights=-1/credit_card_df.loc[x.index, 'MONTHS_BALANCE'])\n",
    "    credit_card_avgs = credit_card_df.groupby('SK_ID_CURR').agg(wm)   \n",
    "    merged_df = merged_df.merge(credit_card_avgs, left_on='SK_ID_CURR', right_index=True,\n",
    "                                how='left', suffixes=['', '_CC_WAVG'])\n",
    "    for agg_method in ['mean', 'max', 'min']:\n",
    "        merged_df = agg_and_merge(merged_df, credit_card_avgs, agg_method, 'CC')\n",
    "    print('Shape after merging with previous apps num data = {}'.format(merged_df.shape))\n",
    "    \n",
    "    # Credit card data - categorical features\n",
    "    most_recent_index = credit_card_df.groupby('SK_ID_CURR')['MONTHS_BALANCE'].idxmax()\n",
    "    cat_feats = credit_card_df.columns[credit_card_df.dtypes == 'object'].tolist()  + ['SK_ID_CURR']\n",
    "    merged_df = merged_df.merge(credit_card_df.loc[most_recent_index, cat_feats], left_on='SK_ID_CURR', right_on='SK_ID_CURR',\n",
    "                       how='left', suffixes=['', '_CCAVG'])\n",
    "    print('Shape after merging with credit card data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Credit bureau data - numerical features\n",
    "    for agg_method in ['mean', 'max', 'min']:\n",
    "        merged_df = agg_and_merge(merged_df, bureau_df, agg_method, 'B')\n",
    "    print('Shape after merging with credit bureau data = {}'.format(merged_df.shape))\n",
    "    \n",
    "    # Bureau balance data\n",
    "    most_recent_index = bureau_balance_df.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'].idxmax()\n",
    "    bureau_balance_df = bureau_balance_df.loc[most_recent_index, :]\n",
    "    merged_df = merged_df.merge(bureau_balance_df, left_on='SK_ID_BUREAU', right_on='SK_ID_BUREAU',\n",
    "                            how='left', suffixes=['', '_B_B'])\n",
    "    print('Shape after merging with bureau balance data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Pos cash data - weight values by recency when averaging\n",
    "    wm = lambda x: np.average(x, weights=-1/pos_cash_df.loc[x.index, 'MONTHS_BALANCE'])\n",
    "    f = {'CNT_INSTALMENT': wm, 'CNT_INSTALMENT_FUTURE': wm, 'SK_DPD': wm, 'SK_DPD_DEF':wm}\n",
    "    cash_avg = pos_cash_df.groupby('SK_ID_CURR')['CNT_INSTALMENT','CNT_INSTALMENT_FUTURE',\n",
    "                                                 'SK_DPD', 'SK_DPD_DEF'].agg(f)\n",
    "    merged_df = merged_df.merge(cash_avg, left_on='SK_ID_CURR', right_index=True,\n",
    "                                how='left', suffixes=['', '_CAVG'])\n",
    "                                \n",
    "    # Unweighted aggregations of numeric features\n",
    "    for agg_method in ['mean', 'max', 'min']:\n",
    "        merged_df = agg_and_merge(merged_df, pos_cash_df, agg_method, 'PC')\n",
    "    \n",
    "    # Pos cash data data - categorical features\n",
    "    most_recent_index = pos_cash_df.groupby('SK_ID_CURR')['MONTHS_BALANCE'].idxmax()\n",
    "    cat_feats = pos_cash_df.columns[pos_cash_df.dtypes == 'object'].tolist()  + ['SK_ID_CURR']\n",
    "    merged_df = merged_df.merge(pos_cash_df.loc[most_recent_index, cat_feats], left_on='SK_ID_CURR', right_on='SK_ID_CURR',\n",
    "                       how='left', suffixes=['', '_CAVG'])\n",
    "    print('Shape after merging with pos cash data = {}'.format(merged_df.shape))\n",
    "\n",
    "    # Installments data\n",
    "    for agg_method in ['mean', 'max', 'min']:\n",
    "        merged_df = agg_and_merge(merged_df, install_df, agg_method, 'I')    \n",
    "    print('Shape after merging with installments data = {}'.format(merged_df.shape))\n",
    "    \n",
    "    # Add more value counts\n",
    "    merged_df = merged_df.merge(pd.DataFrame(bureau_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
    "                                right_index=True, how='left', suffixes=['', '_CNT_BUREAU'])\n",
    "    merged_df = merged_df.merge(pd.DataFrame(credit_card_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
    "                                right_index=True, how='left', suffixes=['', '_CNT_CRED_CARD'])\n",
    "    merged_df = merged_df.merge(pd.DataFrame(pos_cash_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
    "                                right_index=True, how='left', suffixes=['', '_CNT_POS_CASH'])\n",
    "    merged_df = merged_df.merge(pd.DataFrame(install_df['SK_ID_CURR'].value_counts()), left_on='SK_ID_CURR', \n",
    "                                right_index=True, how='left', suffixes=['', '_CNT_INSTALL'])\n",
    "    print('Shape after merging with counts data = {}'.format(merged_df.shape))\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def process_dataframe(input_df, encoder_dict=None):\n",
    "    \"\"\" Process a dataframe into a form useable by LightGBM \"\"\"\n",
    "\n",
    "    # Label encode categoricals\n",
    "    print('Label encoding categorical features...')\n",
    "    categorical_feats = input_df.columns[input_df.dtypes == 'object']\n",
    "    for feat in categorical_feats:\n",
    "        encoder = LabelEncoder()\n",
    "        input_df[feat] = encoder.fit_transform(input_df[feat].fillna('NULL'))\n",
    "    print('Label encoding complete.')\n",
    "\n",
    "    return input_df, categorical_feats.tolist(), encoder_dict\n",
    "\n",
    "# Merge the datasets into a single one for training\n",
    "len_train = len(app_train_df)\n",
    "app_both = pd.concat([app_train_df, app_test_df])\n",
    "merged_df = feature_engineering(app_both, bureau_df, bureau_balance_df, credit_card_df,\n",
    "                                pos_cash_df, prev_app_df, install_df)\n",
    "merged_df.to_csv('processed_input_data.csv', index=False)\n",
    "\n",
    "# Separate metadata\n",
    "meta_cols = ['SK_ID_CURR']\n",
    "meta_df = merged_df[meta_cols]\n",
    "merged_df.drop(columns=meta_cols, inplace=True)\n",
    "\n",
    "# Process the data set.\n",
    "merged_df, categorical_feats, encoder_dict = process_dataframe(input_df=merged_df)\n",
    "\n",
    "# Capture other categorical features not as object data types:\n",
    "non_obj_categoricals = [\n",
    "    'FONDKAPREMONT_MODE', 'HOUR_APPR_PROCESS_START', 'HOUSETYPE_MODE',\n",
    "    'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE',\n",
    "    'NAME_INCOME_TYPE', 'NAME_TYPE_SUITE', 'OCCUPATION_TYPE',\n",
    "    'ORGANIZATION_TYPE', 'STATUS', 'NAME_CONTRACT_STATUS_CAVG',\n",
    "    'WALLSMATERIAL_MODE', 'WEEKDAY_APPR_PROCESS_START', 'NAME_CONTRACT_TYPE_BAVG',\n",
    "    'WEEKDAY_APPR_PROCESS_START_BAVG', 'NAME_CASH_LOAN_PURPOSE', 'NAME_CONTRACT_STATUS', \n",
    "    'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON', 'NAME_TYPE_SUITE_BAVG', \n",
    "    'NAME_CLIENT_TYPE', 'NAME_GOODS_CATEGORY', 'NAME_PORTFOLIO', \n",
    "    'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE', 'NAME_SELLER_INDUSTRY', \n",
    "    'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION', 'NAME_CONTRACT_STATUS_CCAVG' \n",
    "]\n",
    "categorical_feats = categorical_feats + non_obj_categoricals\n",
    "\n",
    "# Re-separate into train and test\n",
    "train_df = merged_df[:len_train]\n",
    "test_df = merged_df[len_train:]\n",
    "del merged_df, app_test_df, bureau_df, bureau_balance_df, credit_card_df, pos_cash_df, prev_app_df\n",
    "gc.collect()\n",
    "\n",
    "\"\"\" Train the model \"\"\"\n",
    "target = train_df.pop('TARGET')\n",
    "test_df.drop(columns='TARGET', inplace=True)\n",
    "lgbm_train = lgbm.Dataset(data=train_df,\n",
    "                          label=target,\n",
    "                          categorical_feature=categorical_feats,\n",
    "                          free_raw_data=False)\n",
    "del app_train_df\n",
    "gc.collect()\n",
    "\n",
    "lgbm_params = {\n",
    "    'boosting': 'dart',\n",
    "    'application': 'binary',\n",
    "    'learning_rate': 0.1,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'feature_fraction': 0.5,\n",
    "    'scale_pos_weight': 2,\n",
    "    'drop_rate': 0.02\n",
    "}\n",
    "\n",
    "cv_results = lgbm.cv(train_set=lgbm_train,\n",
    "                     params=lgbm_params,\n",
    "                     nfold=5,\n",
    "                     num_boost_round=600,\n",
    "                     early_stopping_rounds=50,\n",
    "                     verbose_eval=50,\n",
    "                     metrics=['auc'])\n",
    "\n",
    "optimum_boost_rounds = np.argmax(cv_results['auc-mean'])\n",
    "print('Optimum boost rounds = {}'.format(optimum_boost_rounds))\n",
    "print('Best CV result = {}'.format(np.max(cv_results['auc-mean'])))\n",
    "\n",
    "clf = lgbm.train(train_set=lgbm_train,\n",
    "                 params=lgbm_params,\n",
    "                 num_boost_round=optimum_boost_rounds)\n",
    "\n",
    "\"\"\" Predict on test set and create submission \"\"\"\n",
    "y_pred = clf.predict(test_df)\n",
    "out_df = pd.DataFrame({'SK_ID_CURR': meta_df['SK_ID_CURR'][len_train:], 'TARGET': y_pred})\n",
    "out_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=[11, 7])\n",
    "lgbm.plot_importance(clf, ax=ax, max_num_features=20, importance_type='split')\n",
    "lgbm.plot_importance(clf, ax=ax1, max_num_features=20, importance_type='gain')\n",
    "ax.set_title('Importance by splits')\n",
    "ax1.set_title('Importance by gain')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
