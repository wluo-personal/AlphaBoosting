{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T01:14:17.598935Z",
     "start_time": "2018-07-06T01:14:17.028178Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T01:14:23.632021Z",
     "start_time": "2018-07-06T01:14:17.600719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 329) (48744, 328)\n",
      "(356255, 818)\n",
      "(356255, 200)\n",
      "(356255, 502)\n",
      "(356255, 60)\n",
      "(356255, 554)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_pickle(PATH + 'test/train_ori.pkl')\n",
    "test = pd.read_pickle(PATH + 'test/test_ori.pkl')\n",
    "# train = pd.read_pickle(PATH + 'test/train_w_prev_2.pkl')\n",
    "# test = pd.read_pickle(PATH + 'test/test_w_prev_2.pkl')\n",
    "\n",
    "print(train.shape,test.shape)\n",
    "train.shape, test.shape\n",
    "prev = pd.read_pickle(PATH + 'test/prev2curr_0.pkl')\n",
    "print(prev.shape)\n",
    "# read new pos\n",
    "pos = pd.read_pickle(PATH +'test/new_pos2curr.pkl')\n",
    "# pos = pd.read_pickle(PATH + 'inter/poscash2curr.pkl')\n",
    "print(pos.shape)\n",
    "cred = pd.read_pickle(PATH + 'inter/credit2curr.pkl')\n",
    "print(cred.shape)\n",
    "install = pd.read_pickle(PATH + 'inter/install2curr.pkl')\n",
    "print(install.shape)\n",
    "bureau = pd.read_pickle(PATH + 'inter/bureau2curr.pkl')\n",
    "print(bureau.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T01:15:51.112354Z",
     "start_time": "2018-07-06T01:14:23.634047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 1146) (48744, 1145)\n",
      "(307511, 1345) (48744, 1344)\n",
      "(307511, 1846) (48744, 1845)\n",
      "(307511, 1905) (48744, 1904)\n",
      "(307511, 2458) (48744, 2457)\n"
     ]
    }
   ],
   "source": [
    "files = [prev,pos,cred,install,bureau]\n",
    "# files = [prev,cred,install,bureau]\n",
    "# files = [prev,pos,install,bureau]\n",
    "# files = [pos,cred,install,bureau]\n",
    "for tmp in files:\n",
    "#     cols = [col for col in tmp.columns if 'std' not in col]\n",
    "#     tmp = tmp[cols]\n",
    "#     print(tmp.shape)\n",
    "    train = train.merge(tmp, on='SK_ID_CURR', how='left')\n",
    "    test = test.merge(tmp, on='SK_ID_CURR', how='left')\n",
    "    print(train.shape,test.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T01:15:51.116998Z",
     "start_time": "2018-07-06T01:15:51.114047Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 2458) (48744, 2457)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T01:16:04.364401Z",
     "start_time": "2018-07-06T01:15:51.118407Z"
    }
   },
   "outputs": [],
   "source": [
    "train.to_pickle(PATH +'test/total_train_pos0.pkl')\n",
    "test.to_pickle(PATH +'test/total_test_pos0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T03:01:15.195787Z",
     "start_time": "2018-07-06T03:01:08.691645Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_pickle(PATH+'test/total_train_pos0.pkl')\n",
    "test = pd.read_pickle(PATH+'test/total_test_pos0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T04:40:56.182447Z",
     "start_time": "2018-07-06T03:01:19.196809Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin cv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:390: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's auc: 0.762568 + 0.00417446\n",
      "[200]\tcv_agg's auc: 0.772034 + 0.00338035\n",
      "[300]\tcv_agg's auc: 0.779135 + 0.0030086\n",
      "[400]\tcv_agg's auc: 0.783611 + 0.00289257\n",
      "[500]\tcv_agg's auc: 0.786908 + 0.00265488\n",
      "[600]\tcv_agg's auc: 0.789284 + 0.00245884\n",
      "[700]\tcv_agg's auc: 0.790965 + 0.00233821\n",
      "[800]\tcv_agg's auc: 0.792086 + 0.00228841\n",
      "[900]\tcv_agg's auc: 0.792909 + 0.00223235\n",
      "[1000]\tcv_agg's auc: 0.793504 + 0.00219569\n",
      "[1100]\tcv_agg's auc: 0.793841 + 0.00218204\n",
      "[1200]\tcv_agg's auc: 0.794122 + 0.00221817\n",
      "[1300]\tcv_agg's auc: 0.794365 + 0.00219516\n",
      "[1400]\tcv_agg's auc: 0.79457 + 0.00222761\n",
      "[1500]\tcv_agg's auc: 0.794649 + 0.00221124\n",
      "[1600]\tcv_agg's auc: 0.794704 + 0.00217624\n",
      "[1700]\tcv_agg's auc: 0.794741 + 0.0022072\n",
      "[1800]\tcv_agg's auc: 0.794795 + 0.00211971\n",
      "[1900]\tcv_agg's auc: 0.794872 + 0.0021232\n",
      "[2000]\tcv_agg's auc: 0.794889 + 0.00208991\n",
      "Optimum boost rounds = 1943\n",
      "Best CV result = 0.7948991895451762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 more than half\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "PATH = '/home/kai/data/kaggle/homecredit/'\n",
    "print('begin cv')\n",
    "target = train['TARGET']\n",
    "test_df = test.copy()\n",
    "ignore_cols = ['ORGANIZATION_TYPE', 'TARGET', 'SK_ID_CURR']\n",
    "features = [x for x in train.columns if x not in ignore_cols]\n",
    "train = train[features]\n",
    "test = test[features]\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgbm\n",
    "\n",
    "lgbm_train = lgbm.Dataset(data=train,\n",
    "                          label=target,\n",
    "\n",
    "                          categorical_feature=[],#categorical_feats,\n",
    "                          free_raw_data=False)\n",
    "\n",
    "# lgbm_params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n",
    "#           'learning_rate': 0.01, 'num_leaves': 48, 'num_iteration': 4000, 'verbose': 0 ,\n",
    "#           'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n",
    "#           'min_split_gain':.01, 'min_child_weight':1,'num_threads': 12,'feature_fraction': 0.2,\n",
    "#               'scale_pos_weight':1}\n",
    "lgbm_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.015,\n",
    "    'num_iteration': 4000, #\n",
    "    'num_threads': 24,     #\n",
    "\n",
    "    'num_leaves': int(round(44.368535336628419)),\n",
    "    'feature_fraction': 0.28231763168020257,\n",
    "    'bagging_fraction': 0.94901525271474951,\n",
    "    'max_depth': int(round(8.0430115561596267)),\n",
    "    'lambda_l1': 0.30680079516647751,\n",
    "    'lambda_l2': 0.079128660903201031,\n",
    "    'min_split_gain': 0.034005067457890979,\n",
    "    'min_child_weight':1} #\n",
    "\n",
    "\n",
    "cv_results = lgbm.cv(train_set=lgbm_train,\n",
    "                     params=lgbm_params,\n",
    "                     nfold=5,\n",
    "                     early_stopping_rounds=150,\n",
    "                     verbose_eval=100,\n",
    "                     metrics=['auc'])\n",
    "\n",
    "optimum_boost_rounds = np.argmax(cv_results['auc-mean'])\n",
    "print('Optimum boost rounds = {}'.format(optimum_boost_rounds))\n",
    "print('Best CV result = {}'.format(np.max(cv_results['auc-mean'])))\n",
    "\n",
    "clf = lgbm.train(train_set=lgbm_train,\n",
    "                 params=lgbm_params,\n",
    "                 num_boost_round=optimum_boost_rounds,\n",
    "                verbose_eval=100)\n",
    "\n",
    "\"\"\" Predict on test set and create submission \"\"\"\n",
    "y_pred = clf.predict(test)\n",
    "out_df = pd.DataFrame({'SK_ID_CURR': test_df['SK_ID_CURR'], 'TARGET': y_pred})\n",
    "#     small_len = out_df[out_df['TARGET']< threshold1]\n",
    "#     large_len = out_df[out_df['TARGET']> threshold2]\n",
    "#     print('length of small and large,',len(small_len),len(large_len))\n",
    "print((out_df['TARGET']>0.5).sum(),'more than half')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baye paras/train with modified prev\"\n",
    "----------\n",
    "begin cv\n",
    "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:390: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
    "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
    "/home/kai/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1027: UserWarning: Using categorical_feature in Dataset.\n",
    "  warnings.warn('Using categorical_feature in Dataset.')\n",
    "[100]\tcv_agg's auc: 0.780408 + 0.00290047\n",
    "[200]\tcv_agg's auc: 0.789804 + 0.00263968\n",
    "[300]\tcv_agg's auc: 0.792796 + 0.00252429\n",
    "[400]\tcv_agg's auc: 0.79391 + 0.00252326\n",
    "[500]\tcv_agg's auc: 0.794314 + 0.00242975\n",
    "[600]\tcv_agg's auc: 0.794392 + 0.00237447\n",
    "[700]\tcv_agg's auc: 0.794313 + 0.00234948\n",
    "Optimum boost rounds = 617\n",
    "Best CV result = 0.7944380747322322"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without std bayes para, 7788 (train with prev)\n",
    "with std bayes para, 7789 (train without prev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline bayes para, train only pre+: \n",
    "    [100]\tcv_agg's auc: 0.780408 + 0.00290047\n",
    "[200]\tcv_agg's auc: 0.789804 + 0.00263968\n",
    "[300]\tcv_agg's auc: 0.792796 + 0.00252429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T01:46:08.458435Z",
     "start_time": "2018-07-06T01:14:16.980Z"
    }
   },
   "outputs": [],
   "source": [
    "(out_df['TARGET']>0.5).sum()\n",
    "out_df.to_csv(PATH+'submission/06_29_0.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T01:46:08.459338Z",
     "start_time": "2018-07-06T01:14:16.987Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgbm\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=[15, 7])\n",
    "lgbm.plot_importance(clf, ax=ax, max_num_features=30, importance_type='split')\n",
    "lgbm.plot_importance(clf, ax=ax1, max_num_features=30, importance_type='gain')\n",
    "ax.set_title('Importance by splits')\n",
    "ax1.set_title('Importance by gain')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "x = [x for x in zip(clf.feature_name(), clf.feature_importance('gain'))]\n",
    "x.sort(key=lambda x: x[1], reverse=True)\n",
    "x = [(i, j) for i, j in enumerate(x)]\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T01:46:08.460173Z",
     "start_time": "2018-07-06T01:14:16.994Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "x = [x for x in zip(clf.feature_name(), clf.feature_importance('split'))]\n",
    "x.sort(key=lambda x: x[1], reverse=True)\n",
    "x = [(i, j) for i, j in enumerate(x)]\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
