{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get validation, n downsample indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T13:56:57.092884Z",
     "start_time": "2018-05-24T13:55:17.524475Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def downsampling(positive_idx, negative_idx, ratio):\n",
    "    idx = np.random.choice(negative_idx, int(ratio*len(negative_idx)))\n",
    "    idx = np.concatenate((idx, positive_idx))\n",
    "    return np.sort(idx).astype(int).tolist()\n",
    "\n",
    "\n",
    "PATH1 = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "PATH0 = '/home/kai/data/kaggle/talkingdata/haoyandata/'\n",
    "PATH = '/home/kai/data/kaggle/talkingdata/downsampling/'\n",
    "\n",
    "file = {}\n",
    "train = pd.read_feather(PATH0 + 'train_cleaned.ftr')\n",
    "# train = pd.read_csv(PATH1 + 'train_cleaned.csv', nrows=10000)\n",
    "val_idx = (train['day'] == 9) & (train['hour'] == 13) | (train['hour'] == 17) | (train['hour'] == 21)\n",
    "file['val_idx'] = val_idx[val_idx].index.values.astype(int).tolist()\n",
    "\n",
    "\n",
    "# Downsampling\n",
    "train = train[~val_idx]\n",
    "negative = list(train[train['is_attributed']==0].index.values)\n",
    "positive = list(train[train['is_attributed']==1].index.values)\n",
    "ratio = len(positive)/len(negative)\n",
    "idx_list = []\n",
    "for i in range(5):\n",
    "    idx_list.append(downsampling(positive, negative, ratio))\n",
    "    print(i)\n",
    "file['downsampling'] = idx_list\n",
    "with open(PATH + 'idx_file.json', 'w') as f:\n",
    "    json.dump(file, f)\n",
    "print(ratio)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T14:02:35.770786Z",
     "start_time": "2018-05-24T14:02:35.766699Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00246100785192494\n"
     ]
    }
   ],
   "source": [
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split files into several by validation and down sample indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T15:58:24.847770Z",
     "start_time": "2018-05-24T14:08:15.181898Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making directory\n",
      "down sampling\n",
      "train__nunique_machine_channel.ftr\n",
      "train__unique_ratio_machine_channel.ftr\n",
      "train__range_count_ip_dayhourminute10.ftr\n",
      "train__woe_ip_app_device_os.ftr\n",
      "train__cumcount_ratio_ip_day.ftr\n",
      "train__woe_ip_nextClickLeakDayFlt.ftr\n",
      "train__woe_device_channel_nextClickLeakDayFlt.ftr\n",
      "train__woe_os_channel_nextClickLeakDayFlt.ftr\n",
      "train__woe_app_nextClickLeakDayFlt.ftr\n",
      "train__cumcount_ip_day.ftr\n",
      "train__woe_ip_os.ftr\n",
      "train__woe_ip_os_channel.ftr\n",
      "train__woe_ip_channel_nextClickLeakDayFlt.ftr\n",
      "train__count_ip_device_os_day_hourminute10.ftr\n",
      "train__unique_ratio_day_ip_app.ftr\n",
      "train__range_count_ip_day_hour.ftr\n",
      "train__range_count_ip_day.ftr\n",
      "train__count_ip_app_device_os_day_hour.ftr\n",
      "train__woe_device_nextClickLeakDayFlt.ftr\n",
      "train__woe_ip_device_os.ftr\n",
      "train__unique_ratio_day_ip_os.ftr\n",
      "train__nunique_machine_app.ftr\n",
      "train__woe_ip_channel.ftr\n",
      "train__nunique_day_ip_channel.ftr\n",
      "train__woe_ip_device_nextClickLeakDayFlt.ftr\n",
      "train__count_ip_app_device_channel_day.ftr\n",
      "train__count_ratio_machine_ip.ftr\n",
      "train__woe_app_device_nextClickLeakDayFlt.ftr\n",
      "train__count_ip_app_device_day.ftr\n",
      "train__woe_app_os_nextClickLeakDayFlt.ftr\n",
      "train__count_ip.ftr\n",
      "train__woe_ip_device_channel.ftr\n",
      "train__range_count_ip_channel_dayhourminute.ftr\n",
      "train__filter_time_to_n_next_click_1_day_ip_app_device_os.ftr\n",
      "train__woe_app_channel_nextClickLeakDayFlt.ftr\n",
      "train__variance_ip_device_hour.ftr\n",
      "train__woe_os.ftr\n",
      "train__range_count_app_os_channel_dayhourminute.ftr\n",
      "train__woe_ip_app_nextClickLeakDayFlt.ftr\n",
      "train__woe_app.ftr\n",
      "train__woe_ip_app_os.ftr\n",
      "train__unique_ratio_day_ip_device.ftr\n",
      "train__count_app_day_hourminute.ftr\n",
      "train__woe_ip.ftr\n",
      "train__count_ratio_ip_channel.ftr\n",
      "train__nunique_day_ip_app.ftr\n",
      "train__woe_ip_app_device_channel.ftr\n",
      "train__nunique_day_ip_machine.ftr\n",
      "train__woe_ip_os_nextClickLeakDayFlt.ftr\n",
      "train__cumcount_app_device_os_day.ftr\n",
      "train__woe_device.ftr\n",
      "train__woe_app_device_os.ftr\n",
      "train__woe_app_device_os_channel.ftr\n",
      "train__range_count_ip_device_os_dayhourminute.ftr\n",
      "train__count_app_device_day_hour.ftr\n",
      "train__woe_channel.ftr\n",
      "train__count_app_os_channel_day_hour.ftr\n",
      "train__unique_ratio_day_ip_channel.ftr\n",
      "train__range_count_ip_dayhourminute.ftr\n",
      "train__woe_ip_device_os_channel.ftr\n",
      "train__woe_app_device_channel.ftr\n",
      "train__woe_ip_device.ftr\n",
      "train__count_app_channel.ftr\n",
      "train__woe_ip_app.ftr\n",
      "train__unique_ratio_machine_ip.ftr\n",
      "train__nunique_machine_ip.ftr\n",
      "train__range_count_app_os_channel_dayhourminute10.ftr\n",
      "train__count_device_os_day_hourminute10.ftr\n",
      "train__count_ratio_channel_app.ftr\n",
      "train__woe_ip_app_os_channel.ftr\n",
      "train__unique_ratio_machine_app.ftr\n",
      "train__count_ratio_app_channel.ftr\n",
      "train__filter_time_to_n_next_click_2_day_ip_app_device_os.ftr\n",
      "train__woe_ip_app_channel.ftr\n",
      "train__count_ip_app_os_channel_day.ftr\n",
      "train__woe_device_os_nextClickLeakDayFlt.ftr\n",
      "train__range_count_ip_device_os_dayhourminute10.ftr\n",
      "train__count_ratio_ip_machine.ftr\n",
      "train__unique_ratio_day_ip_machine.ftr\n",
      "train__woe_app_device.ftr\n",
      "train__com1_ip.ftr\n",
      "train__woe_os_nextClickLeakDayFlt.ftr\n",
      "train__woe_app_os.ftr\n",
      "train__com_ip.ftr\n",
      "train__count_ip_os.ftr\n",
      "train__count_ip_day.ftr\n",
      "train__woe_app_os_channel.ftr\n",
      "train__range_count_ip_channel_dayhourminute10.ftr\n",
      "train__nunique_day_ip_device.ftr\n",
      "train__time_to_n_next_click_1_day_ip_app_device_os.ftr\n",
      "train__count_app_device_channel_day_hour.ftr\n",
      "train__cumcount_ip_app_device_os_day_hour.ftr\n",
      "train__count_ip_app_os_channel.ftr\n",
      "train__woe_app_channel.ftr\n",
      "train__woe_ip_app_device.ftr\n",
      "train__nunique_day_ip_os.ftr\n",
      "train__woe_channel_nextClickLeakDayFlt.ftr\n",
      "train__time_to_n_next_click_2_day_ip_app_device_os.ftr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "ORIGINAL_FILE_PATH = '/home/kai/data/kaggle/talkingdata/haoyandata/'\n",
    "DOWNSAMPLING_PATH = '/home/kai/data/kaggle/talkingdata/downsampling/'\n",
    "suffix = 'ftr'\n",
    "with open(DOWNSAMPLING_PATH + 'idx_file.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    val_idx = data['val_idx']\n",
    "    downsampling_idx = data['downsampling']\n",
    "\n",
    "print('making directory')\n",
    "directory = os.path.dirname((DOWNSAMPLING_PATH + 'val/'))\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for i in range(len(downsampling_idx)):\n",
    "    directory = os.path.dirname((DOWNSAMPLING_PATH + str(i) + '/'))\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "print('down sampling')\n",
    "for file in os.listdir(ORIGINAL_FILE_PATH):\n",
    "    if file.split('.')[-1] == suffix and file.split('.')[0].split('__')[0] == 'train':\n",
    "        data = pd.read_feather(ORIGINAL_FILE_PATH + file)\n",
    "        # validation\n",
    "        data.loc[val_idx].reset_index(drop=True).to_feather(DOWNSAMPLING_PATH + 'val/' + file)\n",
    "        # down sampling\n",
    "        for i, x in enumerate(downsampling_idx):\n",
    "            data.loc[x].reset_index(drop=True).to_feather(DOWNSAMPLING_PATH + str(i) + '/' + file)\n",
    "        del data\n",
    "        print(file)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T16:09:40.003832Z",
     "start_time": "2018-05-24T16:08:08.408149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/198 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down sampling\n",
      "train_cleaned.ftr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 198/198 [01:31<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "print('down sampling')\n",
    "for file in tqdm(os.listdir(ORIGINAL_FILE_PATH)):\n",
    "    if file.split('.')[-1] == suffix and file.split('.')[0] == 'train_cleaned':\n",
    "        print(file)\n",
    "        data = pd.read_feather(ORIGINAL_FILE_PATH + file)\n",
    "        # validation\n",
    "        data.loc[val_idx].reset_index(drop=True).to_feather(DOWNSAMPLING_PATH + 'val/' + file)\n",
    "        # down sampling\n",
    "        for i, x in enumerate(downsampling_idx):\n",
    "            data.loc[x].reset_index(drop=True).to_feather(DOWNSAMPLING_PATH + str(i) + '/' + file)\n",
    "        del data\n",
    "        print('done')\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concatenate val, down sampling files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T16:12:26.465562Z",
     "start_time": "2018-05-24T16:10:23.229042Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:21,  4.66it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:20,  4.69it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:00<00:20,  4.72it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:20,  4.75it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:01<00:20,  4.75it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:01<00:19,  4.75it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:01<00:19,  4.75it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:01<00:16,  5.36it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:01<00:17,  5.27it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:02<00:17,  5.23it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:02<00:16,  5.19it/s]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:02<00:16,  5.15it/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:02<00:16,  5.12it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:02<00:16,  5.12it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:03<00:16,  5.11it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:03<00:16,  5.11it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:03<00:16,  5.11it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:03<00:15,  5.09it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:03<00:15,  5.09it/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:04<00:15,  5.09it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:04<00:15,  5.09it/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:04<00:15,  5.09it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:04<00:14,  5.09it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:04<00:14,  5.10it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:05<00:14,  5.10it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:05<00:14,  5.10it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:05<00:14,  4.89it/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:06<00:15,  4.72it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:06<00:15,  4.56it/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:07<00:15,  4.36it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:07<00:16,  4.18it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:08<00:16,  4.08it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:08<00:16,  3.99it/s]\u001b[A\n",
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/kai/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 100/100 [00:59<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kai/data/kaggle/talkingdata/downsampling/val.ftr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n",
      "/home/kai/data/kaggle/talkingdata/downsampling/1.ftr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 43.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kai/data/kaggle/talkingdata/downsampling/2.ftr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 45.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kai/data/kaggle/talkingdata/downsampling/3.ftr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 44.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kai/data/kaggle/talkingdata/downsampling/4.ftr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 45.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting\n",
      "/home/kai/data/kaggle/talkingdata/downsampling/0.ftr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/talkingdata/downsampling/'\n",
    "suffix = 'ftr'\n",
    "dir_list = ['val/', '1/', '2/', '3/', '4/', '0/']\n",
    "for x in dir_list:\n",
    "    CURRENT_PATH = PATH + x\n",
    "    file_name = PATH + x[:-1] + '.' + suffix\n",
    "    df = pd.read_feather(CURRENT_PATH + 'train_cleaned.ftr')\n",
    "    for y in tqdm(os.listdir(CURRENT_PATH)):\n",
    "        splitted_y = y.split('.')\n",
    "        if splitted_y[0] != 'train_cleaned' and splitted_y[1] == suffix:\n",
    "            tmp = pd.read_feather(CURRENT_PATH + y)\n",
    "            df[splitted_y[0].split('__')[1]] = tmp\n",
    "            del tmp\n",
    "    print('converting')\n",
    "    df.to_feather(file_name)\n",
    "    del df\n",
    "    gc.collect()\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test concate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T00:35:35.660038Z",
     "start_time": "2018-05-26T00:35:35.596839Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c2296bf96d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
     ]
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T00:36:50.226675Z",
     "start_time": "2018-05-26T00:35:38.473074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_supplement__woe_ip_device_channel.ftr\n",
      "test_supplement__range_count_ip_device_os_dayhourminute10.ftr\n",
      "test_supplement__woe_device.ftr\n",
      "test_supplement__woe_ip_app_os_channel.ftr\n",
      "test_supplement__woe_app_os_channel.ftr\n",
      "test_supplement__unique_ratio_day_ip_channel.ftr\n",
      "test_supplement__woe_os_channel_nextClickLeakDayFlt.ftr\n",
      "test_supplement__count_ip.ftr\n",
      "test_supplement__count_app_device_channel_day_hour.ftr\n",
      "test_supplement__variance_ip_device_hour.ftr\n",
      "test_supplement__count_ratio_ip_channel.ftr\n",
      "test_supplement__woe_ip_device_os_channel.ftr\n",
      "test_supplement__woe_ip_device_nextClickLeakDayFlt.ftr\n",
      "test_supplement__nunique_day_ip_os.ftr\n",
      "test_supplement__count_app_device_day_hour.ftr\n",
      "test_supplement__woe_ip_app_device_channel.ftr\n",
      "test_supplement__woe_ip_app.ftr\n",
      "test_supplement__woe_app_device_nextClickLeakDayFlt.ftr\n",
      "test_supplement__woe_app_device_channel.ftr\n",
      "test_supplement__range_count_app_os_channel_dayhourminute10.ftr\n",
      "test_supplement__woe_ip_app_channel.ftr\n",
      "test_supplement__range_count_ip_channel_dayhourminute10.ftr\n",
      "test_supplement__woe_ip_app_os.ftr\n",
      "test_supplement__cumcount_ratio_ip_day.ftr\n",
      "test_supplement__count_ip_app_device_os_day_hour.ftr\n",
      "test_supplement__woe_ip_channel.ftr\n",
      "test_supplement__woe_device_channel_nextClickLeakDayFlt.ftr\n",
      "test_supplement__filter_time_to_n_next_click_2_day_ip_app_device_os.ftr\n",
      "test_supplement__range_count_app_os_channel_dayhourminute.ftr\n",
      "test_supplement__count_ip_app_device_channel_day.ftr\n",
      "test_supplement__count_ip_app_device_day.ftr\n",
      "test_supplement__unique_ratio_day_ip_device.ftr\n",
      "test_supplement__cumcount_ip_app_device_os_day_hour.ftr\n",
      "test_supplement__unique_ratio_day_ip_os.ftr\n",
      "test_supplement__count_ip_os.ftr\n",
      "test_supplement__woe_device_os_nextClickLeakDayFlt.ftr\n",
      "test_supplement__nunique_day_ip_app.ftr\n",
      "test_supplement__woe_ip_channel_nextClickLeakDayFlt.ftr\n",
      "test_supplement__range_count_ip_day_hour.ftr\n",
      "test_supplement__count_ip_app_os_channel.ftr\n",
      "test_supplement__woe_ip_os_nextClickLeakDayFlt.ftr\n",
      "test_supplement__filter_time_to_n_next_click_1_day_ip_app_device_os.ftr\n",
      "test_supplement__woe_app_channel_nextClickLeakDayFlt.ftr\n",
      "test_supplement__woe_ip_device_os.ftr\n",
      "test_supplement__range_count_ip_dayhourminute.ftr\n",
      "test_supplement__woe_os_nextClickLeakDayFlt.ftr\n",
      "test_supplement__count_ip_device_os_day_hourminute10.ftr\n",
      "test_supplement__time_to_n_next_click_1_day_ip_app_device_os.ftr\n",
      "test_supplement__woe_channel_nextClickLeakDayFlt.ftr\n",
      "test_supplement__count_ratio_channel_app.ftr\n",
      "test_supplement__woe_app_device_os.ftr\n",
      "test_supplement__count_ip_app_os_channel_day.ftr\n",
      "test_supplement__range_count_ip_device_os_dayhourminute.ftr\n",
      "test_supplement__woe_ip_device.ftr\n",
      "test_supplement__count_ratio_app_channel.ftr\n",
      "test_supplement__woe_app.ftr\n",
      "test_supplement__time_to_n_next_click_2_day_ip_app_device_os.ftr\n",
      "test_supplement__count_app_day_hourminute.ftr\n",
      "test_supplement__woe_channel.ftr\n",
      "test_supplement__count_ip_day.ftr\n",
      "test_supplement__cumcount_ip_day.ftr\n",
      "test_supplement__unique_ratio_machine_app.ftr\n",
      "test_supplement__unique_ratio_day_ip_app.ftr\n",
      "test_supplement__nunique_machine_app.ftr\n",
      "test_supplement__nunique_machine_ip.ftr\n",
      "test_supplement__woe_ip_os.ftr\n",
      "test_supplement__woe_ip_os_channel.ftr\n",
      "test_supplement__unique_ratio_machine_ip.ftr\n",
      "test_supplement__woe_ip_app_nextClickLeakDayFlt.ftr\n",
      "test_supplement__woe_ip.ftr\n",
      "test_supplement__count_ratio_ip_machine.ftr\n",
      "test_supplement__nunique_day_ip_machine.ftr\n",
      "test_supplement__range_count_ip_day.ftr\n",
      "test_supplement__range_count_ip_channel_dayhourminute.ftr\n",
      "test_supplement__count_app_os_channel_day_hour.ftr\n",
      "test_supplement__woe_app_device_os_channel.ftr\n",
      "test_supplement__woe_app_nextClickLeakDayFlt.ftr\n",
      "test_supplement__woe_app_device.ftr\n",
      "test_supplement__nunique_day_ip_device.ftr\n",
      "test_supplement__com1_ip.ftr\n",
      "test_supplement__unique_ratio_day_ip_machine.ftr\n",
      "test_supplement__com_ip.ftr\n",
      "test_supplement__woe_app_os.ftr\n",
      "test_supplement__woe_ip_app_device.ftr\n",
      "test_supplement__woe_device_nextClickLeakDayFlt.ftr\n",
      "test_supplement__woe_ip_nextClickLeakDayFlt.ftr\n",
      "test_supplement__unique_ratio_machine_channel.ftr\n",
      "test_supplement__count_app_channel.ftr\n",
      "test_supplement__count_device_os_day_hourminute10.ftr\n",
      "test_supplement__woe_app_os_nextClickLeakDayFlt.ftr\n",
      "test_supplement__woe_app_channel.ftr\n",
      "test_supplement__range_count_ip_dayhourminute10.ftr\n",
      "test_supplement__cumcount_app_device_os_day.ftr\n",
      "test_supplement__nunique_day_ip_channel.ftr\n",
      "test_supplement__woe_os.ftr\n",
      "test_supplement__count_ratio_machine_ip.ftr\n",
      "test_supplement__nunique_machine_channel.ftr\n",
      "test_supplement__woe_ip_app_device_os.ftr\n",
      "converting\n",
      "/home/kai/data/kaggle/talkingdata/4thplace/test_cleaned.ftr\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "PATH = '/home/kai/data/kaggle/talkingdata/haoyandata/'\n",
    "file_name = '/home/kai/data/kaggle/talkingdata/4thplace/test_cleaned.ftr'\n",
    "df = pd.read_feather(PATH + 'test_cleaned.ftr')\n",
    "for x in os.listdir(PATH):\n",
    "    splitted = x.split('__')\n",
    "    if splitted[0] == 'test_supplement':\n",
    "        print(x)\n",
    "        tmp = pd.read_feather(PATH + x)\n",
    "        df[splitted[1].split('.')[0]] = tmp\n",
    "        del tmp\n",
    "        gc.collect()\n",
    "print('converting')\n",
    "df.to_feather(file_name)\n",
    "del df\n",
    "gc.collect()\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat val train without down sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-26T00:49:22.190812Z",
     "start_time": "2018-05-26T00:36:50.237463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "start\n",
      "train__woe_ip_app_channel.ftr woe_ip_app_channel\n",
      "train__woe_ip_device_nextClickLeakDayFlt.ftr woe_ip_device_nextClickLeakDayFlt\n",
      "train__nunique_machine_app.ftr nunique_machine_app\n",
      "train__woe_os_channel_nextClickLeakDayFlt.ftr woe_os_channel_nextClickLeakDayFlt\n",
      "train__variance_ip_device_hour.ftr variance_ip_device_hour\n",
      "train__range_count_ip_device_os_dayhourminute10.ftr range_count_ip_device_os_dayhourminute10\n",
      "train__woe_app_device_os_channel.ftr woe_app_device_os_channel\n",
      "train__woe_channel.ftr woe_channel\n",
      "train__count_ip_app_os_channel.ftr count_ip_app_os_channel\n",
      "train__nunique_day_ip_os.ftr nunique_day_ip_os\n",
      "train__count_app_channel.ftr count_app_channel\n",
      "train__woe_app_nextClickLeakDayFlt.ftr woe_app_nextClickLeakDayFlt\n",
      "train__woe_ip_channel.ftr woe_ip_channel\n",
      "train__unique_ratio_day_ip_machine.ftr unique_ratio_day_ip_machine\n",
      "train__nunique_machine_channel.ftr nunique_machine_channel\n",
      "train__time_to_n_next_click_1_day_ip_app_device_os.ftr time_to_n_next_click_1_day_ip_app_device_os\n",
      "train__woe_os.ftr woe_os\n",
      "train__woe_ip_device_os_channel.ftr woe_ip_device_os_channel\n",
      "train__count_ip_app_device_day.ftr count_ip_app_device_day\n",
      "train__com1_ip.ftr com1_ip\n",
      "train__unique_ratio_machine_ip.ftr unique_ratio_machine_ip\n",
      "train__count_ratio_ip_machine.ftr count_ratio_ip_machine\n",
      "train__count_ip_app_device_os_day_hour.ftr count_ip_app_device_os_day_hour\n",
      "train__count_app_device_day_hour.ftr count_app_device_day_hour\n",
      "train__woe_app_device_os.ftr woe_app_device_os\n",
      "train__woe_ip_app_os_channel.ftr woe_ip_app_os_channel\n",
      "train__range_count_app_os_channel_dayhourminute10.ftr range_count_app_os_channel_dayhourminute10\n",
      "train__woe_app_os_channel.ftr woe_app_os_channel\n",
      "train__unique_ratio_machine_app.ftr unique_ratio_machine_app\n",
      "train__unique_ratio_day_ip_channel.ftr unique_ratio_day_ip_channel\n",
      "train__woe_ip.ftr woe_ip\n",
      "train__filter_time_to_n_next_click_1_day_ip_app_device_os.ftr filter_time_to_n_next_click_1_day_ip_app_device_os\n",
      "train__cumcount_ip_day.ftr cumcount_ip_day\n",
      "train__nunique_day_ip_channel.ftr nunique_day_ip_channel\n",
      "train__woe_ip_channel_nextClickLeakDayFlt.ftr woe_ip_channel_nextClickLeakDayFlt\n",
      "train__woe_ip_device.ftr woe_ip_device\n",
      "train__range_count_ip_channel_dayhourminute10.ftr range_count_ip_channel_dayhourminute10\n",
      "train__cumcount_app_device_os_day.ftr cumcount_app_device_os_day\n",
      "train__count_ip_day.ftr count_ip_day\n",
      "train__count_ratio_app_channel.ftr count_ratio_app_channel\n",
      "train__woe_ip_app_nextClickLeakDayFlt.ftr woe_ip_app_nextClickLeakDayFlt\n",
      "train__count_app_day_hourminute.ftr count_app_day_hourminute\n",
      "train__count_ratio_channel_app.ftr count_ratio_channel_app\n",
      "train__nunique_day_ip_device.ftr nunique_day_ip_device\n",
      "train__range_count_app_os_channel_dayhourminute.ftr range_count_app_os_channel_dayhourminute\n",
      "train__range_count_ip_device_os_dayhourminute.ftr range_count_ip_device_os_dayhourminute\n",
      "train__woe_device_channel_nextClickLeakDayFlt.ftr woe_device_channel_nextClickLeakDayFlt\n",
      "train__woe_ip_device_channel.ftr woe_ip_device_channel\n",
      "train__woe_ip_app_device_os.ftr woe_ip_app_device_os\n",
      "train__count_ratio_ip_channel.ftr count_ratio_ip_channel\n",
      "train__woe_app_device.ftr woe_app_device\n",
      "train__count_ip.ftr count_ip\n",
      "train__woe_device_os_nextClickLeakDayFlt.ftr woe_device_os_nextClickLeakDayFlt\n",
      "train__nunique_machine_ip.ftr nunique_machine_ip\n",
      "train__count_app_os_channel_day_hour.ftr count_app_os_channel_day_hour\n",
      "train__woe_channel_nextClickLeakDayFlt.ftr woe_channel_nextClickLeakDayFlt\n",
      "train__count_ip_os.ftr count_ip_os\n",
      "train__time_to_n_next_click_2_day_ip_app_device_os.ftr time_to_n_next_click_2_day_ip_app_device_os\n",
      "train__woe_ip_app_os.ftr woe_ip_app_os\n",
      "train__nunique_day_ip_app.ftr nunique_day_ip_app\n",
      "train__woe_app_os.ftr woe_app_os\n",
      "train__woe_ip_app_device.ftr woe_ip_app_device\n",
      "train__cumcount_ip_app_device_os_day_hour.ftr cumcount_ip_app_device_os_day_hour\n",
      "train__range_count_ip_day.ftr range_count_ip_day\n",
      "train__range_count_ip_channel_dayhourminute.ftr range_count_ip_channel_dayhourminute\n",
      "train__woe_ip_app_device_channel.ftr woe_ip_app_device_channel\n",
      "train__unique_ratio_day_ip_os.ftr unique_ratio_day_ip_os\n",
      "train__range_count_ip_dayhourminute10.ftr range_count_ip_dayhourminute10\n",
      "train__woe_ip_nextClickLeakDayFlt.ftr woe_ip_nextClickLeakDayFlt\n",
      "train__woe_device.ftr woe_device\n",
      "train__woe_app_device_nextClickLeakDayFlt.ftr woe_app_device_nextClickLeakDayFlt\n",
      "train__unique_ratio_day_ip_device.ftr unique_ratio_day_ip_device\n",
      "train__count_ip_app_os_channel_day.ftr count_ip_app_os_channel_day\n",
      "train__count_ip_device_os_day_hourminute10.ftr count_ip_device_os_day_hourminute10\n",
      "train__woe_app_channel_nextClickLeakDayFlt.ftr woe_app_channel_nextClickLeakDayFlt\n",
      "train__woe_ip_os.ftr woe_ip_os\n",
      "train__com_ip.ftr com_ip\n",
      "train__nunique_day_ip_machine.ftr nunique_day_ip_machine\n",
      "train__unique_ratio_machine_channel.ftr unique_ratio_machine_channel\n",
      "train__woe_app_os_nextClickLeakDayFlt.ftr woe_app_os_nextClickLeakDayFlt\n",
      "train__woe_ip_os_channel.ftr woe_ip_os_channel\n",
      "train__woe_ip_app.ftr woe_ip_app\n",
      "train__count_device_os_day_hourminute10.ftr count_device_os_day_hourminute10\n",
      "train__filter_time_to_n_next_click_2_day_ip_app_device_os.ftr filter_time_to_n_next_click_2_day_ip_app_device_os\n",
      "train__woe_app.ftr woe_app\n",
      "train__count_app_device_channel_day_hour.ftr count_app_device_channel_day_hour\n",
      "train__woe_ip_os_nextClickLeakDayFlt.ftr woe_ip_os_nextClickLeakDayFlt\n",
      "train__woe_os_nextClickLeakDayFlt.ftr woe_os_nextClickLeakDayFlt\n",
      "train__range_count_ip_dayhourminute.ftr range_count_ip_dayhourminute\n",
      "train__count_ratio_machine_ip.ftr count_ratio_machine_ip\n",
      "train__range_count_ip_day_hour.ftr range_count_ip_day_hour\n",
      "train__woe_app_device_channel.ftr woe_app_device_channel\n",
      "train__woe_ip_device_os.ftr woe_ip_device_os\n",
      "train__unique_ratio_day_ip_app.ftr unique_ratio_day_ip_app\n",
      "train__woe_device_nextClickLeakDayFlt.ftr woe_device_nextClickLeakDayFlt\n",
      "train__count_ip_app_device_channel_day.ftr count_ip_app_device_channel_day\n",
      "train__woe_app_channel.ftr woe_app_channel\n",
      "train__cumcount_ratio_ip_day.ftr cumcount_ratio_ip_day\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "PATH = '/home/kai/data/kaggle/talkingdata/haoyandata/'\n",
    "\n",
    "train = pd.read_feather(PATH + 'train_cleaned.ftr')\n",
    "val_idx = (train['day'] == 9) & (train['hour'] == 13) | (train['hour'] == 17) | (train['hour'] == 21)\n",
    "idx = ~val_idx\n",
    "val = train[val_idx]\n",
    "train = train[idx]\n",
    "print(gc.collect())\n",
    "\n",
    "print('start')\n",
    "for x in os.listdir(PATH):\n",
    "    tmp = x.split('.')\n",
    "    if tmp[-1] == 'ftr':\n",
    "        ttmp = tmp[0].split('__')\n",
    "        if ttmp[0] == 'train':\n",
    "            f = pd.read_feather(PATH + x)\n",
    "            val[ttmp[1]] = f[val_idx]\n",
    "            train[ttmp[1]] = f[idx]\n",
    "            del f\n",
    "            gc.collect()\n",
    "            print(x, ttmp[1])\n",
    "val.reset_index(drop=True).to_feather('/home/kai/data/kaggle/talkingdata/4thplace/val_cleaned.ftr')\n",
    "train.reset_index(drop=True).to_feather('/home/kai/data/kaggle/talkingdata/4thplace/train_cleaned.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
