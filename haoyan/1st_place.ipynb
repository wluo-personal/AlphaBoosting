{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T12:01:52.101358Z",
     "start_time": "2018-06-03T12:01:17.622648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "train\n",
      "test\n",
      "   app  channel  click_id                click_time  click_timestamp  day  \\\n",
      "0    3      379         0 2017-11-06 22:32:21+08:00       1509978741    6   \n",
      "\n",
      "   dayhourminute  dayhourminute10  device  hour  hourminute  hourminute10  \\\n",
      "0           9992             9990       1    22        1352          1350   \n",
      "\n",
      "   index     ip  is_attributed  is_test  machine  minute  minute10  os  \n",
      "0      0  83230              0        0     1013      32        30  13  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "PATH = '/home/kai/data/kaggle/talkingdata/haoyandata/'\n",
    "print('start')\n",
    "train = pd.read_feather(PATH + 'train_cleaned.ftr')\n",
    "print('train')\n",
    "test = pd.read_feather(PATH + 'test_cleaned.ftr')\n",
    "print('test')\n",
    "# PATH = '/home/kai/data/kaggle/talkingdata/data/'\n",
    "# train = pd.read_csv(PATH + 'train_cleaned_final.csv', nrows=10)\n",
    "# test = pd.read_csv(PATH + 'test_supplement_cleaned_final.csv', nrows=30)\n",
    "df = pd.concat([train, test])\n",
    "train_len = train.shape[0]\n",
    "cols = ['ip','device','app','os','channel']\n",
    "fdir = '/home/kai/data/kaggle/talkingdata/haoyandata_1st/'\n",
    "\n",
    "print(df.head(1))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T12:01:52.414561Z",
     "start_time": "2018-06-03T12:01:52.411316Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(df, col_name, train_len):\n",
    "    df.reset_index(drop=True)\n",
    "    df[ : train_len].to_feather(fdir + 'train__' + col_name + '.ftr')\n",
    "    df[train_len : ].reset_index(drop=True).to_feather(fdir + 'test_supplement__' + col_name + '.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nmf lsa lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-03T12:01:32.925Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def MatrixFM(df, key_col_series, value_col_series, n_components, n_jobs = 16):\n",
    "    \n",
    "    # first construct sentence and tranlate using countvectorizer\n",
    "    \n",
    "    dictionary = {}\n",
    "    for i in tqdm(range(key_col_series.shape[0])):\n",
    "        dictionary.setdefault(key_col_series.iloc[i], []).append(str(value_col_series.iloc[i]))\n",
    "\n",
    "    key_list = list(dictionary.keys()) \n",
    "    pos_dict = {key_list[i]:i for i in range(len(key_list))}\n",
    "    sentences = [' '.join(dictionary[key]) for key in key_list]\n",
    "    # now get CountVectorize Matrix\n",
    "    \n",
    "    cvt = CountVectorizer(token_pattern='\\\\b\\\\w+\\\\b')\n",
    "    matrix = cvt.fit_transform(sentences)\n",
    "    \n",
    "    # LDA part\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_components=n_components, n_jobs=n_jobs)\n",
    "    lda_matrix = lda.fit_transform(matrix)\n",
    "    \n",
    "    # LSA part\n",
    "    \n",
    "    lsa = TruncatedSVD(n_components=n_components)\n",
    "    lsa_matrix = lsa.fit_transform(matrix)\n",
    "    \n",
    "    # NMF part\n",
    "    \n",
    "    nmf = NMF(n_components=n_components)\n",
    "    nmf_matrix = nmf.fit_transform(matrix)\n",
    "    \n",
    "    # now store all matrix into feather\n",
    "    \n",
    "    col = []\n",
    "    \n",
    "    for i in ['LDA', 'LSA', 'NMF']:\n",
    "        for j in range(n_components):\n",
    "            col.append(i + str(j + 1))\n",
    "            \n",
    "    result = np.concatenate((lda_matrix, lsa_matrix, nmf_matrix), axis=1)\n",
    "    result = pd.DataFrame(result, columns=col)\n",
    "    \n",
    "    r = df[x].apply(lambda z: result.iloc[pos_dict[z]])\n",
    "    return r\n",
    "    \n",
    "for x in cols:\n",
    "    for y in cols:\n",
    "        if x != y:\n",
    "            result = MatrixFM(df, df[x], df[y], 5).reset_index(drop=True)\n",
    "            file_name = 'MatrixFM_' + x + '_' + y\n",
    "            save(result, file_name, train_len)\n",
    "            del result\n",
    "            gc.collect()\n",
    "            print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# click count in next n hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T12:01:58.467295Z",
     "start_time": "2018-06-03T12:01:52.721684Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = {}\n",
    "feature_col = ['ip', \n",
    "              'app', \n",
    "              'device', \n",
    "              'os', \n",
    "              'channel',\n",
    "              'day',\n",
    "              'hour',]\n",
    "\n",
    "for col in feature_col:\n",
    "    orders[col] = 10 ** (int(np.log(train[col].max() + 1) / np.log(10)) + 1)\n",
    "def get_group(df, cols):\n",
    "    \"\"\"\n",
    "    define an encoding method which can ganrantee the adding value will be unique.\n",
    "    eg: artist_name_composer will be a combination of (artist_name,composer) and the encoding will reflect the unqiue combination of those two\n",
    "    \"\"\"\n",
    "    group = df[cols[0]].copy()\n",
    "    for col in cols[1:]:\n",
    "        group = group * orders[col] + df[col]\n",
    "        \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-03T12:01:24.942Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/242441395 [00:00<?, ?it/s]/home/kai/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  1%|          | 1682247/242441395 [00:03<07:25, 540800.07it/s]"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _click_count_in_next_n_hour(df, cols, n_hour, time_col):\n",
    "    # dataframe should maintain a descending order\n",
    "    rev_train = df.sort_index(ascending=False)\n",
    "    encodings = get_group(rev_train, cols).values\n",
    "    times = rev_train[time_col].values\n",
    "    \n",
    "    dict_count = defaultdict(int)\n",
    "    result = []\n",
    "    bound = 0\n",
    "    for cur in tqdm(range(len(encodings))):\n",
    "\n",
    "        while times[bound] - times[cur] > n_hour:\n",
    "            dict_count[encodings[bound]] -= 1\n",
    "            bound += 1\n",
    "        encoding = encodings[cur]\n",
    "        result.append(dict_count[encoding])\n",
    "        dict_count[encoding] += 1\n",
    "    \n",
    "    r = pd.DataFrame(result[::-1], columns=['click_count_in_next_n_hour_'+'_'.join(cols)+'_'+str(n_hour)])\n",
    "    return r\n",
    "        \n",
    "def _click_count_in_previous_n_hour(df, cols, n_hour, time_col):\n",
    "    # dataframe should maintain an ascending order\n",
    "    encodings = get_group(df, cols).values\n",
    "    times = df[time_col].values\n",
    "    \n",
    "    dict_count = defaultdict(int)\n",
    "    result = []\n",
    "    bound = 0\n",
    "    for cur in tqdm(range(len(encodings))):\n",
    "\n",
    "        while times[cur] - times[bound] > n_hour:\n",
    "            dict_count[encodings[bound]] -= 1\n",
    "            bound += 1\n",
    "        encoding = encodings[cur]\n",
    "        result.append(dict_count[encoding])\n",
    "        dict_count[encoding] += 1\n",
    "    r = pd.DataFrame(result, columns=['click_count_in_previous_n_hour_'+'_'.join(cols)+'_'+str(n_hour)])\n",
    "    return r\n",
    "\n",
    "from itertools import combinations\n",
    "all_cols = []\n",
    "for i in range(1, len(cols)+1):\n",
    "    tmp = combinations(cols, i)\n",
    "    tmp = [list(x) for x in tmp]\n",
    "    all_cols.extend(tmp)\n",
    "for x in all_cols:\n",
    "    tmp = _click_count_in_previous_n_hour(df, x, 1, 'hour')\n",
    "    file_name = 'click_count_in_previous_n_hour_'+'_'.join(x)+'_1'\n",
    "    save(tmp, file_name, train_len)\n",
    "    tmp = _click_count_in_next_n_hour(df, x, 1, 'hour')\n",
    "    file_name = 'click_count_in_next_n_hour_'+'_'.join(x)+'_1'\n",
    "    save(tmp, file_name, train_len)\n",
    "    \n",
    "    tmp = _click_count_in_previous_n_hour(df, x, 6, 'hour')\n",
    "    file_name = 'click_count_in_previous_n_hour_'+'_'.join(x)+'_6'\n",
    "    save(tmp, file_name, train_len)\n",
    "    tmp = _click_count_in_next_n_hour(df, x, 6, 'hour')\n",
    "    file_name = 'click_count_in_next_n_hour_'+'_'.join(x)+'_6'\n",
    "    save(tmp, file_name, train_len)\n",
    "    del tmp\n",
    "    gc.collect()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
